{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of DensRay_BERT-base_Glue.ipynb","provenance":[{"file_id":"1yJM30S1-b-Ih_A5Km4mjTUGhvH2SI30O","timestamp":1589952385400}],"toc_visible":true,"machine_shape":"hm","mount_file_id":"1204q6rM37uAwt10TVp1ycBY6ZmgkYTcs","authorship_tag":"ABX9TyM8TTAbdmkEub7Aa8sVHPZS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"7-nB8AzZgm0n","colab_type":"code","outputId":"70983ad1-c6de-48b5-9cce-d5242325a612","executionInfo":{"status":"ok","timestamp":1589952414542,"user_tz":-120,"elapsed":1909,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":212}},"source":["!wget https://raw.githubusercontent.com/huggingface/transformers/v2.8.0/examples/run_glue.py"],"execution_count":1,"outputs":[{"output_type":"stream","text":["--2020-05-20 05:26:52--  https://raw.githubusercontent.com/huggingface/transformers/v2.8.0/examples/run_glue.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 29117 (28K) [text/plain]\n","Saving to: ‘run_glue.py’\n","\n","\rrun_glue.py           0%[                    ]       0  --.-KB/s               \rrun_glue.py         100%[===================>]  28.43K  --.-KB/s    in 0.01s   \n","\n","2020-05-20 05:26:52 (2.32 MB/s) - ‘run_glue.py’ saved [29117/29117]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_HddjZNSyL95","colab_type":"code","outputId":"a672c037-c1d8-4ab1-c33f-9848055e1021","executionInfo":{"status":"ok","timestamp":1589953154391,"user_tz":-120,"elapsed":57665,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":641}},"source":["!wget https://gist.githubusercontent.com/W4ngatang/60c2bdb54d156a41194446737ce03e2e/raw/17b8dd0d724281ed7c3b2aeeda662b92809aadd5/download_glue_data.py\n","!python download_glue_data.py"],"execution_count":2,"outputs":[{"output_type":"stream","text":["--2020-05-20 05:38:16--  https://gist.githubusercontent.com/W4ngatang/60c2bdb54d156a41194446737ce03e2e/raw/17b8dd0d724281ed7c3b2aeeda662b92809aadd5/download_glue_data.py\n","Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 8225 (8.0K) [text/plain]\n","Saving to: ‘download_glue_data.py’\n","\n","\rdownload_glue_data.   0%[                    ]       0  --.-KB/s               \rdownload_glue_data. 100%[===================>]   8.03K  --.-KB/s    in 0s      \n","\n","2020-05-20 05:38:16 (78.1 MB/s) - ‘download_glue_data.py’ saved [8225/8225]\n","\n","Downloading and extracting CoLA...\n","\tCompleted!\n","Downloading and extracting SST...\n","\tCompleted!\n","Processing MRPC...\n","Local MRPC data not specified, downloading data from https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_train.txt\n","\tCompleted!\n","Downloading and extracting QQP...\n","\tCompleted!\n","Downloading and extracting STS...\n","\tCompleted!\n","Downloading and extracting MNLI...\n","\tCompleted!\n","Downloading and extracting SNLI...\n","\tCompleted!\n","Downloading and extracting QNLI...\n","\tCompleted!\n","Downloading and extracting RTE...\n","\tCompleted!\n","Downloading and extracting WNLI...\n","\tCompleted!\n","Downloading and extracting diagnostic...\n","\tCompleted!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fpKMOM6om3Tl","colab_type":"code","outputId":"f5d2b0b0-dbc6-48af-87f5-071840aa827c","executionInfo":{"status":"ok","timestamp":1589953272020,"user_tz":-120,"elapsed":8919,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":712}},"source":["!pip install transformers==2.8.0"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting transformers==2.8.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n","\u001b[K     |████████████████████████████████| 573kB 2.8MB/s \n","\u001b[?25hCollecting tokenizers==0.5.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n","\u001b[K     |████████████████████████████████| 3.7MB 13.3MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2.23.0)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/88/49e772d686088e1278766ad68a463513642a2a877487decbd691dec02955/sentencepiece-0.1.90-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 28.3MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.18.4)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.13.10)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2019.12.20)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.7)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 38.4MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (3.0.12)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (4.41.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2020.4.5.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2.9)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (0.10.0)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (0.3.3)\n","Requirement already satisfied: botocore<1.17.0,>=1.16.10 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (1.16.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (0.15.0)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.10->boto3->transformers==2.8.0) (2.8.1)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.10->boto3->transformers==2.8.0) (0.15.2)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=2b9053e33dded2ff0df3deac9626eec8252584aba1cdffe696ae08a5dfe06ea7\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.90 tokenizers-0.5.2 transformers-2.8.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3iEUh71Miw7p","colab_type":"code","outputId":"bb9408f3-462d-4cb2-8158-69afeb20b6ca","executionInfo":{"status":"ok","timestamp":1589954204265,"user_tz":-120,"elapsed":327597,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python run_glue.py \\\n","  --model_type bert \\\n","  --model_name_or_path bert-base-uncased \\\n","  --task_name CoLA \\\n","  --do_train \\\n","  --do_eval \\\n","  --data_dir /content/glue_data/CoLA \\\n","  --max_seq_length 128 \\\n","  --per_gpu_train_batch_size 64 \\\n","  --learning_rate 2e-5 \\\n","  --num_train_epochs 3.0 \\\n","  --output_dir /content/tmp/CoLA/ \\\n","  --overwrite_output_dir"],"execution_count":7,"outputs":[{"output_type":"stream","text":["2020-05-20 05:51:17.481820: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","05/20/2020 05:51:19 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","05/20/2020 05:51:19 - INFO - filelock -   Lock 140676698969200 acquired on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n","05/20/2020 05:51:19 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpwmv96stt\n","Downloading: 100% 433/433 [00:00<00:00, 462kB/s]\n","05/20/2020 05:51:19 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json in cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","05/20/2020 05:51:19 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","05/20/2020 05:51:19 - INFO - filelock -   Lock 140676698969200 released on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n","05/20/2020 05:51:19 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","05/20/2020 05:51:19 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": \"cola\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","05/20/2020 05:51:19 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","05/20/2020 05:51:19 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","05/20/2020 05:51:19 - INFO - filelock -   Lock 140676698970544 acquired on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n","05/20/2020 05:51:19 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpqc4qa01s\n","Downloading: 100% 232k/232k [00:00<00:00, 4.37MB/s]\n","05/20/2020 05:51:19 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt in cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","05/20/2020 05:51:19 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","05/20/2020 05:51:19 - INFO - filelock -   Lock 140676698970544 released on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n","05/20/2020 05:51:19 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","05/20/2020 05:51:19 - INFO - filelock -   Lock 140676698971888 acquired on /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n","05/20/2020 05:51:19 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpgkfxal3p\n","Downloading: 100% 440M/440M [00:07<00:00, 56.4MB/s]\n","05/20/2020 05:51:27 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin in cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","05/20/2020 05:51:27 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","05/20/2020 05:51:27 - INFO - filelock -   Lock 140676698971888 released on /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n","05/20/2020 05:51:27 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","05/20/2020 05:51:31 - INFO - transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","05/20/2020 05:51:31 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","05/20/2020 05:51:35 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir='/content/glue_data/CoLA', device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=True, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=2e-05, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=3.0, output_dir='/content/tmp/CoLA/', output_mode='classification', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=64, save_steps=500, seed=42, server_ip='', server_port='', task_name='cola', tokenizer_name='', warmup_steps=0, weight_decay=0.0)\n","05/20/2020 05:51:35 - INFO - __main__ -   Creating features from dataset file at /content/glue_data/CoLA\n","05/20/2020 05:51:35 - INFO - transformers.data.processors.glue -   Writing example 0/8551\n","05/20/2020 05:51:35 - INFO - transformers.data.processors.glue -   *** Example ***\n","05/20/2020 05:51:35 - INFO - transformers.data.processors.glue -   guid: train-0\n","05/20/2020 05:51:35 - INFO - transformers.data.processors.glue -   input_ids: 101 100 2814 2180 1005 1056 4965 2023 4106 1010 2292 2894 1996 2279 2028 2057 16599 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","05/20/2020 05:51:35 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","05/20/2020 05:51:35 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","05/20/2020 05:51:35 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n","05/20/2020 05:51:35 - INFO - transformers.data.processors.glue -   *** Example ***\n","05/20/2020 05:51:35 - INFO - transformers.data.processors.glue -   guid: train-1\n","05/20/2020 05:51:35 - INFO - transformers.data.processors.glue -   input_ids: 101 100 2062 18404 2236 3989 1998 100 1005 1049 3228 2039 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","05/20/2020 05:51:35 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","05/20/2020 05:51:35 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","05/20/2020 05:51:35 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n","05/20/2020 05:51:35 - INFO - transformers.data.processors.glue -   *** Example ***\n","05/20/2020 05:51:35 - INFO - transformers.data.processors.glue -   guid: train-2\n","05/20/2020 05:51:35 - INFO - transformers.data.processors.glue -   input_ids: 101 100 2062 18404 2236 3989 2030 100 1005 1049 3228 2039 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","05/20/2020 05:51:35 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","05/20/2020 05:51:35 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","05/20/2020 05:51:35 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n","05/20/2020 05:51:35 - INFO - transformers.data.processors.glue -   *** Example ***\n","05/20/2020 05:51:35 - INFO - transformers.data.processors.glue -   guid: train-3\n","05/20/2020 05:51:35 - INFO - transformers.data.processors.glue -   input_ids: 101 100 2062 2057 2817 16025 1010 1996 13675 16103 2121 2027 2131 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","05/20/2020 05:51:35 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","05/20/2020 05:51:35 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","05/20/2020 05:51:35 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n","05/20/2020 05:51:35 - INFO - transformers.data.processors.glue -   *** Example ***\n","05/20/2020 05:51:35 - INFO - transformers.data.processors.glue -   guid: train-4\n","05/20/2020 05:51:35 - INFO - transformers.data.processors.glue -   input_ids: 101 100 2011 2154 1996 8866 2024 2893 14163 8024 3771 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","05/20/2020 05:51:35 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","05/20/2020 05:51:35 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","05/20/2020 05:51:35 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n","05/20/2020 05:51:37 - INFO - __main__ -   Saving features into cached file /content/glue_data/CoLA/cached_train_bert-base-uncased_128_cola\n","05/20/2020 05:51:39 - INFO - __main__ -   ***** Running training *****\n","05/20/2020 05:51:39 - INFO - __main__ -     Num examples = 8551\n","05/20/2020 05:51:39 - INFO - __main__ -     Num Epochs = 3\n","05/20/2020 05:51:39 - INFO - __main__ -     Instantaneous batch size per GPU = 64\n","05/20/2020 05:51:39 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64\n","05/20/2020 05:51:39 - INFO - __main__ -     Gradient Accumulation steps = 1\n","05/20/2020 05:51:39 - INFO - __main__ -     Total optimization steps = 402\n","Epoch:   0% 0/3 [00:00<?, ?it/s]\n","Iteration:   0% 0/134 [00:00<?, ?it/s]\u001b[A/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha)\n","\n","Iteration:   1% 1/134 [00:00<01:40,  1.33it/s]\u001b[A\n","Iteration:   1% 2/134 [00:01<01:38,  1.35it/s]\u001b[A\n","Iteration:   2% 3/134 [00:02<01:36,  1.36it/s]\u001b[A\n","Iteration:   3% 4/134 [00:02<01:34,  1.37it/s]\u001b[A\n","Iteration:   4% 5/134 [00:03<01:33,  1.38it/s]\u001b[A\n","Iteration:   4% 6/134 [00:04<01:32,  1.39it/s]\u001b[A\n","Iteration:   5% 7/134 [00:05<01:31,  1.39it/s]\u001b[A\n","Iteration:   6% 8/134 [00:05<01:31,  1.38it/s]\u001b[A\n","Iteration:   7% 9/134 [00:06<01:30,  1.37it/s]\u001b[A\n","Iteration:   7% 10/134 [00:07<01:29,  1.38it/s]\u001b[A\n","Iteration:   8% 11/134 [00:07<01:28,  1.38it/s]\u001b[A\n","Iteration:   9% 12/134 [00:08<01:28,  1.37it/s]\u001b[A\n","Iteration:  10% 13/134 [00:09<01:27,  1.38it/s]\u001b[A\n","Iteration:  10% 14/134 [00:10<01:27,  1.37it/s]\u001b[A\n","Iteration:  11% 15/134 [00:10<01:26,  1.37it/s]\u001b[A\n","Iteration:  12% 16/134 [00:11<01:25,  1.38it/s]\u001b[A\n","Iteration:  13% 17/134 [00:12<01:24,  1.38it/s]\u001b[A\n","Iteration:  13% 18/134 [00:13<01:23,  1.39it/s]\u001b[A\n","Iteration:  14% 19/134 [00:13<01:22,  1.39it/s]\u001b[A\n","Iteration:  15% 20/134 [00:14<01:22,  1.39it/s]\u001b[A\n","Iteration:  16% 21/134 [00:15<01:22,  1.37it/s]\u001b[A\n","Iteration:  16% 22/134 [00:15<01:21,  1.38it/s]\u001b[A\n","Iteration:  17% 23/134 [00:16<01:20,  1.38it/s]\u001b[A\n","Iteration:  18% 24/134 [00:17<01:19,  1.38it/s]\u001b[A\n","Iteration:  19% 25/134 [00:18<01:18,  1.38it/s]\u001b[A\n","Iteration:  19% 26/134 [00:18<01:18,  1.38it/s]\u001b[A\n","Iteration:  20% 27/134 [00:19<01:17,  1.38it/s]\u001b[A\n","Iteration:  21% 28/134 [00:20<01:16,  1.38it/s]\u001b[A\n","Iteration:  22% 29/134 [00:21<01:16,  1.37it/s]\u001b[A\n","Iteration:  22% 30/134 [00:21<01:16,  1.37it/s]\u001b[A\n","Iteration:  23% 31/134 [00:22<01:14,  1.38it/s]\u001b[A\n","Iteration:  24% 32/134 [00:23<01:13,  1.38it/s]\u001b[A\n","Iteration:  25% 33/134 [00:23<01:13,  1.38it/s]\u001b[A\n","Iteration:  25% 34/134 [00:24<01:12,  1.38it/s]\u001b[A\n","Iteration:  26% 35/134 [00:25<01:11,  1.39it/s]\u001b[A\n","Iteration:  27% 36/134 [00:26<01:10,  1.39it/s]\u001b[A\n","Iteration:  28% 37/134 [00:26<01:09,  1.39it/s]\u001b[A\n","Iteration:  28% 38/134 [00:27<01:08,  1.39it/s]\u001b[A\n","Iteration:  29% 39/134 [00:28<01:08,  1.39it/s]\u001b[A\n","Iteration:  30% 40/134 [00:28<01:07,  1.39it/s]\u001b[A\n","Iteration:  31% 41/134 [00:29<01:06,  1.40it/s]\u001b[A\n","Iteration:  31% 42/134 [00:30<01:06,  1.39it/s]\u001b[A\n","Iteration:  32% 43/134 [00:31<01:05,  1.40it/s]\u001b[A\n","Iteration:  33% 44/134 [00:31<01:04,  1.40it/s]\u001b[A\n","Iteration:  34% 45/134 [00:32<01:03,  1.40it/s]\u001b[A\n","Iteration:  34% 46/134 [00:33<01:03,  1.39it/s]\u001b[A\n","Iteration:  35% 47/134 [00:33<01:02,  1.39it/s]\u001b[A\n","Iteration:  36% 48/134 [00:34<01:02,  1.38it/s]\u001b[A\n","Iteration:  37% 49/134 [00:35<01:01,  1.38it/s]\u001b[A\n","Iteration:  37% 50/134 [00:36<01:00,  1.39it/s]\u001b[A\n","Iteration:  38% 51/134 [00:36<00:59,  1.39it/s]\u001b[A\n","Iteration:  39% 52/134 [00:37<00:58,  1.39it/s]\u001b[A\n","Iteration:  40% 53/134 [00:38<00:58,  1.39it/s]\u001b[A\n","Iteration:  40% 54/134 [00:38<00:57,  1.39it/s]\u001b[A\n","Iteration:  41% 55/134 [00:39<00:56,  1.39it/s]\u001b[A\n","Iteration:  42% 56/134 [00:40<00:55,  1.39it/s]\u001b[A\n","Iteration:  43% 57/134 [00:41<00:55,  1.39it/s]\u001b[A\n","Iteration:  43% 58/134 [00:41<00:54,  1.38it/s]\u001b[A\n","Iteration:  44% 59/134 [00:42<00:54,  1.39it/s]\u001b[A\n","Iteration:  45% 60/134 [00:43<00:53,  1.39it/s]\u001b[A\n","Iteration:  46% 61/134 [00:44<00:52,  1.39it/s]\u001b[A\n","Iteration:  46% 62/134 [00:44<00:51,  1.39it/s]\u001b[A\n","Iteration:  47% 63/134 [00:45<00:51,  1.37it/s]\u001b[A\n","Iteration:  48% 64/134 [00:46<00:51,  1.36it/s]\u001b[A\n","Iteration:  49% 65/134 [00:46<00:50,  1.37it/s]\u001b[A\n","Iteration:  49% 66/134 [00:47<00:49,  1.38it/s]\u001b[A\n","Iteration:  50% 67/134 [00:48<00:48,  1.38it/s]\u001b[A\n","Iteration:  51% 68/134 [00:49<00:47,  1.38it/s]\u001b[A\n","Iteration:  51% 69/134 [00:49<00:46,  1.39it/s]\u001b[A\n","Iteration:  52% 70/134 [00:50<00:46,  1.38it/s]\u001b[A\n","Iteration:  53% 71/134 [00:51<00:45,  1.38it/s]\u001b[A\n","Iteration:  54% 72/134 [00:52<00:44,  1.38it/s]\u001b[A\n","Iteration:  54% 73/134 [00:52<00:44,  1.37it/s]\u001b[A\n","Iteration:  55% 74/134 [00:53<00:43,  1.38it/s]\u001b[A\n","Iteration:  56% 75/134 [00:54<00:42,  1.38it/s]\u001b[A\n","Iteration:  57% 76/134 [00:54<00:41,  1.38it/s]\u001b[A\n","Iteration:  57% 77/134 [00:55<00:41,  1.38it/s]\u001b[A\n","Iteration:  58% 78/134 [00:56<00:40,  1.38it/s]\u001b[A\n","Iteration:  59% 79/134 [00:57<00:39,  1.39it/s]\u001b[A\n","Iteration:  60% 80/134 [00:57<00:38,  1.39it/s]\u001b[A\n","Iteration:  60% 81/134 [00:58<00:38,  1.39it/s]\u001b[A\n","Iteration:  61% 82/134 [00:59<00:37,  1.39it/s]\u001b[A\n","Iteration:  62% 83/134 [00:59<00:36,  1.39it/s]\u001b[A\n","Iteration:  63% 84/134 [01:00<00:36,  1.38it/s]\u001b[A\n","Iteration:  63% 85/134 [01:01<00:35,  1.38it/s]\u001b[A\n","Iteration:  64% 86/134 [01:02<00:34,  1.38it/s]\u001b[A\n","Iteration:  65% 87/134 [01:02<00:33,  1.38it/s]\u001b[A\n","Iteration:  66% 88/134 [01:03<00:33,  1.37it/s]\u001b[A\n","Iteration:  66% 89/134 [01:04<00:32,  1.38it/s]\u001b[A\n","Iteration:  67% 90/134 [01:05<00:31,  1.38it/s]\u001b[A\n","Iteration:  68% 91/134 [01:05<00:31,  1.37it/s]\u001b[A\n","Iteration:  69% 92/134 [01:06<00:30,  1.38it/s]\u001b[A\n","Iteration:  69% 93/134 [01:07<00:29,  1.38it/s]\u001b[A\n","Iteration:  70% 94/134 [01:07<00:28,  1.39it/s]\u001b[A\n","Iteration:  71% 95/134 [01:08<00:28,  1.39it/s]\u001b[A\n","Iteration:  72% 96/134 [01:09<00:27,  1.38it/s]\u001b[A\n","Iteration:  72% 97/134 [01:10<00:26,  1.39it/s]\u001b[A\n","Iteration:  73% 98/134 [01:10<00:25,  1.39it/s]\u001b[A\n","Iteration:  74% 99/134 [01:11<00:25,  1.39it/s]\u001b[A\n","Iteration:  75% 100/134 [01:12<00:24,  1.39it/s]\u001b[A\n","Iteration:  75% 101/134 [01:12<00:23,  1.39it/s]\u001b[A\n","Iteration:  76% 102/134 [01:13<00:22,  1.39it/s]\u001b[A\n","Iteration:  77% 103/134 [01:14<00:22,  1.39it/s]\u001b[A\n","Iteration:  78% 104/134 [01:15<00:21,  1.39it/s]\u001b[A\n","Iteration:  78% 105/134 [01:15<00:20,  1.39it/s]\u001b[A\n","Iteration:  79% 106/134 [01:16<00:20,  1.39it/s]\u001b[A\n","Iteration:  80% 107/134 [01:17<00:19,  1.39it/s]\u001b[A\n","Iteration:  81% 108/134 [01:17<00:18,  1.39it/s]\u001b[A\n","Iteration:  81% 109/134 [01:18<00:17,  1.39it/s]\u001b[A\n","Iteration:  82% 110/134 [01:19<00:17,  1.39it/s]\u001b[A\n","Iteration:  83% 111/134 [01:20<00:16,  1.39it/s]\u001b[A\n","Iteration:  84% 112/134 [01:20<00:15,  1.39it/s]\u001b[A\n","Iteration:  84% 113/134 [01:21<00:15,  1.39it/s]\u001b[A\n","Iteration:  85% 114/134 [01:22<00:14,  1.38it/s]\u001b[A\n","Iteration:  86% 115/134 [01:23<00:13,  1.39it/s]\u001b[A\n","Iteration:  87% 116/134 [01:23<00:12,  1.39it/s]\u001b[A\n","Iteration:  87% 117/134 [01:24<00:12,  1.39it/s]\u001b[A\n","Iteration:  88% 118/134 [01:25<00:11,  1.39it/s]\u001b[A\n","Iteration:  89% 119/134 [01:25<00:10,  1.39it/s]\u001b[A\n","Iteration:  90% 120/134 [01:26<00:10,  1.39it/s]\u001b[A\n","Iteration:  90% 121/134 [01:27<00:09,  1.39it/s]\u001b[A\n","Iteration:  91% 122/134 [01:28<00:08,  1.39it/s]\u001b[A\n","Iteration:  92% 123/134 [01:28<00:07,  1.38it/s]\u001b[A\n","Iteration:  93% 124/134 [01:29<00:07,  1.38it/s]\u001b[A\n","Iteration:  93% 125/134 [01:30<00:06,  1.39it/s]\u001b[A\n","Iteration:  94% 126/134 [01:30<00:05,  1.38it/s]\u001b[A\n","Iteration:  95% 127/134 [01:31<00:05,  1.37it/s]\u001b[A\n","Iteration:  96% 128/134 [01:32<00:04,  1.38it/s]\u001b[A\n","Iteration:  96% 129/134 [01:33<00:03,  1.39it/s]\u001b[A\n","Iteration:  97% 130/134 [01:33<00:02,  1.38it/s]\u001b[A\n","Iteration:  98% 131/134 [01:34<00:02,  1.39it/s]\u001b[A\n","Iteration:  99% 132/134 [01:35<00:01,  1.39it/s]\u001b[A\n","Iteration:  99% 133/134 [01:35<00:00,  1.39it/s]\u001b[A\n","Iteration: 100% 134/134 [01:36<00:00,  1.39it/s]\n","Epoch:  33% 1/3 [01:36<03:12, 96.50s/it]\n","Iteration:   0% 0/134 [00:00<?, ?it/s]\u001b[A\n","Iteration:   1% 1/134 [00:00<01:35,  1.39it/s]\u001b[A\n","Iteration:   1% 2/134 [00:01<01:34,  1.39it/s]\u001b[A\n","Iteration:   2% 3/134 [00:02<01:33,  1.40it/s]\u001b[A\n","Iteration:   3% 4/134 [00:02<01:33,  1.39it/s]\u001b[A\n","Iteration:   4% 5/134 [00:03<01:32,  1.39it/s]\u001b[A\n","Iteration:   4% 6/134 [00:04<01:32,  1.38it/s]\u001b[A\n","Iteration:   5% 7/134 [00:05<01:31,  1.39it/s]\u001b[A\n","Iteration:   6% 8/134 [00:05<01:30,  1.39it/s]\u001b[A\n","Iteration:   7% 9/134 [00:06<01:30,  1.39it/s]\u001b[A\n","Iteration:   7% 10/134 [00:07<01:29,  1.38it/s]\u001b[A\n","Iteration:   8% 11/134 [00:07<01:29,  1.38it/s]\u001b[A\n","Iteration:   9% 12/134 [00:08<01:28,  1.38it/s]\u001b[A\n","Iteration:  10% 13/134 [00:09<01:27,  1.38it/s]\u001b[A\n","Iteration:  10% 14/134 [00:10<01:26,  1.38it/s]\u001b[A\n","Iteration:  11% 15/134 [00:10<01:25,  1.39it/s]\u001b[A\n","Iteration:  12% 16/134 [00:11<01:25,  1.38it/s]\u001b[A\n","Iteration:  13% 17/134 [00:12<01:24,  1.38it/s]\u001b[A\n","Iteration:  13% 18/134 [00:12<01:23,  1.38it/s]\u001b[A\n","Iteration:  14% 19/134 [00:13<01:22,  1.39it/s]\u001b[A\n","Iteration:  15% 20/134 [00:14<01:21,  1.39it/s]\u001b[A\n","Iteration:  16% 21/134 [00:15<01:21,  1.39it/s]\u001b[A\n","Iteration:  16% 22/134 [00:15<01:20,  1.39it/s]\u001b[A\n","Iteration:  17% 23/134 [00:16<01:20,  1.38it/s]\u001b[A\n","Iteration:  18% 24/134 [00:17<01:19,  1.38it/s]\u001b[A\n","Iteration:  19% 25/134 [00:18<01:18,  1.39it/s]\u001b[A\n","Iteration:  19% 26/134 [00:18<01:17,  1.39it/s]\u001b[A\n","Iteration:  20% 27/134 [00:19<01:16,  1.39it/s]\u001b[A\n","Iteration:  21% 28/134 [00:20<01:16,  1.38it/s]\u001b[A\n","Iteration:  22% 29/134 [00:20<01:16,  1.37it/s]\u001b[A\n","Iteration:  22% 30/134 [00:21<01:15,  1.38it/s]\u001b[A\n","Iteration:  23% 31/134 [00:22<01:14,  1.38it/s]\u001b[A\n","Iteration:  24% 32/134 [00:23<01:13,  1.39it/s]\u001b[A\n","Iteration:  25% 33/134 [00:23<01:12,  1.39it/s]\u001b[A\n","Iteration:  25% 34/134 [00:24<01:11,  1.39it/s]\u001b[A\n","Iteration:  26% 35/134 [00:25<01:11,  1.39it/s]\u001b[A\n","Iteration:  27% 36/134 [00:25<01:10,  1.38it/s]\u001b[A\n","Iteration:  28% 37/134 [00:26<01:09,  1.39it/s]\u001b[A\n","Iteration:  28% 38/134 [00:27<01:09,  1.39it/s]\u001b[A\n","Iteration:  29% 39/134 [00:28<01:08,  1.38it/s]\u001b[A\n","Iteration:  30% 40/134 [00:28<01:08,  1.38it/s]\u001b[A\n","Iteration:  31% 41/134 [00:29<01:07,  1.39it/s]\u001b[A\n","Iteration:  31% 42/134 [00:30<01:06,  1.39it/s]\u001b[A\n","Iteration:  32% 43/134 [00:31<01:05,  1.39it/s]\u001b[A\n","Iteration:  33% 44/134 [00:31<01:05,  1.38it/s]\u001b[A\n","Iteration:  34% 45/134 [00:32<01:04,  1.38it/s]\u001b[A\n","Iteration:  34% 46/134 [00:33<01:03,  1.38it/s]\u001b[A\n","Iteration:  35% 47/134 [00:33<01:02,  1.39it/s]\u001b[A\n","Iteration:  36% 48/134 [00:34<01:02,  1.39it/s]\u001b[A\n","Iteration:  37% 49/134 [00:35<01:01,  1.39it/s]\u001b[A\n","Iteration:  37% 50/134 [00:36<01:00,  1.39it/s]\u001b[A\n","Iteration:  38% 51/134 [00:36<00:59,  1.39it/s]\u001b[A\n","Iteration:  39% 52/134 [00:37<00:58,  1.39it/s]\u001b[A\n","Iteration:  40% 53/134 [00:38<00:58,  1.38it/s]\u001b[A\n","Iteration:  40% 54/134 [00:38<00:57,  1.39it/s]\u001b[A\n","Iteration:  41% 55/134 [00:39<00:56,  1.39it/s]\u001b[A\n","Iteration:  42% 56/134 [00:40<00:56,  1.38it/s]\u001b[A\n","Iteration:  43% 57/134 [00:41<00:55,  1.39it/s]\u001b[A\n","Iteration:  43% 58/134 [00:41<00:54,  1.39it/s]\u001b[A\n","Iteration:  44% 59/134 [00:42<00:53,  1.39it/s]\u001b[A\n","Iteration:  45% 60/134 [00:43<00:53,  1.39it/s]\u001b[A\n","Iteration:  46% 61/134 [00:44<00:52,  1.38it/s]\u001b[A\n","Iteration:  46% 62/134 [00:44<00:52,  1.38it/s]\u001b[A\n","Iteration:  47% 63/134 [00:45<00:51,  1.38it/s]\u001b[A\n","Iteration:  48% 64/134 [00:46<00:51,  1.37it/s]\u001b[A\n","Iteration:  49% 65/134 [00:46<00:50,  1.38it/s]\u001b[A\n","Iteration:  49% 66/134 [00:47<00:49,  1.38it/s]\u001b[A\n","Iteration:  50% 67/134 [00:48<00:48,  1.38it/s]\u001b[A\n","Iteration:  51% 68/134 [00:49<00:48,  1.37it/s]\u001b[A\n","Iteration:  51% 69/134 [00:49<00:47,  1.37it/s]\u001b[A\n","Iteration:  52% 70/134 [00:50<00:46,  1.38it/s]\u001b[A\n","Iteration:  53% 71/134 [00:51<00:45,  1.38it/s]\u001b[A\n","Iteration:  54% 72/134 [00:51<00:44,  1.38it/s]\u001b[A\n","Iteration:  54% 73/134 [00:52<00:43,  1.39it/s]\u001b[A\n","Iteration:  55% 74/134 [00:53<00:43,  1.39it/s]\u001b[A\n","Iteration:  56% 75/134 [00:54<00:42,  1.39it/s]\u001b[A\n","Iteration:  57% 76/134 [00:54<00:41,  1.39it/s]\u001b[A\n","Iteration:  57% 77/134 [00:55<00:40,  1.39it/s]\u001b[A\n","Iteration:  58% 78/134 [00:56<00:40,  1.38it/s]\u001b[A\n","Iteration:  59% 79/134 [00:57<00:39,  1.39it/s]\u001b[A\n","Iteration:  60% 80/134 [00:57<00:39,  1.38it/s]\u001b[A\n","Iteration:  60% 81/134 [00:58<00:38,  1.38it/s]\u001b[A\n","Iteration:  61% 82/134 [00:59<00:37,  1.38it/s]\u001b[A\n","Iteration:  62% 83/134 [00:59<00:36,  1.38it/s]\u001b[A\n","Iteration:  63% 84/134 [01:00<00:36,  1.38it/s]\u001b[A\n","Iteration:  63% 85/134 [01:01<00:35,  1.39it/s]\u001b[A\n","Iteration:  64% 86/134 [01:02<00:34,  1.39it/s]\u001b[A\n","Iteration:  65% 87/134 [01:02<00:33,  1.39it/s]\u001b[A\n","Iteration:  66% 88/134 [01:03<00:33,  1.39it/s]\u001b[A\n","Iteration:  66% 89/134 [01:04<00:32,  1.39it/s]\u001b[A\n","Iteration:  67% 90/134 [01:04<00:31,  1.39it/s]\u001b[A\n","Iteration:  68% 91/134 [01:05<00:31,  1.38it/s]\u001b[A\n","Iteration:  69% 92/134 [01:06<00:30,  1.38it/s]\u001b[A\n","Iteration:  69% 93/134 [01:07<00:29,  1.39it/s]\u001b[A\n","Iteration:  70% 94/134 [01:07<00:28,  1.39it/s]\u001b[A\n","Iteration:  71% 95/134 [01:08<00:28,  1.39it/s]\u001b[A\n","Iteration:  72% 96/134 [01:09<00:27,  1.39it/s]\u001b[A\n","Iteration:  72% 97/134 [01:09<00:26,  1.39it/s]\u001b[A\n","Iteration:  73% 98/134 [01:10<00:25,  1.39it/s]\u001b[A\n","Iteration:  74% 99/134 [01:11<00:25,  1.39it/s]\u001b[A\n","Iteration:  75% 100/134 [01:12<00:24,  1.39it/s]\u001b[A\n","Iteration:  75% 101/134 [01:12<00:23,  1.39it/s]\u001b[A\n","Iteration:  76% 102/134 [01:13<00:22,  1.39it/s]\u001b[A\n","Iteration:  77% 103/134 [01:14<00:22,  1.39it/s]\u001b[A\n","Iteration:  78% 104/134 [01:15<00:21,  1.39it/s]\u001b[A\n","Iteration:  78% 105/134 [01:15<00:20,  1.39it/s]\u001b[A\n","Iteration:  79% 106/134 [01:16<00:20,  1.39it/s]\u001b[A\n","Iteration:  80% 107/134 [01:17<00:19,  1.39it/s]\u001b[A\n","Iteration:  81% 108/134 [01:17<00:18,  1.39it/s]\u001b[A\n","Iteration:  81% 109/134 [01:18<00:17,  1.39it/s]\u001b[A\n","Iteration:  82% 110/134 [01:19<00:17,  1.39it/s]\u001b[A\n","Iteration:  83% 111/134 [01:20<00:16,  1.39it/s]\u001b[A\n","Iteration:  84% 112/134 [01:20<00:15,  1.38it/s]\u001b[A\n","Iteration:  84% 113/134 [01:21<00:15,  1.37it/s]\u001b[A\n","Iteration:  85% 114/134 [01:22<00:14,  1.38it/s]\u001b[A\n","Iteration:  86% 115/134 [01:22<00:13,  1.38it/s]\u001b[A\n","Iteration:  87% 116/134 [01:23<00:13,  1.38it/s]\u001b[A\n","Iteration:  87% 117/134 [01:24<00:12,  1.38it/s]\u001b[A\n","Iteration:  88% 118/134 [01:25<00:11,  1.39it/s]\u001b[A\n","Iteration:  89% 119/134 [01:25<00:10,  1.38it/s]\u001b[A\n","Iteration:  90% 120/134 [01:26<00:10,  1.39it/s]\u001b[A\n","Iteration:  90% 121/134 [01:27<00:09,  1.38it/s]\u001b[A\n","Iteration:  91% 122/134 [01:28<00:08,  1.37it/s]\u001b[A\n","Iteration:  92% 123/134 [01:28<00:08,  1.37it/s]\u001b[A\n","Iteration:  93% 124/134 [01:29<00:07,  1.37it/s]\u001b[A\n","Iteration:  93% 125/134 [01:30<00:06,  1.38it/s]\u001b[A\n","Iteration:  94% 126/134 [01:30<00:05,  1.39it/s]\u001b[A\n","Iteration:  95% 127/134 [01:31<00:05,  1.39it/s]\u001b[A\n","Iteration:  96% 128/134 [01:32<00:04,  1.39it/s]\u001b[A\n","Iteration:  96% 129/134 [01:33<00:03,  1.39it/s]\u001b[A\n","Iteration:  97% 130/134 [01:33<00:02,  1.40it/s]\u001b[A\n","Iteration:  98% 131/134 [01:34<00:02,  1.40it/s]\u001b[A\n","Iteration:  99% 132/134 [01:35<00:01,  1.39it/s]\u001b[A\n","Iteration:  99% 133/134 [01:35<00:00,  1.39it/s]\u001b[A\n","Iteration: 100% 134/134 [01:36<00:00,  1.39it/s]\n","Epoch:  67% 2/3 [03:12<01:36, 96.48s/it]\n","Iteration:   0% 0/134 [00:00<?, ?it/s]\u001b[A\n","Iteration:   1% 1/134 [00:00<01:35,  1.40it/s]\u001b[A\n","Iteration:   1% 2/134 [00:01<01:34,  1.39it/s]\u001b[A\n","Iteration:   2% 3/134 [00:02<01:33,  1.39it/s]\u001b[A\n","Iteration:   3% 4/134 [00:02<01:33,  1.39it/s]\u001b[A\n","Iteration:   4% 5/134 [00:03<01:32,  1.39it/s]\u001b[A\n","Iteration:   4% 6/134 [00:04<01:32,  1.38it/s]\u001b[A\n","Iteration:   5% 7/134 [00:05<01:31,  1.39it/s]\u001b[A\n","Iteration:   6% 8/134 [00:05<01:30,  1.39it/s]\u001b[A\n","Iteration:   7% 9/134 [00:06<01:30,  1.39it/s]\u001b[A\n","Iteration:   7% 10/134 [00:07<01:30,  1.38it/s]\u001b[A\n","Iteration:   8% 11/134 [00:07<01:29,  1.38it/s]\u001b[A\n","Iteration:   9% 12/134 [00:08<01:28,  1.37it/s]\u001b[A\n","Iteration:  10% 13/134 [00:09<01:27,  1.38it/s]\u001b[A\n","Iteration:  10% 14/134 [00:10<01:26,  1.39it/s]\u001b[A\n","Iteration:  11% 15/134 [00:10<01:26,  1.38it/s]\u001b[A\n","Iteration:  12% 16/134 [00:11<01:25,  1.37it/s]\u001b[A\n","Iteration:  13% 17/134 [00:12<01:25,  1.38it/s]\u001b[A\n","Iteration:  13% 18/134 [00:13<01:23,  1.38it/s]\u001b[A\n","Iteration:  14% 19/134 [00:13<01:23,  1.38it/s]\u001b[A\n","Iteration:  15% 20/134 [00:14<01:22,  1.39it/s]\u001b[A\n","Iteration:  16% 21/134 [00:15<01:21,  1.39it/s]\u001b[A\n","Iteration:  16% 22/134 [00:15<01:20,  1.39it/s]\u001b[A\n","Iteration:  17% 23/134 [00:16<01:20,  1.38it/s]\u001b[A\n","Iteration:  18% 24/134 [00:17<01:19,  1.38it/s]\u001b[A\n","Iteration:  19% 25/134 [00:18<01:18,  1.38it/s]\u001b[A\n","Iteration:  19% 26/134 [00:18<01:18,  1.38it/s]\u001b[A\n","Iteration:  20% 27/134 [00:19<01:17,  1.37it/s]\u001b[A\n","Iteration:  21% 28/134 [00:20<01:17,  1.37it/s]\u001b[A\n","Iteration:  22% 29/134 [00:20<01:16,  1.38it/s]\u001b[A\n","Iteration:  22% 30/134 [00:21<01:15,  1.38it/s]\u001b[A\n","Iteration:  23% 31/134 [00:22<01:14,  1.38it/s]\u001b[A\n","Iteration:  24% 32/134 [00:23<01:13,  1.38it/s]\u001b[A\n","Iteration:  25% 33/134 [00:23<01:12,  1.39it/s]\u001b[A\n","Iteration:  25% 34/134 [00:24<01:11,  1.39it/s]\u001b[A\n","Iteration:  26% 35/134 [00:25<01:11,  1.39it/s]\u001b[A\n","Iteration:  27% 36/134 [00:26<01:10,  1.39it/s]\u001b[A\n","Iteration:  28% 37/134 [00:26<01:09,  1.39it/s]\u001b[A\n","Iteration:  28% 38/134 [00:27<01:08,  1.39it/s]\u001b[A\n","Iteration:  29% 39/134 [00:28<01:08,  1.40it/s]\u001b[A\n","Iteration:  30% 40/134 [00:28<01:07,  1.39it/s]\u001b[A\n","Iteration:  31% 41/134 [00:29<01:07,  1.39it/s]\u001b[A\n","Iteration:  31% 42/134 [00:30<01:06,  1.39it/s]\u001b[A\n","Iteration:  32% 43/134 [00:31<01:05,  1.39it/s]\u001b[A\n","Iteration:  33% 44/134 [00:31<01:04,  1.39it/s]\u001b[A\n","Iteration:  34% 45/134 [00:32<01:04,  1.38it/s]\u001b[A\n","Iteration:  34% 46/134 [00:33<01:03,  1.39it/s]\u001b[A\n","Iteration:  35% 47/134 [00:33<01:02,  1.39it/s]\u001b[A\n","Iteration:  36% 48/134 [00:34<01:01,  1.39it/s]\u001b[A\n","Iteration:  37% 49/134 [00:35<01:01,  1.39it/s]\u001b[A\n","Iteration:  37% 50/134 [00:36<01:00,  1.40it/s]\u001b[A\n","Iteration:  38% 51/134 [00:36<00:59,  1.39it/s]\u001b[A\n","Iteration:  39% 52/134 [00:37<00:58,  1.39it/s]\u001b[A\n","Iteration:  40% 53/134 [00:38<00:58,  1.39it/s]\u001b[A\n","Iteration:  40% 54/134 [00:38<00:57,  1.39it/s]\u001b[A\n","Iteration:  41% 55/134 [00:39<00:56,  1.39it/s]\u001b[A\n","Iteration:  42% 56/134 [00:40<00:55,  1.39it/s]\u001b[A\n","Iteration:  43% 57/134 [00:41<00:55,  1.39it/s]\u001b[A\n","Iteration:  43% 58/134 [00:41<00:54,  1.39it/s]\u001b[A\n","Iteration:  44% 59/134 [00:42<00:53,  1.39it/s]\u001b[A\n","Iteration:  45% 60/134 [00:43<00:53,  1.39it/s]\u001b[A\n","Iteration:  46% 61/134 [00:43<00:52,  1.39it/s]\u001b[A\n","Iteration:  46% 62/134 [00:44<00:51,  1.40it/s]\u001b[A\n","Iteration:  47% 63/134 [00:45<00:50,  1.39it/s]\u001b[A\n","Iteration:  48% 64/134 [00:46<00:50,  1.39it/s]\u001b[A\n","Iteration:  49% 65/134 [00:46<00:49,  1.38it/s]\u001b[A\n","Iteration:  49% 66/134 [00:47<00:49,  1.39it/s]\u001b[A\n","Iteration:  50% 67/134 [00:48<00:48,  1.38it/s]\u001b[A\n","Iteration:  51% 68/134 [00:49<00:47,  1.39it/s]\u001b[A\n","Iteration:  51% 69/134 [00:49<00:46,  1.39it/s]\u001b[A\n","Iteration:  52% 70/134 [00:50<00:46,  1.39it/s]\u001b[A\n","Iteration:  53% 71/134 [00:51<00:45,  1.38it/s]\u001b[A\n","Iteration:  54% 72/134 [00:51<00:44,  1.38it/s]\u001b[A\n","Iteration:  54% 73/134 [00:52<00:44,  1.38it/s]\u001b[A\n","Iteration:  55% 74/134 [00:53<00:43,  1.39it/s]\u001b[A\n","Iteration:  56% 75/134 [00:54<00:42,  1.39it/s]\u001b[A\n","Iteration:  57% 76/134 [00:54<00:41,  1.39it/s]\u001b[A\n","Iteration:  57% 77/134 [00:55<00:40,  1.40it/s]\u001b[A\n","Iteration:  58% 78/134 [00:56<00:40,  1.39it/s]\u001b[A\n","Iteration:  59% 79/134 [00:56<00:39,  1.39it/s]\u001b[A\n","Iteration:  60% 80/134 [00:57<00:38,  1.39it/s]\u001b[A\n","Iteration:  60% 81/134 [00:58<00:37,  1.40it/s]\u001b[A\n","Iteration:  61% 82/134 [00:59<00:37,  1.40it/s]\u001b[A\n","Iteration:  62% 83/134 [00:59<00:36,  1.39it/s]\u001b[A\n","Iteration:  63% 84/134 [01:00<00:35,  1.39it/s]\u001b[A\n","Iteration:  63% 85/134 [01:01<00:35,  1.40it/s]\u001b[A\n","Iteration:  64% 86/134 [01:01<00:34,  1.40it/s]\u001b[A\n","Iteration:  65% 87/134 [01:02<00:33,  1.40it/s]\u001b[A\n","Iteration:  66% 88/134 [01:03<00:32,  1.40it/s]\u001b[A\n","Iteration:  66% 89/134 [01:04<00:32,  1.39it/s]\u001b[A\n","Iteration:  67% 90/134 [01:04<00:31,  1.39it/s]\u001b[A\n","Iteration:  68% 91/134 [01:05<00:30,  1.39it/s]\u001b[A\n","Iteration:  69% 92/134 [01:06<00:30,  1.39it/s]\u001b[A\n","Iteration:  69% 93/134 [01:07<00:29,  1.39it/s]\u001b[A\n","Iteration:  70% 94/134 [01:07<00:28,  1.39it/s]\u001b[A\n","Iteration:  71% 95/134 [01:08<00:28,  1.39it/s]\u001b[A\n","Iteration:  72% 96/134 [01:09<00:27,  1.38it/s]\u001b[A\n","Iteration:  72% 97/134 [01:09<00:26,  1.38it/s]\u001b[A\n","Iteration:  73% 98/134 [01:10<00:25,  1.39it/s]\u001b[A\n","Iteration:  74% 99/134 [01:11<00:25,  1.38it/s]\u001b[A\n","Iteration:  75% 100/134 [01:12<00:24,  1.38it/s]\u001b[A\n","Iteration:  75% 101/134 [01:12<00:23,  1.39it/s]\u001b[A\n","Iteration:  76% 102/134 [01:13<00:23,  1.39it/s]\u001b[A\n","Iteration:  77% 103/134 [01:14<00:22,  1.39it/s]\u001b[A\n","Iteration:  78% 104/134 [01:14<00:21,  1.39it/s]\u001b[A\n","Iteration:  78% 105/134 [01:15<00:20,  1.39it/s]\u001b[A\n","Iteration:  79% 106/134 [01:16<00:20,  1.39it/s]\u001b[A\n","Iteration:  80% 107/134 [01:17<00:19,  1.40it/s]\u001b[A\n","Iteration:  81% 108/134 [01:17<00:18,  1.39it/s]\u001b[A\n","Iteration:  81% 109/134 [01:18<00:17,  1.40it/s]\u001b[A\n","Iteration:  82% 110/134 [01:19<00:17,  1.38it/s]\u001b[A\n","Iteration:  83% 111/134 [01:19<00:16,  1.38it/s]\u001b[A\n","Iteration:  84% 112/134 [01:20<00:15,  1.39it/s]\u001b[A\n","Iteration:  84% 113/134 [01:21<00:15,  1.39it/s]\u001b[A\n","Iteration:  85% 114/134 [01:22<00:14,  1.39it/s]\u001b[A\n","Iteration:  86% 115/134 [01:22<00:13,  1.39it/s]\u001b[A\n","Iteration:  87% 116/134 [01:23<00:12,  1.39it/s]\u001b[A\n","Iteration:  87% 117/134 [01:24<00:12,  1.39it/s]\u001b[A\n","Iteration:  88% 118/134 [01:25<00:11,  1.39it/s]\u001b[A\n","Iteration:  89% 119/134 [01:25<00:10,  1.39it/s]\u001b[A\n","Iteration:  90% 120/134 [01:26<00:10,  1.39it/s]\u001b[A\n","Iteration:  90% 121/134 [01:27<00:09,  1.39it/s]\u001b[A\n","Iteration:  91% 122/134 [01:27<00:08,  1.38it/s]\u001b[A\n","Iteration:  92% 123/134 [01:28<00:07,  1.38it/s]\u001b[A\n","Iteration:  93% 124/134 [01:29<00:07,  1.39it/s]\u001b[A\n","Iteration:  93% 125/134 [01:30<00:06,  1.38it/s]\u001b[A\n","Iteration:  94% 126/134 [01:30<00:05,  1.39it/s]\u001b[A\n","Iteration:  95% 127/134 [01:31<00:05,  1.39it/s]\u001b[A\n","Iteration:  96% 128/134 [01:32<00:04,  1.39it/s]\u001b[A\n","Iteration:  96% 129/134 [01:32<00:03,  1.39it/s]\u001b[A\n","Iteration:  97% 130/134 [01:33<00:02,  1.38it/s]\u001b[A\n","Iteration:  98% 131/134 [01:34<00:02,  1.39it/s]\u001b[A\n","Iteration:  99% 132/134 [01:35<00:01,  1.39it/s]\u001b[A\n","Iteration:  99% 133/134 [01:35<00:00,  1.38it/s]\u001b[A\n","Iteration: 100% 134/134 [01:36<00:00,  1.39it/s]\n","Epoch: 100% 3/3 [04:49<00:00, 96.42s/it]\n","05/20/2020 05:56:28 - INFO - __main__ -    global_step = 402, average loss = 0.41839399092381274\n","05/20/2020 05:56:28 - INFO - __main__ -   Saving model checkpoint to /content/tmp/CoLA/\n","05/20/2020 05:56:28 - INFO - transformers.configuration_utils -   Configuration saved in /content/tmp/CoLA/config.json\n","05/20/2020 05:56:28 - INFO - transformers.modeling_utils -   Model weights saved in /content/tmp/CoLA/pytorch_model.bin\n","05/20/2020 05:56:28 - INFO - transformers.configuration_utils -   loading configuration file /content/tmp/CoLA/config.json\n","05/20/2020 05:56:28 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": \"cola\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","05/20/2020 05:56:28 - INFO - transformers.modeling_utils -   loading weights file /content/tmp/CoLA/pytorch_model.bin\n","05/20/2020 05:56:32 - INFO - transformers.configuration_utils -   loading configuration file /content/tmp/CoLA/config.json\n","05/20/2020 05:56:32 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": \"cola\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","05/20/2020 05:56:32 - INFO - transformers.tokenization_utils -   Model name '/content/tmp/CoLA/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming '/content/tmp/CoLA/' is a path, a model identifier, or url to a directory containing tokenizer files.\n","05/20/2020 05:56:32 - INFO - transformers.tokenization_utils -   Didn't find file /content/tmp/CoLA/added_tokens.json. We won't load it.\n","05/20/2020 05:56:32 - INFO - transformers.tokenization_utils -   loading file /content/tmp/CoLA/vocab.txt\n","05/20/2020 05:56:32 - INFO - transformers.tokenization_utils -   loading file None\n","05/20/2020 05:56:32 - INFO - transformers.tokenization_utils -   loading file /content/tmp/CoLA/special_tokens_map.json\n","05/20/2020 05:56:32 - INFO - transformers.tokenization_utils -   loading file /content/tmp/CoLA/tokenizer_config.json\n","05/20/2020 05:56:32 - INFO - transformers.configuration_utils -   loading configuration file /content/tmp/CoLA/config.json\n","05/20/2020 05:56:32 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": \"cola\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","05/20/2020 05:56:32 - INFO - transformers.tokenization_utils -   Model name '/content/tmp/CoLA/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming '/content/tmp/CoLA/' is a path, a model identifier, or url to a directory containing tokenizer files.\n","05/20/2020 05:56:32 - INFO - transformers.tokenization_utils -   Didn't find file /content/tmp/CoLA/added_tokens.json. We won't load it.\n","05/20/2020 05:56:32 - INFO - transformers.tokenization_utils -   loading file /content/tmp/CoLA/vocab.txt\n","05/20/2020 05:56:32 - INFO - transformers.tokenization_utils -   loading file None\n","05/20/2020 05:56:32 - INFO - transformers.tokenization_utils -   loading file /content/tmp/CoLA/special_tokens_map.json\n","05/20/2020 05:56:32 - INFO - transformers.tokenization_utils -   loading file /content/tmp/CoLA/tokenizer_config.json\n","05/20/2020 05:56:32 - INFO - __main__ -   Evaluate the following checkpoints: ['/content/tmp/CoLA/']\n","05/20/2020 05:56:32 - INFO - transformers.configuration_utils -   loading configuration file /content/tmp/CoLA/config.json\n","05/20/2020 05:56:32 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": \"cola\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","05/20/2020 05:56:32 - INFO - transformers.modeling_utils -   loading weights file /content/tmp/CoLA/pytorch_model.bin\n","05/20/2020 05:56:36 - INFO - __main__ -   Creating features from dataset file at /content/glue_data/CoLA\n","05/20/2020 05:56:36 - INFO - transformers.data.processors.glue -   Writing example 0/1043\n","05/20/2020 05:56:36 - INFO - transformers.data.processors.glue -   *** Example ***\n","05/20/2020 05:56:36 - INFO - transformers.data.processors.glue -   guid: dev-0\n","05/20/2020 05:56:36 - INFO - transformers.data.processors.glue -   input_ids: 101 100 11279 8469 1996 9478 3154 1997 1996 5749 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","05/20/2020 05:56:36 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","05/20/2020 05:56:36 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","05/20/2020 05:56:36 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n","05/20/2020 05:56:36 - INFO - transformers.data.processors.glue -   *** Example ***\n","05/20/2020 05:56:36 - INFO - transformers.data.processors.glue -   guid: dev-1\n","05/20/2020 05:56:36 - INFO - transformers.data.processors.glue -   input_ids: 101 100 15871 2081 1996 8164 7683 2058 1996 4139 3240 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","05/20/2020 05:56:36 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","05/20/2020 05:56:36 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","05/20/2020 05:56:36 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n","05/20/2020 05:56:36 - INFO - transformers.data.processors.glue -   *** Example ***\n","05/20/2020 05:56:36 - INFO - transformers.data.processors.glue -   guid: dev-2\n","05/20/2020 05:56:36 - INFO - transformers.data.processors.glue -   input_ids: 101 100 6228 10658 23277 8004 11533 2993 6065 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","05/20/2020 05:56:36 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","05/20/2020 05:56:36 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","05/20/2020 05:56:36 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n","05/20/2020 05:56:36 - INFO - transformers.data.processors.glue -   *** Example ***\n","05/20/2020 05:56:36 - INFO - transformers.data.processors.glue -   guid: dev-3\n","05/20/2020 05:56:36 - INFO - transformers.data.processors.glue -   input_ids: 101 100 2017 2018 8828 2062 1010 2017 2052 2215 2625 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","05/20/2020 05:56:36 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","05/20/2020 05:56:36 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","05/20/2020 05:56:36 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n","05/20/2020 05:56:36 - INFO - transformers.data.processors.glue -   *** Example ***\n","05/20/2020 05:56:36 - INFO - transformers.data.processors.glue -   guid: dev-4\n","05/20/2020 05:56:36 - INFO - transformers.data.processors.glue -   input_ids: 101 100 2017 4521 1996 2087 1010 2017 2215 1996 2560 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","05/20/2020 05:56:36 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","05/20/2020 05:56:36 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","05/20/2020 05:56:36 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n","05/20/2020 05:56:36 - INFO - __main__ -   Saving features into cached file /content/glue_data/CoLA/cached_dev_bert-base-uncased_128_cola\n","05/20/2020 05:56:37 - INFO - __main__ -   ***** Running evaluation  *****\n","05/20/2020 05:56:37 - INFO - __main__ -     Num examples = 1043\n","05/20/2020 05:56:37 - INFO - __main__ -     Batch size = 8\n","Evaluating: 100% 131/131 [00:04<00:00, 29.40it/s]\n","05/20/2020 05:56:41 - INFO - __main__ -   ***** Eval results  *****\n","05/20/2020 05:56:41 - INFO - __main__ -     mcc = 0.4966579188966687\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"c8yN_i71s-YN","colab_type":"text"},"source":["# DensRay"]},{"cell_type":"code","metadata":{"id":"cf_OLbsfzLdd","colab_type":"code","colab":{}},"source":["nlayer=12\n","nsamples = 5000\n","\n","def get_eigvecs_dict(layer=-1):\n","    eigvecs_dict = {}\n","    #-1:apply to all layers\n","    if layer==-1:\n","        for l in range(nlayer):\n","            eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_base_noavg_'+str(nsamples)+'_'+str(l)+'.pt', True)\n","    elif layer ==-2:\n","        for l in range(nlayer):\n","            eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_base_noavg_'+str(nsamples)+'_'+str(l)+'.pt', False)\n","    else:\n","        for l in range(nlayer):\n","            if l==layer:\n","                eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_base_noavg_'+str(nsamples)+'_'+str(l)+'.pt', True)\n","            else:\n","                eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_base_noavg_'+str(nsamples)+'_'+str(l)+'.pt', False)\n","    return eigvecs_dict\n","\n","import pickle\n","for l in range(-2,nlayer):\n","    d = get_eigvecs_dict(l)\n","    df2=open('/content/eigvecs_dict_'+str(l)+'.txt','wb')\n","    pickle.dump(d,df2)\n","    df2.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pTvKqwhis5Zr","colab_type":"code","outputId":"2ca0fae3-fcab-4a7a-afd5-da8397b0eb5b","executionInfo":{"status":"ok","timestamp":1589955226535,"user_tz":-120,"elapsed":4735,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":515}},"source":["!python run_glue_densray.py \\\n","  --model_type bert \\\n","  --model_name_or_path bert-base-uncased \\\n","  --task_name CoLA \\\n","  --eigvecs_dict=/content/eigvecs_dict_-2.txt \\\n","  --do_eval \\\n","  --data_dir /content/glue_data/CoLA \\\n","  --max_seq_length 128 \\\n","  --per_gpu_train_batch_size 64 \\\n","  --learning_rate 2e-5 \\\n","  --num_train_epochs 3.0 \\\n","  --output_dir /content/tmp/CoLA/"],"execution_count":13,"outputs":[{"output_type":"stream","text":["2020-05-20 06:13:42.415872: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","usage: run_glue_densray.py [-h] --data_dir DATA_DIR --model_type MODEL_TYPE\n","                           --model_name_or_path MODEL_NAME_OR_PATH --task_name\n","                           TASK_NAME --output_dir OUTPUT_DIR\n","                           [--config_name CONFIG_NAME]\n","                           [--tokenizer_name TOKENIZER_NAME]\n","                           [--cache_dir CACHE_DIR]\n","                           [--max_seq_length MAX_SEQ_LENGTH] [--do_train]\n","                           [--do_eval] [--evaluate_during_training]\n","                           [--do_lower_case]\n","                           [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]\n","                           [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]\n","                           [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n","                           [--learning_rate LEARNING_RATE]\n","                           [--weight_decay WEIGHT_DECAY]\n","                           [--adam_epsilon ADAM_EPSILON]\n","                           [--max_grad_norm MAX_GRAD_NORM]\n","                           [--num_train_epochs NUM_TRAIN_EPOCHS]\n","                           [--max_steps MAX_STEPS]\n","                           [--warmup_steps WARMUP_STEPS]\n","                           [--logging_steps LOGGING_STEPS]\n","                           [--save_steps SAVE_STEPS] [--eval_all_checkpoints]\n","                           [--no_cuda] [--overwrite_output_dir]\n","                           [--overwrite_cache] [--seed SEED] [--fp16]\n","                           [--fp16_opt_level FP16_OPT_LEVEL]\n","                           [--local_rank LOCAL_RANK] [--server_ip SERVER_IP]\n","                           [--server_port SERVER_PORT]\n","run_glue_densray.py: error: unrecognized arguments: --eigvecs_dict=/content/eigvecs_dict_-2.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oAMHVlc6s5gm","colab_type":"code","outputId":"bd17820b-5e04-4052-f928-b7d8f35aa19e","executionInfo":{"status":"ok","timestamp":1588244062069,"user_tz":-120,"elapsed":69117,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python run_language_modeling_densray.py \\\n","    --output_dir=output \\\n","    --model_type=bert \\\n","    --model_name_or_path=bert-base-uncased \\\n","    --eigvecs_dict=/content/eigvecs_dict_-1.txt \\\n","    --train_data_file=/content/wikitext-2/wiki.train.tokens \\\n","    --do_eval \\\n","    --eval_data_file=/content/wikitext-2/wiki.test.tokens \\\n","    --mlm "],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-04-30 10:53:48.359408: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","04/30/2020 10:53:49 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","04/30/2020 10:53:50 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","04/30/2020 10:53:50 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:53:51 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","04/30/2020 10:53:52 - INFO - densray_bert -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","04/30/2020 10:54:00 - INFO - densray_bert -   Weights of BertForMaskedLM_1 not initialized from pretrained model: ['cls.predictions.decoder.bias']\n","04/30/2020 10:54:00 - INFO - densray_bert -   Weights from pretrained model not used in BertForMaskedLM_1: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","04/30/2020 10:54:00 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=False, eigvecs_dict={'0': ('/content/drive/My Drive/eigvecs_base_noavg_2000_0.pt', True), '1': ('/content/drive/My Drive/eigvecs_base_noavg_2000_1.pt', True), '2': ('/content/drive/My Drive/eigvecs_base_noavg_2000_2.pt', True), '3': ('/content/drive/My Drive/eigvecs_base_noavg_2000_3.pt', True), '4': ('/content/drive/My Drive/eigvecs_base_noavg_2000_4.pt', True), '5': ('/content/drive/My Drive/eigvecs_base_noavg_2000_5.pt', True), '6': ('/content/drive/My Drive/eigvecs_base_noavg_2000_6.pt', True), '7': ('/content/drive/My Drive/eigvecs_base_noavg_2000_7.pt', True), '8': ('/content/drive/My Drive/eigvecs_base_noavg_2000_8.pt', True), '9': ('/content/drive/My Drive/eigvecs_base_noavg_2000_9.pt', True), '10': ('/content/drive/My Drive/eigvecs_base_noavg_2000_10.pt', True), '11': ('/content/drive/My Drive/eigvecs_base_noavg_2000_11.pt', True)}, eval_all_checkpoints=False, eval_data_file='/content/wikitext-2/wiki.test.tokens', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='/content/wikitext-2/wiki.train.tokens', warmup_steps=0, weight_decay=0.0)\n","04/30/2020 10:54:00 - INFO - __main__ -   Evaluate the following checkpoints: ['output']\n","04/30/2020 10:54:00 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","04/30/2020 10:54:00 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:54:00 - INFO - densray_bert -   loading weights file output/pytorch_model.bin\n","04/30/2020 10:54:04 - INFO - __main__ -   ***** Running evaluation  *****\n","04/30/2020 10:54:04 - INFO - __main__ -     Num examples = 586\n","04/30/2020 10:54:04 - INFO - __main__ -     Batch size = 4\n","Evaluating: 100% 147/147 [00:14<00:00,  9.96it/s]\n","04/30/2020 10:54:19 - INFO - __main__ -   ***** Eval results  *****\n","04/30/2020 10:54:19 - INFO - __main__ -     perplexity = tensor(3.7976)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Pq201K72R4OG","colab_type":"code","outputId":"4d02afd4-2620-4328-afe1-20e61969232d","executionInfo":{"status":"ok","timestamp":1588243620553,"user_tz":-120,"elapsed":33896,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python run_language_modeling_densray.py \\\n","    --output_dir=output \\\n","    --model_type=bert \\\n","    --model_name_or_path=bert-base-uncased \\\n","    --eigvecs_dict=/content/eigvecs_dict_0.txt \\\n","    --train_data_file=/content/wikitext-2/wiki.train.tokens \\\n","    --do_eval \\\n","    --eval_data_file=/content/wikitext-2/wiki.test.tokens \\\n","    --mlm "],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-04-30 10:46:29.197270: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","04/30/2020 10:46:30 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","04/30/2020 10:46:31 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","04/30/2020 10:46:31 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:46:32 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","04/30/2020 10:46:33 - INFO - densray_bert -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","04/30/2020 10:46:40 - INFO - densray_bert -   Weights of BertForMaskedLM_1 not initialized from pretrained model: ['cls.predictions.decoder.bias']\n","04/30/2020 10:46:40 - INFO - densray_bert -   Weights from pretrained model not used in BertForMaskedLM_1: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","04/30/2020 10:46:41 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=False, eigvecs_dict={'0': ('/content/drive/My Drive/eigvecs_base_noavg_2000_0.pt', True), '1': ('/content/drive/My Drive/eigvecs_base_noavg_2000_1.pt', False), '2': ('/content/drive/My Drive/eigvecs_base_noavg_2000_2.pt', False), '3': ('/content/drive/My Drive/eigvecs_base_noavg_2000_3.pt', False), '4': ('/content/drive/My Drive/eigvecs_base_noavg_2000_4.pt', False), '5': ('/content/drive/My Drive/eigvecs_base_noavg_2000_5.pt', False), '6': ('/content/drive/My Drive/eigvecs_base_noavg_2000_6.pt', False), '7': ('/content/drive/My Drive/eigvecs_base_noavg_2000_7.pt', False), '8': ('/content/drive/My Drive/eigvecs_base_noavg_2000_8.pt', False), '9': ('/content/drive/My Drive/eigvecs_base_noavg_2000_9.pt', False), '10': ('/content/drive/My Drive/eigvecs_base_noavg_2000_10.pt', False), '11': ('/content/drive/My Drive/eigvecs_base_noavg_2000_11.pt', False)}, eval_all_checkpoints=False, eval_data_file='/content/wikitext-2/wiki.test.tokens', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='/content/wikitext-2/wiki.train.tokens', warmup_steps=0, weight_decay=0.0)\n","04/30/2020 10:46:41 - INFO - __main__ -   Evaluate the following checkpoints: ['output']\n","04/30/2020 10:46:41 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","04/30/2020 10:46:41 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:46:41 - INFO - densray_bert -   loading weights file output/pytorch_model.bin\n","04/30/2020 10:46:45 - INFO - __main__ -   ***** Running evaluation  *****\n","04/30/2020 10:46:45 - INFO - __main__ -     Num examples = 586\n","04/30/2020 10:46:45 - INFO - __main__ -     Batch size = 4\n","Evaluating: 100% 147/147 [00:13<00:00, 10.94it/s]\n","04/30/2020 10:46:58 - INFO - __main__ -   ***** Eval results  *****\n","04/30/2020 10:46:58 - INFO - __main__ -     perplexity = tensor(3.7866)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KcMSyQxBmHhP","colab_type":"code","outputId":"e2ed4ddd-22da-4736-8644-b56de698ad2a","executionInfo":{"status":"ok","timestamp":1588243655075,"user_tz":-120,"elapsed":34519,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python run_language_modeling_densray.py \\\n","    --output_dir=output \\\n","    --model_type=bert \\\n","    --model_name_or_path=bert-base-uncased \\\n","    --eigvecs_dict=/content/eigvecs_dict_1.txt \\\n","    --train_data_file=/content/wikitext-2/wiki.train.tokens \\\n","    --do_eval \\\n","    --eval_data_file=/content/wikitext-2/wiki.test.tokens \\\n","    --mlm \\\n","    --overwrite_output_dir"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-04-30 10:47:03.403224: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","04/30/2020 10:47:04 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","04/30/2020 10:47:05 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","04/30/2020 10:47:05 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:47:06 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","04/30/2020 10:47:07 - INFO - densray_bert -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","04/30/2020 10:47:15 - INFO - densray_bert -   Weights of BertForMaskedLM_1 not initialized from pretrained model: ['cls.predictions.decoder.bias']\n","04/30/2020 10:47:15 - INFO - densray_bert -   Weights from pretrained model not used in BertForMaskedLM_1: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","04/30/2020 10:47:15 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=False, eigvecs_dict={'0': ('/content/drive/My Drive/eigvecs_base_noavg_2000_0.pt', False), '1': ('/content/drive/My Drive/eigvecs_base_noavg_2000_1.pt', True), '2': ('/content/drive/My Drive/eigvecs_base_noavg_2000_2.pt', False), '3': ('/content/drive/My Drive/eigvecs_base_noavg_2000_3.pt', False), '4': ('/content/drive/My Drive/eigvecs_base_noavg_2000_4.pt', False), '5': ('/content/drive/My Drive/eigvecs_base_noavg_2000_5.pt', False), '6': ('/content/drive/My Drive/eigvecs_base_noavg_2000_6.pt', False), '7': ('/content/drive/My Drive/eigvecs_base_noavg_2000_7.pt', False), '8': ('/content/drive/My Drive/eigvecs_base_noavg_2000_8.pt', False), '9': ('/content/drive/My Drive/eigvecs_base_noavg_2000_9.pt', False), '10': ('/content/drive/My Drive/eigvecs_base_noavg_2000_10.pt', False), '11': ('/content/drive/My Drive/eigvecs_base_noavg_2000_11.pt', False)}, eval_all_checkpoints=False, eval_data_file='/content/wikitext-2/wiki.test.tokens', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='/content/wikitext-2/wiki.train.tokens', warmup_steps=0, weight_decay=0.0)\n","04/30/2020 10:47:15 - INFO - __main__ -   Evaluate the following checkpoints: ['output']\n","04/30/2020 10:47:15 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","04/30/2020 10:47:15 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:47:15 - INFO - densray_bert -   loading weights file output/pytorch_model.bin\n","04/30/2020 10:47:19 - INFO - __main__ -   ***** Running evaluation  *****\n","04/30/2020 10:47:19 - INFO - __main__ -     Num examples = 586\n","04/30/2020 10:47:19 - INFO - __main__ -     Batch size = 4\n","Evaluating: 100% 147/147 [00:13<00:00, 10.92it/s]\n","04/30/2020 10:47:33 - INFO - __main__ -   ***** Eval results  *****\n","04/30/2020 10:47:33 - INFO - __main__ -     perplexity = tensor(3.7913)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_CVwEoQPsl0H","colab_type":"code","outputId":"362043bf-ea60-41ac-d7ef-cd1267ca536c","executionInfo":{"status":"ok","timestamp":1588243690726,"user_tz":-120,"elapsed":35649,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python run_language_modeling_densray.py \\\n","    --output_dir=output \\\n","    --model_type=bert \\\n","    --model_name_or_path=bert-base-uncased \\\n","    --eigvecs_dict=/content/eigvecs_dict_2.txt \\\n","    --train_data_file=/content/wikitext-2/wiki.train.tokens \\\n","    --do_eval \\\n","    --eval_data_file=/content/wikitext-2/wiki.test.tokens \\\n","    --mlm \\\n","    --overwrite_output_dir"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-04-30 10:47:37.855878: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","04/30/2020 10:47:39 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","04/30/2020 10:47:40 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","04/30/2020 10:47:40 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:47:40 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","04/30/2020 10:47:41 - INFO - densray_bert -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","04/30/2020 10:47:49 - INFO - densray_bert -   Weights of BertForMaskedLM_1 not initialized from pretrained model: ['cls.predictions.decoder.bias']\n","04/30/2020 10:47:49 - INFO - densray_bert -   Weights from pretrained model not used in BertForMaskedLM_1: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","04/30/2020 10:47:49 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=False, eigvecs_dict={'0': ('/content/drive/My Drive/eigvecs_base_noavg_2000_0.pt', False), '1': ('/content/drive/My Drive/eigvecs_base_noavg_2000_1.pt', False), '2': ('/content/drive/My Drive/eigvecs_base_noavg_2000_2.pt', True), '3': ('/content/drive/My Drive/eigvecs_base_noavg_2000_3.pt', False), '4': ('/content/drive/My Drive/eigvecs_base_noavg_2000_4.pt', False), '5': ('/content/drive/My Drive/eigvecs_base_noavg_2000_5.pt', False), '6': ('/content/drive/My Drive/eigvecs_base_noavg_2000_6.pt', False), '7': ('/content/drive/My Drive/eigvecs_base_noavg_2000_7.pt', False), '8': ('/content/drive/My Drive/eigvecs_base_noavg_2000_8.pt', False), '9': ('/content/drive/My Drive/eigvecs_base_noavg_2000_9.pt', False), '10': ('/content/drive/My Drive/eigvecs_base_noavg_2000_10.pt', False), '11': ('/content/drive/My Drive/eigvecs_base_noavg_2000_11.pt', False)}, eval_all_checkpoints=False, eval_data_file='/content/wikitext-2/wiki.test.tokens', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='/content/wikitext-2/wiki.train.tokens', warmup_steps=0, weight_decay=0.0)\n","04/30/2020 10:47:49 - INFO - __main__ -   Evaluate the following checkpoints: ['output']\n","04/30/2020 10:47:49 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","04/30/2020 10:47:49 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:47:49 - INFO - densray_bert -   loading weights file output/pytorch_model.bin\n","04/30/2020 10:47:54 - INFO - __main__ -   ***** Running evaluation  *****\n","04/30/2020 10:47:54 - INFO - __main__ -     Num examples = 586\n","04/30/2020 10:47:54 - INFO - __main__ -     Batch size = 4\n","Evaluating: 100% 147/147 [00:13<00:00, 10.94it/s]\n","04/30/2020 10:48:07 - INFO - __main__ -   ***** Eval results  *****\n","04/30/2020 10:48:07 - INFO - __main__ -     perplexity = tensor(3.7849)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9E9szgF8snIS","colab_type":"code","outputId":"028a6256-1f90-4fbc-eec1-957c4d8923df","executionInfo":{"status":"ok","timestamp":1588243726467,"user_tz":-120,"elapsed":34845,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python run_language_modeling_densray.py \\\n","    --output_dir=output \\\n","    --model_type=bert \\\n","    --model_name_or_path=bert-base-uncased \\\n","    --eigvecs_dict=/content/eigvecs_dict_3.txt \\\n","    --train_data_file=/content/wikitext-2/wiki.train.tokens \\\n","    --do_eval \\\n","    --eval_data_file=/content/wikitext-2/wiki.test.tokens \\\n","    --mlm \\\n","    --overwrite_output_dir"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-04-30 10:48:14.590278: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","04/30/2020 10:48:16 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","04/30/2020 10:48:16 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","04/30/2020 10:48:16 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:48:17 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","04/30/2020 10:48:18 - INFO - densray_bert -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","04/30/2020 10:48:26 - INFO - densray_bert -   Weights of BertForMaskedLM_1 not initialized from pretrained model: ['cls.predictions.decoder.bias']\n","04/30/2020 10:48:26 - INFO - densray_bert -   Weights from pretrained model not used in BertForMaskedLM_1: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","04/30/2020 10:48:26 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=False, eigvecs_dict={'0': ('/content/drive/My Drive/eigvecs_base_noavg_2000_0.pt', False), '1': ('/content/drive/My Drive/eigvecs_base_noavg_2000_1.pt', False), '2': ('/content/drive/My Drive/eigvecs_base_noavg_2000_2.pt', False), '3': ('/content/drive/My Drive/eigvecs_base_noavg_2000_3.pt', True), '4': ('/content/drive/My Drive/eigvecs_base_noavg_2000_4.pt', False), '5': ('/content/drive/My Drive/eigvecs_base_noavg_2000_5.pt', False), '6': ('/content/drive/My Drive/eigvecs_base_noavg_2000_6.pt', False), '7': ('/content/drive/My Drive/eigvecs_base_noavg_2000_7.pt', False), '8': ('/content/drive/My Drive/eigvecs_base_noavg_2000_8.pt', False), '9': ('/content/drive/My Drive/eigvecs_base_noavg_2000_9.pt', False), '10': ('/content/drive/My Drive/eigvecs_base_noavg_2000_10.pt', False), '11': ('/content/drive/My Drive/eigvecs_base_noavg_2000_11.pt', False)}, eval_all_checkpoints=False, eval_data_file='/content/wikitext-2/wiki.test.tokens', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='/content/wikitext-2/wiki.train.tokens', warmup_steps=0, weight_decay=0.0)\n","04/30/2020 10:48:26 - INFO - __main__ -   Evaluate the following checkpoints: ['output']\n","04/30/2020 10:48:26 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","04/30/2020 10:48:26 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:48:26 - INFO - densray_bert -   loading weights file output/pytorch_model.bin\n","04/30/2020 10:48:30 - INFO - __main__ -   ***** Running evaluation  *****\n","04/30/2020 10:48:30 - INFO - __main__ -     Num examples = 586\n","04/30/2020 10:48:30 - INFO - __main__ -     Batch size = 4\n","Evaluating: 100% 147/147 [00:13<00:00, 10.96it/s]\n","04/30/2020 10:48:44 - INFO - __main__ -   ***** Eval results  *****\n","04/30/2020 10:48:44 - INFO - __main__ -     perplexity = tensor(3.8068)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Uu-OI30tsoPe","colab_type":"code","outputId":"a2b84301-c8ee-41b2-b412-628a460ded85","executionInfo":{"status":"ok","timestamp":1588243759251,"user_tz":-120,"elapsed":67624,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python run_language_modeling_densray.py \\\n","    --output_dir=output \\\n","    --model_type=bert \\\n","    --model_name_or_path=bert-base-uncased \\\n","    --eigvecs_dict=/content/eigvecs_dict_4.txt \\\n","    --train_data_file=/content/wikitext-2/wiki.train.tokens \\\n","    --do_eval \\\n","    --eval_data_file=/content/wikitext-2/wiki.test.tokens \\\n","    --mlm \\\n","    --overwrite_output_dir"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-04-30 10:48:47.537841: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","04/30/2020 10:48:49 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","04/30/2020 10:48:49 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","04/30/2020 10:48:49 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:48:50 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","04/30/2020 10:48:51 - INFO - densray_bert -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","04/30/2020 10:48:59 - INFO - densray_bert -   Weights of BertForMaskedLM_1 not initialized from pretrained model: ['cls.predictions.decoder.bias']\n","04/30/2020 10:48:59 - INFO - densray_bert -   Weights from pretrained model not used in BertForMaskedLM_1: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","04/30/2020 10:48:59 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=False, eigvecs_dict={'0': ('/content/drive/My Drive/eigvecs_base_noavg_2000_0.pt', False), '1': ('/content/drive/My Drive/eigvecs_base_noavg_2000_1.pt', False), '2': ('/content/drive/My Drive/eigvecs_base_noavg_2000_2.pt', False), '3': ('/content/drive/My Drive/eigvecs_base_noavg_2000_3.pt', False), '4': ('/content/drive/My Drive/eigvecs_base_noavg_2000_4.pt', True), '5': ('/content/drive/My Drive/eigvecs_base_noavg_2000_5.pt', False), '6': ('/content/drive/My Drive/eigvecs_base_noavg_2000_6.pt', False), '7': ('/content/drive/My Drive/eigvecs_base_noavg_2000_7.pt', False), '8': ('/content/drive/My Drive/eigvecs_base_noavg_2000_8.pt', False), '9': ('/content/drive/My Drive/eigvecs_base_noavg_2000_9.pt', False), '10': ('/content/drive/My Drive/eigvecs_base_noavg_2000_10.pt', False), '11': ('/content/drive/My Drive/eigvecs_base_noavg_2000_11.pt', False)}, eval_all_checkpoints=False, eval_data_file='/content/wikitext-2/wiki.test.tokens', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='/content/wikitext-2/wiki.train.tokens', warmup_steps=0, weight_decay=0.0)\n","04/30/2020 10:48:59 - INFO - __main__ -   Evaluate the following checkpoints: ['output']\n","04/30/2020 10:48:59 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","04/30/2020 10:48:59 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:48:59 - INFO - densray_bert -   loading weights file output/pytorch_model.bin\n","04/30/2020 10:49:03 - INFO - __main__ -   ***** Running evaluation  *****\n","04/30/2020 10:49:03 - INFO - __main__ -     Num examples = 586\n","04/30/2020 10:49:03 - INFO - __main__ -     Batch size = 4\n","Evaluating: 100% 147/147 [00:13<00:00, 10.94it/s]\n","04/30/2020 10:49:17 - INFO - __main__ -   ***** Eval results  *****\n","04/30/2020 10:49:17 - INFO - __main__ -     perplexity = tensor(3.8226)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jkD4ZHnqsp4c","colab_type":"code","outputId":"9e44a51a-ab23-4cd5-c466-070c538e3cf4","executionInfo":{"status":"ok","timestamp":1588243791984,"user_tz":-120,"elapsed":100353,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python run_language_modeling_densray.py \\\n","    --output_dir=output \\\n","    --model_type=bert \\\n","    --model_name_or_path=bert-base-uncased \\\n","    --eigvecs_dict=/content/eigvecs_dict_5.txt \\\n","    --train_data_file=/content/wikitext-2/wiki.train.tokens \\\n","    --do_eval \\\n","    --eval_data_file=/content/wikitext-2/wiki.test.tokens \\\n","    --mlm \\\n","    --overwrite_output_dir"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-04-30 10:49:20.750483: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","04/30/2020 10:49:22 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","04/30/2020 10:49:22 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","04/30/2020 10:49:22 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:49:23 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","04/30/2020 10:49:24 - INFO - densray_bert -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","04/30/2020 10:49:32 - INFO - densray_bert -   Weights of BertForMaskedLM_1 not initialized from pretrained model: ['cls.predictions.decoder.bias']\n","04/30/2020 10:49:32 - INFO - densray_bert -   Weights from pretrained model not used in BertForMaskedLM_1: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","04/30/2020 10:49:32 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=False, eigvecs_dict={'0': ('/content/drive/My Drive/eigvecs_base_noavg_2000_0.pt', False), '1': ('/content/drive/My Drive/eigvecs_base_noavg_2000_1.pt', False), '2': ('/content/drive/My Drive/eigvecs_base_noavg_2000_2.pt', False), '3': ('/content/drive/My Drive/eigvecs_base_noavg_2000_3.pt', False), '4': ('/content/drive/My Drive/eigvecs_base_noavg_2000_4.pt', False), '5': ('/content/drive/My Drive/eigvecs_base_noavg_2000_5.pt', True), '6': ('/content/drive/My Drive/eigvecs_base_noavg_2000_6.pt', False), '7': ('/content/drive/My Drive/eigvecs_base_noavg_2000_7.pt', False), '8': ('/content/drive/My Drive/eigvecs_base_noavg_2000_8.pt', False), '9': ('/content/drive/My Drive/eigvecs_base_noavg_2000_9.pt', False), '10': ('/content/drive/My Drive/eigvecs_base_noavg_2000_10.pt', False), '11': ('/content/drive/My Drive/eigvecs_base_noavg_2000_11.pt', False)}, eval_all_checkpoints=False, eval_data_file='/content/wikitext-2/wiki.test.tokens', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='/content/wikitext-2/wiki.train.tokens', warmup_steps=0, weight_decay=0.0)\n","04/30/2020 10:49:32 - INFO - __main__ -   Evaluate the following checkpoints: ['output']\n","04/30/2020 10:49:32 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","04/30/2020 10:49:32 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:49:32 - INFO - densray_bert -   loading weights file output/pytorch_model.bin\n","04/30/2020 10:49:36 - INFO - __main__ -   ***** Running evaluation  *****\n","04/30/2020 10:49:36 - INFO - __main__ -     Num examples = 586\n","04/30/2020 10:49:36 - INFO - __main__ -     Batch size = 4\n","Evaluating: 100% 147/147 [00:13<00:00, 10.94it/s]\n","04/30/2020 10:49:50 - INFO - __main__ -   ***** Eval results  *****\n","04/30/2020 10:49:50 - INFO - __main__ -     perplexity = tensor(3.8504)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IUx5lU-ksrWy","colab_type":"code","outputId":"de3c7e32-dedc-4797-9f37-d93d7b71507a","executionInfo":{"status":"ok","timestamp":1588243826355,"user_tz":-120,"elapsed":34356,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python run_language_modeling_densray.py \\\n","    --output_dir=output \\\n","    --model_type=bert \\\n","    --model_name_or_path=bert-base-uncased \\\n","    --eigvecs_dict=/content/eigvecs_dict_6.txt \\\n","    --train_data_file=/content/wikitext-2/wiki.train.tokens \\\n","    --do_eval \\\n","    --eval_data_file=/content/wikitext-2/wiki.test.tokens \\\n","    --mlm \\\n","    --overwrite_output_dir"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-04-30 10:49:54.689178: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","04/30/2020 10:49:56 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","04/30/2020 10:49:56 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","04/30/2020 10:49:56 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:49:57 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","04/30/2020 10:49:58 - INFO - densray_bert -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","04/30/2020 10:50:06 - INFO - densray_bert -   Weights of BertForMaskedLM_1 not initialized from pretrained model: ['cls.predictions.decoder.bias']\n","04/30/2020 10:50:06 - INFO - densray_bert -   Weights from pretrained model not used in BertForMaskedLM_1: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","04/30/2020 10:50:06 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=False, eigvecs_dict={'0': ('/content/drive/My Drive/eigvecs_base_noavg_2000_0.pt', False), '1': ('/content/drive/My Drive/eigvecs_base_noavg_2000_1.pt', False), '2': ('/content/drive/My Drive/eigvecs_base_noavg_2000_2.pt', False), '3': ('/content/drive/My Drive/eigvecs_base_noavg_2000_3.pt', False), '4': ('/content/drive/My Drive/eigvecs_base_noavg_2000_4.pt', False), '5': ('/content/drive/My Drive/eigvecs_base_noavg_2000_5.pt', False), '6': ('/content/drive/My Drive/eigvecs_base_noavg_2000_6.pt', True), '7': ('/content/drive/My Drive/eigvecs_base_noavg_2000_7.pt', False), '8': ('/content/drive/My Drive/eigvecs_base_noavg_2000_8.pt', False), '9': ('/content/drive/My Drive/eigvecs_base_noavg_2000_9.pt', False), '10': ('/content/drive/My Drive/eigvecs_base_noavg_2000_10.pt', False), '11': ('/content/drive/My Drive/eigvecs_base_noavg_2000_11.pt', False)}, eval_all_checkpoints=False, eval_data_file='/content/wikitext-2/wiki.test.tokens', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='/content/wikitext-2/wiki.train.tokens', warmup_steps=0, weight_decay=0.0)\n","04/30/2020 10:50:06 - INFO - __main__ -   Evaluate the following checkpoints: ['output']\n","04/30/2020 10:50:06 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","04/30/2020 10:50:06 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:50:06 - INFO - densray_bert -   loading weights file output/pytorch_model.bin\n","04/30/2020 10:50:10 - INFO - __main__ -   ***** Running evaluation  *****\n","04/30/2020 10:50:10 - INFO - __main__ -     Num examples = 586\n","04/30/2020 10:50:10 - INFO - __main__ -     Batch size = 4\n","Evaluating: 100% 147/147 [00:13<00:00, 10.94it/s]\n","04/30/2020 10:50:24 - INFO - __main__ -   ***** Eval results  *****\n","04/30/2020 10:50:24 - INFO - __main__ -     perplexity = tensor(3.8655)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DOZLvBW1ssW8","colab_type":"code","outputId":"f9d6a2a6-4914-49fb-f4d9-957bf0ff16f7","executionInfo":{"status":"ok","timestamp":1588243858695,"user_tz":-120,"elapsed":66689,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python run_language_modeling_densray.py \\\n","    --output_dir=output \\\n","    --model_type=bert \\\n","    --model_name_or_path=bert-base-uncased \\\n","    --eigvecs_dict=/content/eigvecs_dict_7.txt \\\n","    --train_data_file=/content/wikitext-2/wiki.train.tokens \\\n","    --do_eval \\\n","    --eval_data_file=/content/wikitext-2/wiki.test.tokens \\\n","    --mlm \\\n","    --overwrite_output_dir"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-04-30 10:50:27.675082: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","04/30/2020 10:50:29 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","04/30/2020 10:50:29 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","04/30/2020 10:50:29 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:50:30 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","04/30/2020 10:50:31 - INFO - densray_bert -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","04/30/2020 10:50:39 - INFO - densray_bert -   Weights of BertForMaskedLM_1 not initialized from pretrained model: ['cls.predictions.decoder.bias']\n","04/30/2020 10:50:39 - INFO - densray_bert -   Weights from pretrained model not used in BertForMaskedLM_1: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","04/30/2020 10:50:39 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=False, eigvecs_dict={'0': ('/content/drive/My Drive/eigvecs_base_noavg_2000_0.pt', False), '1': ('/content/drive/My Drive/eigvecs_base_noavg_2000_1.pt', False), '2': ('/content/drive/My Drive/eigvecs_base_noavg_2000_2.pt', False), '3': ('/content/drive/My Drive/eigvecs_base_noavg_2000_3.pt', False), '4': ('/content/drive/My Drive/eigvecs_base_noavg_2000_4.pt', False), '5': ('/content/drive/My Drive/eigvecs_base_noavg_2000_5.pt', False), '6': ('/content/drive/My Drive/eigvecs_base_noavg_2000_6.pt', False), '7': ('/content/drive/My Drive/eigvecs_base_noavg_2000_7.pt', True), '8': ('/content/drive/My Drive/eigvecs_base_noavg_2000_8.pt', False), '9': ('/content/drive/My Drive/eigvecs_base_noavg_2000_9.pt', False), '10': ('/content/drive/My Drive/eigvecs_base_noavg_2000_10.pt', False), '11': ('/content/drive/My Drive/eigvecs_base_noavg_2000_11.pt', False)}, eval_all_checkpoints=False, eval_data_file='/content/wikitext-2/wiki.test.tokens', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='/content/wikitext-2/wiki.train.tokens', warmup_steps=0, weight_decay=0.0)\n","04/30/2020 10:50:39 - INFO - __main__ -   Evaluate the following checkpoints: ['output']\n","04/30/2020 10:50:39 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","04/30/2020 10:50:39 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:50:39 - INFO - densray_bert -   loading weights file output/pytorch_model.bin\n","04/30/2020 10:50:43 - INFO - __main__ -   ***** Running evaluation  *****\n","04/30/2020 10:50:43 - INFO - __main__ -     Num examples = 586\n","04/30/2020 10:50:43 - INFO - __main__ -     Batch size = 4\n","Evaluating: 100% 147/147 [00:13<00:00, 10.93it/s]\n","04/30/2020 10:50:57 - INFO - __main__ -   ***** Eval results  *****\n","04/30/2020 10:50:57 - INFO - __main__ -     perplexity = tensor(3.8361)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4cEFjnRostPv","colab_type":"code","outputId":"e67252b1-3053-4794-c746-422fff325749","executionInfo":{"status":"ok","timestamp":1588243891961,"user_tz":-120,"elapsed":99952,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python run_language_modeling_densray.py \\\n","    --output_dir=output \\\n","    --model_type=bert \\\n","    --model_name_or_path=bert-base-uncased \\\n","    --eigvecs_dict=/content/eigvecs_dict_8.txt \\\n","    --train_data_file=/content/wikitext-2/wiki.train.tokens \\\n","    --do_eval \\\n","    --eval_data_file=/content/wikitext-2/wiki.test.tokens \\\n","    --mlm \\\n","    --overwrite_output_dir"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-04-30 10:51:00.118073: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","04/30/2020 10:51:01 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","04/30/2020 10:51:02 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","04/30/2020 10:51:02 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:51:03 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","04/30/2020 10:51:03 - INFO - densray_bert -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","04/30/2020 10:51:11 - INFO - densray_bert -   Weights of BertForMaskedLM_1 not initialized from pretrained model: ['cls.predictions.decoder.bias']\n","04/30/2020 10:51:11 - INFO - densray_bert -   Weights from pretrained model not used in BertForMaskedLM_1: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","04/30/2020 10:51:11 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=False, eigvecs_dict={'0': ('/content/drive/My Drive/eigvecs_base_noavg_2000_0.pt', False), '1': ('/content/drive/My Drive/eigvecs_base_noavg_2000_1.pt', False), '2': ('/content/drive/My Drive/eigvecs_base_noavg_2000_2.pt', False), '3': ('/content/drive/My Drive/eigvecs_base_noavg_2000_3.pt', False), '4': ('/content/drive/My Drive/eigvecs_base_noavg_2000_4.pt', False), '5': ('/content/drive/My Drive/eigvecs_base_noavg_2000_5.pt', False), '6': ('/content/drive/My Drive/eigvecs_base_noavg_2000_6.pt', False), '7': ('/content/drive/My Drive/eigvecs_base_noavg_2000_7.pt', False), '8': ('/content/drive/My Drive/eigvecs_base_noavg_2000_8.pt', True), '9': ('/content/drive/My Drive/eigvecs_base_noavg_2000_9.pt', False), '10': ('/content/drive/My Drive/eigvecs_base_noavg_2000_10.pt', False), '11': ('/content/drive/My Drive/eigvecs_base_noavg_2000_11.pt', False)}, eval_all_checkpoints=False, eval_data_file='/content/wikitext-2/wiki.test.tokens', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='/content/wikitext-2/wiki.train.tokens', warmup_steps=0, weight_decay=0.0)\n","04/30/2020 10:51:11 - INFO - __main__ -   Evaluate the following checkpoints: ['output']\n","04/30/2020 10:51:11 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","04/30/2020 10:51:11 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:51:11 - INFO - densray_bert -   loading weights file output/pytorch_model.bin\n","04/30/2020 10:51:16 - INFO - __main__ -   ***** Running evaluation  *****\n","04/30/2020 10:51:16 - INFO - __main__ -     Num examples = 586\n","04/30/2020 10:51:16 - INFO - __main__ -     Batch size = 4\n","Evaluating: 100% 147/147 [00:13<00:00, 10.95it/s]\n","04/30/2020 10:51:29 - INFO - __main__ -   ***** Eval results  *****\n","04/30/2020 10:51:29 - INFO - __main__ -     perplexity = tensor(3.7869)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"B3O3QSuUsuGa","colab_type":"code","outputId":"dfcda4d5-0c40-4591-ce9e-18c585e1630e","executionInfo":{"status":"ok","timestamp":1588243924546,"user_tz":-120,"elapsed":132534,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python run_language_modeling_densray.py \\\n","    --output_dir=output \\\n","    --model_type=bert \\\n","    --model_name_or_path=bert-base-uncased \\\n","    --eigvecs_dict=/content/eigvecs_dict_9.txt \\\n","    --train_data_file=/content/wikitext-2/wiki.train.tokens \\\n","    --do_eval \\\n","    --eval_data_file=/content/wikitext-2/wiki.test.tokens \\\n","    --mlm \\\n","    --overwrite_output_dir"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-04-30 10:51:33.097771: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","04/30/2020 10:51:34 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","04/30/2020 10:51:35 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","04/30/2020 10:51:35 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:51:36 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","04/30/2020 10:51:36 - INFO - densray_bert -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","04/30/2020 10:51:44 - INFO - densray_bert -   Weights of BertForMaskedLM_1 not initialized from pretrained model: ['cls.predictions.decoder.bias']\n","04/30/2020 10:51:44 - INFO - densray_bert -   Weights from pretrained model not used in BertForMaskedLM_1: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","04/30/2020 10:51:44 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=False, eigvecs_dict={'0': ('/content/drive/My Drive/eigvecs_base_noavg_2000_0.pt', False), '1': ('/content/drive/My Drive/eigvecs_base_noavg_2000_1.pt', False), '2': ('/content/drive/My Drive/eigvecs_base_noavg_2000_2.pt', False), '3': ('/content/drive/My Drive/eigvecs_base_noavg_2000_3.pt', False), '4': ('/content/drive/My Drive/eigvecs_base_noavg_2000_4.pt', False), '5': ('/content/drive/My Drive/eigvecs_base_noavg_2000_5.pt', False), '6': ('/content/drive/My Drive/eigvecs_base_noavg_2000_6.pt', False), '7': ('/content/drive/My Drive/eigvecs_base_noavg_2000_7.pt', False), '8': ('/content/drive/My Drive/eigvecs_base_noavg_2000_8.pt', False), '9': ('/content/drive/My Drive/eigvecs_base_noavg_2000_9.pt', True), '10': ('/content/drive/My Drive/eigvecs_base_noavg_2000_10.pt', False), '11': ('/content/drive/My Drive/eigvecs_base_noavg_2000_11.pt', False)}, eval_all_checkpoints=False, eval_data_file='/content/wikitext-2/wiki.test.tokens', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='/content/wikitext-2/wiki.train.tokens', warmup_steps=0, weight_decay=0.0)\n","04/30/2020 10:51:44 - INFO - __main__ -   Evaluate the following checkpoints: ['output']\n","04/30/2020 10:51:44 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","04/30/2020 10:51:44 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:51:44 - INFO - densray_bert -   loading weights file output/pytorch_model.bin\n","04/30/2020 10:51:49 - INFO - __main__ -   ***** Running evaluation  *****\n","04/30/2020 10:51:49 - INFO - __main__ -     Num examples = 586\n","04/30/2020 10:51:49 - INFO - __main__ -     Batch size = 4\n","Evaluating: 100% 147/147 [00:13<00:00, 10.91it/s]\n","04/30/2020 10:52:02 - INFO - __main__ -   ***** Eval results  *****\n","04/30/2020 10:52:02 - INFO - __main__ -     perplexity = tensor(3.7765)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4zad5YoQsvA5","colab_type":"code","outputId":"5d995216-29d5-40ba-936c-999c0a2f0fa0","executionInfo":{"status":"ok","timestamp":1588243957205,"user_tz":-120,"elapsed":165188,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python run_language_modeling_densray.py \\\n","    --output_dir=output \\\n","    --model_type=bert \\\n","    --model_name_or_path=bert-base-uncased \\\n","    --eigvecs_dict=/content/eigvecs_dict_10.txt \\\n","    --train_data_file=/content/wikitext-2/wiki.train.tokens \\\n","    --do_eval \\\n","    --eval_data_file=/content/wikitext-2/wiki.test.tokens \\\n","    --mlm \\\n","    --overwrite_output_dir"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-04-30 10:52:06.149103: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","04/30/2020 10:52:07 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","04/30/2020 10:52:08 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","04/30/2020 10:52:08 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:52:09 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","04/30/2020 10:52:09 - INFO - densray_bert -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","04/30/2020 10:52:17 - INFO - densray_bert -   Weights of BertForMaskedLM_1 not initialized from pretrained model: ['cls.predictions.decoder.bias']\n","04/30/2020 10:52:17 - INFO - densray_bert -   Weights from pretrained model not used in BertForMaskedLM_1: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","04/30/2020 10:52:17 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=False, eigvecs_dict={'0': ('/content/drive/My Drive/eigvecs_base_noavg_2000_0.pt', False), '1': ('/content/drive/My Drive/eigvecs_base_noavg_2000_1.pt', False), '2': ('/content/drive/My Drive/eigvecs_base_noavg_2000_2.pt', False), '3': ('/content/drive/My Drive/eigvecs_base_noavg_2000_3.pt', False), '4': ('/content/drive/My Drive/eigvecs_base_noavg_2000_4.pt', False), '5': ('/content/drive/My Drive/eigvecs_base_noavg_2000_5.pt', False), '6': ('/content/drive/My Drive/eigvecs_base_noavg_2000_6.pt', False), '7': ('/content/drive/My Drive/eigvecs_base_noavg_2000_7.pt', False), '8': ('/content/drive/My Drive/eigvecs_base_noavg_2000_8.pt', False), '9': ('/content/drive/My Drive/eigvecs_base_noavg_2000_9.pt', False), '10': ('/content/drive/My Drive/eigvecs_base_noavg_2000_10.pt', True), '11': ('/content/drive/My Drive/eigvecs_base_noavg_2000_11.pt', False)}, eval_all_checkpoints=False, eval_data_file='/content/wikitext-2/wiki.test.tokens', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='/content/wikitext-2/wiki.train.tokens', warmup_steps=0, weight_decay=0.0)\n","04/30/2020 10:52:17 - INFO - __main__ -   Evaluate the following checkpoints: ['output']\n","04/30/2020 10:52:17 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","04/30/2020 10:52:17 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:52:17 - INFO - densray_bert -   loading weights file output/pytorch_model.bin\n","04/30/2020 10:52:22 - INFO - __main__ -   ***** Running evaluation  *****\n","04/30/2020 10:52:22 - INFO - __main__ -     Num examples = 586\n","04/30/2020 10:52:22 - INFO - __main__ -     Batch size = 4\n","Evaluating: 100% 147/147 [00:13<00:00, 10.89it/s]\n","04/30/2020 10:52:35 - INFO - __main__ -   ***** Eval results  *****\n","04/30/2020 10:52:35 - INFO - __main__ -     perplexity = tensor(3.7754)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ah3zIePisv7C","colab_type":"code","outputId":"977e4235-c324-4571-86e8-ea7964b77de3","executionInfo":{"status":"ok","timestamp":1588243990170,"user_tz":-120,"elapsed":198149,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python run_language_modeling_densray.py \\\n","    --output_dir=output \\\n","    --model_type=bert \\\n","    --model_name_or_path=bert-base-uncased \\\n","    --eigvecs_dict=/content/eigvecs_dict_11.txt \\\n","    --train_data_file=/content/wikitext-2/wiki.train.tokens \\\n","    --do_eval \\\n","    --eval_data_file=/content/wikitext-2/wiki.test.tokens \\\n","    --mlm \\\n","    --overwrite_output_dir"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-04-30 10:52:38.728511: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","04/30/2020 10:52:40 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","04/30/2020 10:52:40 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","04/30/2020 10:52:40 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:52:41 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","04/30/2020 10:52:42 - INFO - densray_bert -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","04/30/2020 10:52:50 - INFO - densray_bert -   Weights of BertForMaskedLM_1 not initialized from pretrained model: ['cls.predictions.decoder.bias']\n","04/30/2020 10:52:50 - INFO - densray_bert -   Weights from pretrained model not used in BertForMaskedLM_1: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","04/30/2020 10:52:50 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=False, eigvecs_dict={'0': ('/content/drive/My Drive/eigvecs_base_noavg_2000_0.pt', False), '1': ('/content/drive/My Drive/eigvecs_base_noavg_2000_1.pt', False), '2': ('/content/drive/My Drive/eigvecs_base_noavg_2000_2.pt', False), '3': ('/content/drive/My Drive/eigvecs_base_noavg_2000_3.pt', False), '4': ('/content/drive/My Drive/eigvecs_base_noavg_2000_4.pt', False), '5': ('/content/drive/My Drive/eigvecs_base_noavg_2000_5.pt', False), '6': ('/content/drive/My Drive/eigvecs_base_noavg_2000_6.pt', False), '7': ('/content/drive/My Drive/eigvecs_base_noavg_2000_7.pt', False), '8': ('/content/drive/My Drive/eigvecs_base_noavg_2000_8.pt', False), '9': ('/content/drive/My Drive/eigvecs_base_noavg_2000_9.pt', False), '10': ('/content/drive/My Drive/eigvecs_base_noavg_2000_10.pt', False), '11': ('/content/drive/My Drive/eigvecs_base_noavg_2000_11.pt', True)}, eval_all_checkpoints=False, eval_data_file='/content/wikitext-2/wiki.test.tokens', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='/content/wikitext-2/wiki.train.tokens', warmup_steps=0, weight_decay=0.0)\n","04/30/2020 10:52:50 - INFO - __main__ -   Evaluate the following checkpoints: ['output']\n","04/30/2020 10:52:50 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","04/30/2020 10:52:50 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:52:50 - INFO - densray_bert -   loading weights file output/pytorch_model.bin\n","04/30/2020 10:52:54 - INFO - __main__ -   ***** Running evaluation  *****\n","04/30/2020 10:52:54 - INFO - __main__ -     Num examples = 586\n","04/30/2020 10:52:54 - INFO - __main__ -     Batch size = 4\n","Evaluating: 100% 147/147 [00:13<00:00, 10.92it/s]\n","04/30/2020 10:53:08 - INFO - __main__ -   ***** Eval results  *****\n","04/30/2020 10:53:08 - INFO - __main__ -     perplexity = tensor(3.7796)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-VRdYR3RsxSS","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}