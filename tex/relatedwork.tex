\subsection{Quantifying Gender Bias}
A typical way to measure gender bias is to evaluate on \textbf{downstream tasks}. For coreference resolution, \citet{zhao2018gender} designed Winobias and \citet{rudinger2018gender} designed Winogender schemas. Different from WinoBias, Winogender schemas include gender-neutral pronouns which WinoBias doesn't, and one Winogender schema has one occupational mention and one "other participant" mention while WinoBias has two occupational mention. \citet{webster2018mind} released GAP, a balanced corpus of Gendered Ambiguous Pronouns, which measured gender bias as the ratio of F1 score on masculine to F1 score on feminine. However the bias ratios were too close to 1 \citep{Chada_2019, Attree_2019} to presented gender bias obviously. For sentiment analysis, Equity Evaluation Corpus (EEC) \citep{Kiritchenko_2018} was designed to measure gender bias by the difference in emotional intensity predictions between gender-swapped sentences.

An alternative way to measure gender bias is based on \textbf{association tests}, which originated from sociological research. \citet{greenwald1998measuring} proposed the Implicit Association Test (IAT) to quantified societal bias. In the IAT, response times were recorded when subjects were asked to match two concepts. For example, subjects were asked to match black and white names with “pleasant” and “unpleasant” words. Subjects tended to have shorter response times for concepts they thought associated. Based on the IAT, \citet{caliskan2017semantics} proposed the Word Embedding Association Test (WEAT), which used word similarities between targets and attributes instead of the response times to get rid of the requirement of human subjects. Later, \citet{may2019measuring} extended WEAT to the Sentence Embedding Association Test (SEAT); \citet{kurita2019measuring} proposed a template-based log probability bias score to measure the association between targets and attributes in BERT.

\subsubsection{Word Embedding Association Test}
\label{sec:weat}
Here we introduce WEAT in detail. Consider two sets of target words $X_1,X_2$ with equal size $|X_1|=|X_2|$, and two sets of attribute words $A_1,A_2$ ($|A_1|=|A_2|$). The null hypothesis in the statistical test of WEAT is: there is no difference in the cosine similarity between $X_1,X_2$ and $A_1,A_2$. Taking the measurement of gender bias as an example, word sets about science and art can be used as the two target sets, masculine and feminine names can be used as the two attribute sets. Intuitively the null hypothesis means science and art are equally similar to each masculine and feminine names. In the prior literature it has been argued that if the null hypothesis can't be rejected, there is no significant gender bias. The WEAT test statistic is defined as
\begin{eqnarray}
s(X_1,X_2,A_1,A_2)=\sum_{x\in X_1}s(x,A_1,A_2)\nonumber\\
-\sum_{x\in X_2}s(x,A_1,A_2),\nonumber
\end{eqnarray}
where cos(x,a)
\begin{eqnarray}
s(x,A_1,A_2)=mean_{a\in A_1}cos(\vec{x},\vec{a})\nonumber\\
-mean_{a\in A_2}cos(\vec{x},\vec{a}),\nonumber
\end{eqnarray}
in which $cos(\vec{x},\vec{a})$ denotes the cosine similarity between embedding vector $\vec{x}$ and $\vec{a}$. Intuitively, $s(x,A_1,A_2)$ measures the association of a word with the attributes, so the test statistic measures the differential association of the two target sets with the attributes. 

Let $\{({X_1}_i,{X_2}_i)\}_{i}$ denote all the partitions of $X_1\cup X_2$. The one-sided $p$-value of the permutation test is defined as $$Pr_i[s({X_1}_i,{X_2}_i,A_1,A_2)]>s(X_1,X_2,A_1,A_2)$$
The effect size $d$-value is a normalized measure of how separated the two distributions of associations between the target and attribute are. It is defined as
\begin{eqnarray}
d=\frac{s(X_1,X_2,A_1,A_2)}{std_{x\in X_1 \cap X_2}s(x,A_1,A_2)}.\nonumber
\end{eqnarray}

\subsection{Debiasing Methods}
Researchers proposed various methods to remove gender bias, in which the most common way is to define a gender direction (or, more generally, a subspace) by a set of gendered words, and debias the word embeddings in post-processing projecting. \citet{bolukbasi2016man} proposed a hard debiasing method where they used the gendered words to compute the difference embedding vector as the gender direction, and a machine learning based soft debiasing method which combined the inner-products objective of word embedding and an objective to project the word embedding into an orthogonal gender subspace. Hard debiasing has been found to work better. \citet{dev2019attenuating} explored partial projection and some simple tricks to improve the hard debiasing method. \citet{zhao2019gender} applied the data augmentation and hard debiasing method of \citet{bolukbasi2016man} to mitigate gender bias on ELMo \citep{Peters:2018}. \citet{karve2019conceptor} introduced the debiasing conceptor, in which they shrined each principal component of the covariance matrix of the word embeddings to achieved a soft debiasing. Besides the above post-processing methods, \citep{zhao2018learning} proposed GN-Glove which debias during training to learn word embedding with protected attributes. In this work, we have the same idea as hard debiasing, both of which are to find and eliminate gender subspace in post-processing, but we make the process more concise by using the analytical solution of DensRay.

\subsection{DensRay}
DensRay is an analytical method proposed to identify the embedding subspace of linguistic features. Same as the methods mentioned in the previous section, we aim to identify the "gender subspace" using a set of gendered words $V:=\{v_1,v_2,\dots,v_n\}$ and their embedding $E \in R^{n\times d}$, thus for word $v_i$ we have the corresponding embedding vector $e_{v_i}$. We denotes the gendered words into a map $l:V\to \{-1,1\}$ (e.g. $l(father)=1,l(sister)=-1$). The objective of DensRay is to find an orthogonal matrix $Q\in R^{d\times d}$ such that $EQ$ is gender-interpretable, specifically, the first $k$ dimensions can be interpreted as the gender subspace.

Consider $L_{=}:=\{(v,w)\in V\times V|l(v)=l(w)\}$ and analogously $L_{\neq}$, the DensRay objective \ref{eq:densray1} tries to maximize the distance of the word pairs from the same gender group $L_{=}$ and minimize the distance of the word pairs from different gender group $L_{\neq}$.
\begin{eqnarray}
    \mathop{max}\limits_{q} 
    \sum_{(v,w)\in L_{\neq}}\alpha_{\neq}||q^Td_{vw}||^2_2\nonumber\\
    -\sum_{(v,w)\in L_{=}}\alpha_{=}||q^Td_{vw}||^2_2
\label{eq:densray1}
\end{eqnarray}
where we define $d_{vw}:=e_v-e_w$. We also have $q\in R^d$ and $q^Tq=1$ since $Q$ is orthogonal, and $\alpha_{\neq},\alpha_{=}\in [0,1]$ are hyperparameters. Regard that $||x||^2_2=x^Tx$, objective \ref{eq:densray1} can be simplified to:
\begin{eqnarray}
    \mathop{max}\limits_{q} q^T(
    \sum_{(v,w)\in L_{\neq}}\alpha_{\neq}||d_{vw}d_{vw}^T||^2_2\nonumber\\
    \sum_{(v,w)\in L_{=}}\alpha_{=}||d_{vw}d_{vw}^T||^2_2)q\nonumber\\
    =:\mathop{max}\limits_{q} q^TAq
\label{eq:densray2}
\end{eqnarray}

The objective \ref{eq:densray2} is maximizing the Rayleigh quotient of $A$ and $q$. Since $A$ is symmetric, we can get an analytical solution $q$ by the eigenvector with the max eigenvalue of $A$ \citep{horn1990matrix}. Thus the matrix of $k$ eigenvectors of $A$ ordered by the corresponding eigenvalues yields the matrix $Q$.
