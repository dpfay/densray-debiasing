%
% File coling2020.tex
%
% Contact: feiliu@cs.ucf.edu & liang.huang.sh@gmail.com
%% Based on the style files for COLING-2018, which were, in turn,
%% Based on the style files for COLING-2016, which were, in turn,
%% Based on the style files for COLING-2014, which were, in turn,
%% Based on the style files for ACL-2014, which were, in turn,
%% Based on the style files for ACL-2013, which were, in turn,
%% Based on the style files for ACL-2012, which were, in turn,
%% based on the style files for ACL-2011, which were, in turn, 
%% based on the style files for ACL-2010, which were, in turn, 
%% based on the style files for ACL-IJCNLP-2009, which were, in turn,
%% based on the style files for EACL-2009 and IJCNLP-2008...

%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt]{article}
\usepackage{coling2020}

\usepackage{CJKutf8}
\def\yin#1{\begin{CJK*}{UTF8}{gbsn}#1\end{CJK*}}


\usepackage{times}
\usepackage{url}
\usepackage{latexsym}
\renewcommand{\UrlFont}{\ttfamily\small}
\usepackage{float}
% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}
%\usepackage[UTF8]{ctex}
\usepackage{graphicx} 
\usepackage{float} 
\usepackage{subfigure} 
\usepackage{graphicx}
\usepackage{subfigure}
%\aclfinalcopy % Uncomment this line for the final submission
%\def\aclpaperid{***} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

% START custom header
\usepackage{amsfonts}
\usepackage{bm}
\usepackage{array,amsmath}
\usepackage{amssymb}
\usepackage{dsfont}
\usepackage{float}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{pgf,tikz}
\usepackage{mathrsfs}
\usepackage{multirow}
\usepackage{booktabs}
\usetikzlibrary{arrows}
\usepackage{threeparttable}

\def\figref#1{Figure~\ref{fig:#1}}
\def\figlabel#1{\label{fig:#1}\label{p:#1}}
\def\chapref#1{Chapter~\ref{chap:#1}}
\def\chaplabel#1{\label{chap:#1}\label{p:#1}}
\def\Tabref#1{Table~\ref{tab:#1}}
\def\tabref#1{Table~\ref{tab:#1}}
\def\tablabel#1{\label{tab:#1}\label{p:#1}}
\def\Secref#1{\S\ref{sec:#1}}
\def\secref#1{\S\ref{sec:#1}}
\def\seclabel#1{\label{sec:#1}}
\def\eqref#1{Eq.~\ref{eqn:#1}}
\def\eqrefn#1{\ref{eqn:#1}}
\def\eqsref#1#2{Eqs.~\ref{eqn:#1}/\ref{eqn:#2}}
\def\eqlabel#1{\label{eqn:#1}}
\def\subsp#1{P_{\mbox{{\scriptsize\rm #1}}}}

\def\numpar{100k}
\def\ppnumpar{5}

\newcounter{notecounter}
\newcommand{\enotesoff}{\long\gdef\enote##1##2{}}
\newcommand{\enoteson}{\long\gdef\enote##1##2{{
			\stepcounter{notecounter}
			{\large\bf
				\hspace{1cm}\arabic{notecounter} $<<<$ ##1: ##2
				$>>>$\hspace{1cm}}}}}
\enoteson
\enotesoff
\long\def\eat#1{}

\def\dnrmupmath#1#2{\mbox{$^#2_{\hbox{\scriptsize #1}}$}}
\def\dnrm#1{\mbox{$_{\hbox{\scriptsize #1}}$}}
\def\uprm#1{\mbox{$^{\hbox{\scriptsize #1}}$}}
\def\cupequal{\cup\!\!=}
\newcommand{\pluseq}{\mathrel{+}=}


%\setlength\titlebox{5cm}
%\colingfinalcopy % Uncomment this line for the final submission

% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.


\title{Monolingual and Multilingual Reduction of Gender Bias in Contextualized Representations}

\author{First Author \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  {\tt email@domain} \\\And
  Second Author \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  {\tt email@domain} \\}

\date{}

\begin{document}
\maketitle
\begin{abstract}
	
Pretrained language models (PLMs) learn stereotypes held by
humans and reflected in text from their training corpora,
including gender bias.  When PLMs are used for downstream
tasks such as picking candidates for a job, people's lives
can be negatively affected by these learned stereotypes.
Prior work usually identifies a linear gender subspace and
removes gender information by eliminating the
subspace. Following this line of work, we propose to use DensRay, an
analytical method for obtaining interpretable dense
subspaces. We show that DensRay performs on-par with prior
approaches, but provide arguments that it is more robust and show that it preserves language model performance better. By applying DensRay to attention heads and layers of BERT 
we show that gender information is spread across all attention heads and most of the layers. Also we show that DensRay can obtain gender bias scores on both token and sentence level. Finally,
we demonstrate that we can remove bias multilingually, e.g.,
from Chinese, using only English training data.
	
\end{abstract}


\section{Introduction}
\input{introduction}

\section{Methodology}
\input{method}

\section{Experiments}
\input{exp}

\section{Results}
\input{results}

%\section{DensRay Debiasing multilingual-BERT}
%\input{multi}

\section{Related Work}
\input{relatedwork}

\section{Conclusion}
\input{conclusion}


%\section*{Acknowledgements}

%The acknowledgements should go immediately before the references.  Do
%not number the acknowledgements section. Do not include this section
%when submitting your paper for review.

% include your own bib file like this:
\bibliographystyle{coling}
\bibliography{coling2020}

%\begin{thebibliography}{}

%\bibitem[\protect\citename{Aho and Ullman}1972]{Aho:72}
%Alfred~V. Aho and Jeffrey~D. Ullman.
%\newblock 1972.
%\newblock {\em The Theory of Parsing, Translation and Compiling}, volume~1.
%\newblock Prentice-{Hall}, Englewood Cliffs, NJ.

%\bibitem[\protect\citename{{American Psychological Association}}1983]{APA:83}
%{American Psychological Association}.
%\newblock 1983.
%\newblock {\em Publications Manual}.
%\newblock American Psychological Association, Washington, DC.

%\bibitem[\protect\citename{{Association for Computing Machinery}}1983]{ACM:83}
%{Association for Computing Machinery}.
%\newblock 1983.
%\newblock {\em Computing Reviews}, 24(11):503--512.

%\bibitem[\protect\citename{Chandra \bgroup et al.\egroup }1981]{Chandra:81}
%Ashok~K. Chandra, Dexter~C. Kozen, and Larry~J. Stockmeyer.
%\newblock 1981.
%\newblock Alternation.
%\newblock {\em Journal of the Association for Computing Machinery},
%  28(1):114--133.

%\bibitem[\protect\citename{Gusfield}1997]{Gusfield:97}
%Dan Gusfield.
%\newblock 1997.
%\newblock {\em Algorithms on Strings, Trees and Sequences}.
%\newblock Cambridge University Press, Cambridge, UK.

%\bibitem[\protect\citename{Rasooli and Tetreault}2015]{rasooli-tetrault-2015}
%Mohammad~Sadegh Rasooli and Joel~R. Tetreault. 2015.
%\newblock {Yara parser: {A} fast and accurate dependency parser}.
%\newblock \emph{Computing Research Repository}, arXiv:1503.06733.
%\newblock Version 2.

%\bibitem[\protect\citename{Borschinger and Johnson}2011]{borsch2011}
%Benjamin Borschinger and Mark Johnson. 2011.
%\newblock A particle filter algorithm for {B}ayesian wordsegmentation.
%\newblock In \emph{Proceedings of the Australasian Language Technology Association %Workshop 2011}, pages 10--18, Canberra, Australia.

%\end{thebibliography}

\end{document}
