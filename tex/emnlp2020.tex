%
% File emnlp2020.tex
%
%% Based on the style files for ACL 2020, which were
%% Based on the style files for ACL 2018, NAACL 2018/19, which were
%% Based on the style files for ACL-2015, with some improvements
%%  taken from the NAACL-2016 style
%% Based on the style files for ACL-2014, which were, in turn,
%% based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009,
%% EACL-2009, IJCNLP-2008...
%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{emnlp2020}
\usepackage{times}
\usepackage{latexsym}
\renewcommand{\UrlFont}{\ttfamily\small}
\usepackage{float}
% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

%\aclfinalcopy % Uncomment this line for the final submission
%\def\aclpaperid{***} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\newcommand\BibTeX{B\textsc{ib}\TeX}

\title{Instructions for EMNLP 2020 Proceedings}

\author{First Author \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  \texttt{email@domain} \\\And
  Second Author \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  \texttt{email@domain} \\}

\date{}

\begin{document}
\maketitle
\begin{abstract}
As one of the representatives of context word embedding, BERT has achieved the most advanced performance on many NLP tasks. Due to the strong feature extraction ability and the high demand for the amounts of training data, BERT can hardly avoid learning many of the human-generated stereotypes in the text data, including gender bias. In this study, we (1) proposed a template based on language models to quantify gender bias in BERT; (2) proposed a DensRay-based word vector space projection analysis method, which is used in Eliminate gender bias. (3) The method of English training is extended to multilingual BERT, which reduces the gender bias of Chinese on our Chinese template.
\end{abstract}

\section{Introduction}
\input{introduction}

\section{Related Work}
\input{related work}

\section{Methodology}
\input{method}

\section{DensRay Debiasing Experiments on BERT Layers}
\input{exp}

\section{DensRay Debiasing multilingual-BERT}
\input{multi}

\section{Conclusion}
\input{conclusion}


%\section*{Acknowledgments}
%
%The acknowledgments should go immediately before the references. Do not number the acknowledgments %section.
%Do not include this section when submitting your paper for review.

\bibliographystyle{acl_natbib}
\bibliography{anthology,emnlp2020}

%\appendix
%\section{Appendices}
%\section{Supplemental Material}
\end{document}
