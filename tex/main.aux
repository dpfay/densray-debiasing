\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{bolukbasi2016man,caliskan2017semantics,garg2018word}
\citation{bolukbasi2016man}
\citation{devlin2018bert}
\citation{zhao2019gender,may2019measuring}
\citation{dufter2019analytical}
\citation{caliskan2017semantics}
\citation{wang2018glue}
\citation{zhao2018gender}
\citation{rudinger2018gender}
\citation{webster2018mind}
\citation{Chada_2019,Attree_2019}
\citation{Kiritchenko_2018}
\citation{greenwald1998measuring}
\citation{caliskan2017semantics}
\citation{may2019measuring}
\citation{kurita2019measuring}
\citation{bolukbasi2016man}
\citation{dev2019attenuating}
\citation{zhao2019gender}
\citation{bolukbasi2016man}
\citation{Peters:2018}
\citation{karve2019conceptor}
\citation{zhao2018learning}
\citation{horn1990matrix}
\newlabel{eq:densray1}{{1}{3}{DensRay}{equation.2.1}{}}
\newlabel{eq:densray2}{{2}{3}{DensRay}{equation.2.2}{}}
\citation{bolukbasi2016man}
\citation{wolf2019huggingfaces}
\citation{mikolov2013efficient}
\citation{karve2019conceptor}
\newlabel{sec:eval}{{3.2}{4}{Evaluations}{subsection.3.2}{}}
\citation{merity2016pointer}
\citation{wolf2019huggingfaces}
\citation{wang2018glue}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:t:templates1}{{1}{5}{\tablabel {t:templates1} BERT debiasing results on templates. \textit {bert-base} and \textit {bert-large} are the original model without debiasing. \textit {prob(he)} is the mean probability that model predict \textit {he} as the [MASK]in all templates. \textit {var} is the variance of the differences between the probability of BERT predicts [MASK] as \textit {he} and \textit {she}.\relax }{table.caption.1}{}}
\newlabel{p:t:templates1}{{1}{5}{\tablabel {t:templates1} BERT debiasing results on templates. \textit {bert-base} and \textit {bert-large} are the original model without debiasing. \textit {prob(he)} is the mean probability that model predict \textit {he} as the [MASK]in all templates. \textit {var} is the variance of the differences between the probability of BERT predicts [MASK] as \textit {he} and \textit {she}.\relax }{table.caption.1}{}}
\newlabel{tab:t:templates2}{{2}{5}{\tablabel {t:templates2} Two example templates with prediction probabilities.\relax }{table.caption.2}{}}
\newlabel{p:t:templates2}{{2}{5}{\tablabel {t:templates2} Two example templates with prediction probabilities.\relax }{table.caption.2}{}}
\newlabel{t:weat1}{{3}{5}{BERT debiasing results on WEAT. * shows significant gender bias.\relax }{table.caption.3}{}}
\newlabel{tab:t:ppl1}{{4}{5}{\tablabel {t:ppl1} Language modeling performance on BERT after debiasing with DensRay.\relax }{table.caption.4}{}}
\newlabel{p:t:ppl1}{{4}{5}{\tablabel {t:ppl1} Language modeling performance on BERT after debiasing with DensRay.\relax }{table.caption.4}{}}
\citation{bolukbasi2016man,zhao2019gender,dev2019attenuating,karve2019conceptor}
\citation{wolf2019huggingfaces}
\newlabel{t:glue1}{{5}{6}{GLUE tasks performance on BERT with/without debiasing with DensRay.\relax }{table.caption.5}{}}
\citation{mikolov2013efficient}
\bibstyle{acl_natbib}
\bibdata{anthology,emnlp2020}
\bibcite{Attree_2019}{{1}{2019}{{Attree}}{{}}}
\newlabel{fig:my_label}{{1}{7}{Here should be a graph.\relax }{figure.caption.6}{}}
\newlabel{fig:fig:layersbase}{{2}{7}{Debiasing on each single layer on BERT base. Bias is measured by \text {diff} on the templates and $d$-value on WEAT categories.\relax }{figure.caption.7}{}}
\newlabel{p:fig:layersbase}{{2}{7}{Debiasing on each single layer on BERT base. Bias is measured by \text {diff} on the templates and $d$-value on WEAT categories.\relax }{figure.caption.7}{}}
\newlabel{tab:t:templates3}{{6}{7}{\tablabel {t:templates3} Results of templates on mBERT after applied DensRay. Models with \textit {-en} are tested on our English templates, and those with \textit {-cn} are tested on our Chinese templates.\relax }{table.caption.8}{}}
\newlabel{p:t:templates3}{{6}{7}{\tablabel {t:templates3} Results of templates on mBERT after applied DensRay. Models with \textit {-en} are tested on our English templates, and those with \textit {-cn} are tested on our Chinese templates.\relax }{table.caption.8}{}}
\newlabel{tab:t:ppl2}{{7}{7}{\tablabel {t:ppl2} Language modeling performance on mBERT after applied DensRay.\relax }{table.caption.9}{}}
\newlabel{p:t:ppl2}{{7}{7}{\tablabel {t:ppl2} Language modeling performance on mBERT after applied DensRay.\relax }{table.caption.9}{}}
\bibcite{bolukbasi2016man}{{2}{2016}{{Bolukbasi et~al.}}{{Bolukbasi, Chang, Zou, Saligrama, and Kalai}}}
\bibcite{caliskan2017semantics}{{3}{2017}{{Caliskan et~al.}}{{Caliskan, Bryson, and Narayanan}}}
\bibcite{Chada_2019}{{4}{2019}{{Chada}}{{}}}
\bibcite{dev2019attenuating}{{5}{2019}{{Dev and Phillips}}{{}}}
\bibcite{devlin2018bert}{{6}{2018}{{Devlin et~al.}}{{Devlin, Chang, Lee, and Toutanova}}}
\bibcite{dufter2019analytical}{{7}{2019}{{Dufter and Sch{\"u}tze}}{{}}}
\bibcite{garg2018word}{{8}{2018}{{Garg et~al.}}{{Garg, Schiebinger, Jurafsky, and Zou}}}
\bibcite{greenwald1998measuring}{{9}{1998}{{Greenwald et~al.}}{{Greenwald, McGhee, and Schwartz}}}
\bibcite{horn1990matrix}{{10}{1990}{{Horn et~al.}}{{Horn, Horn, and Johnson}}}
\bibcite{karve2019conceptor}{{11}{2019}{{Karve et~al.}}{{Karve, Ungar, and Sedoc}}}
\bibcite{Kiritchenko_2018}{{12}{2018}{{Kiritchenko and Mohammad}}{{}}}
\bibcite{kurita2019measuring}{{13}{2019}{{Kurita et~al.}}{{Kurita, Vyas, Pareek, Black, and Tsvetkov}}}
\bibcite{may2019measuring}{{14}{2019}{{May et~al.}}{{May, Wang, Bordia, Bowman, and Rudinger}}}
\bibcite{merity2016pointer}{{15}{2016}{{Merity et~al.}}{{Merity, Xiong, Bradbury, and Socher}}}
\bibcite{mikolov2013efficient}{{16}{2013}{{Mikolov et~al.}}{{Mikolov, Chen, Corrado, and Dean}}}
\bibcite{Peters:2018}{{17}{2018}{{Peters et~al.}}{{Peters, Neumann, Iyyer, Gardner, Clark, Lee, and Zettlemoyer}}}
\bibcite{rudinger2018gender}{{18}{2018}{{Rudinger et~al.}}{{Rudinger, Naradowsky, Leonard, and Van~Durme}}}
\newlabel{t:templates3}{{8}{8}{Sanity check on the Chinese templates, where \textit {他} means \textit {he} and \textit {她} means \textit {she}. The two sentences are translated from \tabref {t:templates2}.\relax }{table.caption.10}{}}
\bibcite{wang2018glue}{{19}{2018}{{Wang et~al.}}{{Wang, Singh, Michael, Hill, Levy, and Bowman}}}
\bibcite{webster2018mind}{{20}{2018}{{Webster et~al.}}{{Webster, Recasens, Axelrod, and Baldridge}}}
\bibcite{wolf2019huggingfaces}{{21}{2019}{{Wolf et~al.}}{{Wolf, Debut, Sanh, Chaumond, Delangue, Moi, Cistac, Rault, Louf, Funtowicz, and Brew}}}
\bibcite{zhao2019gender}{{22}{2019}{{Zhao et~al.}}{{Zhao, Wang, Yatskar, Cotterell, Ordonez, and Chang}}}
\bibcite{zhao2018gender}{{23}{2018{a}}{{Zhao et~al.}}{{Zhao, Wang, Yatskar, Ordonez, and Chang}}}
\bibcite{zhao2018learning}{{24}{2018{b}}{{Zhao et~al.}}{{Zhao, Zhou, Li, Wang, and Chang}}}
