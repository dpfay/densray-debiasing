{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_Conceptor_n_Hard_BERT_Train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8e6a25fe6043426c9381c58363702836": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e39f04469af14995b80ee993cba300fb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6e6b255fb7ed40749b4c3a939f271020",
              "IPY_MODEL_9144e976730c46fd8f4dfeef3e74f58a"
            ]
          }
        },
        "e39f04469af14995b80ee993cba300fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6e6b255fb7ed40749b4c3a939f271020": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7ba69048cbef4f7b8ed531fb1e735a5e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 434,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 434,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e3cad6e6dd1c4877b79790a11f7e2165"
          }
        },
        "9144e976730c46fd8f4dfeef3e74f58a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f8e35bc92a584fdb902d1a3d7d76261b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 434/434 [00:36&lt;00:00, 12.0B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0010aa09c5ec40eab996ecbd74943068"
          }
        },
        "7ba69048cbef4f7b8ed531fb1e735a5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e3cad6e6dd1c4877b79790a11f7e2165": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f8e35bc92a584fdb902d1a3d7d76261b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0010aa09c5ec40eab996ecbd74943068": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "84e4ac850b64482692b0453815db509c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8dc29599b86741dea6789ddc39cc5525",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e8fea6a2553f4572a4da7bdf6b74183a",
              "IPY_MODEL_3d6243eaa04c4cfd819c39bfa3379d45"
            ]
          }
        },
        "8dc29599b86741dea6789ddc39cc5525": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e8fea6a2553f4572a4da7bdf6b74183a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_16e10c863e724d62b25e1971fa068271",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1344997306,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1344997306,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1934d8e1d8c747c2ab3842551c58d655"
          }
        },
        "3d6243eaa04c4cfd819c39bfa3379d45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0e37409424ab469f9898bcaeba819287",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.34G/1.34G [00:24&lt;00:00, 53.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b66bf89672bf4b63bf2f7783b023b0bd"
          }
        },
        "16e10c863e724d62b25e1971fa068271": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1934d8e1d8c747c2ab3842551c58d655": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0e37409424ab469f9898bcaeba819287": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b66bf89672bf4b63bf2f7783b023b0bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "17aea67e1ed543a6a5860730a83e1dac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_168dca3c971e40faa6561cb3ef0c909d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a0019b864cc84780aa385d27c410f8e7",
              "IPY_MODEL_7ebe7392e50344cc8188d7a2cadd2cdf"
            ]
          }
        },
        "168dca3c971e40faa6561cb3ef0c909d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a0019b864cc84780aa385d27c410f8e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_448c8984e9d6478e8600dc9aad990287",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7f71bc655b534591a7ed97fdb88c9864"
          }
        },
        "7ebe7392e50344cc8188d7a2cadd2cdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3fbb7e00eb314ca1ad31046d06ee5fae",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 1.63MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f90d12db84904d87a2bd3d8d440be35c"
          }
        },
        "448c8984e9d6478e8600dc9aad990287": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7f71bc655b534591a7ed97fdb88c9864": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3fbb7e00eb314ca1ad31046d06ee5fae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f90d12db84904d87a2bd3d8d440be35c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bY4RMFQxrWyv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from itertools import combinations, filterfalse\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "import pandas as pd\n",
        "import random\n",
        "import sys\n",
        "import os\n",
        "import pickle\n",
        "import gc\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYjBzzsjwEr_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "outputId": "1dd9e08f-194d-4b82-b1b0-ac1e71fec9e1"
      },
      "source": [
        "!pip install transformers==2.8.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==2.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\u001b[K     |████████████████████████████████| 573kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.7)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.18.5)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 17.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 43.2MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 43.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.14.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2020.6.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (0.15.1)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.9 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (1.17.9)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.9->boto3->transformers==2.8.0) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.9->boto3->transformers==2.8.0) (2.8.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=31a07a2a306c76240382ba7c1ef7f57d8cb2d67b9353e3293cd1b6c2c16f4479\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nka-t9d-Pn7M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "c93c33cc-d8d0-4be6-ab6d-05006f95dc6a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ve3T4fmDyGFN",
        "colab_type": "text"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYFhIYk8v_sL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8e6a25fe6043426c9381c58363702836",
            "e39f04469af14995b80ee993cba300fb",
            "6e6b255fb7ed40749b4c3a939f271020",
            "9144e976730c46fd8f4dfeef3e74f58a",
            "7ba69048cbef4f7b8ed531fb1e735a5e",
            "e3cad6e6dd1c4877b79790a11f7e2165",
            "f8e35bc92a584fdb902d1a3d7d76261b",
            "0010aa09c5ec40eab996ecbd74943068",
            "84e4ac850b64482692b0453815db509c",
            "8dc29599b86741dea6789ddc39cc5525",
            "e8fea6a2553f4572a4da7bdf6b74183a",
            "3d6243eaa04c4cfd819c39bfa3379d45",
            "16e10c863e724d62b25e1971fa068271",
            "1934d8e1d8c747c2ab3842551c58d655",
            "0e37409424ab469f9898bcaeba819287",
            "b66bf89672bf4b63bf2f7783b023b0bd",
            "17aea67e1ed543a6a5860730a83e1dac",
            "168dca3c971e40faa6561cb3ef0c909d",
            "a0019b864cc84780aa385d27c410f8e7",
            "7ebe7392e50344cc8188d7a2cadd2cdf",
            "448c8984e9d6478e8600dc9aad990287",
            "7f71bc655b534591a7ed97fdb88c9864",
            "3fbb7e00eb314ca1ad31046d06ee5fae",
            "f90d12db84904d87a2bd3d8d440be35c"
          ]
        },
        "outputId": "81d8478f-da27-4b3a-cb6f-4c49ba857acb"
      },
      "source": [
        "import torch\n",
        "import transformers\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "config = 'large' #'base'\n",
        "nlayer = 12 if config == 'base' else 24\n",
        "nsamples = 5000\n",
        "\n",
        "model = transformers.BertForMaskedLM.from_pretrained('bert-'+config+'-uncased', output_hidden_states=True).to(device)\n",
        "tokenizer = transformers.BertTokenizer.from_pretrained('bert-'+config+'-uncased')\n",
        "# turn on eval mode\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e6a25fe6043426c9381c58363702836",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=434.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84e4ac850b64482692b0453815db509c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1344997306.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17aea67e1ed543a6a5860730a83e1dac",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForMaskedLM(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 1024)\n",
              "      (token_type_embeddings): Embedding(2, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (12): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (13): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (14): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (15): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (16): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (17): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (18): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (19): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (20): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (21): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (22): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (23): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (cls): BertOnlyMLMHead(\n",
              "    (predictions): BertLMPredictionHead(\n",
              "      (transform): BertPredictionHeadTransform(\n",
              "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (decoder): Linear(in_features=1024, out_features=30522, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuoDtnOOwe57",
        "colab_type": "text"
      },
      "source": [
        "# Analogies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPahoF7awhDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "import tqdm\n",
        "\n",
        "class GoogleAnalogies:\n",
        "    def __init__(self, path='/content/drive/My Drive/questions-words.txt'):\n",
        "        self.Lset = set()\n",
        "        self.Rset = set()\n",
        "        # this time only want the words in vocab !!!!!!!!!!\n",
        "        with open(path,'r',encoding='utf8') as f:\n",
        "            for line in f.readlines():\n",
        "                line = line.strip().split(' ')\n",
        "                self.Rset.update([line[1],line[3]])\n",
        "                for w in [line[0],line[2]]:\n",
        "                    if w in tokenizer.vocab.keys():\n",
        "                        self.Lset.add(w)\n",
        "                for w in [line[1],line[3]]:\n",
        "                    if w in tokenizer.vocab.keys():\n",
        "                        self.Rset.add(w)\n",
        "        self.Lset = tokenizer.convert_tokens_to_ids(list(self.Lset))\n",
        "        self.Rset = tokenizer.convert_tokens_to_ids(list(self.Rset))\n",
        "        self.pieces = self.Lset+self.Rset\n",
        "             \n",
        "    def get_embeddings_from_cropus(self, corpus, layer=11):\n",
        "        #balanced\n",
        "        L = torch.Tensor().to(device)\n",
        "        R = torch.Tensor().to(device)\n",
        "        for i in tqdm.trange(10*nsamples):# just to get a larger range\n",
        "            # get useful idxs\n",
        "            vecs = model(corpus.__getitem__(i))[1][layer+1][0][1:-1]#!!!!!!!!!!!\n",
        "            if L.shape[0]<nsamples//2:\n",
        "                for j in range(vecs.shape[0]):\n",
        "                    if corpus.labels[i][j]==1:\n",
        "                        L = torch.cat((L, vecs[j].unsqueeze(0)))\n",
        "            else:\n",
        "                L = L[:nsamples//2]\n",
        "            if R.shape[0]<nsamples//2:\n",
        "                for j in range(vecs.shape[0]):\n",
        "                    if corpus.labels[i][j]==-1:\n",
        "                        R = torch.cat((R, vecs[j].unsqueeze(0)))\n",
        "            else:\n",
        "                R = R[:nsamples//2]\n",
        "            if L.shape[0]+R.shape[0]>=nsamples:\n",
        "                break\n",
        "        return L.cpu(), R.cpu()\n",
        "    \n",
        "    def get_LR_from_cropus(self, corpus, LR='L', layer=11):\n",
        "        #balanced\n",
        "        flag = 1 if LR== 'L' else -1\n",
        "        L = torch.Tensor().to(device)\n",
        "        #for i in tqdm.trange(nsamples):\n",
        "        iterator = tqdm.trange(corpus.__len__())\n",
        "        for i in iterator:\n",
        "            # get useful idxs\n",
        "            with torch.no_grad():\n",
        "                vecs = model(corpus.__getitem__(i))[1][layer+1][0][1:-1]#!!!!!!!!!!!\n",
        "            if L.shape[0]<nsamples//2:\n",
        "                for j in range(vecs.shape[0]):\n",
        "                    if corpus.labels[i][j]==flag:\n",
        "                        L = torch.cat((L, vecs[j].unsqueeze(0)))\n",
        "            else:\n",
        "                L = L[:nsamples//2]\n",
        "            if L.shape[0]>=nsamples//2:\n",
        "                iterator.close()\n",
        "                break\n",
        "        return L.cpu()\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gacSOiCOs_1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "analogy = GoogleAnalogies('/content/drive/My Drive/questions-words.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVasI9ROwqLI",
        "colab_type": "text"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VdqYHLlwwPV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "import tqdm\n",
        "import pickle\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, path=\"/content/drive/My Drive/wikien_senttok_500k.txt\"):\n",
        "        self.examples, self.labels = pickle.load(open(path, 'rb'))\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        return tokenizer.prepare_for_model(self.examples[i][:510], return_token_type_ids=False, return_tensors='pt')['input_ids'].to(device)\n",
        "        #return torch.tensor(self.examples[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "wiki = TextDataset(\"/content/drive/My Drive/wikien_senttok_500k.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4B276eCxMsr",
        "colab_type": "text"
      },
      "source": [
        "# DensRay"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oK12F1TlxOTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tqdm\n",
        "\n",
        "class DensRay:\n",
        "    def __init__(self, Lemb, Remb):\n",
        "        self.lemb = Lemb\n",
        "        self.remb = Remb\n",
        "\n",
        "    def fit(self, weights=None, normalize_D=True):\n",
        "        \"\"\"Fit DensRay\n",
        "        Args:\n",
        "            weights: only for binary model; how to weight the two\n",
        "                summands; if none\n",
        "                \n",
        "                \n",
        "                : apply dynamic weighting. Example input: [1.0, 1.0]\n",
        "            normalize_D: bool whether to normalize the difference vectors with l2 norm\n",
        "        \"\"\"\n",
        "        self.computeA_binary_part1(normalize_D=normalize_D)\n",
        "        #self.A_equal = self.opsum(self.lemb) + self.opsum(self.remb)\n",
        "        #self.A_unequal = self.opsum(self.lemb, self.remb) + self.opsum(self.remb, self.lemb)\n",
        "        self.computeA_binary_part2(weights=weights)\n",
        "        self.compute_trafo()\n",
        "        #self.compute_mean_var()\n",
        "\n",
        "    @staticmethod\n",
        "    def opsum(a, b=None):\n",
        "        if b is None: b = a\n",
        "        out = -torch.ger(a.sum(dim=0), b.sum(dim=0))\n",
        "        out = out + out.T\n",
        "        out += b.shape[0] * torch.mm(a.T,a)\n",
        "        out += a.shape[0] * torch.mm(b.T,b)\n",
        "        return out\n",
        "\n",
        "    @staticmethod\n",
        "    def outer_product_sub_binary(v, M, normD):\n",
        "        \"\"\"Helper function to compute the sum of outer products\n",
        "\n",
        "        While it is not very readable, it is more efficient than\n",
        "        a brute force implementation.\n",
        "        \"\"\"\n",
        "        d = v.unsqueeze(0) - M\n",
        "        if normD:\n",
        "            norm = d.norm(dim=1)\n",
        "            norm[norm == 0] = 1\n",
        "            d = d / (norm.unsqueeze(0).T)\n",
        "        return torch.mm(d.T, d)\n",
        "    \n",
        "    def computeA_binary_part1(self, normalize_D=False):\n",
        "        \"\"\"First part of computing the matrix A.\n",
        "        Args:\n",
        "            normalize_D: bool whether to normalize the difference vectors with l2 norm.\n",
        "        \"\"\"\n",
        "        dim = self.lemb.shape[1]\n",
        "        self.A_equal = torch.zeros((dim, dim)).to(device)\n",
        "        self.A_unequal = torch.zeros((dim, dim)).to(device)\n",
        "        for ipos in tqdm.trange(self.lemb.shape[0]):\n",
        "            v = self.lemb[ipos]\n",
        "            self.A_equal += self.outer_product_sub_binary(v, self.lemb, normalize_D)\n",
        "            self.A_unequal += self.outer_product_sub_binary(v, self.remb, normalize_D)\n",
        "        for ineg in tqdm.trange(self.remb.shape[0]):\n",
        "            v = self.remb[ineg]\n",
        "            self.A_equal += self.outer_product_sub_binary(v, self.remb, normalize_D)\n",
        "            self.A_unequal += self.outer_product_sub_binary(v, self.lemb, normalize_D)\n",
        "\n",
        "    def computeA_binary_part2(self, weights=None):\n",
        "        \"\"\"Second part of computing the matrix A.\n",
        "        Args:\n",
        "            weights: only for binary model; how to weight the two \n",
        "                summands; if none: apply dynamic weighting. Example input: [1.0, 1.0]\n",
        "        \"\"\"\n",
        "        if weights is None:\n",
        "            weights = [1 / (2 * self.lemb.shape[0] * self.remb.shape[0]), 1 /\n",
        "                       (self.lemb.shape[0]**2 + self.remb.shape[0]**2)]\n",
        "        # normalize matrices for numerical reasons\n",
        "        # note that this does not change the eigenvectors\n",
        "        n1 = self.A_unequal.max()\n",
        "        n2 = self.A_equal.max()\n",
        "        weights = [weights[0] / max(n1, n2), weights[1] / max(n1, n2)]\n",
        "        self.A = weights[0] * self.A_unequal - weights[1] * self.A_equal\n",
        "\n",
        "    def compute_trafo(self):\n",
        "        \"\"\"Given A, this function computes the actual Transformation.\n",
        "        It essentially just does an eigenvector decomposition.\n",
        "        \"\"\"\n",
        "        eigvals, eigvecs = self.A.symeig(eigenvectors=True)\n",
        "        # need to sort the eigenvalues\n",
        "        idx = eigvals.argsort(descending=True)\n",
        "        eigvals, self.eigvecs = eigvals[idx], eigvecs[:, idx]\n",
        "    \n",
        "    def compute_mean_var(self):\n",
        "        first_dim = torch.mm(torch.cat((self.lemb, self.remb)), self.eigvecs)[:, 0]\n",
        "        self.mean = first_dim.mean()\n",
        "        self.std = first_dim.var().sqrt()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueYU-pR6KgFw",
        "colab_type": "text"
      },
      "source": [
        "# Conceptor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEHW8O1sIkqK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def train_Conceptor(x, alpha = 1):\n",
        "    print(\"starting...\")\n",
        "    #x = orig_embd.vectors\n",
        "    print(x.shape)\n",
        "    #Calculate the correlation matrix\n",
        "    R = x.T.dot(x)/(x.shape[0])\n",
        "    #Calculate the conceptor matrix\n",
        "    C = R @ (np.linalg.inv(R + alpha ** (-2) * np.eye(x.shape[1])))\n",
        "    print(\"C calculated\")\n",
        "    dim = C.shape[0]\n",
        "    not_C = np.eye(dim) - C\n",
        "    return not_C\n",
        "\n",
        "def process_cn_matrix(subspace, alpha = 2):\n",
        "    \"\"\"Returns the conceptor negation matrix\n",
        "    Arguments\n",
        "            subspace : n x d matrix of word vectors from a oarticular subspace\n",
        "            alpha : Tunable parameter\n",
        "    \"\"\"\n",
        "    # Compute the negation conceptor matrix\n",
        "    negC = train_Conceptor(subspace, alpha)    \n",
        "    return negC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hP4z1T6xVc4",
        "colab_type": "text"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oz4VoKIhAKdI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a1480399-417a-4b8a-fb6b-2360b2f1aa1e"
      },
      "source": [
        "def save_lr(corpus=None):\n",
        "    for l in range(nlayer):\n",
        "        L = analogy.get_LR_from_cropus(corpus,'L', l)\n",
        "        R = analogy.get_LR_from_cropus(corpus,'R', l)\n",
        "        torch.save(L, '/content/drive/My Drive/L'+config+'_'+str(nsamples)+'_'+str(l)+'.pt')\n",
        "        torch.save(R, '/content/drive/My Drive/R'+config+'_'+str(nsamples)+'_'+str(l)+'.pt')\n",
        "        print(\"Layer saved: \", l)\n",
        "\n",
        "save_lr(wiki)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2165/500001 [01:04<4:05:22, 33.82it/s]\n",
            "  1%|▏         | 6652/500001 [03:16<4:03:12, 33.81it/s]\n",
            "  0%|          | 4/500001 [00:00<4:10:26, 33.28it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Layer saved:  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2164/500001 [01:04<4:05:48, 33.76it/s]\n",
            "  1%|▏         | 6652/500001 [03:16<4:03:14, 33.80it/s]\n",
            "  0%|          | 4/500001 [00:00<4:16:05, 32.54it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Layer saved:  1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2164/500001 [01:04<4:06:44, 33.63it/s]\n",
            "  1%|▏         | 6652/500001 [03:17<4:04:36, 33.62it/s]\n",
            "  0%|          | 4/500001 [00:00<4:02:35, 34.35it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Layer saved:  2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2164/500001 [01:04<4:06:32, 33.65it/s]\n",
            "  1%|▏         | 6652/500001 [03:18<4:04:49, 33.58it/s]\n",
            "  0%|          | 4/500001 [00:00<3:58:12, 34.98it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Layer saved:  3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2164/500001 [01:04<4:08:15, 33.42it/s]\n",
            "  1%|▏         | 6652/500001 [03:17<4:04:31, 33.63it/s]\n",
            "  0%|          | 4/500001 [00:00<3:58:44, 34.91it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Layer saved:  4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2164/500001 [01:04<4:06:02, 33.72it/s]\n",
            "  1%|▏         | 6652/500001 [03:17<4:04:26, 33.64it/s]\n",
            "  0%|          | 4/500001 [00:00<4:09:11, 33.44it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Layer saved:  5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2164/500001 [01:04<4:05:47, 33.76it/s]\n",
            "  1%|▏         | 6652/500001 [03:16<4:03:00, 33.84it/s]\n",
            "  0%|          | 4/500001 [00:00<4:09:57, 33.34it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Layer saved:  6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2163/500001 [01:04<4:07:14, 33.56it/s]\n",
            "  1%|▏         | 6652/500001 [03:16<4:02:53, 33.85it/s]\n",
            "  0%|          | 4/500001 [00:00<4:01:43, 34.48it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Layer saved:  7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2164/500001 [01:04<4:05:27, 33.80it/s]\n",
            "  1%|▏         | 6652/500001 [03:17<4:04:16, 33.66it/s]\n",
            "  0%|          | 4/500001 [00:00<4:14:46, 32.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Layer saved:  8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2163/500001 [01:04<4:08:14, 33.43it/s]\n",
            "  1%|▏         | 6652/500001 [03:17<4:04:32, 33.62it/s]\n",
            "  0%|          | 4/500001 [00:00<4:05:26, 33.95it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Layer saved:  9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2164/500001 [01:04<4:07:03, 33.58it/s]\n",
            "  1%|▏         | 6652/500001 [03:17<4:04:43, 33.60it/s]\n",
            "  0%|          | 4/500001 [00:00<4:17:51, 32.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Layer saved:  10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2164/500001 [01:04<4:07:22, 33.54it/s]\n",
            "  1%|▏         | 6652/500001 [03:17<4:04:21, 33.65it/s]\n",
            "  0%|          | 4/500001 [00:00<3:59:47, 34.75it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Layer saved:  11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2164/500001 [01:04<4:07:54, 33.47it/s]\n",
            "  1%|▏         | 6652/500001 [03:16<4:03:16, 33.80it/s]\n",
            "  0%|          | 3/500001 [00:00<4:39:33, 29.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Layer saved:  12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2163/500001 [01:04<4:06:00, 33.73it/s]\n",
            "  1%|▏         | 6652/500001 [03:16<4:03:26, 33.78it/s]\n",
            "  0%|          | 4/500001 [00:00<4:13:40, 32.85it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Layer saved:  13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2164/500001 [01:04<4:06:41, 33.63it/s]\n",
            "  1%|▏         | 6652/500001 [03:17<4:03:42, 33.74it/s]\n",
            "  0%|          | 4/500001 [00:00<3:59:45, 34.76it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Layer saved:  14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2164/500001 [01:04<4:06:44, 33.63it/s]\n",
            "  1%|▏         | 6652/500001 [03:17<4:04:39, 33.61it/s]\n",
            "  0%|          | 4/500001 [00:00<4:23:58, 31.57it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Layer saved:  15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2164/500001 [01:04<4:08:34, 33.38it/s]\n",
            "  1%|▏         | 6652/500001 [03:18<4:04:49, 33.58it/s]\n",
            "  0%|          | 4/500001 [00:00<4:21:52, 31.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Layer saved:  16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2164/500001 [01:04<4:07:03, 33.58it/s]\n",
            "  1%|▏         | 6652/500001 [03:17<4:04:27, 33.64it/s]\n",
            "  0%|          | 4/500001 [00:00<4:17:35, 32.35it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Layer saved:  17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2164/500001 [01:04<4:08:00, 33.46it/s]\n",
            "  1%|▏         | 6652/500001 [03:17<4:04:25, 33.64it/s]\n",
            "  0%|          | 4/500001 [00:00<4:20:08, 32.03it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Layer saved:  18\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2163/500001 [01:04<4:08:46, 33.35it/s]\n",
            "  1%|▏         | 6652/500001 [03:17<4:03:54, 33.71it/s]\n",
            "  0%|          | 4/500001 [00:00<4:03:35, 34.21it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Layer saved:  19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2164/500001 [01:04<4:07:10, 33.57it/s]\n",
            "  1%|▏         | 6655/500001 [03:17<4:03:54, 33.71it/s]\n",
            "  0%|          | 4/500001 [00:00<4:02:22, 34.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Layer saved:  20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2164/500001 [01:04<4:06:46, 33.62it/s]\n",
            "  1%|▏         | 6652/500001 [03:17<4:03:36, 33.75it/s]\n",
            "  0%|          | 4/500001 [00:00<4:20:45, 31.96it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Layer saved:  21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2164/500001 [01:04<4:07:27, 33.53it/s]\n",
            "  1%|▏         | 6652/500001 [03:17<4:04:34, 33.62it/s]\n",
            "  0%|          | 4/500001 [00:00<4:06:30, 33.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Layer saved:  22\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2164/500001 [01:04<4:07:32, 33.52it/s]\n",
            "  1%|▏         | 6652/500001 [03:16<4:03:08, 33.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Layer saved:  23\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGNlejS-xW2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "def train_only(corpus=None, layer=11):\n",
        "    # prepare training data for densray\n",
        "    L = torch.load('/content/drive/My Drive/L'+config+'_'+str(nsamples)+'_'+str(layer)+'.pt').to(device)\n",
        "    R = torch.load('/content/drive/My Drive/R'+config+'_'+str(nsamples)+'_'+str(layer)+'.pt').to(device)\n",
        "    Z = torch.cat((L,R)).cpu().detach().numpy()\n",
        "    # compute conceptor\n",
        "    negC = process_cn_matrix(Z)\n",
        "    torch.save(torch.Tensor(negC).cpu(), '/content/drive/My Drive/negc'+config+'_'+str(nsamples)+'_'+str(layer)+'.pt')\n",
        "    # compute hard debiasing\n",
        "    #pca = PCA(n_components = 1)\n",
        "    #pca.fit(Z)\n",
        "    #pc1 = np.array(pca.components_)\n",
        "    #torch.save(torch.Tensor(pc1).cpu(), '/content/drive/My Drive/pc1'+config+'_'+str(nsamples)+'_'+str(layer)+'.pt')\n",
        "    # compute densray\n",
        "    #densray = DensRay(L,R)\n",
        "    #densray.fit(normalize_D=True)\n",
        "    #torch.save(densray.eigvecs, '/content/drive/My Drive/eigvecs_'+config+'_new2_'+str(nsamples)+'_'+str(layer)+'.pt')\n",
        "    print(str(layer)+' saved')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWRnzGNUZsSp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bebce705-d5be-47d0-cdef-7731822ecc13"
      },
      "source": [
        "for l in range(nlayer):\n",
        "    print(\"Layer \", l)\n",
        "    train_only(wiki, layer=l)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Layer  0\n",
            "starting...\n",
            "(5000, 1024)\n",
            "C calculated\n",
            "0 saved\n",
            "Layer  1\n",
            "starting...\n",
            "(5000, 1024)\n",
            "C calculated\n",
            "1 saved\n",
            "Layer  2\n",
            "starting...\n",
            "(5000, 1024)\n",
            "C calculated\n",
            "2 saved\n",
            "Layer  3\n",
            "starting...\n",
            "(5000, 1024)\n",
            "C calculated\n",
            "3 saved\n",
            "Layer  4\n",
            "starting...\n",
            "(5000, 1024)\n",
            "C calculated\n",
            "4 saved\n",
            "Layer  5\n",
            "starting...\n",
            "(5000, 1024)\n",
            "C calculated\n",
            "5 saved\n",
            "Layer  6\n",
            "starting...\n",
            "(5000, 1024)\n",
            "C calculated\n",
            "6 saved\n",
            "Layer  7\n",
            "starting...\n",
            "(5000, 1024)\n",
            "C calculated\n",
            "7 saved\n",
            "Layer  8\n",
            "starting...\n",
            "(5000, 1024)\n",
            "C calculated\n",
            "8 saved\n",
            "Layer  9\n",
            "starting...\n",
            "(5000, 1024)\n",
            "C calculated\n",
            "9 saved\n",
            "Layer  10\n",
            "starting...\n",
            "(5000, 1024)\n",
            "C calculated\n",
            "10 saved\n",
            "Layer  11\n",
            "starting...\n",
            "(5000, 1024)\n",
            "C calculated\n",
            "11 saved\n",
            "Layer  12\n",
            "starting...\n",
            "(5000, 1024)\n",
            "C calculated\n",
            "12 saved\n",
            "Layer  13\n",
            "starting...\n",
            "(5000, 1024)\n",
            "C calculated\n",
            "13 saved\n",
            "Layer  14\n",
            "starting...\n",
            "(5000, 1024)\n",
            "C calculated\n",
            "14 saved\n",
            "Layer  15\n",
            "starting...\n",
            "(5000, 1024)\n",
            "C calculated\n",
            "15 saved\n",
            "Layer  16\n",
            "starting...\n",
            "(5000, 1024)\n",
            "C calculated\n",
            "16 saved\n",
            "Layer  17\n",
            "starting...\n",
            "(5000, 1024)\n",
            "C calculated\n",
            "17 saved\n",
            "Layer  18\n",
            "starting...\n",
            "(5000, 1024)\n",
            "C calculated\n",
            "18 saved\n",
            "Layer  19\n",
            "starting...\n",
            "(5000, 1024)\n",
            "C calculated\n",
            "19 saved\n",
            "Layer  20\n",
            "starting...\n",
            "(5000, 1024)\n",
            "C calculated\n",
            "20 saved\n",
            "Layer  21\n",
            "starting...\n",
            "(5000, 1024)\n",
            "C calculated\n",
            "21 saved\n",
            "Layer  22\n",
            "starting...\n",
            "(5000, 1024)\n",
            "C calculated\n",
            "22 saved\n",
            "Layer  23\n",
            "starting...\n",
            "(5000, 1024)\n",
            "C calculated\n",
            "23 saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8Me4_OyFyKo",
        "colab_type": "text"
      },
      "source": [
        "# WEAT Algorithm\n",
        "The Word Embeddings Association Test (WEAT), as proposed by Calikson et. al., is a statistical test analogous to the Implicit Association Test (IAT) which helps quantify human biases in textual data. WEAT uses the cosine similarity between word embeddings which is analogous to the reaction time when subjects are asked to pair two concepts they find similar in the IAT.  WEAT considers two sets of target words and two sets of attribute words of equal size. The null hypothesis is that there is no difference between the two sets of target words and the sets of attribute words in terms of their relative similarities measured as the cosine similarity between the embeddings. For example, consider the target sets as words representing *Career* and *Family* and let the two sets of attribute words be *Male* and *Female* in that order. The null hypothesis states that *Career* and *Family* are equally similar (mathematically, in terms of the mean cosine similarity between the word representations) to each of the words in the *Male* and *Female* word lists. \n",
        "\n",
        "REF: https://gist.github.com/SandyRogers/e5c2e938502a75dcae25216e4fae2da5\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf6_liysF8en",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def swAB(W, A, B):\n",
        "    \"\"\"Calculates differential cosine-similarity between word vectors in W, A and W, B\n",
        "        Arguments\n",
        "                W, A, B : n x d matrix of word embeddings stored row wise\n",
        "    \"\"\"\n",
        "    WA = cosine_similarity(W,A)\n",
        "    WB = cosine_similarity(W,B)\n",
        "    \n",
        "    #Take mean along columns\n",
        "    WAmean = np.mean(WA, axis = 1)\n",
        "    WBmean = np.mean(WB, axis = 1)\n",
        "    \n",
        "    return (WAmean - WBmean)\n",
        "  \n",
        "def test_statistic(X, Y, A, B):\n",
        "    \"\"\"Calculates test-statistic between the pair of association words and target words\n",
        "        Arguments\n",
        "                X, Y, A, B : n x d matrix of word embeddings stored row wise\n",
        "        Returns\n",
        "                Test Statistic\n",
        "    \"\"\"\n",
        "    return (sum(swAB(X, A, B)) - sum(swAB(Y, A, B)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9ZO4--vpBh6",
        "colab_type": "text"
      },
      "source": [
        "## Effect Size (d-value)\n",
        "\n",
        "The ''effect size'' is a normalized measure of how separated the two distributions are."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHPKwHLjo-m8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weat_effect_size(X, Y, A, B, embd):\n",
        "    \"\"\"Computes the effect size for the given list of association and target word pairs\n",
        "        Arguments\n",
        "                X, Y : List of association words\n",
        "                A, B : List of target words\n",
        "                embd : Dictonary of word-to-embedding for all words\n",
        "        Returns\n",
        "                Effect Size\n",
        "    \"\"\"\n",
        "    Xmat = np.array([embd[w] for w in X if w in embd])\n",
        "    Ymat = np.array([embd[w] for w in Y if w in embd])\n",
        "    Amat = np.array([embd[w] for w in A if w in embd])\n",
        "    Bmat = np.array([embd[w] for w in B if w in embd])\n",
        "    XuY = list(set(X).union(Y))\n",
        "    XuYmat = []\n",
        "    for w in XuY:\n",
        "        if w.lower() in embd:\n",
        "            XuYmat.append(embd[w.lower()])\n",
        "    XuYmat = np.array(XuYmat)\n",
        "    d = (np.mean(swAB(Xmat,Amat,Bmat)) - np.mean(swAB(Ymat,Amat,Bmat)))/np.std(swAB(XuYmat, Amat, Bmat))\n",
        "    return d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8foGwVSGI16",
        "colab_type": "text"
      },
      "source": [
        "## P-Value\n",
        "\n",
        "The one-sided P value measures the likelihood that a random permutation of the attribute words would produce at least the observed test statistic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDy-duFOFj71",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_permutation(iterable, r=None):\n",
        "    \"\"\"Returns a random permutation for any iterable object\"\"\"\n",
        "    pool = tuple(iterable)\n",
        "    r = len(pool) if r is None else r\n",
        "    return tuple(random.sample(pool, r))\n",
        "\n",
        "def weat_p_value(X, Y, A, B, embd, sample=None):\n",
        "    np.random.seed(42)\n",
        "    random.seed(42)\n",
        "    \"\"\"Computes the one-sided P value for the given list of association and target word pairs\n",
        "        Arguments\n",
        "                X, Y : List of association words\n",
        "                A, B : List of target words\n",
        "                embd : Dictonary of word-to-embedding for all words\n",
        "                sample : Number of random permutations used.\n",
        "        Returns\n",
        "    \"\"\"\n",
        "    size_of_permutation = min(len(X), len(Y))\n",
        "    X_Y = X + Y\n",
        "    test_stats_over_permutation = []\n",
        "    \n",
        "    Xmat = np.array([embd[w.lower()] for w in X if w.lower() in embd])\n",
        "    Ymat = np.array([embd[w.lower()] for w in Y if w.lower() in embd])\n",
        "    Amat = np.array([embd[w.lower()] for w in A if w.lower() in embd])\n",
        "    Bmat = np.array([embd[w.lower()] for w in B if w.lower() in embd])\n",
        "    \n",
        "    if not sample:\n",
        "        permutations = combinations(X_Y, size_of_permutation)\n",
        "    else:\n",
        "        permutations = [random_permutation(X_Y, size_of_permutation) for s in range(sample)]\n",
        "        \n",
        "    for Xi in permutations:\n",
        "        Yi = filterfalse(lambda w:w in Xi, X_Y)\n",
        "        Ximat = np.array([embd[w.lower()] for w in Xi if w.lower() in embd])\n",
        "        Yimat = np.array([embd[w.lower()] for w in Yi if w.lower() in embd])\n",
        "        test_stats_over_permutation.append(test_statistic(Ximat, Yimat, Amat, Bmat))\n",
        "        \n",
        "    unperturbed = test_statistic(Xmat, Ymat, Amat, Bmat)\n",
        "    \n",
        "    is_over = np.array([o > unperturbed for o in test_stats_over_permutation])\n",
        "    \n",
        "    return is_over.sum() / is_over.size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdo3YyjgKXzs",
        "colab_type": "text"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuvUghoSl5tF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def category(type=1):\n",
        "    m_words = \"male, man, boy, brother, he, him, his, son, father, uncle, grandfather\".lower().replace(\" \", \"\").split(',')\n",
        "    f_words = \"female, woman, girl, sister, she, her, hers, daughter, mother, aunt, grandmother\".lower().replace(\" \", \"\").split(',')\n",
        "    if type == 1:\n",
        "        #B1: career vs family\n",
        "        x_words = \"executive, management, professional, corporation, salary, office, business, career\".lower().replace(\" \", \"\").split(',')\n",
        "        y_words = \"home, parents, children, family, cousins, marriage, wedding, relatives\".lower().replace(\" \", \"\").split(',')\n",
        "    elif type == 2:\n",
        "        #B2: maths vs arts\n",
        "        x_words = \"math, algebra, geometry, calculus, equations, computation, numbers, addition\".lower().replace(\" \", \"\").split(',')\n",
        "        y_words = \"poetry, art, Shakespeare, dance, literature, novel, symphony, drama\".lower().replace(\" \", \"\").split(',')\n",
        "    elif type == 3:\n",
        "        #B3: science vs arts\n",
        "        x_words = \"science, technology, physics, chemistry, Einstein, NASA, experiment, astronomy\".lower().replace(\" \", \"\").split(',')\n",
        "        y_words = \"poetry, art, Shakespeare, dance, literature, novel, symphony, drama\".lower().replace(\" \", \"\").split(',')\n",
        "    elif type == 4:\n",
        "        #B4: intelligence vs appearance\n",
        "        x_words = \"precocious, resourceful, inquisitive, genius, inventive, astute, adaptable, reflective,discerning, intuitive, inquiring, judicious, analytical, apt, venerable, imaginative,shrewd, thoughtful, wise, smart, ingenious, clever, brilliant, logical, intelligent\".lower().replace(\" \", \"\").split(',')\n",
        "        y_words = \"alluring, voluptuous, blushing, homely, plump, sensual, gorgeous, slim, bald,athletic, fashionable, stout, ugly, muscular, slender, feeble, handsome, healthy,attractive, fat, weak, thin, pretty, beautiful, strong\".lower().replace(\" \", \"\").split(',')\n",
        "    elif type == 5:\n",
        "        #B5: strength vs weakness\n",
        "        x_words = \"power, strong, confident, dominant, potent, command, assert, loud, bold, succeed,triumph, leader, shout, dynamic, winner\".lower().replace(\" \", \"\").split(',')\n",
        "        y_words = \"weak, surrender, timid, vulnerable, weakness, wispy, withdraw, yield, failure, shy,follow, lose, fragile, afraid, loser\".lower().replace(\" \", \"\").split(',')\n",
        "    return m_words, f_words, x_words, y_words\n",
        "\n",
        "def category_2(type=1):\n",
        "    if type == 1:\n",
        "        #Career/Family\n",
        "        m_words = 'John, Paul, Mike, Kevin, Steve, Greg, Jeff, Bill'.lower().replace(\" \", \"\").split(',')\n",
        "        f_words = 'Amy, Joan, Lisa, Sarah, Diana, Kate, Ann, Donna'.lower().replace(\" \", \"\").split(',')\n",
        "        x_words = 'executive, management, professional, corporation, salary, office, business, career'.lower().replace(\" \", \"\").split(',')\n",
        "        y_words = 'home, parents, children, family, cousins, marriage, wedding, relatives'.lower().replace(\" \", \"\").split(',')\n",
        "    elif type == 2:\n",
        "        #Math/Art\n",
        "        m_words = 'math, algebra, geometry, calculus, equations, computation, numbers, addition'.lower().replace(\" \", \"\").split(',')\n",
        "        f_words = 'poetry, art, dance, literature, novel, symphony, drama, sculpture'.lower().replace(\" \", \"\").split(',')\n",
        "        x_words = 'male, man, boy, brother, he, him, his, son'.lower().replace(\" \", \"\").split(',')\n",
        "        y_words = 'female, woman, girl, sister, she, her, hers, daughter'.lower().replace(\" \", \"\").split(',')\n",
        "    elif type == 3:\n",
        "        #Science/Art\n",
        "        m_words = 'science, technology, physics, chemistry, Einstein, NASA, experiment, astronomy'.lower().replace(\" \", \"\").split(',')\n",
        "        f_words = 'poetry, art, Shakespeare, dance, literature, novel, symphony, drama'.lower().replace(\" \", \"\").split(',')\n",
        "        x_words = 'brother, father, uncle, grandfather, son, he, his, him'.lower().replace(\" \", \"\").split(',')\n",
        "        y_words = 'sister, mother, aunt, grandmother, daughter, she, hers, her'.lower().replace(\" \", \"\").split(',')\n",
        "    return m_words, f_words, x_words, y_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvwnbWHdxCJs",
        "colab_type": "text"
      },
      "source": [
        "# Get Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFn83YmOpHUY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "49e24115-7324-48a5-ffcd-a1abc0db14da"
      },
      "source": [
        "import densray_bert\n",
        "\n",
        "\n",
        "def get_eigvecs_dict(layer=-1):\n",
        "    eigvecs_dict = {}\n",
        "    #-1:apply to all layers\n",
        "    if layer == -1:\n",
        "        for l in range(nlayer):\n",
        "            eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_'+config+'_noavg_'+str(nsamples)+'_'+str(l)+'.pt', True)\n",
        "    elif layer ==-2:\n",
        "        for l in range(nlayer):\n",
        "            eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_'+config+'_noavg_'+str(nsamples)+'_'+str(l)+'.pt', False)\n",
        "    else:\n",
        "        for l in range(nlayer):\n",
        "            if l==layer:\n",
        "                eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_'+config+'_noavg_'+str(nsamples)+'_'+str(l)+'.pt', True)\n",
        "            else:\n",
        "                eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_'+config+'_noavg_'+str(nsamples)+'_'+str(l)+'.pt', False)\n",
        "    return eigvecs_dict\n",
        "\n",
        "\n",
        "def get_bert_embedding(model, wordlist, is_targets=1):\n",
        "    vecss = torch.Tensor().to(device)\n",
        "    for w in wordlist:\n",
        "        text = w + ' is ' + tokenizer.mask_token + '.' if is_targets else tokenizer.mask_token + ' is ' + w + '.'\n",
        "        vec = tokenizer.prepare_for_model(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text)),\n",
        "                                            return_token_type_ids=False, return_tensors='pt')['input_ids'].to(device)\n",
        "        vecs = vec.clone().detach()\n",
        "        # get output\n",
        "        vecs = model.bert(vecs)[0]#[2][nlayer]\n",
        "        vecs = vecs[0][1:-4,:].mean(dim=0).unsqueeze(0) if is_targets else vecs[0][3:-2,:].mean(dim=0).unsqueeze(0)\n",
        "        vecss = torch.cat((vecss,vecs))\n",
        "    return vecss\n",
        "\n",
        "def eval_per_layer(layer=-2):\n",
        "    config_class = get_eigvecs_dict(layer)\n",
        "    model = densray_bert.BertForMaskedLM_1.from_pretrained('bert-'+config+'-uncased', eigvecs_dict=get_eigvecs_dict(l)).to(device)\n",
        "    # turn on eval mode\n",
        "    model.eval()\n",
        "    m = get_bert_embedding(model, m_words, is_targets=0).cpu().detach().numpy()\n",
        "    f = get_bert_embedding(model, f_words, is_targets=0).cpu().detach().numpy()\n",
        "    x = get_bert_embedding(model, x_words, is_targets=1).cpu().detach().numpy()\n",
        "    y = get_bert_embedding(model, y_words, is_targets=1).cpu().detach().numpy()\n",
        "    embed = {}\n",
        "    for i in range(len(m_words)): embed[m_words[i]] = m[i]\n",
        "    for i in range(len(f_words)): embed[f_words[i]] = f[i]\n",
        "    for i in range(len(x_words)): embed[x_words[i]] = x[i]\n",
        "    for i in range(len(y_words)): embed[y_words[i]] = y[i]\n",
        "    return embed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-85221fb33ae4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdensray_bert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_eigvecs_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0meigvecs_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'densray_bert'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHkY40G5KpbY",
        "colab_type": "text"
      },
      "source": [
        "# Go!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nTgkJtD814V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "outputId": "4ae820b3-f747-4305-87dc-0ddab5f013cc"
      },
      "source": [
        "for t in range(1,4):\n",
        "    m_words, f_words, x_words, y_words = category_2(t)\n",
        "    print('d    d_densray |d|-|d_densray|   p   p-densray   p_densray-p')\n",
        "    l=-2\n",
        "    # no densray\n",
        "    embed = eval_per_layer(layer=l)\n",
        "    d =  weat_effect_size(x_words, y_words, m_words, f_words, embed)\n",
        "    p = weat_p_value(x_words, y_words, m_words, f_words, embed, sample=1000)\n",
        "    #densray\n",
        "    for l in range(-1, 0):\n",
        "        # densray\n",
        "        embed = eval_per_layer(layer=l)\n",
        "        d_densray =  weat_effect_size(x_words, y_words, m_words, f_words, embed)\n",
        "        p_densray = weat_p_value(x_words, y_words, m_words, f_words, embed, sample=1000)\n",
        "        print(round(d,4), round(d_densray,4), round(abs(d)-abs(d_densray),4), \n",
        "              round(p,4), round(p_densray,4), round(p_densray-p,4))\n",
        "    print('\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "d    d_densray |d|-|d_densray|   p   p-densray   p_densray-p\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-e850a8b9cc07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0ml\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# no densray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0membed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_per_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mweat_effect_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweat_p_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'eval_per_layer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpvAEp76A3R8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wsx5wTbfA3aD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LihkhEoaA3dP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt2I_oTtA3iz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rzlSkklA3l0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJZw5G9OA3gn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y0F4rc1L42nN",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_BbF4ckFEVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1qNkR7m3Mwn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "92c4ede8-9326-429a-eb6a-525276d5c52b"
      },
      "source": [
        "eigviecs.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([768, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkBq0QjsYE0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pc1=torch.load('/content/drive/My Drive/pc1base_'+str(5000)+'_'+str(11)+'.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSFwpKCrYOjH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "85c3cf90-666d-45ef-c9c3-3d36d713d412"
      },
      "source": [
        "pc1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzAwQyzbYQm-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pc1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fkOG-s7aRZU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "33644154-9cb5-4068-c97a-d41c2034d24d"
      },
      "source": [
        "import re\n",
        "pc1=torch.load('/content/drive/My Drive/pc1base_'+str(5000)+'_'+str(11)+'.pt')\n",
        "titles='boy girl brother sister dad mom father mother he she king queen uncle aunt nephew niece groom bride prince princess'.split(' ')\n",
        "lines = [re.sub('_',' ',tokenizer.mask_token+' is a '+i+' .') for i in titles]\n",
        "examples = tokenizer.batch_encode_plus(lines, add_special_tokens=True, max_length=128)[\"input_ids\"]\n",
        "baseline = []\n",
        "for i in range(len(examples)):\n",
        "    ei = torch.tensor(examples[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "    output = model(ei)[1][11][0]#[5]\n",
        "    print(titles[i],torch.mm(output,pc1.T.to(device))[4].data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "boy tensor([1.5560], device='cuda:0')\n",
            "girl tensor([-1.7348], device='cuda:0')\n",
            "brother tensor([2.3765], device='cuda:0')\n",
            "sister tensor([-0.7137], device='cuda:0')\n",
            "dad tensor([1.6269], device='cuda:0')\n",
            "mom tensor([-1.8257], device='cuda:0')\n",
            "father tensor([1.8576], device='cuda:0')\n",
            "mother tensor([-1.9006], device='cuda:0')\n",
            "he tensor([3.5507], device='cuda:0')\n",
            "she tensor([-3.3792], device='cuda:0')\n",
            "king tensor([0.9770], device='cuda:0')\n",
            "queen tensor([-1.5296], device='cuda:0')\n",
            "uncle tensor([1.8033], device='cuda:0')\n",
            "aunt tensor([-1.0254], device='cuda:0')\n",
            "nephew tensor([1.5656], device='cuda:0')\n",
            "niece tensor([-1.1062], device='cuda:0')\n",
            "groom tensor([0.5650], device='cuda:0')\n",
            "bride tensor([-1.0015], device='cuda:0')\n",
            "prince tensor([0.9464], device='cuda:0')\n",
            "princess tensor([-1.1232], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ank18evL3Yvi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "55c20480-b26a-4ea0-9141-658bf305f137"
      },
      "source": [
        "import re\n",
        "eigviecs=torch.load('/content/drive/My Drive/eigvecs_base_new_'+str(5000)+'_'+str(9)+'.pt')\n",
        "titles='boy girl brother sister dad mom father mother he she king queen uncle aunt nephew niece groom bride prince princess'.split(' ')\n",
        "lines = [re.sub('_',' ',tokenizer.mask_token+' is a '+i+' .') for i in titles]\n",
        "examples = tokenizer.batch_encode_plus(lines, add_special_tokens=True, max_length=128)[\"input_ids\"]\n",
        "baseline = []\n",
        "for i in range(len(examples)):\n",
        "    ei = torch.tensor(examples[i], dtype=torch.long).unsqueeze(0).to(device)\n",
        "    output = model(ei)[1][6][0]#[5]\n",
        "    print(titles[i],torch.mm(output,eigviecs.to(device))[4][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "boy tensor(-2.8731, device='cuda:0', grad_fn=<SelectBackward>)\n",
            "girl tensor(2.8983, device='cuda:0', grad_fn=<SelectBackward>)\n",
            "brother tensor(-1.6107, device='cuda:0', grad_fn=<SelectBackward>)\n",
            "sister tensor(4.3276, device='cuda:0', grad_fn=<SelectBackward>)\n",
            "dad tensor(-1.6326, device='cuda:0', grad_fn=<SelectBackward>)\n",
            "mom tensor(3.0312, device='cuda:0', grad_fn=<SelectBackward>)\n",
            "father tensor(-2.0066, device='cuda:0', grad_fn=<SelectBackward>)\n",
            "mother tensor(3.7363, device='cuda:0', grad_fn=<SelectBackward>)\n",
            "he tensor(-4.0711, device='cuda:0', grad_fn=<SelectBackward>)\n",
            "she tensor(3.0651, device='cuda:0', grad_fn=<SelectBackward>)\n",
            "king tensor(-2.3243, device='cuda:0', grad_fn=<SelectBackward>)\n",
            "queen tensor(3.6856, device='cuda:0', grad_fn=<SelectBackward>)\n",
            "uncle tensor(-1.4492, device='cuda:0', grad_fn=<SelectBackward>)\n",
            "aunt tensor(4.2484, device='cuda:0', grad_fn=<SelectBackward>)\n",
            "nephew tensor(-1.5659, device='cuda:0', grad_fn=<SelectBackward>)\n",
            "niece tensor(3.5433, device='cuda:0', grad_fn=<SelectBackward>)\n",
            "groom tensor(-1.9304, device='cuda:0', grad_fn=<SelectBackward>)\n",
            "bride tensor(4.5391, device='cuda:0', grad_fn=<SelectBackward>)\n",
            "prince tensor(-3.1355, device='cuda:0', grad_fn=<SelectBackward>)\n",
            "princess tensor(2.9099, device='cuda:0', grad_fn=<SelectBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eP1cE2Cw1okv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "26ca3ea2-967d-4260-d072-c54fb926cd12"
      },
      "source": [
        "output[1][12][0]#[5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBvxpIRL1s6i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "40198a1b-a8d6-4f7c-eca4-cc07bc0800e9"
      },
      "source": [
        "examples"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[101, 103, 2003, 1037, 2158, 1012, 102],\n",
              " [101, 103, 2003, 1037, 2450, 1012, 102],\n",
              " [101, 103, 2003, 1037, 2269, 1012, 102],\n",
              " [101, 103, 2003, 1037, 2388, 1012, 102]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHBR4zZU15bl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}