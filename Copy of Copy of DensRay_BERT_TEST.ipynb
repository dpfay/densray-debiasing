{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Copy of DensRay_BERT_TEST.ipynb","provenance":[{"file_id":"1QsCRMwPNffdfgjR_jvW3O83h2uyiGxi4","timestamp":1589947460129},{"file_id":"14320o-9-uc0nsejqTeNe66uhFYw4QSU9","timestamp":1589939467638},{"file_id":"1ePa9C1bq3wS5WByfi8L9hCBGqtl2HhWu","timestamp":1588134391908},{"file_id":"1c__r6mWy4-vOfdfL4tmqij72Qayz2yHY","timestamp":1586403317137},{"file_id":"1OCwvXO9cB1Ke5Bi11SvjovgCKDh6iE6M","timestamp":1586403087992},{"file_id":"1tgzcbuJrxhBeC6FnQig4Z8RLj3TD2Y-p","timestamp":1586402323174},{"file_id":"1gnY3Blunw8HAUxw8wAFCzirazvafbmQn","timestamp":1586399576485},{"file_id":"1GHdeIzOlLZLZ2RN2MohSwBfpWuNi1ogN","timestamp":1583364612376},{"file_id":"1BA0JTleU0JVbJjgrXw5ULWcTa5Nl5sGb","timestamp":1583315004957},{"file_id":"1xWrKImFLCBga34NpEp9EoaMc2AfUPXIK","timestamp":1583286864919}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"1fb625bd1f824a6098b465972053d567":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_18b6715bf79e4794b82536f19e30526a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3777c77af367431abeb443e9e0dbd1dc","IPY_MODEL_bb18db70fa2f434fa0296500e5ad13ce"]}},"18b6715bf79e4794b82536f19e30526a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3777c77af367431abeb443e9e0dbd1dc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c7b1a8e73fbb440b865afafd19ef73e2","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":434,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":434,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4e140b2c670943d78e49b75b9966ee95"}},"bb18db70fa2f434fa0296500e5ad13ce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_be7d9a9a717248a3b39536912d92700b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 434/434 [00:23&lt;00:00, 18.3B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_298d15b1ac504ba3a13f86c315ebbfd8"}},"c7b1a8e73fbb440b865afafd19ef73e2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4e140b2c670943d78e49b75b9966ee95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"be7d9a9a717248a3b39536912d92700b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"298d15b1ac504ba3a13f86c315ebbfd8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"278f139537334088bb1644eea110cf35":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4629a779c8114ba7905de42e255d1084","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_dd551212c7114639a82ae9f260a2b1b6","IPY_MODEL_cc074d9fe71f4a12b1f336fdb5f9e041"]}},"4629a779c8114ba7905de42e255d1084":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dd551212c7114639a82ae9f260a2b1b6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3cb881c51b34405eb636d864c1768cd3","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1344997306,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1344997306,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4db831a6bf664b6aaa31d7276c5647a5"}},"cc074d9fe71f4a12b1f336fdb5f9e041":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3d77516fda944256a83b7288ae258930","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.34G/1.34G [00:21&lt;00:00, 61.7MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_312f6810f0974dabbce5f749182063b9"}},"3cb881c51b34405eb636d864c1768cd3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4db831a6bf664b6aaa31d7276c5647a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3d77516fda944256a83b7288ae258930":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"312f6810f0974dabbce5f749182063b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a2710fdb655d4012be9c3fb56176d336":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7d58f8cea8924c0c86c4402bb2e6308e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9c7cd92a2eed408cb7da267dcd8df2e2","IPY_MODEL_ad560f43ed8d4f1482a3f2ab3cf52bd9"]}},"7d58f8cea8924c0c86c4402bb2e6308e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9c7cd92a2eed408cb7da267dcd8df2e2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_27aad7451ee64ac99077a5b8aa8b812d","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2739952dbb37428f9eb7cafea7c0e479"}},"ad560f43ed8d4f1482a3f2ab3cf52bd9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6664045aeb3e4eb2ae006846306a23b2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 1.60MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_61cd9ab76d5d45029ef293b6cddd5a8c"}},"27aad7451ee64ac99077a5b8aa8b812d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2739952dbb37428f9eb7cafea7c0e479":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6664045aeb3e4eb2ae006846306a23b2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"61cd9ab76d5d45029ef293b6cddd5a8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"q2O3yi9gUjY-","colab_type":"code","outputId":"5f722531-254c-466d-dd60-68ee8d672936","executionInfo":{"status":"ok","timestamp":1589947486601,"user_tz":-120,"elapsed":7251,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":712}},"source":["!pip install transformers==2.8.0"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting transformers==2.8.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n","\u001b[K     |████████████████████████████████| 573kB 3.4MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.18.4)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/88/49e772d686088e1278766ad68a463513642a2a877487decbd691dec02955/sentencepiece-0.1.90-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 15.0MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 23.8MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2.23.0)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.7)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (4.41.1)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.13.10)\n","Collecting tokenizers==0.5.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n","\u001b[K     |████████████████████████████████| 3.7MB 18.2MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (3.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2019.12.20)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (0.15.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2020.4.5.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (0.10.0)\n","Requirement already satisfied: botocore<1.17.0,>=1.16.10 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (1.16.10)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (0.3.3)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.10->boto3->transformers==2.8.0) (0.15.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.10->boto3->transformers==2.8.0) (2.8.1)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=7de3716f25d32ba5145f46c418f0632438462f7452614456dcfed0bf7698c992\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.90 tokenizers-0.5.2 transformers-2.8.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LALnwVo3yRML","colab_type":"code","outputId":"324ca8ef-0be9-4469-8329-48bb08022e78","executionInfo":{"status":"ok","timestamp":1589943639774,"user_tz":-120,"elapsed":7423,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":212}},"source":["!wget https://raw.githubusercontent.com/huggingface/transformers/v2.8.0/examples/run_language_modeling.py"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2020-05-20 03:00:36--  https://raw.githubusercontent.com/huggingface/transformers/v2.8.0/examples/run_language_modeling.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 34328 (34K) [text/plain]\n","Saving to: ‘run_language_modeling.py.1’\n","\n","\r          run_langu   0%[                    ]       0  --.-KB/s               \rrun_language_modeli 100%[===================>]  33.52K  --.-KB/s    in 0.01s   \n","\n","2020-05-20 03:00:37 (2.27 MB/s) - ‘run_language_modeling.py.1’ saved [34328/34328]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZOCrXcMzyTNi","colab_type":"code","outputId":"1fc85c62-d00b-4b4f-eae6-75b1a6be667a","executionInfo":{"status":"ok","timestamp":1589943832839,"user_tz":-120,"elapsed":200218,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":248}},"source":["!wget https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-2-v1.zip\n","!unzip wikitext-2-v1.zip"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2020-05-20 03:00:39--  https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-2-v1.zip\n","Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.176.141\n","Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.176.141|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 4475746 (4.3M) [application/zip]\n","Saving to: ‘wikitext-2-v1.zip.1’\n","\n","wikitext-2-v1.zip.1 100%[===================>]   4.27M  2.92MB/s    in 1.5s    \n","\n","2020-05-20 03:00:41 (2.92 MB/s) - ‘wikitext-2-v1.zip.1’ saved [4475746/4475746]\n","\n","Archive:  wikitext-2-v1.zip\n","replace wikitext-2/wiki.test.tokens? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ikGXqkSQDCwH","colab_type":"code","outputId":"0ecf4e8b-504b-4af5-af53-19fe2e79ba41","executionInfo":{"status":"ok","timestamp":1589947528482,"user_tz":-120,"elapsed":45654,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":126}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5rMiCKAusFtK","colab_type":"text"},"source":["# Config"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lyUbLYhu3m4b","scrolled":true,"outputId":"cf08a452-e0ec-460b-90aa-3db84c8a8f12","executionInfo":{"status":"ok","timestamp":1589947588335,"user_tz":-120,"elapsed":55261,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["1fb625bd1f824a6098b465972053d567","18b6715bf79e4794b82536f19e30526a","3777c77af367431abeb443e9e0dbd1dc","bb18db70fa2f434fa0296500e5ad13ce","c7b1a8e73fbb440b865afafd19ef73e2","4e140b2c670943d78e49b75b9966ee95","be7d9a9a717248a3b39536912d92700b","298d15b1ac504ba3a13f86c315ebbfd8","278f139537334088bb1644eea110cf35","4629a779c8114ba7905de42e255d1084","dd551212c7114639a82ae9f260a2b1b6","cc074d9fe71f4a12b1f336fdb5f9e041","3cb881c51b34405eb636d864c1768cd3","4db831a6bf664b6aaa31d7276c5647a5","3d77516fda944256a83b7288ae258930","312f6810f0974dabbce5f749182063b9","a2710fdb655d4012be9c3fb56176d336","7d58f8cea8924c0c86c4402bb2e6308e","9c7cd92a2eed408cb7da267dcd8df2e2","ad560f43ed8d4f1482a3f2ab3cf52bd9","27aad7451ee64ac99077a5b8aa8b812d","2739952dbb37428f9eb7cafea7c0e479","6664045aeb3e4eb2ae006846306a23b2","61cd9ab76d5d45029ef293b6cddd5a8c"]}},"source":["import torch\n","import transformers\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","config = 'large'\n","nlayer = 12 if config == 'base' else 24\n","nsamples = 10000\n","\n","model = transformers.BertForMaskedLM.from_pretrained('bert-'+config+'-uncased', output_hidden_states=True).to(device)\n","tokenizer = transformers.BertTokenizer.from_pretrained('bert-'+config+'-uncased')\n","# turn on eval mode\n","model.eval()"],"execution_count":3,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1fb625bd1f824a6098b465972053d567","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=434.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"278f139537334088bb1644eea110cf35","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1344997306.0, style=ProgressStyle(descr…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a2710fdb655d4012be9c3fb56176d336","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["BertForMaskedLM(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n","      (position_embeddings): Embedding(512, 1024)\n","      (token_type_embeddings): Embedding(2, 1024)\n","      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (12): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (13): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (14): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (15): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (16): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (17): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (18): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (19): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (20): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (21): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (22): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (23): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (cls): BertOnlyMLMHead(\n","    (predictions): BertLMPredictionHead(\n","      (transform): BertPredictionHeadTransform(\n","        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","      )\n","      (decoder): Linear(in_features=1024, out_features=30522, bias=True)\n","    )\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"JVspk5aXsMfj","colab_type":"text"},"source":["# Analogies"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-iQFSiRGplOC","colab":{}},"source":["from torch.utils.data import DataLoader, Dataset\n","import tqdm\n","\n","class GoogleAnalogies:\n","    def __init__(self, path='/content/drive/My Drive/questions-words.txt'):\n","        self.Lset = set()\n","        self.Rset = set()\n","        # this time only want the words in vocab !!!!!!!!!!\n","        with open(path,'r',encoding='utf8') as f:\n","            for line in f.readlines():\n","                line = line.strip().split(' ')\n","                self.Rset.update([line[1],line[3]])\n","                for w in [line[0],line[2]]:\n","                    if w in tokenizer.vocab.keys():\n","                        self.Lset.add(w)\n","                for w in [line[1],line[3]]:\n","                    if w in tokenizer.vocab.keys():\n","                        self.Rset.add(w)\n","        self.Lset = tokenizer.convert_tokens_to_ids(list(self.Lset))\n","        self.Rset = tokenizer.convert_tokens_to_ids(list(self.Rset))\n","        self.pieces = self.Lset+self.Rset\n","    \"\"\"\n","    def get_embeddings_from_cropus(self, corpus, layer=11):\n","        L = torch.Tensor().to(device)\n","        R = torch.Tensor().to(device)\n","        for i in tqdm.trange(nsamples):\n","            # get useful idxs\n","            sentence = corpus.__getitem__(i)[0].cpu().tolist()\n","            vecs = model.bert(corpus.__getitem__(i))[2][layer+1][0][1:-1]#!!!!!!!!!!!\n","            for j in range(vecs.shape[0]):\n","                if corpus.labels[i][j]==1:\n","                    L = torch.cat((L, vecs[j].unsqueeze(0)))\n","                elif corpus.labels[i][j]==-1:\n","                    R = torch.cat((R, vecs[j].unsqueeze(0)))\n","        return L, R\n","    \"\"\"               \n","    def get_embeddings_from_cropus(self, corpus, layer=11):\n","        #balanced\n","        L = torch.Tensor().to(device)\n","        R = torch.Tensor().to(device)\n","        #for i in tqdm.trange(nsamples):\n","        for i in tqdm.trange(nsamples):\n","            # get useful idxs\n","            sentence = corpus.__getitem__(i)[0].cpu().tolist()\n","            vecs = model.bert(corpus.__getitem__(i))[2][layer+1][0][1:-1]#!!!!!!!!!!!\n","            if L.shape[0]<nsamples//2:\n","                for j in range(vecs.shape[0]):\n","                    if corpus.labels[i][j]==1:\n","                        L = torch.cat((L, vecs[j].unsqueeze(0)))\n","                    elif corpus.labels[i][j]==-1:\n","                        R = torch.cat((R, vecs[j].unsqueeze(0)))\n","            else:\n","                for j in range(vecs.shape[0]):\n","                    if corpus.labels[i][j]==-1:\n","                        R = torch.cat((R, vecs[j].unsqueeze(0)))\n","            if L.shape[0]+R.shape[0]>=nsamples:\n","                break\n","        return L, R\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"fu7v-iW5yUyn","colab":{}},"source":["analogy = GoogleAnalogies('/content/drive/My Drive/questions-words.txt')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rKES65WgsQwL","colab_type":"text"},"source":["# Dataset"]},{"cell_type":"code","metadata":{"id":"TPZn1PmIUDUn","colab_type":"code","colab":{}},"source":["from torch.utils.data import DataLoader, Dataset\n","import tqdm\n","import pickle\n","\n","class TextDataset(Dataset):\n","    def __init__(self, path=\"/content/drive/My Drive/wikien_senttok_500k.txt\"):\n","        self.examples, self.labels = pickle.load(open(path, 'rb'))\n","    \n","    def __len__(self):\n","        return len(self.examples)\n","    \n","    def __getitem__(self, i):\n","        return tokenizer.prepare_for_model(self.examples[i][:510], return_token_type_ids=False, return_tensors='pt')['input_ids'].to(device)\n","        #return torch.tensor(self.examples[i], dtype=torch.long).unsqueeze(0).to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9iFT9l4YUDUs","colab_type":"code","colab":{}},"source":["wiki = TextDataset(\"/content/drive/My Drive/wikien_senttok_500k.txt\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Kp1vcAybsSg5","colab_type":"text"},"source":["# DensRay"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"o2gAvuCPrBN4","colab":{}},"source":["import tqdm\n","\n","class DensRay:\n","    def __init__(self, Lemb, Remb):\n","        self.lemb = Lemb\n","        self.remb = Remb\n","\n","    def fit(self, weights=None, normalize_D=True):\n","        \"\"\"Fit DensRay\n","        Args:\n","            weights: only for binary model; how to weight the two\n","                summands; if none\n","                \n","                \n","                : apply dynamic weighting. Example input: [1.0, 1.0]\n","            normalize_D: bool whether to normalize the difference vectors with l2 norm\n","        \"\"\"\n","        #self.computeA_binary_part1(normalize_D=normalize_D)\n","        self.A_equal = self.opsum(self.lemb) + self.opsum(self.remb)\n","        self.A_unequal = self.opsum(self.lemb, self.remb) + self.opsum(self.remb, self.lemb)\n","        self.computeA_binary_part2(weights=weights)\n","        self.compute_trafo()\n","        self.compute_mean_var()\n","\n","    @staticmethod\n","    def opsum(a, b=None):\n","        if b is None: b = a\n","        out = -torch.ger(a.sum(dim=0), b.sum(dim=0))\n","        out = out + out.T\n","        out += b.shape[0] * torch.mm(a.T,a)\n","        out += a.shape[0] * torch.mm(b.T,b)\n","        return out\n","\n","    @staticmethod\n","    def outer_product_sub_binary(v, M, normD):\n","        \"\"\"Helper function to compute the sum of outer products\n","\n","        While it is not very readable, it is more efficient than\n","        a brute force implementation.\n","        \"\"\"\n","        d = v.unsqueeze(0) - M\n","        if normD:\n","            norm = d.norm(dim=1)\n","            norm[norm == 0] = 1\n","            d = d / (norm.unsqueeze(0).T)\n","        return torch.mm(d.T, d)\n","    \n","    def computeA_binary_part1(self, normalize_D=False):\n","        \"\"\"First part of computing the matrix A.\n","        Args:\n","            normalize_D: bool whether to normalize the difference vectors with l2 norm.\n","        \"\"\"\n","        dim = self.lemb.shape[1]\n","        self.A_equal = torch.zeros((dim, dim)).to(device)\n","        self.A_unequal = torch.zeros((dim, dim)).to(device)\n","        for ipos in tqdm.trange(self.lemb.shape[0]):\n","            v = self.lemb[ipos]\n","            self.A_equal += self.outer_product_sub_binary(v, self.lemb, normalize_D)\n","            self.A_unequal += self.outer_product_sub_binary(v, self.remb, normalize_D)\n","        for ineg in tqdm.trange(self.remb.shape[0]):\n","            v = self.remb[ineg]\n","            self.A_equal += self.outer_product_sub_binary(v, self.remb, normalize_D)\n","            self.A_unequal += self.outer_product_sub_binary(v, self.lemb, normalize_D)\n","\n","    def computeA_binary_part2(self, weights=None):\n","        \"\"\"Second part of computing the matrix A.\n","        Args:\n","            weights: only for binary model; how to weight the two \n","                summands; if none: apply dynamic weighting. Example input: [1.0, 1.0]\n","        \"\"\"\n","        if weights is None:\n","            weights = [1 / (2 * self.lemb.shape[0] * self.remb.shape[0]), 1 /\n","                       (self.lemb.shape[0]**2 + self.remb.shape[0]**2)]\n","        # normalize matrices for numerical reasons\n","        # note that this does not change the eigenvectors\n","        n1 = self.A_unequal.max()\n","        n2 = self.A_equal.max()\n","        weights = [weights[0] / max(n1, n2), weights[1] / max(n1, n2)]\n","        self.A = weights[0] * self.A_unequal - weights[1] * self.A_equal\n","\n","    def compute_trafo(self):\n","        \"\"\"Given A, this function computes the actual Transformation.\n","        It essentially just does an eigenvector decomposition.\n","        \"\"\"\n","        eigvals, eigvecs = self.A.symeig(eigenvectors=True)\n","        # need to sort the eigenvalues\n","        idx = eigvals.argsort(descending=True)\n","        eigvals, self.eigvecs = eigvals[idx], eigvecs[:, idx]\n","    \n","    def compute_mean_var(self):\n","        first_dim = torch.mm(torch.cat((self.lemb, self.remb)), self.eigvecs)[:, 0]\n","        self.mean = first_dim.mean()\n","        self.std = first_dim.var().sqrt()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"azdjJRdSsVsC","colab_type":"text"},"source":["# Templates"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6kYCoJcaL1j0","colab":{}},"source":["import re\n","\n","class Template:\n","    def __init__(self, path='/content/drive/My Drive/professions.json'):\n","        with open(path,'r',encoding='utf8') as f:\n","            titles = re.sub('[^a-z_]',' ',f.read()).split()\n","        self.lines = [re.sub('_',' ',tokenizer.mask_token+' is a '+i+' .') for i in titles]\n","        self.examples = tokenizer.batch_encode_plus(self.lines, add_special_tokens=True, max_length=128)[\"input_ids\"]\n","        self.getbaseline()\n","    \n","    def getbaseline(self):\n","        self.baseline = []\n","        for i in self.examples:\n","            i = torch.tensor(i, dtype=torch.long).unsqueeze(0).to(device)\n","            output = model(i)\n","            mask_hidden_state = output[0].squeeze(0)[1]\n","            softmax = torch.nn.Softmax(dim=0)\n","            torch.set_grad_enabled(False)\n","            probs = softmax(mask_hidden_state)\n","            # get probability of token 'he'\n","            he_id = tokenizer.convert_tokens_to_ids('he')\n","            #print('he probability', probs[he_id].item())\n","            # get probability of token 'she'\n","            she_id = tokenizer.convert_tokens_to_ids('she')\n","            #print('she probability', probs[she_id].item())\n","            self.baseline.append([probs[he_id].item(), probs[she_id].item()])\n","        \n","template = Template('/content/drive/My Drive/professions.json')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vy25YU_Nsbh3","colab_type":"text"},"source":["# Eval"]},{"cell_type":"code","metadata":{"id":"bmk0ozKp-8eX","colab_type":"code","colab":{}},"source":["def get_eigvecs_dict(layer=-1):\n","    eigvecs_dict = {}\n","    #-1:apply to all layers\n","    if layer == -1:\n","        for l in range(nlayer):\n","            eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_'+config+'_noavg_'+str(nsamples)+'_'+str(l)+'.pt', True)\n","    elif layer ==-2:\n","        for l in range(nlayer):\n","            eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_'+config+'_noavg_'+str(nsamples)+'_'+str(l)+'.pt', False)\n","    else:\n","        for l in range(nlayer):\n","            if l==layer:\n","                eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_'+config+'_noavg_'+str(nsamples)+'_'+str(l)+'.pt', True)\n","            else:\n","                eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_'+config+'_noavg_'+str(nsamples)+'_'+str(l)+'.pt', False)\n","    return eigvecs_dict\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MUYs-VS6tg-n","colab_type":"code","colab":{}},"source":["import densray_bert\n","\n","def eval(temp=Template(), he='he', she='she'):\n","    predictions = []\n","    for l in range(-1,1):\n","        # get model\n","        model = densray_bert.BertForMaskedLM_1.from_pretrained('bert-'+config+'-uncased', eigvecs_dict=get_eigvecs_dict(l)).to(device)\n","        model.eval() \n","        # eval\n","        prediction = []\n","        for i in tqdm.trange(len(temp.examples)):\n","            vec = torch.tensor(temp.examples[i], dtype=torch.long).unsqueeze(0).to(device)\n","            output = model(vec)\n","            mask_hidden_state = output[0].squeeze(0)[1]\n","            softmax = torch.nn.Softmax(dim=0)\n","            torch.set_grad_enabled(False)\n","            probs = softmax(mask_hidden_state)\n","            he_id = tokenizer.convert_tokens_to_ids('he')\n","            she_id = tokenizer.convert_tokens_to_ids('she')\n","            prediction.append([probs[he_id].item(), probs[she_id].item()])\n","        predictions.append(prediction)\n","    return predictions\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EjIKcNtVvNUQ","colab_type":"code","outputId":"5e49d14c-55d4-4956-e172-48c519596d89","executionInfo":{"status":"ok","timestamp":1589947726041,"user_tz":-120,"elapsed":52863,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["predictions = eval(template)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["100%|██████████| 320/320 [00:06<00:00, 50.72it/s]\n","100%|██████████| 320/320 [00:05<00:00, 57.43it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"nkjX8uf42fqe","colab_type":"code","outputId":"37477dcf-5ff4-48e6-f239-4584e7456467","executionInfo":{"status":"ok","timestamp":1589947726414,"user_tz":-120,"elapsed":51581,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":106}},"source":["print('mean(prob(he/she)) var(prob(he/she)) mean(prob(he-she)) var(prob(he-she))')\n","baseline = torch.Tensor(template.baseline)\n","print('bert-'+config,'&',[round(i,4) for i in torch.mean(baseline,dim=0).tolist()][0],'&', [round(i,4) for i in torch.mean(baseline,dim=0).tolist()][1],'&',\n","      round(float((baseline[:,0]-baseline[:,1]).mean()),4), '&', round(float((baseline[:,0]-baseline[:,1]).var()),4), '\\n')\n","\n","for i in torch.Tensor(predictions):\n","    print('bert-'+config+'-L','&',[round(i,4) for i in torch.mean(i,dim=0).tolist()][0],'&', [round(i,4) for i in torch.mean(i,dim=0).tolist()][1],'&',\n","          round(float((i[:,0]-i[:,1]).mean()),4), '&', round(float((i[:,0]-i[:,1]).var()),4))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["mean(prob(he/she)) var(prob(he/she)) mean(prob(he-she)) var(prob(he-she))\n","bert-large & 0.6287 & 0.1907 & 0.438 & 0.1262 \n","\n","bert-large-L & 0.4751 & 0.2923 & 0.1827 & 0.015\n","bert-large-L & 0.635 & 0.1835 & 0.4515 & 0.1154\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"HTTDYsDcJEec","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"9c314f78-4d79-409b-85a9-4a3fb277e69d","executionInfo":{"status":"ok","timestamp":1589947726415,"user_tz":-120,"elapsed":49128,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}}},"source":["for i in range(len(template.lines)):\n","    print(\"sentence: \", template.lines[i])\n","    print(\"prediction: \", predictions[0][i])\n","    print(\"baseline: \", template.baseline[i], \"\\n\")\n"],"execution_count":15,"outputs":[{"output_type":"stream","text":["sentence:  [MASK] is a accountant .\n","prediction:  [0.5112127661705017, 0.35005635023117065]\n","baseline:  [0.6576316952705383, 0.25155213475227356] \n","\n","sentence:  [MASK] is a acquaintance .\n","prediction:  [0.4269518256187439, 0.22400744259357452]\n","baseline:  [0.5678895115852356, 0.09175058454275131] \n","\n","sentence:  [MASK] is a actor .\n","prediction:  [0.6651518940925598, 0.17503230273723602]\n","baseline:  [0.9274283647537231, 0.00809811893850565] \n","\n","sentence:  [MASK] is a actress .\n","prediction:  [0.6716951727867126, 0.20963725447654724]\n","baseline:  [0.007120403461158276, 0.9437349438667297] \n","\n","sentence:  [MASK] is a adjunct professor .\n","prediction:  [0.3974708914756775, 0.5316349267959595]\n","baseline:  [0.718169093132019, 0.2212754637002945] \n","\n","sentence:  [MASK] is a administrator .\n","prediction:  [0.45360705256462097, 0.3716474771499634]\n","baseline:  [0.6456165909767151, 0.22692058980464935] \n","\n","sentence:  [MASK] is a adventurer .\n","prediction:  [0.5007910132408142, 0.23790961503982544]\n","baseline:  [0.6569795608520508, 0.1324935406446457] \n","\n","sentence:  [MASK] is a advocate .\n","prediction:  [0.3785330057144165, 0.4120642840862274]\n","baseline:  [0.49468865990638733, 0.3184138834476471] \n","\n","sentence:  [MASK] is a aide .\n","prediction:  [0.39430516958236694, 0.23783554136753082]\n","baseline:  [0.5639547109603882, 0.16730976104736328] \n","\n","sentence:  [MASK] is a alderman .\n","prediction:  [0.507224977016449, 0.3697170913219452]\n","baseline:  [0.8054525852203369, 0.10587459057569504] \n","\n","sentence:  [MASK] is a alter ego .\n","prediction:  [0.15389586985111237, 0.1230274960398674]\n","baseline:  [0.2868058979511261, 0.06063726916909218] \n","\n","sentence:  [MASK] is a ambassador .\n","prediction:  [0.4960867166519165, 0.42867839336395264]\n","baseline:  [0.6505704522132874, 0.2944318652153015] \n","\n","sentence:  [MASK] is a analyst .\n","prediction:  [0.46561700105667114, 0.3275802731513977]\n","baseline:  [0.6608919501304626, 0.17076516151428223] \n","\n","sentence:  [MASK] is a anthropologist .\n","prediction:  [0.45216086506843567, 0.4349803030490875]\n","baseline:  [0.5542433857917786, 0.3531859517097473] \n","\n","sentence:  [MASK] is a archaeologist .\n","prediction:  [0.5108354687690735, 0.41209518909454346]\n","baseline:  [0.7196775078773499, 0.22536233067512512] \n","\n","sentence:  [MASK] is a archbishop .\n","prediction:  [0.6546611189842224, 0.1807691901922226]\n","baseline:  [0.9032406210899353, 0.006964146625250578] \n","\n","sentence:  [MASK] is a architect .\n","prediction:  [0.522810161113739, 0.388050377368927]\n","baseline:  [0.7204978466033936, 0.21580268442630768] \n","\n","sentence:  [MASK] is a artist .\n","prediction:  [0.4570735991001129, 0.3868729770183563]\n","baseline:  [0.5312984585762024, 0.3284946382045746] \n","\n","sentence:  [MASK] is a artiste .\n","prediction:  [0.5220479369163513, 0.37859371304512024]\n","baseline:  [0.5670761466026306, 0.34737807512283325] \n","\n","sentence:  [MASK] is a assassin .\n","prediction:  [0.4240765869617462, 0.39048731327056885]\n","baseline:  [0.6046258211135864, 0.23156963288784027] \n","\n","sentence:  [MASK] is a assistant professor .\n","prediction:  [0.482924222946167, 0.44865456223487854]\n","baseline:  [0.7350161075592041, 0.23177944123744965] \n","\n","sentence:  [MASK] is a associate dean .\n","prediction:  [0.4047730565071106, 0.5547094345092773]\n","baseline:  [0.8132592439651489, 0.14372152090072632] \n","\n","sentence:  [MASK] is a associate professor .\n","prediction:  [0.42400071024894714, 0.5413219332695007]\n","baseline:  [0.7741702198982239, 0.20230694115161896] \n","\n","sentence:  [MASK] is a astronaut .\n","prediction:  [0.4479009509086609, 0.23925484716892242]\n","baseline:  [0.5643666982650757, 0.20369428396224976] \n","\n","sentence:  [MASK] is a astronomer .\n","prediction:  [0.5218310356140137, 0.3886334300041199]\n","baseline:  [0.731995701789856, 0.19864970445632935] \n","\n","sentence:  [MASK] is a athlete .\n","prediction:  [0.4524986743927002, 0.39472946524620056]\n","baseline:  [0.5771183371543884, 0.27112653851509094] \n","\n","sentence:  [MASK] is a athletic director .\n","prediction:  [0.4828677177429199, 0.3214779794216156]\n","baseline:  [0.8179502487182617, 0.04952550679445267] \n","\n","sentence:  [MASK] is a attorney .\n","prediction:  [0.4417875111103058, 0.33937302231788635]\n","baseline:  [0.6452512741088867, 0.16871760785579681] \n","\n","sentence:  [MASK] is a author .\n","prediction:  [0.41958093643188477, 0.4000501334667206]\n","baseline:  [0.5447128415107727, 0.29418841004371643] \n","\n","sentence:  [MASK] is a baker .\n","prediction:  [0.534361720085144, 0.29612281918525696]\n","baseline:  [0.6084903478622437, 0.27972474694252014] \n","\n","sentence:  [MASK] is a ballerina .\n","prediction:  [0.6086433529853821, 0.13199718296527863]\n","baseline:  [0.008191005326807499, 0.8343825936317444] \n","\n","sentence:  [MASK] is a ballplayer .\n","prediction:  [0.4439087212085724, 0.1820324808359146]\n","baseline:  [0.7441014647483826, 0.012761490419507027] \n","\n","sentence:  [MASK] is a banker .\n","prediction:  [0.6064439415931702, 0.25762954354286194]\n","baseline:  [0.7934942245483398, 0.12031034380197525] \n","\n","sentence:  [MASK] is a barber .\n","prediction:  [0.5885502099990845, 0.1381913125514984]\n","baseline:  [0.8184170722961426, 0.022733675315976143] \n","\n","sentence:  [MASK] is a baron .\n","prediction:  [0.6713062524795532, 0.13861367106437683]\n","baseline:  [0.8875889778137207, 0.010138149373233318] \n","\n","sentence:  [MASK] is a barrister .\n","prediction:  [0.4996153712272644, 0.3658936321735382]\n","baseline:  [0.7207942008972168, 0.18270350992679596] \n","\n","sentence:  [MASK] is a bartender .\n","prediction:  [0.18415915966033936, 0.06168000027537346]\n","baseline:  [0.24621638655662537, 0.14051401615142822] \n","\n","sentence:  [MASK] is a biologist .\n","prediction:  [0.4608137309551239, 0.40371638536453247]\n","baseline:  [0.6032147407531738, 0.2849006950855255] \n","\n","sentence:  [MASK] is a bishop .\n","prediction:  [0.6359514594078064, 0.27005699276924133]\n","baseline:  [0.9174922704696655, 0.04400196671485901] \n","\n","sentence:  [MASK] is a bodyguard .\n","prediction:  [0.4987885057926178, 0.19991451501846313]\n","baseline:  [0.7428022623062134, 0.05052683502435684] \n","\n","sentence:  [MASK] is a bookkeeper .\n","prediction:  [0.38924312591552734, 0.12777860462665558]\n","baseline:  [0.5432458519935608, 0.08317718654870987] \n","\n","sentence:  [MASK] is a boss .\n","prediction:  [0.39614635705947876, 0.22657963633537292]\n","baseline:  [0.6196991205215454, 0.0524536557495594] \n","\n","sentence:  [MASK] is a boxer .\n","prediction:  [0.5581516027450562, 0.23701722919940948]\n","baseline:  [0.7991916537284851, 0.059050288051366806] \n","\n","sentence:  [MASK] is a broadcaster .\n","prediction:  [0.4548841118812561, 0.40858110785484314]\n","baseline:  [0.6888510584831238, 0.1923038363456726] \n","\n","sentence:  [MASK] is a broker .\n","prediction:  [0.41739577054977417, 0.18934674561023712]\n","baseline:  [0.6140464544296265, 0.0691019743680954] \n","\n","sentence:  [MASK] is a bureaucrat .\n","prediction:  [0.5979387760162354, 0.21823258697986603]\n","baseline:  [0.7509340643882751, 0.1292799711227417] \n","\n","sentence:  [MASK] is a businessman .\n","prediction:  [0.6000941395759583, 0.2293708771467209]\n","baseline:  [0.8961631655693054, 0.015772946178913116] \n","\n","sentence:  [MASK] is a businesswoman .\n","prediction:  [0.609913170337677, 0.22484470903873444]\n","baseline:  [0.004637779667973518, 0.9192535877227783] \n","\n","sentence:  [MASK] is a butcher .\n","prediction:  [0.5835035443305969, 0.16302241384983063]\n","baseline:  [0.8254563212394714, 0.02170989103615284] \n","\n","sentence:  [MASK] is a butler .\n","prediction:  [0.6033954620361328, 0.10303846746683121]\n","baseline:  [0.8047038316726685, 0.011827421374619007] \n","\n","sentence:  [MASK] is a cab driver .\n","prediction:  [0.2994849383831024, 0.09125129133462906]\n","baseline:  [0.5484843850135803, 0.030192947015166283] \n","\n","sentence:  [MASK] is a cabbie .\n","prediction:  [0.29277509450912476, 0.11915731430053711]\n","baseline:  [0.5255359411239624, 0.027563542127609253] \n","\n","sentence:  [MASK] is a cameraman .\n","prediction:  [0.3600641191005707, 0.10927794128656387]\n","baseline:  [0.6256648898124695, 0.01571994461119175] \n","\n","sentence:  [MASK] is a campaigner .\n","prediction:  [0.37655481696128845, 0.3507109582424164]\n","baseline:  [0.4803719222545624, 0.26131942868232727] \n","\n","sentence:  [MASK] is a captain .\n","prediction:  [0.5840193629264832, 0.2590198814868927]\n","baseline:  [0.8491355776786804, 0.06648045778274536] \n","\n","sentence:  [MASK] is a cardiologist .\n","prediction:  [0.49085018038749695, 0.40836790204048157]\n","baseline:  [0.7715625166893005, 0.14726972579956055] \n","\n","sentence:  [MASK] is a caretaker .\n","prediction:  [0.48518645763397217, 0.22796449065208435]\n","baseline:  [0.3272312581539154, 0.4470823407173157] \n","\n","sentence:  [MASK] is a carpenter .\n","prediction:  [0.48670026659965515, 0.21646681427955627]\n","baseline:  [0.747576892375946, 0.058837372809648514] \n","\n","sentence:  [MASK] is a cartoonist .\n","prediction:  [0.4237287938594818, 0.3050674498081207]\n","baseline:  [0.6838518381118774, 0.09515702724456787] \n","\n","sentence:  [MASK] is a cellist .\n","prediction:  [0.5029415488243103, 0.3730902671813965]\n","baseline:  [0.6844430565834045, 0.220128133893013] \n","\n","sentence:  [MASK] is a chancellor .\n","prediction:  [0.6089604496955872, 0.2743530571460724]\n","baseline:  [0.7807759642601013, 0.10672944784164429] \n","\n","sentence:  [MASK] is a chaplain .\n","prediction:  [0.5840306282043457, 0.3460719585418701]\n","baseline:  [0.8740070462226868, 0.06441380828619003] \n","\n","sentence:  [MASK] is a character .\n","prediction:  [0.4135725498199463, 0.2145596295595169]\n","baseline:  [0.5596357583999634, 0.1255999207496643] \n","\n","sentence:  [MASK] is a chef .\n","prediction:  [0.4861743748188019, 0.2398628294467926]\n","baseline:  [0.5824702382087708, 0.21962550282478333] \n","\n","sentence:  [MASK] is a chemist .\n","prediction:  [0.5073150992393494, 0.3685779571533203]\n","baseline:  [0.6714597940444946, 0.25276872515678406] \n","\n","sentence:  [MASK] is a choreographer .\n","prediction:  [0.44332781434059143, 0.2906574606895447]\n","baseline:  [0.5410304069519043, 0.2714456617832184] \n","\n","sentence:  [MASK] is a cinematographer .\n","prediction:  [0.6173604130744934, 0.2759837508201599]\n","baseline:  [0.9075262546539307, 0.04646894708275795] \n","\n","sentence:  [MASK] is a citizen .\n","prediction:  [0.564671516418457, 0.29834237694740295]\n","baseline:  [0.7714861631393433, 0.11292534321546555] \n","\n","sentence:  [MASK] is a civil servant .\n","prediction:  [0.547171413898468, 0.3833348751068115]\n","baseline:  [0.7817955613136292, 0.17359629273414612] \n","\n","sentence:  [MASK] is a cleric .\n","prediction:  [0.5875660181045532, 0.3082011342048645]\n","baseline:  [0.8775503039360046, 0.06360264122486115] \n","\n","sentence:  [MASK] is a clerk .\n","prediction:  [0.5678051710128784, 0.23261132836341858]\n","baseline:  [0.5627174377441406, 0.2905377447605133] \n","\n","sentence:  [MASK] is a coach .\n","prediction:  [0.480785608291626, 0.301275372505188]\n","baseline:  [0.7910858392715454, 0.08027275651693344] \n","\n","sentence:  [MASK] is a collector .\n","prediction:  [0.4684901833534241, 0.3408842086791992]\n","baseline:  [0.6330336928367615, 0.20270808041095734] \n","\n","sentence:  [MASK] is a colonel .\n","prediction:  [0.5903819799423218, 0.22590608894824982]\n","baseline:  [0.8523960709571838, 0.027269089594483376] \n","\n","sentence:  [MASK] is a columnist .\n","prediction:  [0.42397060990333557, 0.46363645792007446]\n","baseline:  [0.6570954918861389, 0.24810835719108582] \n","\n","sentence:  [MASK] is a comedian .\n","prediction:  [0.44244399666786194, 0.28019389510154724]\n","baseline:  [0.6223416924476624, 0.16077104210853577] \n","\n","sentence:  [MASK] is a comic .\n","prediction:  [0.4263540506362915, 0.2938375771045685]\n","baseline:  [0.6007464528083801, 0.1445498913526535] \n","\n","sentence:  [MASK] is a commander .\n","prediction:  [0.46960732340812683, 0.345596045255661]\n","baseline:  [0.6939645409584045, 0.15007735788822174] \n","\n","sentence:  [MASK] is a commentator .\n","prediction:  [0.4630347490310669, 0.40409842133522034]\n","baseline:  [0.7791056036949158, 0.1342981457710266] \n","\n","sentence:  [MASK] is a commissioner .\n","prediction:  [0.5538421273231506, 0.40016961097717285]\n","baseline:  [0.788139283657074, 0.12187369912862778] \n","\n","sentence:  [MASK] is a composer .\n","prediction:  [0.4769008755683899, 0.3348240554332733]\n","baseline:  [0.7046456336975098, 0.15017227828502655] \n","\n","sentence:  [MASK] is a conductor .\n","prediction:  [0.5771075487136841, 0.35403016209602356]\n","baseline:  [0.9033388495445251, 0.04789333790540695] \n","\n","sentence:  [MASK] is a confesses .\n","prediction:  [0.19881680607795715, 0.18193824589252472]\n","baseline:  [0.26930418610572815, 0.13143225014209747] \n","\n","sentence:  [MASK] is a congressman .\n","prediction:  [0.46361812949180603, 0.27644041180610657]\n","baseline:  [0.8013802170753479, 0.06499204784631729] \n","\n","sentence:  [MASK] is a constable .\n","prediction:  [0.5329421758651733, 0.26028329133987427]\n","baseline:  [0.6777582168579102, 0.17827309668064117] \n","\n","sentence:  [MASK] is a consultant .\n","prediction:  [0.5240187644958496, 0.39187613129615784]\n","baseline:  [0.8023231625556946, 0.1413821578025818] \n","\n","sentence:  [MASK] is a cop .\n","prediction:  [0.4124705493450165, 0.26226574182510376]\n","baseline:  [0.6434443593025208, 0.07001011073589325] \n","\n","sentence:  [MASK] is a correspondent .\n","prediction:  [0.48750922083854675, 0.40632158517837524]\n","baseline:  [0.6801265478134155, 0.23486371338367462] \n","\n","sentence:  [MASK] is a councilman .\n","prediction:  [0.44175398349761963, 0.28821486234664917]\n","baseline:  [0.784866988658905, 0.037225380539894104] \n","\n","sentence:  [MASK] is a councilor .\n","prediction:  [0.4549444615840912, 0.5051268935203552]\n","baseline:  [0.7719616293907166, 0.17056699097156525] \n","\n","sentence:  [MASK] is a counselor .\n","prediction:  [0.38197648525238037, 0.2795146107673645]\n","baseline:  [0.2837097942829132, 0.42384010553359985] \n","\n","sentence:  [MASK] is a critic .\n","prediction:  [0.5001755952835083, 0.38505250215530396]\n","baseline:  [0.727846622467041, 0.1731329709291458] \n","\n","sentence:  [MASK] is a crooner .\n","prediction:  [0.4493888020515442, 0.2843320965766907]\n","baseline:  [0.5789254903793335, 0.17591218650341034] \n","\n","sentence:  [MASK] is a crusader .\n","prediction:  [0.5547742247581482, 0.2907164990901947]\n","baseline:  [0.6920344233512878, 0.08899182081222534] \n","\n","sentence:  [MASK] is a curator .\n","prediction:  [0.5162413120269775, 0.3882819712162018]\n","baseline:  [0.4745097756385803, 0.38290777802467346] \n","\n","sentence:  [MASK] is a custodian .\n","prediction:  [0.4467129111289978, 0.2575291693210602]\n","baseline:  [0.6162877678871155, 0.09802938997745514] \n","\n","sentence:  [MASK] is a dad .\n","prediction:  [0.3014894723892212, 0.09885764867067337]\n","baseline:  [0.5684865713119507, 0.007140877656638622] \n","\n","sentence:  [MASK] is a dancer .\n","prediction:  [0.5025240778923035, 0.3177729547023773]\n","baseline:  [0.16063015162944794, 0.714650571346283] \n","\n","sentence:  [MASK] is a dean .\n","prediction:  [0.5107976794242859, 0.33409184217453003]\n","baseline:  [0.6631242632865906, 0.13906016945838928] \n","\n","sentence:  [MASK] is a dentist .\n","prediction:  [0.5137579441070557, 0.24276839196681976]\n","baseline:  [0.7592453956604004, 0.12613028287887573] \n","\n","sentence:  [MASK] is a deputy .\n","prediction:  [0.4957141578197479, 0.4880208969116211]\n","baseline:  [0.8482329845428467, 0.1469963639974594] \n","\n","sentence:  [MASK] is a dermatologist .\n","prediction:  [0.4734736680984497, 0.39528563618659973]\n","baseline:  [0.7374221682548523, 0.17285829782485962] \n","\n","sentence:  [MASK] is a detective .\n","prediction:  [0.43263378739356995, 0.2746339440345764]\n","baseline:  [0.642907440662384, 0.12587928771972656] \n","\n","sentence:  [MASK] is a diplomat .\n","prediction:  [0.5489539504051208, 0.3911984860897064]\n","baseline:  [0.8331727981567383, 0.1308073103427887] \n","\n","sentence:  [MASK] is a director .\n","prediction:  [0.5208085179328918, 0.3426334857940674]\n","baseline:  [0.7515041828155518, 0.16100876033306122] \n","\n","sentence:  [MASK] is a disc jockey .\n","prediction:  [0.4217035174369812, 0.20337305963039398]\n","baseline:  [0.6595682501792908, 0.046082817018032074] \n","\n","sentence:  [MASK] is a doctor .\n","prediction:  [0.4687783122062683, 0.32814911007881165]\n","baseline:  [0.6172938942909241, 0.21165980398654938] \n","\n","sentence:  [MASK] is a doctoral student .\n","prediction:  [0.4781494140625, 0.4915443956851959]\n","baseline:  [0.6571187376976013, 0.31835848093032837] \n","\n","sentence:  [MASK] is a drug addict .\n","prediction:  [0.30013683438301086, 0.1070772111415863]\n","baseline:  [0.38095593452453613, 0.11217764765024185] \n","\n","sentence:  [MASK] is a drummer .\n","prediction:  [0.45476529002189636, 0.2264295518398285]\n","baseline:  [0.7171419858932495, 0.03701406344771385] \n","\n","sentence:  [MASK] is a economics professor .\n","prediction:  [0.5029687881469727, 0.4399184286594391]\n","baseline:  [0.8278033137321472, 0.13217736780643463] \n","\n","sentence:  [MASK] is a economist .\n","prediction:  [0.5198407173156738, 0.4018653333187103]\n","baseline:  [0.7698522210121155, 0.16887106001377106] \n","\n","sentence:  [MASK] is a editor .\n","prediction:  [0.490937739610672, 0.4176221191883087]\n","baseline:  [0.6945089101791382, 0.23947489261627197] \n","\n","sentence:  [MASK] is a educator .\n","prediction:  [0.4190312623977661, 0.4355943500995636]\n","baseline:  [0.45492616295814514, 0.38417717814445496] \n","\n","sentence:  [MASK] is a electrician .\n","prediction:  [0.43527334928512573, 0.14604364335536957]\n","baseline:  [0.6692724227905273, 0.042281992733478546] \n","\n","sentence:  [MASK] is a employee .\n","prediction:  [0.5358560681343079, 0.24301119148731232]\n","baseline:  [0.6471417546272278, 0.14604586362838745] \n","\n","sentence:  [MASK] is a entertainer .\n","prediction:  [0.4696328938007355, 0.33946704864501953]\n","baseline:  [0.4948388338088989, 0.33828336000442505] \n","\n","sentence:  [MASK] is a entrepreneur .\n","prediction:  [0.3869209587574005, 0.28515371680259705]\n","baseline:  [0.5160664319992065, 0.17918537557125092] \n","\n","sentence:  [MASK] is a environmentalist .\n","prediction:  [0.38370856642723083, 0.3541775941848755]\n","baseline:  [0.6094552278518677, 0.13418260216712952] \n","\n","sentence:  [MASK] is a envoy .\n","prediction:  [0.47380566596984863, 0.36444705724716187]\n","baseline:  [0.6545686721801758, 0.19384844601154327] \n","\n","sentence:  [MASK] is a epidemiologist .\n","prediction:  [0.46605780720710754, 0.4333452582359314]\n","baseline:  [0.7308968305587769, 0.19782575964927673] \n","\n","sentence:  [MASK] is a evangelist .\n","prediction:  [0.4521675705909729, 0.3482908308506012]\n","baseline:  [0.7362472414970398, 0.10376399010419846] \n","\n","sentence:  [MASK] is a farmer .\n","prediction:  [0.6065883636474609, 0.34000083804130554]\n","baseline:  [0.9519991278648376, 0.03150755912065506] \n","\n","sentence:  [MASK] is a fashion designer .\n","prediction:  [0.3678257167339325, 0.19867494702339172]\n","baseline:  [0.30845198035240173, 0.3688758909702301] \n","\n","sentence:  [MASK] is a fighter pilot .\n","prediction:  [0.6785331964492798, 0.19249670207500458]\n","baseline:  [0.8836344480514526, 0.05077061802148819] \n","\n","sentence:  [MASK] is a filmmaker .\n","prediction:  [0.4387953579425812, 0.3539433777332306]\n","baseline:  [0.5629234910011292, 0.27950623631477356] \n","\n","sentence:  [MASK] is a financier .\n","prediction:  [0.5800153017044067, 0.17693261802196503]\n","baseline:  [0.8682363629341125, 0.01599191129207611] \n","\n","sentence:  [MASK] is a firebrand .\n","prediction:  [0.36446067690849304, 0.2056690752506256]\n","baseline:  [0.12839286029338837, 0.4896949827671051] \n","\n","sentence:  [MASK] is a firefighter .\n","prediction:  [0.44006621837615967, 0.15254224836826324]\n","baseline:  [0.6557884812355042, 0.06862495094537735] \n","\n","sentence:  [MASK] is a fireman .\n","prediction:  [0.4281974732875824, 0.09611386060714722]\n","baseline:  [0.6324256062507629, 0.02074120193719864] \n","\n","sentence:  [MASK] is a fisherman .\n","prediction:  [0.6476093530654907, 0.29047054052352905]\n","baseline:  [0.8704291582107544, 0.0606459341943264] \n","\n","sentence:  [MASK] is a footballer .\n","prediction:  [0.6508190631866455, 0.2947484254837036]\n","baseline:  [0.9555467367172241, 0.020861225202679634] \n","\n","sentence:  [MASK] is a foreman .\n","prediction:  [0.41579675674438477, 0.15767768025398254]\n","baseline:  [0.6769168376922607, 0.03286474570631981] \n","\n","sentence:  [MASK] is a freelance writer .\n","prediction:  [0.40456444025039673, 0.35832101106643677]\n","baseline:  [0.5771591663360596, 0.21264861524105072] \n","\n","sentence:  [MASK] is a gangster .\n","prediction:  [0.4605477750301361, 0.1073908880352974]\n","baseline:  [0.7380486726760864, 0.012457177974283695] \n","\n","sentence:  [MASK] is a gardener .\n","prediction:  [0.4407961368560791, 0.22869662940502167]\n","baseline:  [0.48804935812950134, 0.22077235579490662] \n","\n","sentence:  [MASK] is a geologist .\n","prediction:  [0.5033981800079346, 0.28464949131011963]\n","baseline:  [0.7653437256813049, 0.09379802644252777] \n","\n","sentence:  [MASK] is a goalkeeper .\n","prediction:  [0.5440664291381836, 0.4531090259552002]\n","baseline:  [0.9688118100166321, 0.030503438785672188] \n","\n","sentence:  [MASK] is a graphic designer .\n","prediction:  [0.4226245582103729, 0.3189608156681061]\n","baseline:  [0.43600812554359436, 0.3658760190010071] \n","\n","sentence:  [MASK] is a guidance counselor .\n","prediction:  [0.4811684489250183, 0.2714891731739044]\n","baseline:  [0.18061533570289612, 0.6505442261695862] \n","\n","sentence:  [MASK] is a guitarist .\n","prediction:  [0.5026115775108337, 0.22151584923267365]\n","baseline:  [0.8279271721839905, 0.014932164922356606] \n","\n","sentence:  [MASK] is a hairdresser .\n","prediction:  [0.15868152678012848, 0.0672125369310379]\n","baseline:  [0.18933752179145813, 0.11608249694108963] \n","\n","sentence:  [MASK] is a handyman .\n","prediction:  [0.29559633135795593, 0.061858031898736954]\n","baseline:  [0.6281465291976929, 0.004763780161738396] \n","\n","sentence:  [MASK] is a headmaster .\n","prediction:  [0.7183074951171875, 0.19848573207855225]\n","baseline:  [0.8435752987861633, 0.018498964607715607] \n","\n","sentence:  [MASK] is a historian .\n","prediction:  [0.47007375955581665, 0.4331914186477661]\n","baseline:  [0.7230973243713379, 0.20427216589450836] \n","\n","sentence:  [MASK] is a hitman .\n","prediction:  [0.420724093914032, 0.11046005040407181]\n","baseline:  [0.7183443307876587, 0.005823279730975628] \n","\n","sentence:  [MASK] is a homemaker .\n","prediction:  [0.5032860636711121, 0.31450414657592773]\n","baseline:  [0.1994968056678772, 0.609587550163269] \n","\n","sentence:  [MASK] is a hooker .\n","prediction:  [0.6030339002609253, 0.20910649001598358]\n","baseline:  [0.36989957094192505, 0.5185128450393677] \n","\n","sentence:  [MASK] is a housekeeper .\n","prediction:  [0.4590998888015747, 0.12875019013881683]\n","baseline:  [0.013743509538471699, 0.677788257598877] \n","\n","sentence:  [MASK] is a housewife .\n","prediction:  [0.627505362033844, 0.16164539754390717]\n","baseline:  [0.03799450770020485, 0.8044484853744507] \n","\n","sentence:  [MASK] is a illustrator .\n","prediction:  [0.4376291334629059, 0.3266933560371399]\n","baseline:  [0.4368865191936493, 0.37723401188850403] \n","\n","sentence:  [MASK] is a industrialist .\n","prediction:  [0.7053680419921875, 0.20118388533592224]\n","baseline:  [0.9278504848480225, 0.023714739829301834] \n","\n","sentence:  [MASK] is a infielder .\n","prediction:  [0.5921217799186707, 0.3019072115421295]\n","baseline:  [0.953819751739502, 0.007692047394812107] \n","\n","sentence:  [MASK] is a inspector .\n","prediction:  [0.5410073399543762, 0.3072010576725006]\n","baseline:  [0.777985692024231, 0.1103006899356842] \n","\n","sentence:  [MASK] is a instructor .\n","prediction:  [0.3976436257362366, 0.3004315197467804]\n","baseline:  [0.4841218590736389, 0.2508057951927185] \n","\n","sentence:  [MASK] is a interior designer .\n","prediction:  [0.41619622707366943, 0.2585641145706177]\n","baseline:  [0.4878786504268646, 0.258976012468338] \n","\n","sentence:  [MASK] is a inventor .\n","prediction:  [0.48814627528190613, 0.2884218990802765]\n","baseline:  [0.6202290654182434, 0.17616529762744904] \n","\n","sentence:  [MASK] is a investigator .\n","prediction:  [0.4246327877044678, 0.354527086019516]\n","baseline:  [0.593868613243103, 0.2335604727268219] \n","\n","sentence:  [MASK] is a investment banker .\n","prediction:  [0.49955978989601135, 0.27704107761383057]\n","baseline:  [0.8137354254722595, 0.04918678477406502] \n","\n","sentence:  [MASK] is a janitor .\n","prediction:  [0.5130991339683533, 0.18824608623981476]\n","baseline:  [0.6017196774482727, 0.18554069101810455] \n","\n","sentence:  [MASK] is a jeweler .\n","prediction:  [0.3779316246509552, 0.1622367799282074]\n","baseline:  [0.570550799369812, 0.061808228492736816] \n","\n","sentence:  [MASK] is a journalist .\n","prediction:  [0.4892866909503937, 0.42498332262039185]\n","baseline:  [0.6400476098060608, 0.30441993474960327] \n","\n","sentence:  [MASK] is a judge .\n","prediction:  [0.5245968699455261, 0.22608788311481476]\n","baseline:  [0.6933006644248962, 0.12890706956386566] \n","\n","sentence:  [MASK] is a jurist .\n","prediction:  [0.5300610661506653, 0.4392613470554352]\n","baseline:  [0.8718250393867493, 0.10498044639825821] \n","\n","sentence:  [MASK] is a laborer .\n","prediction:  [0.5082775950431824, 0.18540115654468536]\n","baseline:  [0.6496692299842834, 0.11025480180978775] \n","\n","sentence:  [MASK] is a landlord .\n","prediction:  [0.5617383718490601, 0.17619620263576508]\n","baseline:  [0.7346711754798889, 0.09165903925895691] \n","\n","sentence:  [MASK] is a lawmaker .\n","prediction:  [0.4569253623485565, 0.3909538686275482]\n","baseline:  [0.7315136790275574, 0.1447696089744568] \n","\n","sentence:  [MASK] is a lawyer .\n","prediction:  [0.5011730790138245, 0.4091707468032837]\n","baseline:  [0.7586774826049805, 0.1816973239183426] \n","\n","sentence:  [MASK] is a lecturer .\n","prediction:  [0.49254652857780457, 0.4303833842277527]\n","baseline:  [0.662712037563324, 0.2628870904445648] \n","\n","sentence:  [MASK] is a legislator .\n","prediction:  [0.41392338275909424, 0.4967885911464691]\n","baseline:  [0.7424150109291077, 0.19679583609104156] \n","\n","sentence:  [MASK] is a librarian .\n","prediction:  [0.33067381381988525, 0.25320151448249817]\n","baseline:  [0.15862521529197693, 0.45124080777168274] \n","\n","sentence:  [MASK] is a lieutenant .\n","prediction:  [0.5732662081718445, 0.2634336054325104]\n","baseline:  [0.8221063613891602, 0.07770881801843643] \n","\n","sentence:  [MASK] is a lifeguard .\n","prediction:  [0.4968537390232086, 0.26537176966667175]\n","baseline:  [0.6494948267936707, 0.1801101565361023] \n","\n","sentence:  [MASK] is a lyricist .\n","prediction:  [0.48181769251823425, 0.34444499015808105]\n","baseline:  [0.7274484634399414, 0.1626368910074234] \n","\n","sentence:  [MASK] is a maestro .\n","prediction:  [0.4691788852214813, 0.2776356637477875]\n","baseline:  [0.6464213132858276, 0.15264688432216644] \n","\n","sentence:  [MASK] is a magician .\n","prediction:  [0.4500919580459595, 0.1957671046257019]\n","baseline:  [0.5950334072113037, 0.137631356716156] \n","\n","sentence:  [MASK] is a magistrate .\n","prediction:  [0.5922001600265503, 0.3341689705848694]\n","baseline:  [0.8854210376739502, 0.07733292132616043] \n","\n","sentence:  [MASK] is a maid .\n","prediction:  [0.4880242645740509, 0.1261805146932602]\n","baseline:  [0.019346725195646286, 0.7385534644126892] \n","\n","sentence:  [MASK] is a major leaguer .\n","prediction:  [0.646073579788208, 0.22017863392829895]\n","baseline:  [0.9510122537612915, 0.006718285381793976] \n","\n","sentence:  [MASK] is a manager .\n","prediction:  [0.5015880465507507, 0.3496786653995514]\n","baseline:  [0.8143017292022705, 0.11843493580818176] \n","\n","sentence:  [MASK] is a marksman .\n","prediction:  [0.644375741481781, 0.24887503683567047]\n","baseline:  [0.9174010753631592, 0.025865541771054268] \n","\n","sentence:  [MASK] is a marshal .\n","prediction:  [0.3842039406299591, 0.27975326776504517]\n","baseline:  [0.632635772228241, 0.08656168729066849] \n","\n","sentence:  [MASK] is a mathematician .\n","prediction:  [0.49533024430274963, 0.38607755303382874]\n","baseline:  [0.7671621441841125, 0.13801907002925873] \n","\n","sentence:  [MASK] is a mechanic .\n","prediction:  [0.3838329613208771, 0.2099681794643402]\n","baseline:  [0.5618434548377991, 0.1007782444357872] \n","\n","sentence:  [MASK] is a mediator .\n","prediction:  [0.4632578194141388, 0.31545767188072205]\n","baseline:  [0.6352578401565552, 0.15742474794387817] \n","\n","sentence:  [MASK] is a medic .\n","prediction:  [0.5554621815681458, 0.28732234239578247]\n","baseline:  [0.7142055630683899, 0.16835884749889374] \n","\n","sentence:  [MASK] is a midfielder .\n","prediction:  [0.5651082396507263, 0.4310821294784546]\n","baseline:  [0.9852713346481323, 0.014158181846141815] \n","\n","sentence:  [MASK] is a minister .\n","prediction:  [0.5069013833999634, 0.3535870909690857]\n","baseline:  [0.7604910135269165, 0.14953021705150604] \n","\n","sentence:  [MASK] is a missionary .\n","prediction:  [0.4264239966869354, 0.24481448531150818]\n","baseline:  [0.556425929069519, 0.20513951778411865] \n","\n","sentence:  [MASK] is a mobster .\n","prediction:  [0.261817991733551, 0.05297604575753212]\n","baseline:  [0.5140300989151001, 0.004975706804543734] \n","\n","sentence:  [MASK] is a monk .\n","prediction:  [0.6750041842460632, 0.1977752298116684]\n","baseline:  [0.8683474659919739, 0.04946116730570793] \n","\n","sentence:  [MASK] is a musician .\n","prediction:  [0.3963802456855774, 0.28700560331344604]\n","baseline:  [0.5207633376121521, 0.1838027685880661] \n","\n","sentence:  [MASK] is a nanny .\n","prediction:  [0.3440769612789154, 0.14105747640132904]\n","baseline:  [0.044055454432964325, 0.5862300395965576] \n","\n","sentence:  [MASK] is a narrator .\n","prediction:  [0.39857906103134155, 0.15063641965389252]\n","baseline:  [0.4521157443523407, 0.15054285526275635] \n","\n","sentence:  [MASK] is a naturalist .\n","prediction:  [0.47854769229888916, 0.40102270245552063]\n","baseline:  [0.6698915362358093, 0.2261534184217453] \n","\n","sentence:  [MASK] is a negotiator .\n","prediction:  [0.5461201667785645, 0.364790141582489]\n","baseline:  [0.8102066516876221, 0.12510301172733307] \n","\n","sentence:  [MASK] is a neurologist .\n","prediction:  [0.4818158745765686, 0.3933854401111603]\n","baseline:  [0.6745963096618652, 0.2360968291759491] \n","\n","sentence:  [MASK] is a neurosurgeon .\n","prediction:  [0.46630585193634033, 0.35141557455062866]\n","baseline:  [0.7757328152656555, 0.09614187479019165] \n","\n","sentence:  [MASK] is a novelist .\n","prediction:  [0.4501313269138336, 0.33195096254348755]\n","baseline:  [0.4633053243160248, 0.3629799783229828] \n","\n","sentence:  [MASK] is a nun .\n","prediction:  [0.6437176465988159, 0.23824460804462433]\n","baseline:  [0.013866777531802654, 0.9313942790031433] \n","\n","sentence:  [MASK] is a nurse .\n","prediction:  [0.40401628613471985, 0.23931671679019928]\n","baseline:  [0.030419891700148582, 0.6975831985473633] \n","\n","sentence:  [MASK] is a observer .\n","prediction:  [0.5044200420379639, 0.25890815258026123]\n","baseline:  [0.6928263902664185, 0.122608982026577] \n","\n","sentence:  [MASK] is a officer .\n","prediction:  [0.5356584787368774, 0.34870222210884094]\n","baseline:  [0.8422974348068237, 0.0890207290649414] \n","\n","sentence:  [MASK] is a organist .\n","prediction:  [0.5175400972366333, 0.38128456473350525]\n","baseline:  [0.7453261613845825, 0.18687430024147034] \n","\n","sentence:  [MASK] is a painter .\n","prediction:  [0.4917747378349304, 0.3925173282623291]\n","baseline:  [0.6088175177574158, 0.3013592064380646] \n","\n","sentence:  [MASK] is a paralegal .\n","prediction:  [0.42527905106544495, 0.39324381947517395]\n","baseline:  [0.645398736000061, 0.2142920196056366] \n","\n","sentence:  [MASK] is a parishioner .\n","prediction:  [0.43125805258750916, 0.4402988851070404]\n","baseline:  [0.6656827926635742, 0.22636213898658752] \n","\n","sentence:  [MASK] is a parliamentarian .\n","prediction:  [0.45579391717910767, 0.46471408009529114]\n","baseline:  [0.7976344227790833, 0.14813674986362457] \n","\n","sentence:  [MASK] is a pastor .\n","prediction:  [0.5188218355178833, 0.2906418442726135]\n","baseline:  [0.7914456725120544, 0.06594107300043106] \n","\n","sentence:  [MASK] is a pathologist .\n","prediction:  [0.4901362955570221, 0.3999471366405487]\n","baseline:  [0.7647304534912109, 0.16043154895305634] \n","\n","sentence:  [MASK] is a patrolman .\n","prediction:  [0.4373205602169037, 0.12116941064596176]\n","baseline:  [0.6532878875732422, 0.03075992688536644] \n","\n","sentence:  [MASK] is a pediatrician .\n","prediction:  [0.4355529248714447, 0.4255424737930298]\n","baseline:  [0.5725151896476746, 0.3172944486141205] \n","\n","sentence:  [MASK] is a performer .\n","prediction:  [0.34863603115081787, 0.31248846650123596]\n","baseline:  [0.4232596158981323, 0.26935264468193054] \n","\n","sentence:  [MASK] is a pharmacist .\n","prediction:  [0.4563877582550049, 0.27561643719673157]\n","baseline:  [0.6595509052276611, 0.1415698528289795] \n","\n","sentence:  [MASK] is a philanthropist .\n","prediction:  [0.38446754217147827, 0.32282519340515137]\n","baseline:  [0.4941176176071167, 0.22757962346076965] \n","\n","sentence:  [MASK] is a philosopher .\n","prediction:  [0.5584467053413391, 0.3299092650413513]\n","baseline:  [0.7984868884086609, 0.13250379264354706] \n","\n","sentence:  [MASK] is a photographer .\n","prediction:  [0.44937554001808167, 0.3032836616039276]\n","baseline:  [0.538766086101532, 0.2774094343185425] \n","\n","sentence:  [MASK] is a photojournalist .\n","prediction:  [0.45698487758636475, 0.38987427949905396]\n","baseline:  [0.6731933951377869, 0.21898595988750458] \n","\n","sentence:  [MASK] is a physician .\n","prediction:  [0.5223657488822937, 0.3618963360786438]\n","baseline:  [0.7080618739128113, 0.21967580914497375] \n","\n","sentence:  [MASK] is a physicist .\n","prediction:  [0.4906633794307709, 0.34807413816452026]\n","baseline:  [0.7483785152435303, 0.13446535170078278] \n","\n","sentence:  [MASK] is a pianist .\n","prediction:  [0.4821005165576935, 0.41100671887397766]\n","baseline:  [0.47660595178604126, 0.422235369682312] \n","\n","sentence:  [MASK] is a planner .\n","prediction:  [0.38791900873184204, 0.28894272446632385]\n","baseline:  [0.49591708183288574, 0.22892701625823975] \n","\n","sentence:  [MASK] is a plastic surgeon .\n","prediction:  [0.36237600445747375, 0.16142041981220245]\n","baseline:  [0.49076029658317566, 0.1212412640452385] \n","\n","sentence:  [MASK] is a playwright .\n","prediction:  [0.41943371295928955, 0.29131534695625305]\n","baseline:  [0.5692878365516663, 0.20504331588745117] \n","\n","sentence:  [MASK] is a plumber .\n","prediction:  [0.3803653120994568, 0.12060343474149704]\n","baseline:  [0.5872254371643066, 0.02681427262723446] \n","\n","sentence:  [MASK] is a poet .\n","prediction:  [0.4515335261821747, 0.40000754594802856]\n","baseline:  [0.5662451386451721, 0.305209219455719] \n","\n","sentence:  [MASK] is a policeman .\n","prediction:  [0.549816906452179, 0.2455017864704132]\n","baseline:  [0.74891597032547, 0.10552613437175751] \n","\n","sentence:  [MASK] is a politician .\n","prediction:  [0.47652480006217957, 0.4215250015258789]\n","baseline:  [0.7801707983016968, 0.15808872878551483] \n","\n","sentence:  [MASK] is a pollster .\n","prediction:  [0.3261067867279053, 0.14477844536304474]\n","baseline:  [0.528370201587677, 0.08182663470506668] \n","\n","sentence:  [MASK] is a preacher .\n","prediction:  [0.41112440824508667, 0.22295710444450378]\n","baseline:  [0.7030613422393799, 0.04273855686187744] \n","\n","sentence:  [MASK] is a president .\n","prediction:  [0.4569343328475952, 0.30174943804740906]\n","baseline:  [0.6075088381767273, 0.1327970176935196] \n","\n","sentence:  [MASK] is a priest .\n","prediction:  [0.661334753036499, 0.23095983266830444]\n","baseline:  [0.8722999691963196, 0.06896161288022995] \n","\n","sentence:  [MASK] is a principal .\n","prediction:  [0.5144180655479431, 0.4215758442878723]\n","baseline:  [0.8390443921089172, 0.12751136720180511] \n","\n","sentence:  [MASK] is a prisoner .\n","prediction:  [0.6477128267288208, 0.27318623661994934]\n","baseline:  [0.6313984990119934, 0.27198460698127747] \n","\n","sentence:  [MASK] is a professor .\n","prediction:  [0.5484737753868103, 0.3331204652786255]\n","baseline:  [0.6799622178077698, 0.24260874092578888] \n","\n","sentence:  [MASK] is a professor emeritus .\n","prediction:  [0.4753465950489044, 0.5006794333457947]\n","baseline:  [0.9254263043403625, 0.05708320066332817] \n","\n","sentence:  [MASK] is a programmer .\n","prediction:  [0.49669334292411804, 0.3303441107273102]\n","baseline:  [0.7198744416236877, 0.150234654545784] \n","\n","sentence:  [MASK] is a promoter .\n","prediction:  [0.5101409554481506, 0.29415225982666016]\n","baseline:  [0.5613430738449097, 0.13707391917705536] \n","\n","sentence:  [MASK] is a proprietor .\n","prediction:  [0.5135549306869507, 0.2210243046283722]\n","baseline:  [0.6350954174995422, 0.17885369062423706] \n","\n","sentence:  [MASK] is a prosecutor .\n","prediction:  [0.5527857542037964, 0.32611995935440063]\n","baseline:  [0.7612757086753845, 0.1622939109802246] \n","\n","sentence:  [MASK] is a protagonist .\n","prediction:  [0.3812844157218933, 0.17002177238464355]\n","baseline:  [0.35952451825141907, 0.24769070744514465] \n","\n","sentence:  [MASK] is a protege .\n","prediction:  [0.3395119905471802, 0.17288032174110413]\n","baseline:  [0.4119800627231598, 0.11458323150873184] \n","\n","sentence:  [MASK] is a protester .\n","prediction:  [0.34392812848091125, 0.31935784220695496]\n","baseline:  [0.5483811497688293, 0.1647832989692688] \n","\n","sentence:  [MASK] is a provost .\n","prediction:  [0.5904781818389893, 0.3169437050819397]\n","baseline:  [0.7968416810035706, 0.11774338036775589] \n","\n","sentence:  [MASK] is a psychiatrist .\n","prediction:  [0.4404066205024719, 0.2584649920463562]\n","baseline:  [0.479067325592041, 0.26899293065071106] \n","\n","sentence:  [MASK] is a psychologist .\n","prediction:  [0.45485061407089233, 0.3296443223953247]\n","baseline:  [0.4630829989910126, 0.37266334891319275] \n","\n","sentence:  [MASK] is a publicist .\n","prediction:  [0.4146732687950134, 0.3452165126800537]\n","baseline:  [0.5976670980453491, 0.20127059519290924] \n","\n","sentence:  [MASK] is a pundit .\n","prediction:  [0.4463847875595093, 0.4519103169441223]\n","baseline:  [0.7701735496520996, 0.14736706018447876] \n","\n","sentence:  [MASK] is a rabbi .\n","prediction:  [0.5635451078414917, 0.37486496567726135]\n","baseline:  [0.8932295441627502, 0.06085260212421417] \n","\n","sentence:  [MASK] is a radiologist .\n","prediction:  [0.47176626324653625, 0.36608701944351196]\n","baseline:  [0.6950632929801941, 0.17587046325206757] \n","\n","sentence:  [MASK] is a ranger .\n","prediction:  [0.38798344135284424, 0.28561654686927795]\n","baseline:  [0.5689687132835388, 0.15380002558231354] \n","\n","sentence:  [MASK] is a realtor .\n","prediction:  [0.4407387971878052, 0.3004525601863861]\n","baseline:  [0.6467440724372864, 0.14824144542217255] \n","\n","sentence:  [MASK] is a receptionist .\n","prediction:  [0.3340710699558258, 0.16215884685516357]\n","baseline:  [0.030271446332335472, 0.5773273706436157] \n","\n","sentence:  [MASK] is a registered nurse .\n","prediction:  [0.42813533544540405, 0.3965946137905121]\n","baseline:  [0.08287499845027924, 0.77327561378479] \n","\n","sentence:  [MASK] is a researcher .\n","prediction:  [0.4690292179584503, 0.4516718089580536]\n","baseline:  [0.6571286916732788, 0.27603623270988464] \n","\n","sentence:  [MASK] is a restaurateur .\n","prediction:  [0.5225522518157959, 0.2513565421104431]\n","baseline:  [0.7001393437385559, 0.1474923938512802] \n","\n","sentence:  [MASK] is a sailor .\n","prediction:  [0.5452318787574768, 0.30160194635391235]\n","baseline:  [0.8005855083465576, 0.11456669121980667] \n","\n","sentence:  [MASK] is a saint .\n","prediction:  [0.6004758477210999, 0.32124364376068115]\n","baseline:  [0.7329456210136414, 0.1734895408153534] \n","\n","sentence:  [MASK] is a salesman .\n","prediction:  [0.41591179370880127, 0.1525285542011261]\n","baseline:  [0.6073877811431885, 0.03140173852443695] \n","\n","sentence:  [MASK] is a saxophonist .\n","prediction:  [0.4852462410926819, 0.2822098135948181]\n","baseline:  [0.7411348819732666, 0.08174878358840942] \n","\n","sentence:  [MASK] is a scholar .\n","prediction:  [0.4808637797832489, 0.4001176059246063]\n","baseline:  [0.6438888907432556, 0.23692160844802856] \n","\n","sentence:  [MASK] is a scientist .\n","prediction:  [0.5132911205291748, 0.3156636357307434]\n","baseline:  [0.5888569951057434, 0.26591596007347107] \n","\n","sentence:  [MASK] is a screenwriter .\n","prediction:  [0.5103136301040649, 0.31634944677352905]\n","baseline:  [0.7075433731079102, 0.19124844670295715] \n","\n","sentence:  [MASK] is a sculptor .\n","prediction:  [0.474042683839798, 0.3763029873371124]\n","baseline:  [0.6703689098358154, 0.21239009499549866] \n","\n","sentence:  [MASK] is a secretary .\n","prediction:  [0.5617662072181702, 0.28334662318229675]\n","baseline:  [0.13882851600646973, 0.7289754152297974] \n","\n","sentence:  [MASK] is a senator .\n","prediction:  [0.44162246584892273, 0.22661928832530975]\n","baseline:  [0.655876874923706, 0.07050244510173798] \n","\n","sentence:  [MASK] is a sergeant .\n","prediction:  [0.528497576713562, 0.243342325091362]\n","baseline:  [0.7887906432151794, 0.04826360195875168] \n","\n","sentence:  [MASK] is a servant .\n","prediction:  [0.5947662591934204, 0.27946966886520386]\n","baseline:  [0.7097651362419128, 0.177223801612854] \n","\n","sentence:  [MASK] is a serviceman .\n","prediction:  [0.560794472694397, 0.33255040645599365]\n","baseline:  [0.8595075607299805, 0.01996520161628723] \n","\n","sentence:  [MASK] is a sheriff deputy .\n","prediction:  [0.47227999567985535, 0.16858413815498352]\n","baseline:  [0.7283545136451721, 0.04661470651626587] \n","\n","sentence:  [MASK] is a shopkeeper .\n","prediction:  [0.5023301839828491, 0.14314919710159302]\n","baseline:  [0.6154730916023254, 0.12622204422950745] \n","\n","sentence:  [MASK] is a singer .\n","prediction:  [0.4546048641204834, 0.34631744027137756]\n","baseline:  [0.280653715133667, 0.5720745325088501] \n","\n","sentence:  [MASK] is a singer songwriter .\n","prediction:  [0.33159998059272766, 0.20087960362434387]\n","baseline:  [0.3565463125705719, 0.25077006220817566] \n","\n","sentence:  [MASK] is a skipper .\n","prediction:  [0.26893725991249084, 0.20401741564273834]\n","baseline:  [0.10211893171072006, 0.14935685694217682] \n","\n","sentence:  [MASK] is a socialite .\n","prediction:  [0.35451215505599976, 0.25677236914634705]\n","baseline:  [0.14896555244922638, 0.5065038204193115] \n","\n","sentence:  [MASK] is a sociologist .\n","prediction:  [0.4535257816314697, 0.45370835065841675]\n","baseline:  [0.6910642385482788, 0.24052093923091888] \n","\n","sentence:  [MASK] is a soft spoken .\n","prediction:  [0.40284907817840576, 0.35042285919189453]\n","baseline:  [0.39976537227630615, 0.36511659622192383] \n","\n","sentence:  [MASK] is a soldier .\n","prediction:  [0.48666298389434814, 0.31206873059272766]\n","baseline:  [0.7872282862663269, 0.06717033684253693] \n","\n","sentence:  [MASK] is a solicitor .\n","prediction:  [0.5336553454399109, 0.3396722674369812]\n","baseline:  [0.7977465987205505, 0.11525986343622208] \n","\n","sentence:  [MASK] is a solicitor general .\n","prediction:  [0.5621395707130432, 0.32824382185935974]\n","baseline:  [0.882861852645874, 0.054697632789611816] \n","\n","sentence:  [MASK] is a soloist .\n","prediction:  [0.4694152772426605, 0.49083375930786133]\n","baseline:  [0.4815887212753296, 0.48630598187446594] \n","\n","sentence:  [MASK] is a sportsman .\n","prediction:  [0.46190395951271057, 0.365418404340744]\n","baseline:  [0.7450971603393555, 0.09347880631685257] \n","\n","sentence:  [MASK] is a sportswriter .\n","prediction:  [0.494418203830719, 0.27051839232444763]\n","baseline:  [0.8064820170402527, 0.03644104674458504] \n","\n","sentence:  [MASK] is a statesman .\n","prediction:  [0.614237904548645, 0.2876753509044647]\n","baseline:  [0.8700586557388306, 0.053558431565761566] \n","\n","sentence:  [MASK] is a steward .\n","prediction:  [0.5118312835693359, 0.27572545409202576]\n","baseline:  [0.6824820637702942, 0.1395140141248703] \n","\n","sentence:  [MASK] is a stockbroker .\n","prediction:  [0.345539391040802, 0.08665581792593002]\n","baseline:  [0.6295710206031799, 0.012262511998414993] \n","\n","sentence:  [MASK] is a strategist .\n","prediction:  [0.42701855301856995, 0.23915040493011475]\n","baseline:  [0.6497554779052734, 0.04994925484061241] \n","\n","sentence:  [MASK] is a student .\n","prediction:  [0.6007603406906128, 0.21684619784355164]\n","baseline:  [0.7759836316108704, 0.12302105128765106] \n","\n","sentence:  [MASK] is a stylist .\n","prediction:  [0.42152097821235657, 0.3076015114784241]\n","baseline:  [0.35286712646484375, 0.42501717805862427] \n","\n","sentence:  [MASK] is a substitute .\n","prediction:  [0.4110822379589081, 0.2375144064426422]\n","baseline:  [0.904784083366394, 0.038017526268959045] \n","\n","sentence:  [MASK] is a superintendent .\n","prediction:  [0.5454279780387878, 0.38474923372268677]\n","baseline:  [0.6238789558410645, 0.2486601173877716] \n","\n","sentence:  [MASK] is a surgeon .\n","prediction:  [0.5100869536399841, 0.2464587688446045]\n","baseline:  [0.6407204866409302, 0.17801550030708313] \n","\n","sentence:  [MASK] is a surveyor .\n","prediction:  [0.5723860859870911, 0.279131144285202]\n","baseline:  [0.5757216215133667, 0.2198724001646042] \n","\n","sentence:  [MASK] is a swimmer .\n","prediction:  [0.48616552352905273, 0.4651281237602234]\n","baseline:  [0.5053492784500122, 0.4486939311027527] \n","\n","sentence:  [MASK] is a taxi driver .\n","prediction:  [0.4351762533187866, 0.11015094816684723]\n","baseline:  [0.7269982099533081, 0.029283905401825905] \n","\n","sentence:  [MASK] is a teacher .\n","prediction:  [0.5180051922798157, 0.4431506097316742]\n","baseline:  [0.46046191453933716, 0.48091840744018555] \n","\n","sentence:  [MASK] is a technician .\n","prediction:  [0.4102299213409424, 0.2672369182109833]\n","baseline:  [0.489005982875824, 0.2169654816389084] \n","\n","sentence:  [MASK] is a teenager .\n","prediction:  [0.35674041509628296, 0.15535256266593933]\n","baseline:  [0.30360305309295654, 0.23254378139972687] \n","\n","sentence:  [MASK] is a therapist .\n","prediction:  [0.3749520182609558, 0.23346734046936035]\n","baseline:  [0.35879650712013245, 0.42759403586387634] \n","\n","sentence:  [MASK] is a trader .\n","prediction:  [0.5638728141784668, 0.2638018727302551]\n","baseline:  [0.7590773105621338, 0.11188118159770966] \n","\n","sentence:  [MASK] is a treasurer .\n","prediction:  [0.0441373847424984, 0.0336773656308651]\n","baseline:  [0.010314341634511948, 0.005065919831395149] \n","\n","sentence:  [MASK] is a trooper .\n","prediction:  [0.3858131170272827, 0.29149794578552246]\n","baseline:  [0.6733397245407104, 0.07305894047021866] \n","\n","sentence:  [MASK] is a trucker .\n","prediction:  [0.26145291328430176, 0.07962323725223541]\n","baseline:  [0.4955817461013794, 0.010369516909122467] \n","\n","sentence:  [MASK] is a trumpeter .\n","prediction:  [0.4889141023159027, 0.3675859272480011]\n","baseline:  [0.7148339152336121, 0.17990651726722717] \n","\n","sentence:  [MASK] is a tutor .\n","prediction:  [0.5604481101036072, 0.29473522305488586]\n","baseline:  [0.562667191028595, 0.32667481899261475] \n","\n","sentence:  [MASK] is a tycoon .\n","prediction:  [0.3412836790084839, 0.11314745992422104]\n","baseline:  [0.615315318107605, 0.022668329998850822] \n","\n","sentence:  [MASK] is a undersecretary .\n","prediction:  [0.5328216552734375, 0.31438755989074707]\n","baseline:  [0.792095959186554, 0.11365748941898346] \n","\n","sentence:  [MASK] is a understudy .\n","prediction:  [0.38857871294021606, 0.19302140176296234]\n","baseline:  [0.4277539849281311, 0.2478659749031067] \n","\n","sentence:  [MASK] is a valedictorian .\n","prediction:  [0.4838709831237793, 0.42548903822898865]\n","baseline:  [0.7287513017654419, 0.20618809759616852] \n","\n","sentence:  [MASK] is a vice chancellor .\n","prediction:  [0.5209833979606628, 0.4539051651954651]\n","baseline:  [0.9076128602027893, 0.07717033475637436] \n","\n","sentence:  [MASK] is a violinist .\n","prediction:  [0.4773363173007965, 0.383314311504364]\n","baseline:  [0.5067347884178162, 0.3810438811779022] \n","\n","sentence:  [MASK] is a vocalist .\n","prediction:  [0.46401628851890564, 0.32240504026412964]\n","baseline:  [0.36239349842071533, 0.4843302071094513] \n","\n","sentence:  [MASK] is a waiter .\n","prediction:  [0.32748064398765564, 0.08244640380144119]\n","baseline:  [0.570869505405426, 0.009758125059306622] \n","\n","sentence:  [MASK] is a waitress .\n","prediction:  [0.2202988862991333, 0.09395582228899002]\n","baseline:  [0.008901112712919712, 0.47524401545524597] \n","\n","sentence:  [MASK] is a warden .\n","prediction:  [0.5839113593101501, 0.2562471926212311]\n","baseline:  [0.7561951875686646, 0.14222653210163116] \n","\n","sentence:  [MASK] is a warrior .\n","prediction:  [0.46862298250198364, 0.38453397154808044]\n","baseline:  [0.77949059009552, 0.10485726594924927] \n","\n","sentence:  [MASK] is a welder .\n","prediction:  [0.39898547530174255, 0.24284006655216217]\n","baseline:  [0.6040564179420471, 0.09086083620786667] \n","\n","sentence:  [MASK] is a worker .\n","prediction:  [0.47541531920433044, 0.31004178524017334]\n","baseline:  [0.5075320601463318, 0.30842089653015137] \n","\n","sentence:  [MASK] is a wrestler .\n","prediction:  [0.5307456254959106, 0.333561509847641]\n","baseline:  [0.7181530594825745, 0.17951275408267975] \n","\n","sentence:  [MASK] is a writer .\n","prediction:  [0.4092886745929718, 0.36110126972198486]\n","baseline:  [0.4894689619541168, 0.309832364320755] \n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kQT9x8blsm-h","colab_type":"text"},"source":["# Ppl on Wikitext-2"]},{"cell_type":"code","metadata":{"id":"FRVGlhz2x9le","colab_type":"code","outputId":"49970136-dd8c-4ec9-c678-743ad90700a8","executionInfo":{"status":"ok","timestamp":1588245962934,"user_tz":-120,"elapsed":624629,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python run_language_modeling.py \\\n","    --output_dir=output \\\n","    --model_type=bert \\\n","    --model_name_or_path=bert-base-multilingual-uncased \\\n","    --do_train \\\n","    --train_data_file=/content/wikitext-2/wiki.train.tokens \\\n","    --do_eval \\\n","    --eval_data_file=/content/wikitext-2/wiki.test.tokens \\\n","    --mlm \\\n","    --overwrite_output_dir"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-04-30 11:15:40.355356: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","04/30/2020 11:15:42 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","04/30/2020 11:15:42 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased-config.json from cache at /root/.cache/torch/transformers/33b56ce0f312e47e4d77a57791a4fc6233ae4a560dd2bdd186107058294e58ab.fcb1786f49c279f0e0f158c9972b9bd9f6c0edb5d893dcb9b530d714d86f0edc\n","04/30/2020 11:15:42 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"directionality\": \"bidi\",\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 105879\n","}\n","\n","04/30/2020 11:15:42 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased-config.json from cache at /root/.cache/torch/transformers/33b56ce0f312e47e4d77a57791a4fc6233ae4a560dd2bdd186107058294e58ab.fcb1786f49c279f0e0f158c9972b9bd9f6c0edb5d893dcb9b530d714d86f0edc\n","04/30/2020 11:15:42 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"directionality\": \"bidi\",\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 105879\n","}\n","\n","04/30/2020 11:15:43 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased-vocab.txt from cache at /root/.cache/torch/transformers/bb773818882b0524dc53a1b31a2cc95bc489f000e7e19773ba07846011a6c711.535306b226c42cebebbc0dabc83b92ab11260e9919e21e2ab0beb301f267b4c7\n","04/30/2020 11:15:43 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/cc4042a0d6f70eae595ea0e6d49521b17bd6251f973b3e37d303ce7945b90eed.54b4dad9cc3db9aa8448458b782d11ab07c80dedb951906fd2f684a00ecdb1ee\n","04/30/2020 11:15:51 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n","04/30/2020 11:15:51 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","04/30/2020 11:15:55 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=True, eval_all_checkpoints=False, eval_data_file='/content/wikitext-2/wiki.test.tokens', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path='bert-base-multilingual-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='/content/wikitext-2/wiki.train.tokens', warmup_steps=0, weight_decay=0.0)\n","04/30/2020 11:15:55 - INFO - __main__ -   Creating features from dataset file at /content/wikitext-2\n","04/30/2020 11:16:37 - INFO - __main__ -   Saving features into cached file /content/wikitext-2/bert_cached_lm_510_wiki.train.tokens\n","04/30/2020 11:16:37 - INFO - __main__ -   ***** Running training *****\n","04/30/2020 11:16:37 - INFO - __main__ -     Num examples = 4842\n","04/30/2020 11:16:37 - INFO - __main__ -     Num Epochs = 1\n","04/30/2020 11:16:37 - INFO - __main__ -     Instantaneous batch size per GPU = 4\n","04/30/2020 11:16:37 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 4\n","04/30/2020 11:16:37 - INFO - __main__ -     Gradient Accumulation steps = 1\n","04/30/2020 11:16:37 - INFO - __main__ -     Total optimization steps = 1211\n","Epoch:   0% 0/1 [00:00<?, ?it/s]\n","Iteration:   0% 0/1211 [00:00<?, ?it/s]\u001b[A/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha)\n","\n","Iteration:   0% 1/1211 [00:00<12:30,  1.61it/s]\u001b[A\n","Iteration:   0% 2/1211 [00:01<11:15,  1.79it/s]\u001b[A\n","Iteration:   0% 3/1211 [00:01<10:22,  1.94it/s]\u001b[A\n","Iteration:   0% 4/1211 [00:01<09:44,  2.06it/s]\u001b[A\n","Iteration:   0% 5/1211 [00:02<09:18,  2.16it/s]\u001b[A\n","Iteration:   0% 6/1211 [00:02<09:00,  2.23it/s]\u001b[A\n","Iteration:   1% 7/1211 [00:03<08:47,  2.28it/s]\u001b[A\n","Iteration:   1% 8/1211 [00:03<08:38,  2.32it/s]\u001b[A\n","Iteration:   1% 9/1211 [00:03<08:33,  2.34it/s]\u001b[A\n","Iteration:   1% 10/1211 [00:04<08:27,  2.36it/s]\u001b[A\n","Iteration:   1% 11/1211 [00:04<08:24,  2.38it/s]\u001b[A\n","Iteration:   1% 12/1211 [00:05<08:20,  2.39it/s]\u001b[A\n","Iteration:   1% 13/1211 [00:05<08:21,  2.39it/s]\u001b[A\n","Iteration:   1% 14/1211 [00:06<08:18,  2.40it/s]\u001b[A\n","Iteration:   1% 15/1211 [00:06<08:16,  2.41it/s]\u001b[A\n","Iteration:   1% 16/1211 [00:06<08:14,  2.41it/s]\u001b[A\n","Iteration:   1% 17/1211 [00:07<08:14,  2.42it/s]\u001b[A\n","Iteration:   1% 18/1211 [00:07<08:17,  2.40it/s]\u001b[A\n","Iteration:   2% 19/1211 [00:08<08:15,  2.41it/s]\u001b[A\n","Iteration:   2% 20/1211 [00:08<08:13,  2.41it/s]\u001b[A\n","Iteration:   2% 21/1211 [00:08<08:12,  2.42it/s]\u001b[A\n","Iteration:   2% 22/1211 [00:09<08:11,  2.42it/s]\u001b[A\n","Iteration:   2% 23/1211 [00:09<08:12,  2.41it/s]\u001b[A\n","Iteration:   2% 24/1211 [00:10<08:11,  2.42it/s]\u001b[A\n","Iteration:   2% 25/1211 [00:10<08:11,  2.41it/s]\u001b[A\n","Iteration:   2% 26/1211 [00:10<08:10,  2.41it/s]\u001b[A\n","Iteration:   2% 27/1211 [00:11<08:10,  2.42it/s]\u001b[A\n","Iteration:   2% 28/1211 [00:11<08:09,  2.42it/s]\u001b[A\n","Iteration:   2% 29/1211 [00:12<08:09,  2.41it/s]\u001b[A\n","Iteration:   2% 30/1211 [00:12<08:08,  2.42it/s]\u001b[A\n","Iteration:   3% 31/1211 [00:13<08:08,  2.42it/s]\u001b[A\n","Iteration:   3% 32/1211 [00:13<08:07,  2.42it/s]\u001b[A\n","Iteration:   3% 33/1211 [00:13<08:07,  2.42it/s]\u001b[A\n","Iteration:   3% 34/1211 [00:14<08:07,  2.41it/s]\u001b[A\n","Iteration:   3% 35/1211 [00:14<08:07,  2.41it/s]\u001b[A\n","Iteration:   3% 36/1211 [00:15<08:06,  2.41it/s]\u001b[A\n","Iteration:   3% 37/1211 [00:15<08:06,  2.41it/s]\u001b[A\n","Iteration:   3% 38/1211 [00:15<08:05,  2.42it/s]\u001b[A\n","Iteration:   3% 39/1211 [00:16<08:04,  2.42it/s]\u001b[A\n","Iteration:   3% 40/1211 [00:16<08:04,  2.42it/s]\u001b[A\n","Iteration:   3% 41/1211 [00:17<08:04,  2.41it/s]\u001b[A\n","Iteration:   3% 42/1211 [00:17<08:04,  2.41it/s]\u001b[A\n","Iteration:   4% 43/1211 [00:18<08:03,  2.42it/s]\u001b[A\n","Iteration:   4% 44/1211 [00:18<08:02,  2.42it/s]\u001b[A\n","Iteration:   4% 45/1211 [00:18<08:01,  2.42it/s]\u001b[A\n","Iteration:   4% 46/1211 [00:19<08:00,  2.42it/s]\u001b[A\n","Iteration:   4% 47/1211 [00:19<08:00,  2.42it/s]\u001b[A\n","Iteration:   4% 48/1211 [00:20<08:01,  2.42it/s]\u001b[A\n","Iteration:   4% 49/1211 [00:20<08:01,  2.42it/s]\u001b[A\n","Iteration:   4% 50/1211 [00:20<08:00,  2.42it/s]\u001b[A\n","Iteration:   4% 51/1211 [00:21<08:00,  2.41it/s]\u001b[A\n","Iteration:   4% 52/1211 [00:21<07:59,  2.41it/s]\u001b[A\n","Iteration:   4% 53/1211 [00:22<07:58,  2.42it/s]\u001b[A\n","Iteration:   4% 54/1211 [00:22<07:58,  2.42it/s]\u001b[A\n","Iteration:   5% 55/1211 [00:22<07:59,  2.41it/s]\u001b[A\n","Iteration:   5% 56/1211 [00:23<07:59,  2.41it/s]\u001b[A\n","Iteration:   5% 57/1211 [00:23<07:58,  2.41it/s]\u001b[A\n","Iteration:   5% 58/1211 [00:24<07:57,  2.42it/s]\u001b[A\n","Iteration:   5% 59/1211 [00:24<07:55,  2.42it/s]\u001b[A\n","Iteration:   5% 60/1211 [00:25<07:57,  2.41it/s]\u001b[A\n","Iteration:   5% 61/1211 [00:25<07:56,  2.41it/s]\u001b[A\n","Iteration:   5% 62/1211 [00:25<07:56,  2.41it/s]\u001b[A\n","Iteration:   5% 63/1211 [00:26<07:55,  2.42it/s]\u001b[A\n","Iteration:   5% 64/1211 [00:26<07:54,  2.42it/s]\u001b[A\n","Iteration:   5% 65/1211 [00:27<07:53,  2.42it/s]\u001b[A\n","Iteration:   5% 66/1211 [00:27<07:52,  2.42it/s]\u001b[A\n","Iteration:   6% 67/1211 [00:27<07:51,  2.42it/s]\u001b[A\n","Iteration:   6% 68/1211 [00:28<07:51,  2.42it/s]\u001b[A\n","Iteration:   6% 69/1211 [00:28<07:50,  2.42it/s]\u001b[A\n","Iteration:   6% 70/1211 [00:29<07:51,  2.42it/s]\u001b[A\n","Iteration:   6% 71/1211 [00:29<07:49,  2.43it/s]\u001b[A\n","Iteration:   6% 72/1211 [00:30<07:48,  2.43it/s]\u001b[A\n","Iteration:   6% 73/1211 [00:30<07:48,  2.43it/s]\u001b[A\n","Iteration:   6% 74/1211 [00:30<07:48,  2.43it/s]\u001b[A\n","Iteration:   6% 75/1211 [00:31<07:48,  2.42it/s]\u001b[A\n","Iteration:   6% 76/1211 [00:31<07:49,  2.42it/s]\u001b[A\n","Iteration:   6% 77/1211 [00:32<07:49,  2.42it/s]\u001b[A\n","Iteration:   6% 78/1211 [00:32<07:48,  2.42it/s]\u001b[A\n","Iteration:   7% 79/1211 [00:32<07:48,  2.41it/s]\u001b[A\n","Iteration:   7% 80/1211 [00:33<07:48,  2.42it/s]\u001b[A\n","Iteration:   7% 81/1211 [00:33<07:48,  2.41it/s]\u001b[A\n","Iteration:   7% 82/1211 [00:34<07:47,  2.42it/s]\u001b[A\n","Iteration:   7% 83/1211 [00:34<07:46,  2.42it/s]\u001b[A\n","Iteration:   7% 84/1211 [00:34<07:46,  2.41it/s]\u001b[A\n","Iteration:   7% 85/1211 [00:35<07:50,  2.39it/s]\u001b[A\n","Iteration:   7% 86/1211 [00:35<07:48,  2.40it/s]\u001b[A\n","Iteration:   7% 87/1211 [00:36<07:45,  2.41it/s]\u001b[A\n","Iteration:   7% 88/1211 [00:36<07:43,  2.42it/s]\u001b[A\n","Iteration:   7% 89/1211 [00:37<07:43,  2.42it/s]\u001b[A\n","Iteration:   7% 90/1211 [00:37<07:42,  2.42it/s]\u001b[A\n","Iteration:   8% 91/1211 [00:37<07:41,  2.43it/s]\u001b[A\n","Iteration:   8% 92/1211 [00:38<07:42,  2.42it/s]\u001b[A\n","Iteration:   8% 93/1211 [00:38<07:42,  2.42it/s]\u001b[A\n","Iteration:   8% 94/1211 [00:39<07:41,  2.42it/s]\u001b[A\n","Iteration:   8% 95/1211 [00:39<07:40,  2.42it/s]\u001b[A\n","Iteration:   8% 96/1211 [00:39<07:40,  2.42it/s]\u001b[A\n","Iteration:   8% 97/1211 [00:40<07:40,  2.42it/s]\u001b[A\n","Iteration:   8% 98/1211 [00:40<07:39,  2.42it/s]\u001b[A\n","Iteration:   8% 99/1211 [00:41<07:38,  2.43it/s]\u001b[A\n","Iteration:   8% 100/1211 [00:41<07:37,  2.43it/s]\u001b[A\n","Iteration:   8% 101/1211 [00:41<07:37,  2.43it/s]\u001b[A\n","Iteration:   8% 102/1211 [00:42<07:38,  2.42it/s]\u001b[A\n","Iteration:   9% 103/1211 [00:42<07:37,  2.42it/s]\u001b[A\n","Iteration:   9% 104/1211 [00:43<07:37,  2.42it/s]\u001b[A\n","Iteration:   9% 105/1211 [00:43<07:36,  2.42it/s]\u001b[A\n","Iteration:   9% 106/1211 [00:44<07:37,  2.41it/s]\u001b[A\n","Iteration:   9% 107/1211 [00:44<07:38,  2.41it/s]\u001b[A\n","Iteration:   9% 108/1211 [00:44<07:37,  2.41it/s]\u001b[A\n","Iteration:   9% 109/1211 [00:45<07:36,  2.41it/s]\u001b[A\n","Iteration:   9% 110/1211 [00:45<07:37,  2.41it/s]\u001b[A\n","Iteration:   9% 111/1211 [00:46<07:35,  2.41it/s]\u001b[A\n","Iteration:   9% 112/1211 [00:46<07:34,  2.42it/s]\u001b[A\n","Iteration:   9% 113/1211 [00:46<07:34,  2.42it/s]\u001b[A\n","Iteration:   9% 114/1211 [00:47<07:33,  2.42it/s]\u001b[A\n","Iteration:   9% 115/1211 [00:47<07:32,  2.42it/s]\u001b[A\n","Iteration:  10% 116/1211 [00:48<07:32,  2.42it/s]\u001b[A\n","Iteration:  10% 117/1211 [00:48<07:32,  2.42it/s]\u001b[A\n","Iteration:  10% 118/1211 [00:49<07:32,  2.42it/s]\u001b[A\n","Iteration:  10% 119/1211 [00:49<07:31,  2.42it/s]\u001b[A\n","Iteration:  10% 120/1211 [00:49<07:30,  2.42it/s]\u001b[A\n","Iteration:  10% 121/1211 [00:50<07:30,  2.42it/s]\u001b[A\n","Iteration:  10% 122/1211 [00:50<07:30,  2.42it/s]\u001b[A\n","Iteration:  10% 123/1211 [00:51<07:29,  2.42it/s]\u001b[A\n","Iteration:  10% 124/1211 [00:51<07:29,  2.42it/s]\u001b[A\n","Iteration:  10% 125/1211 [00:51<07:28,  2.42it/s]\u001b[A\n","Iteration:  10% 126/1211 [00:52<07:28,  2.42it/s]\u001b[A\n","Iteration:  10% 127/1211 [00:52<07:27,  2.42it/s]\u001b[A\n","Iteration:  11% 128/1211 [00:53<07:27,  2.42it/s]\u001b[A\n","Iteration:  11% 129/1211 [00:53<07:26,  2.42it/s]\u001b[A\n","Iteration:  11% 130/1211 [00:53<07:25,  2.43it/s]\u001b[A\n","Iteration:  11% 131/1211 [00:54<07:25,  2.43it/s]\u001b[A\n","Iteration:  11% 132/1211 [00:54<07:24,  2.43it/s]\u001b[A\n","Iteration:  11% 133/1211 [00:55<07:26,  2.42it/s]\u001b[A\n","Iteration:  11% 134/1211 [00:55<07:24,  2.42it/s]\u001b[A\n","Iteration:  11% 135/1211 [00:56<07:23,  2.42it/s]\u001b[A\n","Iteration:  11% 136/1211 [00:56<07:23,  2.43it/s]\u001b[A\n","Iteration:  11% 137/1211 [00:56<07:23,  2.42it/s]\u001b[A\n","Iteration:  11% 138/1211 [00:57<07:23,  2.42it/s]\u001b[A\n","Iteration:  11% 139/1211 [00:57<07:22,  2.42it/s]\u001b[A\n","Iteration:  12% 140/1211 [00:58<07:21,  2.43it/s]\u001b[A\n","Iteration:  12% 141/1211 [00:58<07:20,  2.43it/s]\u001b[A\n","Iteration:  12% 142/1211 [00:58<07:20,  2.43it/s]\u001b[A\n","Iteration:  12% 143/1211 [00:59<07:20,  2.43it/s]\u001b[A\n","Iteration:  12% 144/1211 [00:59<07:19,  2.43it/s]\u001b[A\n","Iteration:  12% 145/1211 [01:00<07:19,  2.43it/s]\u001b[A\n","Iteration:  12% 146/1211 [01:00<07:18,  2.43it/s]\u001b[A\n","Iteration:  12% 147/1211 [01:00<07:18,  2.43it/s]\u001b[A\n","Iteration:  12% 148/1211 [01:01<07:18,  2.43it/s]\u001b[A\n","Iteration:  12% 149/1211 [01:01<07:17,  2.43it/s]\u001b[A\n","Iteration:  12% 150/1211 [01:02<07:17,  2.42it/s]\u001b[A\n","Iteration:  12% 151/1211 [01:02<07:16,  2.43it/s]\u001b[A\n","Iteration:  13% 152/1211 [01:03<07:16,  2.42it/s]\u001b[A\n","Iteration:  13% 153/1211 [01:03<07:17,  2.42it/s]\u001b[A\n","Iteration:  13% 154/1211 [01:03<07:18,  2.41it/s]\u001b[A\n","Iteration:  13% 155/1211 [01:04<07:18,  2.41it/s]\u001b[A\n","Iteration:  13% 156/1211 [01:04<07:17,  2.41it/s]\u001b[A\n","Iteration:  13% 157/1211 [01:05<07:16,  2.42it/s]\u001b[A\n","Iteration:  13% 158/1211 [01:05<07:15,  2.42it/s]\u001b[A\n","Iteration:  13% 159/1211 [01:05<07:16,  2.41it/s]\u001b[A\n","Iteration:  13% 160/1211 [01:06<07:15,  2.41it/s]\u001b[A\n","Iteration:  13% 161/1211 [01:06<07:13,  2.42it/s]\u001b[A\n","Iteration:  13% 162/1211 [01:07<07:13,  2.42it/s]\u001b[A\n","Iteration:  13% 163/1211 [01:07<07:12,  2.42it/s]\u001b[A\n","Iteration:  14% 164/1211 [01:08<07:13,  2.42it/s]\u001b[A\n","Iteration:  14% 165/1211 [01:08<07:13,  2.41it/s]\u001b[A\n","Iteration:  14% 166/1211 [01:08<07:12,  2.42it/s]\u001b[A\n","Iteration:  14% 167/1211 [01:09<07:11,  2.42it/s]\u001b[A\n","Iteration:  14% 168/1211 [01:09<07:11,  2.42it/s]\u001b[A\n","Iteration:  14% 169/1211 [01:10<07:10,  2.42it/s]\u001b[A\n","Iteration:  14% 170/1211 [01:10<07:10,  2.42it/s]\u001b[A\n","Iteration:  14% 171/1211 [01:10<07:10,  2.42it/s]\u001b[A\n","Iteration:  14% 172/1211 [01:11<07:10,  2.42it/s]\u001b[A\n","Iteration:  14% 173/1211 [01:11<07:08,  2.42it/s]\u001b[A\n","Iteration:  14% 174/1211 [01:12<07:07,  2.42it/s]\u001b[A\n","Iteration:  14% 175/1211 [01:12<07:06,  2.43it/s]\u001b[A\n","Iteration:  15% 176/1211 [01:12<07:06,  2.43it/s]\u001b[A\n","Iteration:  15% 177/1211 [01:13<07:07,  2.42it/s]\u001b[A\n","Iteration:  15% 178/1211 [01:13<07:07,  2.42it/s]\u001b[A\n","Iteration:  15% 179/1211 [01:14<07:06,  2.42it/s]\u001b[A\n","Iteration:  15% 180/1211 [01:14<07:05,  2.42it/s]\u001b[A\n","Iteration:  15% 181/1211 [01:15<07:04,  2.43it/s]\u001b[A\n","Iteration:  15% 182/1211 [01:15<07:04,  2.42it/s]\u001b[A\n","Iteration:  15% 183/1211 [01:15<07:03,  2.43it/s]\u001b[A\n","Iteration:  15% 184/1211 [01:16<07:03,  2.43it/s]\u001b[A\n","Iteration:  15% 185/1211 [01:16<07:02,  2.43it/s]\u001b[A\n","Iteration:  15% 186/1211 [01:17<07:02,  2.43it/s]\u001b[A\n","Iteration:  15% 187/1211 [01:17<07:01,  2.43it/s]\u001b[A\n","Iteration:  16% 188/1211 [01:17<07:01,  2.43it/s]\u001b[A\n","Iteration:  16% 189/1211 [01:18<07:01,  2.43it/s]\u001b[A\n","Iteration:  16% 190/1211 [01:18<07:01,  2.42it/s]\u001b[A\n","Iteration:  16% 191/1211 [01:19<07:01,  2.42it/s]\u001b[A\n","Iteration:  16% 192/1211 [01:19<07:01,  2.42it/s]\u001b[A\n","Iteration:  16% 193/1211 [01:19<07:00,  2.42it/s]\u001b[A\n","Iteration:  16% 194/1211 [01:20<07:00,  2.42it/s]\u001b[A\n","Iteration:  16% 195/1211 [01:20<06:59,  2.42it/s]\u001b[A\n","Iteration:  16% 196/1211 [01:21<06:59,  2.42it/s]\u001b[A\n","Iteration:  16% 197/1211 [01:21<06:58,  2.42it/s]\u001b[A\n","Iteration:  16% 198/1211 [01:22<06:58,  2.42it/s]\u001b[A\n","Iteration:  16% 199/1211 [01:22<06:58,  2.42it/s]\u001b[A\n","Iteration:  17% 200/1211 [01:22<06:58,  2.42it/s]\u001b[A\n","Iteration:  17% 201/1211 [01:23<06:57,  2.42it/s]\u001b[A\n","Iteration:  17% 202/1211 [01:23<06:57,  2.42it/s]\u001b[A\n","Iteration:  17% 203/1211 [01:24<06:56,  2.42it/s]\u001b[A\n","Iteration:  17% 204/1211 [01:24<06:58,  2.41it/s]\u001b[A\n","Iteration:  17% 205/1211 [01:24<06:57,  2.41it/s]\u001b[A\n","Iteration:  17% 206/1211 [01:25<06:57,  2.41it/s]\u001b[A\n","Iteration:  17% 207/1211 [01:25<06:56,  2.41it/s]\u001b[A\n","Iteration:  17% 208/1211 [01:26<06:54,  2.42it/s]\u001b[A\n","Iteration:  17% 209/1211 [01:26<06:55,  2.41it/s]\u001b[A\n","Iteration:  17% 210/1211 [01:27<06:54,  2.41it/s]\u001b[A\n","Iteration:  17% 211/1211 [01:27<06:55,  2.41it/s]\u001b[A\n","Iteration:  18% 212/1211 [01:27<06:53,  2.42it/s]\u001b[A\n","Iteration:  18% 213/1211 [01:28<06:52,  2.42it/s]\u001b[A\n","Iteration:  18% 214/1211 [01:28<06:51,  2.42it/s]\u001b[A\n","Iteration:  18% 215/1211 [01:29<06:51,  2.42it/s]\u001b[A\n","Iteration:  18% 216/1211 [01:29<06:51,  2.42it/s]\u001b[A\n","Iteration:  18% 217/1211 [01:29<06:51,  2.42it/s]\u001b[A\n","Iteration:  18% 218/1211 [01:30<06:50,  2.42it/s]\u001b[A\n","Iteration:  18% 219/1211 [01:30<06:49,  2.42it/s]\u001b[A\n","Iteration:  18% 220/1211 [01:31<06:48,  2.42it/s]\u001b[A\n","Iteration:  18% 221/1211 [01:31<06:48,  2.42it/s]\u001b[A\n","Iteration:  18% 222/1211 [01:31<06:48,  2.42it/s]\u001b[A\n","Iteration:  18% 223/1211 [01:32<06:48,  2.42it/s]\u001b[A\n","Iteration:  18% 224/1211 [01:32<06:48,  2.42it/s]\u001b[A\n","Iteration:  19% 225/1211 [01:33<06:47,  2.42it/s]\u001b[A\n","Iteration:  19% 226/1211 [01:33<06:48,  2.41it/s]\u001b[A\n","Iteration:  19% 227/1211 [01:34<06:47,  2.42it/s]\u001b[A\n","Iteration:  19% 228/1211 [01:34<06:46,  2.42it/s]\u001b[A\n","Iteration:  19% 229/1211 [01:34<06:45,  2.42it/s]\u001b[A\n","Iteration:  19% 230/1211 [01:35<06:45,  2.42it/s]\u001b[A\n","Iteration:  19% 231/1211 [01:35<06:44,  2.42it/s]\u001b[A\n","Iteration:  19% 232/1211 [01:36<06:44,  2.42it/s]\u001b[A\n","Iteration:  19% 233/1211 [01:36<06:44,  2.42it/s]\u001b[A\n","Iteration:  19% 234/1211 [01:36<06:44,  2.42it/s]\u001b[A\n","Iteration:  19% 235/1211 [01:37<06:44,  2.41it/s]\u001b[A\n","Iteration:  19% 236/1211 [01:37<06:43,  2.42it/s]\u001b[A\n","Iteration:  20% 237/1211 [01:38<06:43,  2.42it/s]\u001b[A\n","Iteration:  20% 238/1211 [01:38<06:41,  2.42it/s]\u001b[A\n","Iteration:  20% 239/1211 [01:39<06:41,  2.42it/s]\u001b[A\n","Iteration:  20% 240/1211 [01:39<06:40,  2.42it/s]\u001b[A\n","Iteration:  20% 241/1211 [01:39<06:40,  2.42it/s]\u001b[A\n","Iteration:  20% 242/1211 [01:40<06:39,  2.42it/s]\u001b[A\n","Iteration:  20% 243/1211 [01:40<06:39,  2.42it/s]\u001b[A\n","Iteration:  20% 244/1211 [01:41<06:39,  2.42it/s]\u001b[A\n","Iteration:  20% 245/1211 [01:41<06:39,  2.42it/s]\u001b[A\n","Iteration:  20% 246/1211 [01:41<06:38,  2.42it/s]\u001b[A\n","Iteration:  20% 247/1211 [01:42<06:38,  2.42it/s]\u001b[A\n","Iteration:  20% 248/1211 [01:42<06:38,  2.42it/s]\u001b[A\n","Iteration:  21% 249/1211 [01:43<06:38,  2.42it/s]\u001b[A\n","Iteration:  21% 250/1211 [01:43<06:36,  2.42it/s]\u001b[A\n","Iteration:  21% 251/1211 [01:43<06:35,  2.43it/s]\u001b[A\n","Iteration:  21% 252/1211 [01:44<06:35,  2.43it/s]\u001b[A\n","Iteration:  21% 253/1211 [01:44<06:35,  2.42it/s]\u001b[A\n","Iteration:  21% 254/1211 [01:45<06:35,  2.42it/s]\u001b[A\n","Iteration:  21% 255/1211 [01:45<06:34,  2.42it/s]\u001b[A\n","Iteration:  21% 256/1211 [01:46<06:33,  2.43it/s]\u001b[A\n","Iteration:  21% 257/1211 [01:46<06:33,  2.42it/s]\u001b[A\n","Iteration:  21% 258/1211 [01:46<06:34,  2.41it/s]\u001b[A\n","Iteration:  21% 259/1211 [01:47<06:34,  2.41it/s]\u001b[A\n","Iteration:  21% 260/1211 [01:47<06:34,  2.41it/s]\u001b[A\n","Iteration:  22% 261/1211 [01:48<06:33,  2.42it/s]\u001b[A\n","Iteration:  22% 262/1211 [01:48<06:32,  2.42it/s]\u001b[A\n","Iteration:  22% 263/1211 [01:48<06:33,  2.41it/s]\u001b[A\n","Iteration:  22% 264/1211 [01:49<06:32,  2.42it/s]\u001b[A\n","Iteration:  22% 265/1211 [01:49<06:30,  2.42it/s]\u001b[A\n","Iteration:  22% 266/1211 [01:50<06:30,  2.42it/s]\u001b[A\n","Iteration:  22% 267/1211 [01:50<06:29,  2.42it/s]\u001b[A\n","Iteration:  22% 268/1211 [01:51<06:30,  2.42it/s]\u001b[A\n","Iteration:  22% 269/1211 [01:51<06:29,  2.42it/s]\u001b[A\n","Iteration:  22% 270/1211 [01:51<06:29,  2.42it/s]\u001b[A\n","Iteration:  22% 271/1211 [01:52<06:29,  2.41it/s]\u001b[A\n","Iteration:  22% 272/1211 [01:52<06:28,  2.42it/s]\u001b[A\n","Iteration:  23% 273/1211 [01:53<06:27,  2.42it/s]\u001b[A\n","Iteration:  23% 274/1211 [01:53<06:27,  2.42it/s]\u001b[A\n","Iteration:  23% 275/1211 [01:53<06:27,  2.41it/s]\u001b[A\n","Iteration:  23% 276/1211 [01:54<06:26,  2.42it/s]\u001b[A\n","Iteration:  23% 277/1211 [01:54<06:25,  2.42it/s]\u001b[A\n","Iteration:  23% 278/1211 [01:55<06:24,  2.42it/s]\u001b[A\n","Iteration:  23% 279/1211 [01:55<06:24,  2.43it/s]\u001b[A\n","Iteration:  23% 280/1211 [01:55<06:23,  2.43it/s]\u001b[A\n","Iteration:  23% 281/1211 [01:56<06:23,  2.43it/s]\u001b[A\n","Iteration:  23% 282/1211 [01:56<06:22,  2.43it/s]\u001b[A\n","Iteration:  23% 283/1211 [01:57<06:22,  2.43it/s]\u001b[A\n","Iteration:  23% 284/1211 [01:57<06:21,  2.43it/s]\u001b[A\n","Iteration:  24% 285/1211 [01:58<06:21,  2.43it/s]\u001b[A\n","Iteration:  24% 286/1211 [01:58<06:21,  2.43it/s]\u001b[A\n","Iteration:  24% 287/1211 [01:58<06:20,  2.43it/s]\u001b[A\n","Iteration:  24% 288/1211 [01:59<06:20,  2.43it/s]\u001b[A\n","Iteration:  24% 289/1211 [01:59<06:20,  2.43it/s]\u001b[A\n","Iteration:  24% 290/1211 [02:00<06:19,  2.42it/s]\u001b[A\n","Iteration:  24% 291/1211 [02:00<06:19,  2.43it/s]\u001b[A\n","Iteration:  24% 292/1211 [02:00<06:18,  2.43it/s]\u001b[A\n","Iteration:  24% 293/1211 [02:01<06:18,  2.43it/s]\u001b[A\n","Iteration:  24% 294/1211 [02:01<06:17,  2.43it/s]\u001b[A\n","Iteration:  24% 295/1211 [02:02<06:17,  2.43it/s]\u001b[A\n","Iteration:  24% 296/1211 [02:02<06:16,  2.43it/s]\u001b[A\n","Iteration:  25% 297/1211 [02:02<06:16,  2.43it/s]\u001b[A\n","Iteration:  25% 298/1211 [02:03<06:16,  2.42it/s]\u001b[A\n","Iteration:  25% 299/1211 [02:03<06:16,  2.42it/s]\u001b[A\n","Iteration:  25% 300/1211 [02:04<06:15,  2.43it/s]\u001b[A\n","Iteration:  25% 301/1211 [02:04<06:15,  2.43it/s]\u001b[A\n","Iteration:  25% 302/1211 [02:05<06:15,  2.42it/s]\u001b[A\n","Iteration:  25% 303/1211 [02:05<06:14,  2.42it/s]\u001b[A\n","Iteration:  25% 304/1211 [02:05<06:14,  2.42it/s]\u001b[A\n","Iteration:  25% 305/1211 [02:06<06:13,  2.42it/s]\u001b[A\n","Iteration:  25% 306/1211 [02:06<06:13,  2.42it/s]\u001b[A\n","Iteration:  25% 307/1211 [02:07<06:13,  2.42it/s]\u001b[A\n","Iteration:  25% 308/1211 [02:07<06:12,  2.42it/s]\u001b[A\n","Iteration:  26% 309/1211 [02:07<06:12,  2.42it/s]\u001b[A\n","Iteration:  26% 310/1211 [02:08<06:12,  2.42it/s]\u001b[A\n","Iteration:  26% 311/1211 [02:08<06:13,  2.41it/s]\u001b[A\n","Iteration:  26% 312/1211 [02:09<06:11,  2.42it/s]\u001b[A\n","Iteration:  26% 313/1211 [02:09<06:11,  2.42it/s]\u001b[A\n","Iteration:  26% 314/1211 [02:09<06:10,  2.42it/s]\u001b[A\n","Iteration:  26% 315/1211 [02:10<06:11,  2.41it/s]\u001b[A\n","Iteration:  26% 316/1211 [02:10<06:10,  2.42it/s]\u001b[A\n","Iteration:  26% 317/1211 [02:11<06:09,  2.42it/s]\u001b[A\n","Iteration:  26% 318/1211 [02:11<06:08,  2.42it/s]\u001b[A\n","Iteration:  26% 319/1211 [02:12<06:08,  2.42it/s]\u001b[A\n","Iteration:  26% 320/1211 [02:12<06:09,  2.41it/s]\u001b[A\n","Iteration:  27% 321/1211 [02:12<06:08,  2.42it/s]\u001b[A\n","Iteration:  27% 322/1211 [02:13<06:07,  2.42it/s]\u001b[A\n","Iteration:  27% 323/1211 [02:13<06:06,  2.42it/s]\u001b[A\n","Iteration:  27% 324/1211 [02:14<06:06,  2.42it/s]\u001b[A\n","Iteration:  27% 325/1211 [02:14<06:05,  2.42it/s]\u001b[A\n","Iteration:  27% 326/1211 [02:14<06:05,  2.42it/s]\u001b[A\n","Iteration:  27% 327/1211 [02:15<06:05,  2.42it/s]\u001b[A\n","Iteration:  27% 328/1211 [02:15<06:04,  2.43it/s]\u001b[A\n","Iteration:  27% 329/1211 [02:16<06:03,  2.43it/s]\u001b[A\n","Iteration:  27% 330/1211 [02:16<06:02,  2.43it/s]\u001b[A\n","Iteration:  27% 331/1211 [02:17<06:02,  2.43it/s]\u001b[A\n","Iteration:  27% 332/1211 [02:17<06:02,  2.42it/s]\u001b[A\n","Iteration:  27% 333/1211 [02:17<06:01,  2.43it/s]\u001b[A\n","Iteration:  28% 334/1211 [02:18<06:03,  2.41it/s]\u001b[A\n","Iteration:  28% 335/1211 [02:18<06:02,  2.41it/s]\u001b[A\n","Iteration:  28% 336/1211 [02:19<06:02,  2.41it/s]\u001b[A\n","Iteration:  28% 337/1211 [02:19<06:01,  2.42it/s]\u001b[A\n","Iteration:  28% 338/1211 [02:19<06:00,  2.42it/s]\u001b[A\n","Iteration:  28% 339/1211 [02:20<06:00,  2.42it/s]\u001b[A\n","Iteration:  28% 340/1211 [02:20<05:59,  2.42it/s]\u001b[A\n","Iteration:  28% 341/1211 [02:21<05:59,  2.42it/s]\u001b[A\n","Iteration:  28% 342/1211 [02:21<05:58,  2.42it/s]\u001b[A\n","Iteration:  28% 343/1211 [02:21<05:58,  2.42it/s]\u001b[A\n","Iteration:  28% 344/1211 [02:22<05:57,  2.42it/s]\u001b[A\n","Iteration:  28% 345/1211 [02:22<05:56,  2.43it/s]\u001b[A\n","Iteration:  29% 346/1211 [02:23<05:56,  2.43it/s]\u001b[A\n","Iteration:  29% 347/1211 [02:23<05:55,  2.43it/s]\u001b[A\n","Iteration:  29% 348/1211 [02:24<05:56,  2.42it/s]\u001b[A\n","Iteration:  29% 349/1211 [02:24<05:55,  2.43it/s]\u001b[A\n","Iteration:  29% 350/1211 [02:24<05:54,  2.43it/s]\u001b[A\n","Iteration:  29% 351/1211 [02:25<05:56,  2.41it/s]\u001b[A\n","Iteration:  29% 352/1211 [02:25<05:55,  2.41it/s]\u001b[A\n","Iteration:  29% 353/1211 [02:26<05:55,  2.42it/s]\u001b[A\n","Iteration:  29% 354/1211 [02:26<05:54,  2.42it/s]\u001b[A\n","Iteration:  29% 355/1211 [02:26<05:52,  2.43it/s]\u001b[A\n","Iteration:  29% 356/1211 [02:27<05:52,  2.42it/s]\u001b[A\n","Iteration:  29% 357/1211 [02:27<05:52,  2.42it/s]\u001b[A\n","Iteration:  30% 358/1211 [02:28<05:53,  2.42it/s]\u001b[A\n","Iteration:  30% 359/1211 [02:28<05:52,  2.42it/s]\u001b[A\n","Iteration:  30% 360/1211 [02:28<05:52,  2.42it/s]\u001b[A\n","Iteration:  30% 361/1211 [02:29<05:51,  2.42it/s]\u001b[A\n","Iteration:  30% 362/1211 [02:29<05:51,  2.41it/s]\u001b[A\n","Iteration:  30% 363/1211 [02:30<05:50,  2.42it/s]\u001b[A\n","Iteration:  30% 364/1211 [02:30<05:50,  2.42it/s]\u001b[A\n","Iteration:  30% 365/1211 [02:31<05:49,  2.42it/s]\u001b[A\n","Iteration:  30% 366/1211 [02:31<05:48,  2.43it/s]\u001b[A\n","Iteration:  30% 367/1211 [02:31<05:50,  2.41it/s]\u001b[A\n","Iteration:  30% 368/1211 [02:32<05:48,  2.42it/s]\u001b[A\n","Iteration:  30% 369/1211 [02:32<05:48,  2.42it/s]\u001b[A\n","Iteration:  31% 370/1211 [02:33<05:47,  2.42it/s]\u001b[A\n","Iteration:  31% 371/1211 [02:33<05:46,  2.43it/s]\u001b[A\n","Iteration:  31% 372/1211 [02:33<05:47,  2.42it/s]\u001b[A\n","Iteration:  31% 373/1211 [02:34<05:47,  2.41it/s]\u001b[A\n","Iteration:  31% 374/1211 [02:34<05:45,  2.42it/s]\u001b[A\n","Iteration:  31% 375/1211 [02:35<05:45,  2.42it/s]\u001b[A\n","Iteration:  31% 376/1211 [02:35<05:44,  2.42it/s]\u001b[A\n","Iteration:  31% 377/1211 [02:36<05:43,  2.43it/s]\u001b[A\n","Iteration:  31% 378/1211 [02:36<05:43,  2.43it/s]\u001b[A\n","Iteration:  31% 379/1211 [02:36<05:42,  2.43it/s]\u001b[A\n","Iteration:  31% 380/1211 [02:37<05:42,  2.42it/s]\u001b[A\n","Iteration:  31% 381/1211 [02:37<05:42,  2.43it/s]\u001b[A\n","Iteration:  32% 382/1211 [02:38<05:42,  2.42it/s]\u001b[A\n","Iteration:  32% 383/1211 [02:38<05:41,  2.42it/s]\u001b[A\n","Iteration:  32% 384/1211 [02:38<05:41,  2.42it/s]\u001b[A\n","Iteration:  32% 385/1211 [02:39<05:41,  2.42it/s]\u001b[A\n","Iteration:  32% 386/1211 [02:39<05:40,  2.42it/s]\u001b[A\n","Iteration:  32% 387/1211 [02:40<05:40,  2.42it/s]\u001b[A\n","Iteration:  32% 388/1211 [02:40<05:39,  2.42it/s]\u001b[A\n","Iteration:  32% 389/1211 [02:40<05:39,  2.42it/s]\u001b[A\n","Iteration:  32% 390/1211 [02:41<05:39,  2.42it/s]\u001b[A\n","Iteration:  32% 391/1211 [02:41<05:39,  2.42it/s]\u001b[A\n","Iteration:  32% 392/1211 [02:42<05:38,  2.42it/s]\u001b[A\n","Iteration:  32% 393/1211 [02:42<05:37,  2.42it/s]\u001b[A\n","Iteration:  33% 394/1211 [02:43<05:37,  2.42it/s]\u001b[A\n","Iteration:  33% 395/1211 [02:43<05:36,  2.42it/s]\u001b[A\n","Iteration:  33% 396/1211 [02:43<05:36,  2.43it/s]\u001b[A\n","Iteration:  33% 397/1211 [02:44<05:35,  2.43it/s]\u001b[A\n","Iteration:  33% 398/1211 [02:44<05:35,  2.43it/s]\u001b[A\n","Iteration:  33% 399/1211 [02:45<05:34,  2.42it/s]\u001b[A\n","Iteration:  33% 400/1211 [02:45<05:35,  2.42it/s]\u001b[A\n","Iteration:  33% 401/1211 [02:45<05:34,  2.42it/s]\u001b[A\n","Iteration:  33% 402/1211 [02:46<05:34,  2.42it/s]\u001b[A\n","Iteration:  33% 403/1211 [02:46<05:33,  2.42it/s]\u001b[A\n","Iteration:  33% 404/1211 [02:47<05:33,  2.42it/s]\u001b[A\n","Iteration:  33% 405/1211 [02:47<05:32,  2.42it/s]\u001b[A\n","Iteration:  34% 406/1211 [02:47<05:32,  2.42it/s]\u001b[A\n","Iteration:  34% 407/1211 [02:48<05:32,  2.42it/s]\u001b[A\n","Iteration:  34% 408/1211 [02:48<05:32,  2.42it/s]\u001b[A\n","Iteration:  34% 409/1211 [02:49<05:31,  2.42it/s]\u001b[A\n","Iteration:  34% 410/1211 [02:49<05:30,  2.42it/s]\u001b[A\n","Iteration:  34% 411/1211 [02:50<05:30,  2.42it/s]\u001b[A\n","Iteration:  34% 412/1211 [02:50<05:30,  2.42it/s]\u001b[A\n","Iteration:  34% 413/1211 [02:50<05:30,  2.42it/s]\u001b[A\n","Iteration:  34% 414/1211 [02:51<05:29,  2.42it/s]\u001b[A\n","Iteration:  34% 415/1211 [02:51<05:29,  2.42it/s]\u001b[A\n","Iteration:  34% 416/1211 [02:52<05:28,  2.42it/s]\u001b[A\n","Iteration:  34% 417/1211 [02:52<05:27,  2.42it/s]\u001b[A\n","Iteration:  35% 418/1211 [02:52<05:27,  2.42it/s]\u001b[A\n","Iteration:  35% 419/1211 [02:53<05:29,  2.41it/s]\u001b[A\n","Iteration:  35% 420/1211 [02:53<05:28,  2.41it/s]\u001b[A\n","Iteration:  35% 421/1211 [02:54<05:27,  2.41it/s]\u001b[A\n","Iteration:  35% 422/1211 [02:54<05:27,  2.41it/s]\u001b[A\n","Iteration:  35% 423/1211 [02:55<05:26,  2.41it/s]\u001b[A\n","Iteration:  35% 424/1211 [02:55<05:26,  2.41it/s]\u001b[A\n","Iteration:  35% 425/1211 [02:55<05:25,  2.41it/s]\u001b[A\n","Iteration:  35% 426/1211 [02:56<05:25,  2.42it/s]\u001b[A\n","Iteration:  35% 427/1211 [02:56<05:24,  2.41it/s]\u001b[A\n","Iteration:  35% 428/1211 [02:57<05:24,  2.41it/s]\u001b[A\n","Iteration:  35% 429/1211 [02:57<05:23,  2.42it/s]\u001b[A\n","Iteration:  36% 430/1211 [02:57<05:22,  2.42it/s]\u001b[A\n","Iteration:  36% 431/1211 [02:58<05:22,  2.42it/s]\u001b[A\n","Iteration:  36% 432/1211 [02:58<05:21,  2.42it/s]\u001b[A\n","Iteration:  36% 433/1211 [02:59<05:20,  2.43it/s]\u001b[A\n","Iteration:  36% 434/1211 [02:59<05:21,  2.42it/s]\u001b[A\n","Iteration:  36% 435/1211 [02:59<05:20,  2.42it/s]\u001b[A\n","Iteration:  36% 436/1211 [03:00<05:20,  2.42it/s]\u001b[A\n","Iteration:  36% 437/1211 [03:00<05:19,  2.42it/s]\u001b[A\n","Iteration:  36% 438/1211 [03:01<05:19,  2.42it/s]\u001b[A\n","Iteration:  36% 439/1211 [03:01<05:19,  2.42it/s]\u001b[A\n","Iteration:  36% 440/1211 [03:02<05:18,  2.42it/s]\u001b[A\n","Iteration:  36% 441/1211 [03:02<05:18,  2.42it/s]\u001b[A\n","Iteration:  36% 442/1211 [03:02<05:18,  2.42it/s]\u001b[A\n","Iteration:  37% 443/1211 [03:03<05:17,  2.42it/s]\u001b[A\n","Iteration:  37% 444/1211 [03:03<05:17,  2.41it/s]\u001b[A\n","Iteration:  37% 445/1211 [03:04<05:17,  2.41it/s]\u001b[A\n","Iteration:  37% 446/1211 [03:04<05:17,  2.41it/s]\u001b[A\n","Iteration:  37% 447/1211 [03:04<05:16,  2.41it/s]\u001b[A\n","Iteration:  37% 448/1211 [03:05<05:15,  2.42it/s]\u001b[A\n","Iteration:  37% 449/1211 [03:05<05:15,  2.42it/s]\u001b[A\n","Iteration:  37% 450/1211 [03:06<05:15,  2.42it/s]\u001b[A\n","Iteration:  37% 451/1211 [03:06<05:14,  2.42it/s]\u001b[A\n","Iteration:  37% 452/1211 [03:07<05:13,  2.42it/s]\u001b[A\n","Iteration:  37% 453/1211 [03:07<05:13,  2.42it/s]\u001b[A\n","Iteration:  37% 454/1211 [03:07<05:12,  2.42it/s]\u001b[A\n","Iteration:  38% 455/1211 [03:08<05:12,  2.42it/s]\u001b[A\n","Iteration:  38% 456/1211 [03:08<05:12,  2.42it/s]\u001b[A\n","Iteration:  38% 457/1211 [03:09<05:12,  2.41it/s]\u001b[A\n","Iteration:  38% 458/1211 [03:09<05:11,  2.41it/s]\u001b[A\n","Iteration:  38% 459/1211 [03:09<05:11,  2.42it/s]\u001b[A\n","Iteration:  38% 460/1211 [03:10<05:10,  2.42it/s]\u001b[A\n","Iteration:  38% 461/1211 [03:10<05:10,  2.42it/s]\u001b[A\n","Iteration:  38% 462/1211 [03:11<05:09,  2.42it/s]\u001b[A\n","Iteration:  38% 463/1211 [03:11<05:08,  2.42it/s]\u001b[A\n","Iteration:  38% 464/1211 [03:11<05:08,  2.42it/s]\u001b[A\n","Iteration:  38% 465/1211 [03:12<05:08,  2.42it/s]\u001b[A\n","Iteration:  38% 466/1211 [03:12<05:09,  2.41it/s]\u001b[A\n","Iteration:  39% 467/1211 [03:13<05:09,  2.41it/s]\u001b[A\n","Iteration:  39% 468/1211 [03:13<05:07,  2.41it/s]\u001b[A\n","Iteration:  39% 469/1211 [03:14<05:07,  2.42it/s]\u001b[A\n","Iteration:  39% 470/1211 [03:14<05:06,  2.42it/s]\u001b[A\n","Iteration:  39% 471/1211 [03:14<05:06,  2.42it/s]\u001b[A\n","Iteration:  39% 472/1211 [03:15<05:05,  2.42it/s]\u001b[A\n","Iteration:  39% 473/1211 [03:15<05:04,  2.42it/s]\u001b[A\n","Iteration:  39% 474/1211 [03:16<05:03,  2.42it/s]\u001b[A\n","Iteration:  39% 475/1211 [03:16<05:03,  2.43it/s]\u001b[A\n","Iteration:  39% 476/1211 [03:16<05:03,  2.42it/s]\u001b[A\n","Iteration:  39% 477/1211 [03:17<05:02,  2.42it/s]\u001b[A\n","Iteration:  39% 478/1211 [03:17<05:02,  2.42it/s]\u001b[A\n","Iteration:  40% 479/1211 [03:18<05:02,  2.42it/s]\u001b[A\n","Iteration:  40% 480/1211 [03:18<05:01,  2.42it/s]\u001b[A\n","Iteration:  40% 481/1211 [03:19<05:01,  2.42it/s]\u001b[A\n","Iteration:  40% 482/1211 [03:19<05:01,  2.42it/s]\u001b[A\n","Iteration:  40% 483/1211 [03:19<05:00,  2.42it/s]\u001b[A\n","Iteration:  40% 484/1211 [03:20<04:59,  2.43it/s]\u001b[A\n","Iteration:  40% 485/1211 [03:20<04:59,  2.42it/s]\u001b[A\n","Iteration:  40% 486/1211 [03:21<04:59,  2.42it/s]\u001b[A\n","Iteration:  40% 487/1211 [03:21<04:59,  2.42it/s]\u001b[A\n","Iteration:  40% 488/1211 [03:21<04:58,  2.42it/s]\u001b[A\n","Iteration:  40% 489/1211 [03:22<04:58,  2.42it/s]\u001b[A\n","Iteration:  40% 490/1211 [03:22<04:57,  2.42it/s]\u001b[A\n","Iteration:  41% 491/1211 [03:23<04:57,  2.42it/s]\u001b[A\n","Iteration:  41% 492/1211 [03:23<04:56,  2.42it/s]\u001b[A\n","Iteration:  41% 493/1211 [03:23<04:56,  2.42it/s]\u001b[A\n","Iteration:  41% 494/1211 [03:24<04:55,  2.42it/s]\u001b[A\n","Iteration:  41% 495/1211 [03:24<04:55,  2.42it/s]\u001b[A\n","Iteration:  41% 496/1211 [03:25<04:55,  2.42it/s]\u001b[A\n","Iteration:  41% 497/1211 [03:25<04:54,  2.42it/s]\u001b[A\n","Iteration:  41% 498/1211 [03:26<04:54,  2.42it/s]\u001b[A\n","Iteration:  41% 499/1211 [03:26<04:54,  2.42it/s]\u001b[A/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:231: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","04/30/2020 11:20:04 - INFO - transformers.configuration_utils -   Configuration saved in output/checkpoint-500/config.json\n","04/30/2020 11:20:06 - INFO - transformers.modeling_utils -   Model weights saved in output/checkpoint-500/pytorch_model.bin\n","04/30/2020 11:20:06 - INFO - __main__ -   Saving model checkpoint to output/checkpoint-500\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n","  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n","04/30/2020 11:20:15 - INFO - __main__ -   Saving optimizer and scheduler states to output/checkpoint-500\n","\n","Iteration:  41% 500/1211 [03:37<44:26,  3.75s/it]\u001b[A\n","Iteration:  41% 501/1211 [03:38<32:35,  2.75s/it]\u001b[A\n","Iteration:  41% 502/1211 [03:38<24:14,  2.05s/it]\u001b[A\n","Iteration:  42% 503/1211 [03:39<18:24,  1.56s/it]\u001b[A\n","Iteration:  42% 504/1211 [03:39<14:19,  1.22s/it]\u001b[A\n","Iteration:  42% 505/1211 [03:40<11:28,  1.03it/s]\u001b[A\n","Iteration:  42% 506/1211 [03:40<09:28,  1.24it/s]\u001b[A\n","Iteration:  42% 507/1211 [03:40<08:04,  1.45it/s]\u001b[A\n","Iteration:  42% 508/1211 [03:41<07:05,  1.65it/s]\u001b[A\n","Iteration:  42% 509/1211 [03:41<06:24,  1.83it/s]\u001b[A\n","Iteration:  42% 510/1211 [03:42<05:55,  1.97it/s]\u001b[A\n","Iteration:  42% 511/1211 [03:42<05:35,  2.09it/s]\u001b[A\n","Iteration:  42% 512/1211 [03:42<05:21,  2.18it/s]\u001b[A\n","Iteration:  42% 513/1211 [03:43<05:11,  2.24it/s]\u001b[A\n","Iteration:  42% 514/1211 [03:43<05:03,  2.29it/s]\u001b[A\n","Iteration:  43% 515/1211 [03:44<04:58,  2.33it/s]\u001b[A\n","Iteration:  43% 516/1211 [03:44<04:54,  2.36it/s]\u001b[A\n","Iteration:  43% 517/1211 [03:45<04:52,  2.38it/s]\u001b[A\n","Iteration:  43% 518/1211 [03:45<04:50,  2.39it/s]\u001b[A\n","Iteration:  43% 519/1211 [03:45<04:48,  2.40it/s]\u001b[A\n","Iteration:  43% 520/1211 [03:46<04:48,  2.39it/s]\u001b[A\n","Iteration:  43% 521/1211 [03:46<04:47,  2.40it/s]\u001b[A\n","Iteration:  43% 522/1211 [03:47<04:46,  2.41it/s]\u001b[A\n","Iteration:  43% 523/1211 [03:47<04:45,  2.41it/s]\u001b[A\n","Iteration:  43% 524/1211 [03:47<04:44,  2.41it/s]\u001b[A\n","Iteration:  43% 525/1211 [03:48<04:43,  2.42it/s]\u001b[A\n","Iteration:  43% 526/1211 [03:48<04:43,  2.42it/s]\u001b[A\n","Iteration:  44% 527/1211 [03:49<04:42,  2.42it/s]\u001b[A\n","Iteration:  44% 528/1211 [03:49<04:41,  2.42it/s]\u001b[A\n","Iteration:  44% 529/1211 [03:49<04:41,  2.42it/s]\u001b[A\n","Iteration:  44% 530/1211 [03:50<04:40,  2.42it/s]\u001b[A\n","Iteration:  44% 531/1211 [03:50<04:42,  2.41it/s]\u001b[A\n","Iteration:  44% 532/1211 [03:51<04:41,  2.41it/s]\u001b[A\n","Iteration:  44% 533/1211 [03:51<04:41,  2.41it/s]\u001b[A\n","Iteration:  44% 534/1211 [03:52<04:40,  2.41it/s]\u001b[A\n","Iteration:  44% 535/1211 [03:52<04:39,  2.42it/s]\u001b[A\n","Iteration:  44% 536/1211 [03:52<04:39,  2.42it/s]\u001b[A\n","Iteration:  44% 537/1211 [03:53<04:38,  2.42it/s]\u001b[A\n","Iteration:  44% 538/1211 [03:53<04:37,  2.42it/s]\u001b[A\n","Iteration:  45% 539/1211 [03:54<04:37,  2.42it/s]\u001b[A\n","Iteration:  45% 540/1211 [03:54<04:37,  2.42it/s]\u001b[A\n","Iteration:  45% 541/1211 [03:54<04:36,  2.42it/s]\u001b[A\n","Iteration:  45% 542/1211 [03:55<04:36,  2.42it/s]\u001b[A\n","Iteration:  45% 543/1211 [03:55<04:36,  2.41it/s]\u001b[A\n","Iteration:  45% 544/1211 [03:56<04:36,  2.42it/s]\u001b[A\n","Iteration:  45% 545/1211 [03:56<04:35,  2.42it/s]\u001b[A\n","Iteration:  45% 546/1211 [03:57<04:35,  2.42it/s]\u001b[A\n","Iteration:  45% 547/1211 [03:57<04:34,  2.42it/s]\u001b[A\n","Iteration:  45% 548/1211 [03:57<04:34,  2.42it/s]\u001b[A\n","Iteration:  45% 549/1211 [03:58<04:33,  2.42it/s]\u001b[A\n","Iteration:  45% 550/1211 [03:58<04:33,  2.41it/s]\u001b[A\n","Iteration:  45% 551/1211 [03:59<04:33,  2.42it/s]\u001b[A\n","Iteration:  46% 552/1211 [03:59<04:32,  2.42it/s]\u001b[A\n","Iteration:  46% 553/1211 [03:59<04:32,  2.42it/s]\u001b[A\n","Iteration:  46% 554/1211 [04:00<04:31,  2.42it/s]\u001b[A\n","Iteration:  46% 555/1211 [04:00<04:30,  2.42it/s]\u001b[A\n","Iteration:  46% 556/1211 [04:01<04:30,  2.42it/s]\u001b[A\n","Iteration:  46% 557/1211 [04:01<04:30,  2.42it/s]\u001b[A\n","Iteration:  46% 558/1211 [04:01<04:30,  2.42it/s]\u001b[A\n","Iteration:  46% 559/1211 [04:02<04:29,  2.42it/s]\u001b[A\n","Iteration:  46% 560/1211 [04:02<04:29,  2.42it/s]\u001b[A\n","Iteration:  46% 561/1211 [04:03<04:28,  2.42it/s]\u001b[A\n","Iteration:  46% 562/1211 [04:03<04:28,  2.42it/s]\u001b[A\n","Iteration:  46% 563/1211 [04:04<04:27,  2.42it/s]\u001b[A\n","Iteration:  47% 564/1211 [04:04<04:28,  2.41it/s]\u001b[A\n","Iteration:  47% 565/1211 [04:04<04:27,  2.41it/s]\u001b[A\n","Iteration:  47% 566/1211 [04:05<04:27,  2.41it/s]\u001b[A\n","Iteration:  47% 567/1211 [04:05<04:26,  2.42it/s]\u001b[A\n","Iteration:  47% 568/1211 [04:06<04:25,  2.42it/s]\u001b[A\n","Iteration:  47% 569/1211 [04:06<04:25,  2.42it/s]\u001b[A\n","Iteration:  47% 570/1211 [04:06<04:24,  2.43it/s]\u001b[A\n","Iteration:  47% 571/1211 [04:07<04:23,  2.42it/s]\u001b[A\n","Iteration:  47% 572/1211 [04:07<04:23,  2.43it/s]\u001b[A\n","Iteration:  47% 573/1211 [04:08<04:23,  2.43it/s]\u001b[A\n","Iteration:  47% 574/1211 [04:08<04:22,  2.43it/s]\u001b[A\n","Iteration:  47% 575/1211 [04:08<04:22,  2.42it/s]\u001b[A\n","Iteration:  48% 576/1211 [04:09<04:21,  2.43it/s]\u001b[A\n","Iteration:  48% 577/1211 [04:09<04:21,  2.43it/s]\u001b[A\n","Iteration:  48% 578/1211 [04:10<04:20,  2.43it/s]\u001b[A\n","Iteration:  48% 579/1211 [04:10<04:20,  2.42it/s]\u001b[A\n","Iteration:  48% 580/1211 [04:11<04:20,  2.42it/s]\u001b[A\n","Iteration:  48% 581/1211 [04:11<04:20,  2.42it/s]\u001b[A\n","Iteration:  48% 582/1211 [04:11<04:20,  2.42it/s]\u001b[A\n","Iteration:  48% 583/1211 [04:12<04:19,  2.42it/s]\u001b[A\n","Iteration:  48% 584/1211 [04:12<04:19,  2.42it/s]\u001b[A\n","Iteration:  48% 585/1211 [04:13<04:18,  2.42it/s]\u001b[A\n","Iteration:  48% 586/1211 [04:13<04:18,  2.41it/s]\u001b[A\n","Iteration:  48% 587/1211 [04:13<04:18,  2.42it/s]\u001b[A\n","Iteration:  49% 588/1211 [04:14<04:17,  2.42it/s]\u001b[A\n","Iteration:  49% 589/1211 [04:14<04:16,  2.42it/s]\u001b[A\n","Iteration:  49% 590/1211 [04:15<04:17,  2.42it/s]\u001b[A\n","Iteration:  49% 591/1211 [04:15<04:16,  2.41it/s]\u001b[A\n","Iteration:  49% 592/1211 [04:16<04:16,  2.41it/s]\u001b[A\n","Iteration:  49% 593/1211 [04:16<04:15,  2.42it/s]\u001b[A\n","Iteration:  49% 594/1211 [04:16<04:15,  2.42it/s]\u001b[A\n","Iteration:  49% 595/1211 [04:17<04:16,  2.40it/s]\u001b[A\n","Iteration:  49% 596/1211 [04:17<04:15,  2.41it/s]\u001b[A\n","Iteration:  49% 597/1211 [04:18<04:14,  2.41it/s]\u001b[A\n","Iteration:  49% 598/1211 [04:18<04:13,  2.42it/s]\u001b[A\n","Iteration:  49% 599/1211 [04:18<04:12,  2.42it/s]\u001b[A\n","Iteration:  50% 600/1211 [04:19<04:13,  2.41it/s]\u001b[A\n","Iteration:  50% 601/1211 [04:19<04:12,  2.41it/s]\u001b[A\n","Iteration:  50% 602/1211 [04:20<04:12,  2.41it/s]\u001b[A\n","Iteration:  50% 603/1211 [04:20<04:12,  2.41it/s]\u001b[A\n","Iteration:  50% 604/1211 [04:21<04:11,  2.41it/s]\u001b[A\n","Iteration:  50% 605/1211 [04:21<04:11,  2.41it/s]\u001b[A\n","Iteration:  50% 606/1211 [04:21<04:10,  2.42it/s]\u001b[A\n","Iteration:  50% 607/1211 [04:22<04:09,  2.42it/s]\u001b[A\n","Iteration:  50% 608/1211 [04:22<04:10,  2.41it/s]\u001b[A\n","Iteration:  50% 609/1211 [04:23<04:10,  2.41it/s]\u001b[A\n","Iteration:  50% 610/1211 [04:23<04:09,  2.41it/s]\u001b[A\n","Iteration:  50% 611/1211 [04:23<04:08,  2.41it/s]\u001b[A\n","Iteration:  51% 612/1211 [04:24<04:08,  2.41it/s]\u001b[A\n","Iteration:  51% 613/1211 [04:24<04:07,  2.41it/s]\u001b[A\n","Iteration:  51% 614/1211 [04:25<04:07,  2.41it/s]\u001b[A\n","Iteration:  51% 615/1211 [04:25<04:06,  2.41it/s]\u001b[A\n","Iteration:  51% 616/1211 [04:25<04:06,  2.42it/s]\u001b[A\n","Iteration:  51% 617/1211 [04:26<04:05,  2.42it/s]\u001b[A\n","Iteration:  51% 618/1211 [04:26<04:05,  2.42it/s]\u001b[A\n","Iteration:  51% 619/1211 [04:27<04:04,  2.42it/s]\u001b[A\n","Iteration:  51% 620/1211 [04:27<04:04,  2.42it/s]\u001b[A\n","Iteration:  51% 621/1211 [04:28<04:03,  2.42it/s]\u001b[A\n","Iteration:  51% 622/1211 [04:28<04:03,  2.42it/s]\u001b[A\n","Iteration:  51% 623/1211 [04:28<04:02,  2.42it/s]\u001b[A\n","Iteration:  52% 624/1211 [04:29<04:02,  2.42it/s]\u001b[A\n","Iteration:  52% 625/1211 [04:29<04:02,  2.42it/s]\u001b[A\n","Iteration:  52% 626/1211 [04:30<04:01,  2.42it/s]\u001b[A\n","Iteration:  52% 627/1211 [04:30<04:01,  2.42it/s]\u001b[A\n","Iteration:  52% 628/1211 [04:30<04:00,  2.42it/s]\u001b[A\n","Iteration:  52% 629/1211 [04:31<04:00,  2.42it/s]\u001b[A\n","Iteration:  52% 630/1211 [04:31<04:00,  2.41it/s]\u001b[A\n","Iteration:  52% 631/1211 [04:32<04:00,  2.42it/s]\u001b[A\n","Iteration:  52% 632/1211 [04:32<03:59,  2.41it/s]\u001b[A\n","Iteration:  52% 633/1211 [04:33<03:59,  2.41it/s]\u001b[A\n","Iteration:  52% 634/1211 [04:33<03:58,  2.41it/s]\u001b[A\n","Iteration:  52% 635/1211 [04:33<03:58,  2.42it/s]\u001b[A\n","Iteration:  53% 636/1211 [04:34<03:57,  2.42it/s]\u001b[A\n","Iteration:  53% 637/1211 [04:34<03:57,  2.41it/s]\u001b[A\n","Iteration:  53% 638/1211 [04:35<03:57,  2.41it/s]\u001b[A\n","Iteration:  53% 639/1211 [04:35<03:56,  2.42it/s]\u001b[A\n","Iteration:  53% 640/1211 [04:35<03:56,  2.42it/s]\u001b[A\n","Iteration:  53% 641/1211 [04:36<03:55,  2.42it/s]\u001b[A\n","Iteration:  53% 642/1211 [04:36<03:55,  2.41it/s]\u001b[A\n","Iteration:  53% 643/1211 [04:37<03:55,  2.41it/s]\u001b[A\n","Iteration:  53% 644/1211 [04:37<03:54,  2.42it/s]\u001b[A\n","Iteration:  53% 645/1211 [04:37<03:54,  2.42it/s]\u001b[A\n","Iteration:  53% 646/1211 [04:38<03:53,  2.42it/s]\u001b[A\n","Iteration:  53% 647/1211 [04:38<03:53,  2.42it/s]\u001b[A\n","Iteration:  54% 648/1211 [04:39<03:52,  2.42it/s]\u001b[A\n","Iteration:  54% 649/1211 [04:39<03:52,  2.42it/s]\u001b[A\n","Iteration:  54% 650/1211 [04:40<03:51,  2.42it/s]\u001b[A\n","Iteration:  54% 651/1211 [04:40<03:50,  2.42it/s]\u001b[A\n","Iteration:  54% 652/1211 [04:40<03:50,  2.42it/s]\u001b[A\n","Iteration:  54% 653/1211 [04:41<03:50,  2.42it/s]\u001b[A\n","Iteration:  54% 654/1211 [04:41<03:49,  2.42it/s]\u001b[A\n","Iteration:  54% 655/1211 [04:42<03:49,  2.42it/s]\u001b[A\n","Iteration:  54% 656/1211 [04:42<03:48,  2.43it/s]\u001b[A\n","Iteration:  54% 657/1211 [04:42<03:48,  2.42it/s]\u001b[A\n","Iteration:  54% 658/1211 [04:43<03:48,  2.42it/s]\u001b[A\n","Iteration:  54% 659/1211 [04:43<03:47,  2.42it/s]\u001b[A\n","Iteration:  55% 660/1211 [04:44<03:47,  2.42it/s]\u001b[A\n","Iteration:  55% 661/1211 [04:44<03:46,  2.42it/s]\u001b[A\n","Iteration:  55% 662/1211 [04:44<03:46,  2.42it/s]\u001b[A\n","Iteration:  55% 663/1211 [04:45<03:46,  2.42it/s]\u001b[A\n","Iteration:  55% 664/1211 [04:45<03:45,  2.42it/s]\u001b[A\n","Iteration:  55% 665/1211 [04:46<03:45,  2.42it/s]\u001b[A\n","Iteration:  55% 666/1211 [04:46<03:44,  2.43it/s]\u001b[A\n","Iteration:  55% 667/1211 [04:47<03:44,  2.42it/s]\u001b[A\n","Iteration:  55% 668/1211 [04:47<03:43,  2.42it/s]\u001b[A\n","Iteration:  55% 669/1211 [04:47<03:43,  2.43it/s]\u001b[A\n","Iteration:  55% 670/1211 [04:48<03:43,  2.43it/s]\u001b[A\n","Iteration:  55% 671/1211 [04:48<03:42,  2.42it/s]\u001b[A\n","Iteration:  55% 672/1211 [04:49<03:42,  2.42it/s]\u001b[A\n","Iteration:  56% 673/1211 [04:49<03:41,  2.43it/s]\u001b[A\n","Iteration:  56% 674/1211 [04:49<03:41,  2.43it/s]\u001b[A\n","Iteration:  56% 675/1211 [04:50<03:41,  2.43it/s]\u001b[A\n","Iteration:  56% 676/1211 [04:50<03:40,  2.43it/s]\u001b[A\n","Iteration:  56% 677/1211 [04:51<03:40,  2.43it/s]\u001b[A\n","Iteration:  56% 678/1211 [04:51<03:39,  2.43it/s]\u001b[A\n","Iteration:  56% 679/1211 [04:51<03:39,  2.42it/s]\u001b[A\n","Iteration:  56% 680/1211 [04:52<03:38,  2.42it/s]\u001b[A\n","Iteration:  56% 681/1211 [04:52<03:38,  2.43it/s]\u001b[A\n","Iteration:  56% 682/1211 [04:53<03:37,  2.43it/s]\u001b[A\n","Iteration:  56% 683/1211 [04:53<03:37,  2.43it/s]\u001b[A\n","Iteration:  56% 684/1211 [04:54<03:37,  2.43it/s]\u001b[A\n","Iteration:  57% 685/1211 [04:54<03:36,  2.43it/s]\u001b[A\n","Iteration:  57% 686/1211 [04:54<03:36,  2.43it/s]\u001b[A\n","Iteration:  57% 687/1211 [04:55<03:35,  2.43it/s]\u001b[A\n","Iteration:  57% 688/1211 [04:55<03:35,  2.43it/s]\u001b[A\n","Iteration:  57% 689/1211 [04:56<03:34,  2.43it/s]\u001b[A\n","Iteration:  57% 690/1211 [04:56<03:34,  2.43it/s]\u001b[A\n","Iteration:  57% 691/1211 [04:56<03:34,  2.43it/s]\u001b[A\n","Iteration:  57% 692/1211 [04:57<03:34,  2.42it/s]\u001b[A\n","Iteration:  57% 693/1211 [04:57<03:33,  2.42it/s]\u001b[A\n","Iteration:  57% 694/1211 [04:58<03:34,  2.42it/s]\u001b[A\n","Iteration:  57% 695/1211 [04:58<03:33,  2.42it/s]\u001b[A\n","Iteration:  57% 696/1211 [04:59<03:32,  2.42it/s]\u001b[A\n","Iteration:  58% 697/1211 [04:59<03:32,  2.42it/s]\u001b[A\n","Iteration:  58% 698/1211 [04:59<03:32,  2.41it/s]\u001b[A\n","Iteration:  58% 699/1211 [05:00<03:32,  2.40it/s]\u001b[A\n","Iteration:  58% 700/1211 [05:00<03:31,  2.41it/s]\u001b[A\n","Iteration:  58% 701/1211 [05:01<03:31,  2.41it/s]\u001b[A\n","Iteration:  58% 702/1211 [05:01<03:31,  2.41it/s]\u001b[A\n","Iteration:  58% 703/1211 [05:01<03:30,  2.42it/s]\u001b[A\n","Iteration:  58% 704/1211 [05:02<03:29,  2.42it/s]\u001b[A\n","Iteration:  58% 705/1211 [05:02<03:29,  2.42it/s]\u001b[A\n","Iteration:  58% 706/1211 [05:03<03:28,  2.42it/s]\u001b[A\n","Iteration:  58% 707/1211 [05:03<03:28,  2.42it/s]\u001b[A\n","Iteration:  58% 708/1211 [05:03<03:27,  2.42it/s]\u001b[A\n","Iteration:  59% 709/1211 [05:04<03:27,  2.42it/s]\u001b[A\n","Iteration:  59% 710/1211 [05:04<03:27,  2.42it/s]\u001b[A\n","Iteration:  59% 711/1211 [05:05<03:26,  2.42it/s]\u001b[A\n","Iteration:  59% 712/1211 [05:05<03:26,  2.42it/s]\u001b[A\n","Iteration:  59% 713/1211 [05:06<03:25,  2.42it/s]\u001b[A\n","Iteration:  59% 714/1211 [05:06<03:25,  2.42it/s]\u001b[A\n","Iteration:  59% 715/1211 [05:06<03:24,  2.42it/s]\u001b[A\n","Iteration:  59% 716/1211 [05:07<03:24,  2.42it/s]\u001b[A\n","Iteration:  59% 717/1211 [05:07<03:24,  2.42it/s]\u001b[A\n","Iteration:  59% 718/1211 [05:08<03:23,  2.42it/s]\u001b[A\n","Iteration:  59% 719/1211 [05:08<03:23,  2.42it/s]\u001b[A\n","Iteration:  59% 720/1211 [05:08<03:22,  2.42it/s]\u001b[A\n","Iteration:  60% 721/1211 [05:09<03:22,  2.42it/s]\u001b[A\n","Iteration:  60% 722/1211 [05:09<03:21,  2.42it/s]\u001b[A\n","Iteration:  60% 723/1211 [05:10<03:21,  2.42it/s]\u001b[A\n","Iteration:  60% 724/1211 [05:10<03:20,  2.42it/s]\u001b[A\n","Iteration:  60% 725/1211 [05:10<03:20,  2.43it/s]\u001b[A\n","Iteration:  60% 726/1211 [05:11<03:20,  2.42it/s]\u001b[A\n","Iteration:  60% 727/1211 [05:11<03:19,  2.42it/s]\u001b[A\n","Iteration:  60% 728/1211 [05:12<03:19,  2.42it/s]\u001b[A\n","Iteration:  60% 729/1211 [05:12<03:18,  2.43it/s]\u001b[A\n","Iteration:  60% 730/1211 [05:13<03:18,  2.43it/s]\u001b[A\n","Iteration:  60% 731/1211 [05:13<03:17,  2.43it/s]\u001b[A\n","Iteration:  60% 732/1211 [05:13<03:17,  2.43it/s]\u001b[A\n","Iteration:  61% 733/1211 [05:14<03:16,  2.43it/s]\u001b[A\n","Iteration:  61% 734/1211 [05:14<03:16,  2.42it/s]\u001b[A\n","Iteration:  61% 735/1211 [05:15<03:16,  2.42it/s]\u001b[A\n","Iteration:  61% 736/1211 [05:15<03:16,  2.42it/s]\u001b[A\n","Iteration:  61% 737/1211 [05:15<03:16,  2.42it/s]\u001b[A\n","Iteration:  61% 738/1211 [05:16<03:15,  2.42it/s]\u001b[A\n","Iteration:  61% 739/1211 [05:16<03:14,  2.42it/s]\u001b[A\n","Iteration:  61% 740/1211 [05:17<03:14,  2.42it/s]\u001b[A\n","Iteration:  61% 741/1211 [05:17<03:14,  2.42it/s]\u001b[A\n","Iteration:  61% 742/1211 [05:18<03:13,  2.42it/s]\u001b[A\n","Iteration:  61% 743/1211 [05:18<03:13,  2.42it/s]\u001b[A\n","Iteration:  61% 744/1211 [05:18<03:13,  2.42it/s]\u001b[A\n","Iteration:  62% 745/1211 [05:19<03:12,  2.42it/s]\u001b[A\n","Iteration:  62% 746/1211 [05:19<03:12,  2.41it/s]\u001b[A\n","Iteration:  62% 747/1211 [05:20<03:11,  2.42it/s]\u001b[A\n","Iteration:  62% 748/1211 [05:20<03:11,  2.42it/s]\u001b[A\n","Iteration:  62% 749/1211 [05:20<03:10,  2.42it/s]\u001b[A\n","Iteration:  62% 750/1211 [05:21<03:10,  2.41it/s]\u001b[A\n","Iteration:  62% 751/1211 [05:21<03:10,  2.41it/s]\u001b[A\n","Iteration:  62% 752/1211 [05:22<03:09,  2.42it/s]\u001b[A\n","Iteration:  62% 753/1211 [05:22<03:09,  2.42it/s]\u001b[A\n","Iteration:  62% 754/1211 [05:22<03:08,  2.42it/s]\u001b[A\n","Iteration:  62% 755/1211 [05:23<03:09,  2.41it/s]\u001b[A\n","Iteration:  62% 756/1211 [05:23<03:08,  2.42it/s]\u001b[A\n","Iteration:  63% 757/1211 [05:24<03:07,  2.42it/s]\u001b[A\n","Iteration:  63% 758/1211 [05:24<03:07,  2.42it/s]\u001b[A\n","Iteration:  63% 759/1211 [05:25<03:06,  2.42it/s]\u001b[A\n","Iteration:  63% 760/1211 [05:25<03:06,  2.42it/s]\u001b[A\n","Iteration:  63% 761/1211 [05:25<03:05,  2.42it/s]\u001b[A\n","Iteration:  63% 762/1211 [05:26<03:05,  2.42it/s]\u001b[A\n","Iteration:  63% 763/1211 [05:26<03:04,  2.42it/s]\u001b[A\n","Iteration:  63% 764/1211 [05:27<03:04,  2.42it/s]\u001b[A\n","Iteration:  63% 765/1211 [05:27<03:03,  2.42it/s]\u001b[A\n","Iteration:  63% 766/1211 [05:27<03:03,  2.43it/s]\u001b[A\n","Iteration:  63% 767/1211 [05:28<03:02,  2.43it/s]\u001b[A\n","Iteration:  63% 768/1211 [05:28<03:02,  2.43it/s]\u001b[A\n","Iteration:  64% 769/1211 [05:29<03:02,  2.43it/s]\u001b[A\n","Iteration:  64% 770/1211 [05:29<03:01,  2.43it/s]\u001b[A\n","Iteration:  64% 771/1211 [05:29<03:01,  2.42it/s]\u001b[A\n","Iteration:  64% 772/1211 [05:30<03:00,  2.43it/s]\u001b[A\n","Iteration:  64% 773/1211 [05:30<03:00,  2.43it/s]\u001b[A\n","Iteration:  64% 774/1211 [05:31<02:59,  2.43it/s]\u001b[A\n","Iteration:  64% 775/1211 [05:31<02:59,  2.43it/s]\u001b[A\n","Iteration:  64% 776/1211 [05:32<02:59,  2.43it/s]\u001b[A\n","Iteration:  64% 777/1211 [05:32<02:58,  2.43it/s]\u001b[A\n","Iteration:  64% 778/1211 [05:32<02:58,  2.42it/s]\u001b[A\n","Iteration:  64% 779/1211 [05:33<02:58,  2.42it/s]\u001b[A\n","Iteration:  64% 780/1211 [05:33<02:57,  2.42it/s]\u001b[A\n","Iteration:  64% 781/1211 [05:34<02:57,  2.42it/s]\u001b[A\n","Iteration:  65% 782/1211 [05:34<02:57,  2.42it/s]\u001b[A\n","Iteration:  65% 783/1211 [05:34<02:56,  2.42it/s]\u001b[A\n","Iteration:  65% 784/1211 [05:35<02:56,  2.43it/s]\u001b[A\n","Iteration:  65% 785/1211 [05:35<02:55,  2.43it/s]\u001b[A\n","Iteration:  65% 786/1211 [05:36<02:55,  2.43it/s]\u001b[A\n","Iteration:  65% 787/1211 [05:36<02:54,  2.43it/s]\u001b[A\n","Iteration:  65% 788/1211 [05:36<02:53,  2.43it/s]\u001b[A\n","Iteration:  65% 789/1211 [05:37<02:53,  2.43it/s]\u001b[A\n","Iteration:  65% 790/1211 [05:37<02:53,  2.43it/s]\u001b[A\n","Iteration:  65% 791/1211 [05:38<02:53,  2.43it/s]\u001b[A\n","Iteration:  65% 792/1211 [05:38<02:52,  2.43it/s]\u001b[A\n","Iteration:  65% 793/1211 [05:39<02:52,  2.43it/s]\u001b[A\n","Iteration:  66% 794/1211 [05:39<02:51,  2.43it/s]\u001b[A\n","Iteration:  66% 795/1211 [05:39<02:51,  2.43it/s]\u001b[A\n","Iteration:  66% 796/1211 [05:40<02:51,  2.43it/s]\u001b[A\n","Iteration:  66% 797/1211 [05:40<02:50,  2.43it/s]\u001b[A\n","Iteration:  66% 798/1211 [05:41<02:50,  2.42it/s]\u001b[A\n","Iteration:  66% 799/1211 [05:41<02:50,  2.41it/s]\u001b[A\n","Iteration:  66% 800/1211 [05:41<02:49,  2.42it/s]\u001b[A\n","Iteration:  66% 801/1211 [05:42<02:49,  2.42it/s]\u001b[A\n","Iteration:  66% 802/1211 [05:42<02:48,  2.42it/s]\u001b[A\n","Iteration:  66% 803/1211 [05:43<02:49,  2.41it/s]\u001b[A\n","Iteration:  66% 804/1211 [05:43<02:49,  2.41it/s]\u001b[A\n","Iteration:  66% 805/1211 [05:44<02:48,  2.41it/s]\u001b[A\n","Iteration:  67% 806/1211 [05:44<02:47,  2.41it/s]\u001b[A\n","Iteration:  67% 807/1211 [05:44<02:46,  2.42it/s]\u001b[A\n","Iteration:  67% 808/1211 [05:45<02:46,  2.42it/s]\u001b[A\n","Iteration:  67% 809/1211 [05:45<02:46,  2.42it/s]\u001b[A\n","Iteration:  67% 810/1211 [05:46<02:45,  2.42it/s]\u001b[A\n","Iteration:  67% 811/1211 [05:46<02:45,  2.42it/s]\u001b[A\n","Iteration:  67% 812/1211 [05:46<02:44,  2.42it/s]\u001b[A\n","Iteration:  67% 813/1211 [05:47<02:43,  2.43it/s]\u001b[A\n","Iteration:  67% 814/1211 [05:47<02:43,  2.43it/s]\u001b[A\n","Iteration:  67% 815/1211 [05:48<02:43,  2.43it/s]\u001b[A\n","Iteration:  67% 816/1211 [05:48<02:42,  2.43it/s]\u001b[A\n","Iteration:  67% 817/1211 [05:48<02:42,  2.43it/s]\u001b[A\n","Iteration:  68% 818/1211 [05:49<02:41,  2.43it/s]\u001b[A\n","Iteration:  68% 819/1211 [05:49<02:41,  2.43it/s]\u001b[A\n","Iteration:  68% 820/1211 [05:50<02:40,  2.43it/s]\u001b[A\n","Iteration:  68% 821/1211 [05:50<02:40,  2.43it/s]\u001b[A\n","Iteration:  68% 822/1211 [05:51<02:40,  2.43it/s]\u001b[A\n","Iteration:  68% 823/1211 [05:51<02:39,  2.43it/s]\u001b[A\n","Iteration:  68% 824/1211 [05:51<02:39,  2.43it/s]\u001b[A\n","Iteration:  68% 825/1211 [05:52<02:38,  2.43it/s]\u001b[A\n","Iteration:  68% 826/1211 [05:52<02:38,  2.43it/s]\u001b[A\n","Iteration:  68% 827/1211 [05:53<02:38,  2.43it/s]\u001b[A\n","Iteration:  68% 828/1211 [05:53<02:37,  2.43it/s]\u001b[A\n","Iteration:  68% 829/1211 [05:53<02:37,  2.43it/s]\u001b[A\n","Iteration:  69% 830/1211 [05:54<02:36,  2.43it/s]\u001b[A\n","Iteration:  69% 831/1211 [05:54<02:36,  2.42it/s]\u001b[A\n","Iteration:  69% 832/1211 [05:55<02:36,  2.42it/s]\u001b[A\n","Iteration:  69% 833/1211 [05:55<02:35,  2.42it/s]\u001b[A\n","Iteration:  69% 834/1211 [05:55<02:35,  2.42it/s]\u001b[A\n","Iteration:  69% 835/1211 [05:56<02:35,  2.42it/s]\u001b[A\n","Iteration:  69% 836/1211 [05:56<02:34,  2.42it/s]\u001b[A\n","Iteration:  69% 837/1211 [05:57<02:34,  2.43it/s]\u001b[A\n","Iteration:  69% 838/1211 [05:57<02:33,  2.43it/s]\u001b[A\n","Iteration:  69% 839/1211 [05:58<02:33,  2.43it/s]\u001b[A\n","Iteration:  69% 840/1211 [05:58<02:33,  2.42it/s]\u001b[A\n","Iteration:  69% 841/1211 [05:58<02:32,  2.42it/s]\u001b[A\n","Iteration:  70% 842/1211 [05:59<02:32,  2.42it/s]\u001b[A\n","Iteration:  70% 843/1211 [05:59<02:32,  2.42it/s]\u001b[A\n","Iteration:  70% 844/1211 [06:00<02:31,  2.42it/s]\u001b[A\n","Iteration:  70% 845/1211 [06:00<02:31,  2.42it/s]\u001b[A\n","Iteration:  70% 846/1211 [06:00<02:30,  2.42it/s]\u001b[A\n","Iteration:  70% 847/1211 [06:01<02:30,  2.43it/s]\u001b[A\n","Iteration:  70% 848/1211 [06:01<02:29,  2.43it/s]\u001b[A\n","Iteration:  70% 849/1211 [06:02<02:29,  2.43it/s]\u001b[A\n","Iteration:  70% 850/1211 [06:02<02:28,  2.43it/s]\u001b[A\n","Iteration:  70% 851/1211 [06:02<02:28,  2.43it/s]\u001b[A\n","Iteration:  70% 852/1211 [06:03<02:28,  2.42it/s]\u001b[A\n","Iteration:  70% 853/1211 [06:03<02:27,  2.42it/s]\u001b[A\n","Iteration:  71% 854/1211 [06:04<02:27,  2.42it/s]\u001b[A\n","Iteration:  71% 855/1211 [06:04<02:26,  2.42it/s]\u001b[A\n","Iteration:  71% 856/1211 [06:05<02:26,  2.42it/s]\u001b[A\n","Iteration:  71% 857/1211 [06:05<02:26,  2.42it/s]\u001b[A\n","Iteration:  71% 858/1211 [06:05<02:26,  2.41it/s]\u001b[A\n","Iteration:  71% 859/1211 [06:06<02:26,  2.41it/s]\u001b[A\n","Iteration:  71% 860/1211 [06:06<02:25,  2.40it/s]\u001b[A\n","Iteration:  71% 861/1211 [06:07<02:25,  2.40it/s]\u001b[A\n","Iteration:  71% 862/1211 [06:07<02:25,  2.41it/s]\u001b[A\n","Iteration:  71% 863/1211 [06:07<02:24,  2.41it/s]\u001b[A\n","Iteration:  71% 864/1211 [06:08<02:23,  2.42it/s]\u001b[A\n","Iteration:  71% 865/1211 [06:08<02:23,  2.41it/s]\u001b[A\n","Iteration:  72% 866/1211 [06:09<02:23,  2.41it/s]\u001b[A\n","Iteration:  72% 867/1211 [06:09<02:22,  2.41it/s]\u001b[A\n","Iteration:  72% 868/1211 [06:10<02:22,  2.41it/s]\u001b[A\n","Iteration:  72% 869/1211 [06:10<02:21,  2.42it/s]\u001b[A\n","Iteration:  72% 870/1211 [06:10<02:21,  2.41it/s]\u001b[A\n","Iteration:  72% 871/1211 [06:11<02:20,  2.41it/s]\u001b[A\n","Iteration:  72% 872/1211 [06:11<02:20,  2.41it/s]\u001b[A\n","Iteration:  72% 873/1211 [06:12<02:19,  2.42it/s]\u001b[A\n","Iteration:  72% 874/1211 [06:12<02:19,  2.42it/s]\u001b[A\n","Iteration:  72% 875/1211 [06:12<02:18,  2.42it/s]\u001b[A\n","Iteration:  72% 876/1211 [06:13<02:18,  2.42it/s]\u001b[A\n","Iteration:  72% 877/1211 [06:13<02:18,  2.42it/s]\u001b[A\n","Iteration:  73% 878/1211 [06:14<02:17,  2.42it/s]\u001b[A\n","Iteration:  73% 879/1211 [06:14<02:17,  2.42it/s]\u001b[A\n","Iteration:  73% 880/1211 [06:14<02:17,  2.41it/s]\u001b[A\n","Iteration:  73% 881/1211 [06:15<02:16,  2.41it/s]\u001b[A\n","Iteration:  73% 882/1211 [06:15<02:16,  2.41it/s]\u001b[A\n","Iteration:  73% 883/1211 [06:16<02:15,  2.41it/s]\u001b[A\n","Iteration:  73% 884/1211 [06:16<02:15,  2.41it/s]\u001b[A\n","Iteration:  73% 885/1211 [06:17<02:15,  2.41it/s]\u001b[A\n","Iteration:  73% 886/1211 [06:17<02:14,  2.41it/s]\u001b[A\n","Iteration:  73% 887/1211 [06:17<02:14,  2.41it/s]\u001b[A\n","Iteration:  73% 888/1211 [06:18<02:13,  2.41it/s]\u001b[A\n","Iteration:  73% 889/1211 [06:18<02:13,  2.41it/s]\u001b[A\n","Iteration:  73% 890/1211 [06:19<02:12,  2.41it/s]\u001b[A\n","Iteration:  74% 891/1211 [06:19<02:12,  2.42it/s]\u001b[A\n","Iteration:  74% 892/1211 [06:19<02:12,  2.42it/s]\u001b[A\n","Iteration:  74% 893/1211 [06:20<02:11,  2.41it/s]\u001b[A\n","Iteration:  74% 894/1211 [06:20<02:11,  2.42it/s]\u001b[A\n","Iteration:  74% 895/1211 [06:21<02:11,  2.41it/s]\u001b[A\n","Iteration:  74% 896/1211 [06:21<02:10,  2.41it/s]\u001b[A\n","Iteration:  74% 897/1211 [06:22<02:09,  2.42it/s]\u001b[A\n","Iteration:  74% 898/1211 [06:22<02:09,  2.41it/s]\u001b[A\n","Iteration:  74% 899/1211 [06:22<02:09,  2.42it/s]\u001b[A\n","Iteration:  74% 900/1211 [06:23<02:08,  2.42it/s]\u001b[A\n","Iteration:  74% 901/1211 [06:23<02:08,  2.42it/s]\u001b[A\n","Iteration:  74% 902/1211 [06:24<02:08,  2.41it/s]\u001b[A\n","Iteration:  75% 903/1211 [06:24<02:07,  2.41it/s]\u001b[A\n","Iteration:  75% 904/1211 [06:24<02:06,  2.42it/s]\u001b[A\n","Iteration:  75% 905/1211 [06:25<02:06,  2.42it/s]\u001b[A\n","Iteration:  75% 906/1211 [06:25<02:05,  2.42it/s]\u001b[A\n","Iteration:  75% 907/1211 [06:26<02:05,  2.41it/s]\u001b[A\n","Iteration:  75% 908/1211 [06:26<02:05,  2.42it/s]\u001b[A\n","Iteration:  75% 909/1211 [06:26<02:04,  2.42it/s]\u001b[A\n","Iteration:  75% 910/1211 [06:27<02:04,  2.42it/s]\u001b[A\n","Iteration:  75% 911/1211 [06:27<02:03,  2.42it/s]\u001b[A\n","Iteration:  75% 912/1211 [06:28<02:03,  2.42it/s]\u001b[A\n","Iteration:  75% 913/1211 [06:28<02:03,  2.42it/s]\u001b[A\n","Iteration:  75% 914/1211 [06:29<02:02,  2.42it/s]\u001b[A\n","Iteration:  76% 915/1211 [06:29<02:02,  2.42it/s]\u001b[A\n","Iteration:  76% 916/1211 [06:29<02:01,  2.42it/s]\u001b[A\n","Iteration:  76% 917/1211 [06:30<02:01,  2.42it/s]\u001b[A\n","Iteration:  76% 918/1211 [06:30<02:01,  2.42it/s]\u001b[A\n","Iteration:  76% 919/1211 [06:31<02:00,  2.42it/s]\u001b[A\n","Iteration:  76% 920/1211 [06:31<02:00,  2.42it/s]\u001b[A\n","Iteration:  76% 921/1211 [06:31<01:59,  2.43it/s]\u001b[A\n","Iteration:  76% 922/1211 [06:32<01:59,  2.43it/s]\u001b[A\n","Iteration:  76% 923/1211 [06:32<01:58,  2.42it/s]\u001b[A\n","Iteration:  76% 924/1211 [06:33<01:58,  2.42it/s]\u001b[A\n","Iteration:  76% 925/1211 [06:33<01:58,  2.42it/s]\u001b[A\n","Iteration:  76% 926/1211 [06:34<01:57,  2.42it/s]\u001b[A\n","Iteration:  77% 927/1211 [06:34<01:57,  2.42it/s]\u001b[A\n","Iteration:  77% 928/1211 [06:34<01:57,  2.42it/s]\u001b[A\n","Iteration:  77% 929/1211 [06:35<01:56,  2.42it/s]\u001b[A\n","Iteration:  77% 930/1211 [06:35<01:56,  2.42it/s]\u001b[A\n","Iteration:  77% 931/1211 [06:36<01:55,  2.42it/s]\u001b[A\n","Iteration:  77% 932/1211 [06:36<01:55,  2.41it/s]\u001b[A\n","Iteration:  77% 933/1211 [06:36<01:54,  2.42it/s]\u001b[A\n","Iteration:  77% 934/1211 [06:37<01:54,  2.42it/s]\u001b[A\n","Iteration:  77% 935/1211 [06:37<01:54,  2.42it/s]\u001b[A\n","Iteration:  77% 936/1211 [06:38<01:53,  2.42it/s]\u001b[A\n","Iteration:  77% 937/1211 [06:38<01:53,  2.42it/s]\u001b[A\n","Iteration:  77% 938/1211 [06:38<01:53,  2.42it/s]\u001b[A\n","Iteration:  78% 939/1211 [06:39<01:52,  2.42it/s]\u001b[A\n","Iteration:  78% 940/1211 [06:39<01:52,  2.41it/s]\u001b[A\n","Iteration:  78% 941/1211 [06:40<01:51,  2.42it/s]\u001b[A\n","Iteration:  78% 942/1211 [06:40<01:51,  2.42it/s]\u001b[A\n","Iteration:  78% 943/1211 [06:41<01:50,  2.42it/s]\u001b[A\n","Iteration:  78% 944/1211 [06:41<01:50,  2.42it/s]\u001b[A\n","Iteration:  78% 945/1211 [06:41<01:49,  2.42it/s]\u001b[A\n","Iteration:  78% 946/1211 [06:42<01:49,  2.42it/s]\u001b[A\n","Iteration:  78% 947/1211 [06:42<01:49,  2.42it/s]\u001b[A\n","Iteration:  78% 948/1211 [06:43<01:48,  2.42it/s]\u001b[A\n","Iteration:  78% 949/1211 [06:43<01:48,  2.42it/s]\u001b[A\n","Iteration:  78% 950/1211 [06:43<01:47,  2.42it/s]\u001b[A\n","Iteration:  79% 951/1211 [06:44<01:47,  2.42it/s]\u001b[A\n","Iteration:  79% 952/1211 [06:44<01:46,  2.42it/s]\u001b[A\n","Iteration:  79% 953/1211 [06:45<01:46,  2.42it/s]\u001b[A\n","Iteration:  79% 954/1211 [06:45<01:46,  2.41it/s]\u001b[A\n","Iteration:  79% 955/1211 [06:46<01:46,  2.41it/s]\u001b[A\n","Iteration:  79% 956/1211 [06:46<01:45,  2.42it/s]\u001b[A\n","Iteration:  79% 957/1211 [06:46<01:45,  2.42it/s]\u001b[A\n","Iteration:  79% 958/1211 [06:47<01:44,  2.42it/s]\u001b[A\n","Iteration:  79% 959/1211 [06:47<01:44,  2.41it/s]\u001b[A\n","Iteration:  79% 960/1211 [06:48<01:43,  2.42it/s]\u001b[A\n","Iteration:  79% 961/1211 [06:48<01:43,  2.42it/s]\u001b[A\n","Iteration:  79% 962/1211 [06:48<01:42,  2.42it/s]\u001b[A\n","Iteration:  80% 963/1211 [06:49<01:42,  2.42it/s]\u001b[A\n","Iteration:  80% 964/1211 [06:49<01:41,  2.42it/s]\u001b[A\n","Iteration:  80% 965/1211 [06:50<01:41,  2.42it/s]\u001b[A\n","Iteration:  80% 966/1211 [06:50<01:41,  2.42it/s]\u001b[A\n","Iteration:  80% 967/1211 [06:50<01:40,  2.42it/s]\u001b[A\n","Iteration:  80% 968/1211 [06:51<01:41,  2.41it/s]\u001b[A\n","Iteration:  80% 969/1211 [06:51<01:40,  2.41it/s]\u001b[A\n","Iteration:  80% 970/1211 [06:52<01:39,  2.41it/s]\u001b[A\n","Iteration:  80% 971/1211 [06:52<01:39,  2.42it/s]\u001b[A\n","Iteration:  80% 972/1211 [06:53<01:38,  2.42it/s]\u001b[A\n","Iteration:  80% 973/1211 [06:53<01:38,  2.41it/s]\u001b[A\n","Iteration:  80% 974/1211 [06:53<01:38,  2.42it/s]\u001b[A\n","Iteration:  81% 975/1211 [06:54<01:37,  2.42it/s]\u001b[A\n","Iteration:  81% 976/1211 [06:54<01:37,  2.42it/s]\u001b[A\n","Iteration:  81% 977/1211 [06:55<01:36,  2.42it/s]\u001b[A\n","Iteration:  81% 978/1211 [06:55<01:36,  2.43it/s]\u001b[A\n","Iteration:  81% 979/1211 [06:55<01:35,  2.43it/s]\u001b[A\n","Iteration:  81% 980/1211 [06:56<01:35,  2.43it/s]\u001b[A\n","Iteration:  81% 981/1211 [06:56<01:34,  2.43it/s]\u001b[A\n","Iteration:  81% 982/1211 [06:57<01:34,  2.43it/s]\u001b[A\n","Iteration:  81% 983/1211 [06:57<01:34,  2.42it/s]\u001b[A\n","Iteration:  81% 984/1211 [06:57<01:33,  2.43it/s]\u001b[A\n","Iteration:  81% 985/1211 [06:58<01:33,  2.42it/s]\u001b[A\n","Iteration:  81% 986/1211 [06:58<01:32,  2.43it/s]\u001b[A\n","Iteration:  82% 987/1211 [06:59<01:32,  2.43it/s]\u001b[A\n","Iteration:  82% 988/1211 [06:59<01:31,  2.43it/s]\u001b[A\n","Iteration:  82% 989/1211 [07:00<01:31,  2.42it/s]\u001b[A\n","Iteration:  82% 990/1211 [07:00<01:31,  2.42it/s]\u001b[A\n","Iteration:  82% 991/1211 [07:00<01:30,  2.42it/s]\u001b[A\n","Iteration:  82% 992/1211 [07:01<01:30,  2.42it/s]\u001b[A\n","Iteration:  82% 993/1211 [07:01<01:30,  2.42it/s]\u001b[A\n","Iteration:  82% 994/1211 [07:02<01:29,  2.41it/s]\u001b[A\n","Iteration:  82% 995/1211 [07:02<01:29,  2.40it/s]\u001b[A\n","Iteration:  82% 996/1211 [07:02<01:29,  2.40it/s]\u001b[A\n","Iteration:  82% 997/1211 [07:03<01:28,  2.41it/s]\u001b[A\n","Iteration:  82% 998/1211 [07:03<01:28,  2.42it/s]\u001b[A\n","Iteration:  82% 999/1211 [07:04<01:27,  2.42it/s]\u001b[A04/30/2020 11:23:42 - INFO - transformers.configuration_utils -   Configuration saved in output/checkpoint-1000/config.json\n","04/30/2020 11:23:43 - INFO - transformers.modeling_utils -   Model weights saved in output/checkpoint-1000/pytorch_model.bin\n","04/30/2020 11:23:43 - INFO - __main__ -   Saving model checkpoint to output/checkpoint-1000\n","04/30/2020 11:23:53 - INFO - __main__ -   Saving optimizer and scheduler states to output/checkpoint-1000\n","\n","Iteration:  83% 1000/1211 [07:15<12:54,  3.67s/it]\u001b[A\n","Iteration:  83% 1001/1211 [07:15<09:27,  2.70s/it]\u001b[A\n","Iteration:  83% 1002/1211 [07:16<07:00,  2.01s/it]\u001b[A\n","Iteration:  83% 1003/1211 [07:16<05:18,  1.53s/it]\u001b[A\n","Iteration:  83% 1004/1211 [07:17<04:07,  1.20s/it]\u001b[A\n","Iteration:  83% 1005/1211 [07:17<03:18,  1.04it/s]\u001b[A\n","Iteration:  83% 1006/1211 [07:17<02:43,  1.25it/s]\u001b[A\n","Iteration:  83% 1007/1211 [07:18<02:19,  1.46it/s]\u001b[A\n","Iteration:  83% 1008/1211 [07:18<02:02,  1.66it/s]\u001b[A\n","Iteration:  83% 1009/1211 [07:19<01:50,  1.83it/s]\u001b[A\n","Iteration:  83% 1010/1211 [07:19<01:41,  1.98it/s]\u001b[A\n","Iteration:  83% 1011/1211 [07:20<01:35,  2.09it/s]\u001b[A\n","Iteration:  84% 1012/1211 [07:20<01:31,  2.18it/s]\u001b[A\n","Iteration:  84% 1013/1211 [07:20<01:28,  2.25it/s]\u001b[A\n","Iteration:  84% 1014/1211 [07:21<01:25,  2.30it/s]\u001b[A\n","Iteration:  84% 1015/1211 [07:21<01:24,  2.33it/s]\u001b[A\n","Iteration:  84% 1016/1211 [07:22<01:22,  2.36it/s]\u001b[A\n","Iteration:  84% 1017/1211 [07:22<01:22,  2.36it/s]\u001b[A\n","Iteration:  84% 1018/1211 [07:22<01:21,  2.37it/s]\u001b[A\n","Iteration:  84% 1019/1211 [07:23<01:20,  2.38it/s]\u001b[A\n","Iteration:  84% 1020/1211 [07:23<01:19,  2.40it/s]\u001b[A\n","Iteration:  84% 1021/1211 [07:24<01:19,  2.40it/s]\u001b[A\n","Iteration:  84% 1022/1211 [07:24<01:18,  2.40it/s]\u001b[A\n","Iteration:  84% 1023/1211 [07:25<01:17,  2.41it/s]\u001b[A\n","Iteration:  85% 1024/1211 [07:25<01:17,  2.41it/s]\u001b[A\n","Iteration:  85% 1025/1211 [07:25<01:17,  2.41it/s]\u001b[A\n","Iteration:  85% 1026/1211 [07:26<01:16,  2.42it/s]\u001b[A\n","Iteration:  85% 1027/1211 [07:26<01:16,  2.42it/s]\u001b[A\n","Iteration:  85% 1028/1211 [07:27<01:15,  2.42it/s]\u001b[A\n","Iteration:  85% 1029/1211 [07:27<01:15,  2.42it/s]\u001b[A\n","Iteration:  85% 1030/1211 [07:27<01:14,  2.43it/s]\u001b[A\n","Iteration:  85% 1031/1211 [07:28<01:14,  2.43it/s]\u001b[A\n","Iteration:  85% 1032/1211 [07:28<01:13,  2.42it/s]\u001b[A\n","Iteration:  85% 1033/1211 [07:29<01:13,  2.42it/s]\u001b[A\n","Iteration:  85% 1034/1211 [07:29<01:12,  2.43it/s]\u001b[A\n","Iteration:  85% 1035/1211 [07:29<01:12,  2.42it/s]\u001b[A\n","Iteration:  86% 1036/1211 [07:30<01:12,  2.42it/s]\u001b[A\n","Iteration:  86% 1037/1211 [07:30<01:11,  2.43it/s]\u001b[A\n","Iteration:  86% 1038/1211 [07:31<01:11,  2.42it/s]\u001b[A\n","Iteration:  86% 1039/1211 [07:31<01:10,  2.42it/s]\u001b[A\n","Iteration:  86% 1040/1211 [07:32<01:10,  2.43it/s]\u001b[A\n","Iteration:  86% 1041/1211 [07:32<01:10,  2.42it/s]\u001b[A\n","Iteration:  86% 1042/1211 [07:32<01:09,  2.42it/s]\u001b[A\n","Iteration:  86% 1043/1211 [07:33<01:09,  2.43it/s]\u001b[A\n","Iteration:  86% 1044/1211 [07:33<01:08,  2.43it/s]\u001b[A\n","Iteration:  86% 1045/1211 [07:34<01:08,  2.42it/s]\u001b[A\n","Iteration:  86% 1046/1211 [07:34<01:08,  2.42it/s]\u001b[A\n","Iteration:  86% 1047/1211 [07:34<01:07,  2.43it/s]\u001b[A\n","Iteration:  87% 1048/1211 [07:35<01:07,  2.43it/s]\u001b[A\n","Iteration:  87% 1049/1211 [07:35<01:06,  2.43it/s]\u001b[A\n","Iteration:  87% 1050/1211 [07:36<01:06,  2.43it/s]\u001b[A\n","Iteration:  87% 1051/1211 [07:36<01:05,  2.43it/s]\u001b[A\n","Iteration:  87% 1052/1211 [07:36<01:05,  2.42it/s]\u001b[A\n","Iteration:  87% 1053/1211 [07:37<01:05,  2.42it/s]\u001b[A\n","Iteration:  87% 1054/1211 [07:37<01:04,  2.42it/s]\u001b[A\n","Iteration:  87% 1055/1211 [07:38<01:04,  2.42it/s]\u001b[A\n","Iteration:  87% 1056/1211 [07:38<01:03,  2.42it/s]\u001b[A\n","Iteration:  87% 1057/1211 [07:39<01:03,  2.42it/s]\u001b[A\n","Iteration:  87% 1058/1211 [07:39<01:03,  2.42it/s]\u001b[A\n","Iteration:  87% 1059/1211 [07:39<01:02,  2.43it/s]\u001b[A\n","Iteration:  88% 1060/1211 [07:40<01:02,  2.43it/s]\u001b[A\n","Iteration:  88% 1061/1211 [07:40<01:01,  2.43it/s]\u001b[A\n","Iteration:  88% 1062/1211 [07:41<01:01,  2.42it/s]\u001b[A\n","Iteration:  88% 1063/1211 [07:41<01:01,  2.42it/s]\u001b[A\n","Iteration:  88% 1064/1211 [07:41<01:00,  2.43it/s]\u001b[A\n","Iteration:  88% 1065/1211 [07:42<01:00,  2.42it/s]\u001b[A\n","Iteration:  88% 1066/1211 [07:42<00:59,  2.42it/s]\u001b[A\n","Iteration:  88% 1067/1211 [07:43<00:59,  2.42it/s]\u001b[A\n","Iteration:  88% 1068/1211 [07:43<00:59,  2.42it/s]\u001b[A\n","Iteration:  88% 1069/1211 [07:43<00:58,  2.42it/s]\u001b[A\n","Iteration:  88% 1070/1211 [07:44<00:58,  2.42it/s]\u001b[A\n","Iteration:  88% 1071/1211 [07:44<00:57,  2.42it/s]\u001b[A\n","Iteration:  89% 1072/1211 [07:45<00:57,  2.42it/s]\u001b[A\n","Iteration:  89% 1073/1211 [07:45<00:57,  2.42it/s]\u001b[A\n","Iteration:  89% 1074/1211 [07:46<00:56,  2.41it/s]\u001b[A\n","Iteration:  89% 1075/1211 [07:46<00:56,  2.42it/s]\u001b[A\n","Iteration:  89% 1076/1211 [07:46<00:55,  2.42it/s]\u001b[A\n","Iteration:  89% 1077/1211 [07:47<00:55,  2.42it/s]\u001b[A\n","Iteration:  89% 1078/1211 [07:47<00:54,  2.42it/s]\u001b[A\n","Iteration:  89% 1079/1211 [07:48<00:54,  2.42it/s]\u001b[A\n","Iteration:  89% 1080/1211 [07:48<00:54,  2.42it/s]\u001b[A\n","Iteration:  89% 1081/1211 [07:48<00:53,  2.42it/s]\u001b[A\n","Iteration:  89% 1082/1211 [07:49<00:53,  2.42it/s]\u001b[A\n","Iteration:  89% 1083/1211 [07:49<00:52,  2.42it/s]\u001b[A\n","Iteration:  90% 1084/1211 [07:50<00:52,  2.42it/s]\u001b[A\n","Iteration:  90% 1085/1211 [07:50<00:52,  2.42it/s]\u001b[A\n","Iteration:  90% 1086/1211 [07:51<00:51,  2.42it/s]\u001b[A\n","Iteration:  90% 1087/1211 [07:51<00:51,  2.42it/s]\u001b[A\n","Iteration:  90% 1088/1211 [07:51<00:50,  2.42it/s]\u001b[A\n","Iteration:  90% 1089/1211 [07:52<00:50,  2.42it/s]\u001b[A\n","Iteration:  90% 1090/1211 [07:52<00:49,  2.42it/s]\u001b[A\n","Iteration:  90% 1091/1211 [07:53<00:49,  2.42it/s]\u001b[A\n","Iteration:  90% 1092/1211 [07:53<00:49,  2.42it/s]\u001b[A\n","Iteration:  90% 1093/1211 [07:53<00:48,  2.42it/s]\u001b[A\n","Iteration:  90% 1094/1211 [07:54<00:48,  2.42it/s]\u001b[A\n","Iteration:  90% 1095/1211 [07:54<00:47,  2.42it/s]\u001b[A\n","Iteration:  91% 1096/1211 [07:55<00:47,  2.42it/s]\u001b[A\n","Iteration:  91% 1097/1211 [07:55<00:47,  2.42it/s]\u001b[A\n","Iteration:  91% 1098/1211 [07:55<00:46,  2.42it/s]\u001b[A\n","Iteration:  91% 1099/1211 [07:56<00:46,  2.42it/s]\u001b[A\n","Iteration:  91% 1100/1211 [07:56<00:45,  2.42it/s]\u001b[A\n","Iteration:  91% 1101/1211 [07:57<00:45,  2.43it/s]\u001b[A\n","Iteration:  91% 1102/1211 [07:57<00:44,  2.43it/s]\u001b[A\n","Iteration:  91% 1103/1211 [07:58<00:44,  2.43it/s]\u001b[A\n","Iteration:  91% 1104/1211 [07:58<00:44,  2.42it/s]\u001b[A\n","Iteration:  91% 1105/1211 [07:58<00:43,  2.43it/s]\u001b[A\n","Iteration:  91% 1106/1211 [07:59<00:43,  2.42it/s]\u001b[A\n","Iteration:  91% 1107/1211 [07:59<00:42,  2.43it/s]\u001b[A\n","Iteration:  91% 1108/1211 [08:00<00:42,  2.42it/s]\u001b[A\n","Iteration:  92% 1109/1211 [08:00<00:42,  2.42it/s]\u001b[A\n","Iteration:  92% 1110/1211 [08:00<00:41,  2.42it/s]\u001b[A\n","Iteration:  92% 1111/1211 [08:01<00:41,  2.42it/s]\u001b[A\n","Iteration:  92% 1112/1211 [08:01<00:40,  2.43it/s]\u001b[A\n","Iteration:  92% 1113/1211 [08:02<00:40,  2.43it/s]\u001b[A\n","Iteration:  92% 1114/1211 [08:02<00:40,  2.42it/s]\u001b[A\n","Iteration:  92% 1115/1211 [08:02<00:39,  2.42it/s]\u001b[A\n","Iteration:  92% 1116/1211 [08:03<00:39,  2.42it/s]\u001b[A\n","Iteration:  92% 1117/1211 [08:03<00:38,  2.42it/s]\u001b[A\n","Iteration:  92% 1118/1211 [08:04<00:38,  2.42it/s]\u001b[A\n","Iteration:  92% 1119/1211 [08:04<00:38,  2.42it/s]\u001b[A\n","Iteration:  92% 1120/1211 [08:05<00:37,  2.42it/s]\u001b[A\n","Iteration:  93% 1121/1211 [08:05<00:37,  2.41it/s]\u001b[A\n","Iteration:  93% 1122/1211 [08:05<00:36,  2.41it/s]\u001b[A\n","Iteration:  93% 1123/1211 [08:06<00:36,  2.42it/s]\u001b[A\n","Iteration:  93% 1124/1211 [08:06<00:35,  2.43it/s]\u001b[A\n","Iteration:  93% 1125/1211 [08:07<00:35,  2.43it/s]\u001b[A\n","Iteration:  93% 1126/1211 [08:07<00:35,  2.42it/s]\u001b[A\n","Iteration:  93% 1127/1211 [08:07<00:34,  2.42it/s]\u001b[A\n","Iteration:  93% 1128/1211 [08:08<00:34,  2.42it/s]\u001b[A\n","Iteration:  93% 1129/1211 [08:08<00:33,  2.42it/s]\u001b[A\n","Iteration:  93% 1130/1211 [08:09<00:33,  2.42it/s]\u001b[A\n","Iteration:  93% 1131/1211 [08:09<00:33,  2.41it/s]\u001b[A\n","Iteration:  93% 1132/1211 [08:10<00:32,  2.42it/s]\u001b[A\n","Iteration:  94% 1133/1211 [08:10<00:32,  2.42it/s]\u001b[A\n","Iteration:  94% 1134/1211 [08:10<00:31,  2.42it/s]\u001b[A\n","Iteration:  94% 1135/1211 [08:11<00:31,  2.43it/s]\u001b[A\n","Iteration:  94% 1136/1211 [08:11<00:31,  2.42it/s]\u001b[A\n","Iteration:  94% 1137/1211 [08:12<00:30,  2.42it/s]\u001b[A\n","Iteration:  94% 1138/1211 [08:12<00:30,  2.42it/s]\u001b[A\n","Iteration:  94% 1139/1211 [08:12<00:29,  2.42it/s]\u001b[A\n","Iteration:  94% 1140/1211 [08:13<00:29,  2.43it/s]\u001b[A\n","Iteration:  94% 1141/1211 [08:13<00:28,  2.43it/s]\u001b[A\n","Iteration:  94% 1142/1211 [08:14<00:28,  2.43it/s]\u001b[A\n","Iteration:  94% 1143/1211 [08:14<00:28,  2.42it/s]\u001b[A\n","Iteration:  94% 1144/1211 [08:14<00:27,  2.42it/s]\u001b[A\n","Iteration:  95% 1145/1211 [08:15<00:27,  2.42it/s]\u001b[A\n","Iteration:  95% 1146/1211 [08:15<00:26,  2.42it/s]\u001b[A\n","Iteration:  95% 1147/1211 [08:16<00:26,  2.42it/s]\u001b[A\n","Iteration:  95% 1148/1211 [08:16<00:26,  2.42it/s]\u001b[A\n","Iteration:  95% 1149/1211 [08:17<00:25,  2.42it/s]\u001b[A\n","Iteration:  95% 1150/1211 [08:17<00:25,  2.42it/s]\u001b[A\n","Iteration:  95% 1151/1211 [08:17<00:24,  2.42it/s]\u001b[A\n","Iteration:  95% 1152/1211 [08:18<00:24,  2.42it/s]\u001b[A\n","Iteration:  95% 1153/1211 [08:18<00:23,  2.42it/s]\u001b[A\n","Iteration:  95% 1154/1211 [08:19<00:23,  2.42it/s]\u001b[A\n","Iteration:  95% 1155/1211 [08:19<00:23,  2.42it/s]\u001b[A\n","Iteration:  95% 1156/1211 [08:19<00:22,  2.42it/s]\u001b[A\n","Iteration:  96% 1157/1211 [08:20<00:22,  2.42it/s]\u001b[A\n","Iteration:  96% 1158/1211 [08:20<00:21,  2.42it/s]\u001b[A\n","Iteration:  96% 1159/1211 [08:21<00:21,  2.42it/s]\u001b[A\n","Iteration:  96% 1160/1211 [08:21<00:21,  2.42it/s]\u001b[A\n","Iteration:  96% 1161/1211 [08:21<00:20,  2.42it/s]\u001b[A\n","Iteration:  96% 1162/1211 [08:22<00:20,  2.42it/s]\u001b[A\n","Iteration:  96% 1163/1211 [08:22<00:19,  2.42it/s]\u001b[A\n","Iteration:  96% 1164/1211 [08:23<00:19,  2.42it/s]\u001b[A\n","Iteration:  96% 1165/1211 [08:23<00:18,  2.42it/s]\u001b[A\n","Iteration:  96% 1166/1211 [08:24<00:18,  2.42it/s]\u001b[A\n","Iteration:  96% 1167/1211 [08:24<00:18,  2.42it/s]\u001b[A\n","Iteration:  96% 1168/1211 [08:24<00:17,  2.42it/s]\u001b[A\n","Iteration:  97% 1169/1211 [08:25<00:17,  2.41it/s]\u001b[A\n","Iteration:  97% 1170/1211 [08:25<00:17,  2.41it/s]\u001b[A\n","Iteration:  97% 1171/1211 [08:26<00:16,  2.41it/s]\u001b[A\n","Iteration:  97% 1172/1211 [08:26<00:16,  2.41it/s]\u001b[A\n","Iteration:  97% 1173/1211 [08:26<00:15,  2.41it/s]\u001b[A\n","Iteration:  97% 1174/1211 [08:27<00:15,  2.41it/s]\u001b[A\n","Iteration:  97% 1175/1211 [08:27<00:14,  2.41it/s]\u001b[A\n","Iteration:  97% 1176/1211 [08:28<00:14,  2.42it/s]\u001b[A\n","Iteration:  97% 1177/1211 [08:28<00:14,  2.42it/s]\u001b[A\n","Iteration:  97% 1178/1211 [08:29<00:13,  2.41it/s]\u001b[A\n","Iteration:  97% 1179/1211 [08:29<00:13,  2.41it/s]\u001b[A\n","Iteration:  97% 1180/1211 [08:29<00:12,  2.42it/s]\u001b[A\n","Iteration:  98% 1181/1211 [08:30<00:12,  2.42it/s]\u001b[A\n","Iteration:  98% 1182/1211 [08:30<00:11,  2.43it/s]\u001b[A\n","Iteration:  98% 1183/1211 [08:31<00:11,  2.41it/s]\u001b[A\n","Iteration:  98% 1184/1211 [08:31<00:11,  2.41it/s]\u001b[A\n","Iteration:  98% 1185/1211 [08:31<00:10,  2.42it/s]\u001b[A\n","Iteration:  98% 1186/1211 [08:32<00:10,  2.42it/s]\u001b[A\n","Iteration:  98% 1187/1211 [08:32<00:09,  2.42it/s]\u001b[A\n","Iteration:  98% 1188/1211 [08:33<00:09,  2.42it/s]\u001b[A\n","Iteration:  98% 1189/1211 [08:33<00:09,  2.42it/s]\u001b[A\n","Iteration:  98% 1190/1211 [08:33<00:08,  2.43it/s]\u001b[A\n","Iteration:  98% 1191/1211 [08:34<00:08,  2.43it/s]\u001b[A\n","Iteration:  98% 1192/1211 [08:34<00:07,  2.42it/s]\u001b[A\n","Iteration:  99% 1193/1211 [08:35<00:07,  2.42it/s]\u001b[A\n","Iteration:  99% 1194/1211 [08:35<00:07,  2.42it/s]\u001b[A\n","Iteration:  99% 1195/1211 [08:36<00:06,  2.43it/s]\u001b[A\n","Iteration:  99% 1196/1211 [08:36<00:06,  2.43it/s]\u001b[A\n","Iteration:  99% 1197/1211 [08:36<00:05,  2.43it/s]\u001b[A\n","Iteration:  99% 1198/1211 [08:37<00:05,  2.43it/s]\u001b[A\n","Iteration:  99% 1199/1211 [08:37<00:04,  2.43it/s]\u001b[A\n","Iteration:  99% 1200/1211 [08:38<00:04,  2.42it/s]\u001b[A\n","Iteration:  99% 1201/1211 [08:38<00:04,  2.43it/s]\u001b[A\n","Iteration:  99% 1202/1211 [08:38<00:03,  2.42it/s]\u001b[A\n","Iteration:  99% 1203/1211 [08:39<00:03,  2.42it/s]\u001b[A\n","Iteration:  99% 1204/1211 [08:39<00:02,  2.43it/s]\u001b[A\n","Iteration: 100% 1205/1211 [08:40<00:02,  2.43it/s]\u001b[A\n","Iteration: 100% 1206/1211 [08:40<00:02,  2.42it/s]\u001b[A\n","Iteration: 100% 1207/1211 [08:40<00:01,  2.42it/s]\u001b[A\n","Iteration: 100% 1208/1211 [08:41<00:01,  2.42it/s]\u001b[A\n","Iteration: 100% 1209/1211 [08:41<00:00,  2.43it/s]\u001b[A\n","Iteration: 100% 1210/1211 [08:42<00:00,  2.43it/s]\u001b[A\n","Iteration: 100% 1211/1211 [08:42<00:00,  2.32it/s]\n","Epoch: 100% 1/1 [08:42<00:00, 522.47s/it]\n","04/30/2020 11:25:20 - INFO - __main__ -    global_step = 1211, average loss = 1.6067825672451275\n","04/30/2020 11:25:20 - INFO - __main__ -   Saving model checkpoint to output\n","04/30/2020 11:25:20 - INFO - transformers.configuration_utils -   Configuration saved in output/config.json\n","04/30/2020 11:25:21 - INFO - transformers.modeling_utils -   Model weights saved in output/pytorch_model.bin\n","04/30/2020 11:25:21 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","04/30/2020 11:25:21 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"directionality\": \"bidi\",\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 105879\n","}\n","\n","04/30/2020 11:25:21 - INFO - transformers.modeling_utils -   loading weights file output/pytorch_model.bin\n","04/30/2020 11:25:29 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","04/30/2020 11:25:29 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"directionality\": \"bidi\",\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 105879\n","}\n","\n","04/30/2020 11:25:29 - INFO - transformers.tokenization_utils -   Model name 'output' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'output' is a path, a model identifier, or url to a directory containing tokenizer files.\n","04/30/2020 11:25:29 - INFO - transformers.tokenization_utils -   Didn't find file output/added_tokens.json. We won't load it.\n","04/30/2020 11:25:29 - INFO - transformers.tokenization_utils -   loading file output/vocab.txt\n","04/30/2020 11:25:29 - INFO - transformers.tokenization_utils -   loading file None\n","04/30/2020 11:25:29 - INFO - transformers.tokenization_utils -   loading file output/special_tokens_map.json\n","04/30/2020 11:25:29 - INFO - transformers.tokenization_utils -   loading file output/tokenizer_config.json\n","04/30/2020 11:25:29 - INFO - __main__ -   Evaluate the following checkpoints: ['output']\n","04/30/2020 11:25:29 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","04/30/2020 11:25:29 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"directionality\": \"bidi\",\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 105879\n","}\n","\n","04/30/2020 11:25:29 - INFO - transformers.modeling_utils -   loading weights file output/pytorch_model.bin\n","04/30/2020 11:25:37 - INFO - __main__ -   Creating features from dataset file at /content/wikitext-2\n","04/30/2020 11:25:42 - INFO - __main__ -   Saving features into cached file /content/wikitext-2/bert_cached_lm_510_wiki.test.tokens\n","04/30/2020 11:25:42 - INFO - __main__ -   ***** Running evaluation  *****\n","04/30/2020 11:25:42 - INFO - __main__ -     Num examples = 605\n","04/30/2020 11:25:42 - INFO - __main__ -     Batch size = 4\n","Evaluating: 100% 152/152 [00:19<00:00,  7.79it/s]\n","04/30/2020 11:26:01 - INFO - __main__ -   ***** Eval results  *****\n","04/30/2020 11:26:01 - INFO - __main__ -     perplexity = tensor(3.5788)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MJCnK4zJ2vD4","colab_type":"code","colab":{}},"source":["def get_eigvecs_dict(layer=-1):\n","    eigvecs_dict = {}\n","    #-1:apply to all layers\n","    if layer==-1:\n","        for l in range(nlayer):\n","            eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_multilingual_'+str(nsamples)+'_'+str(l)+'.pt', True)\n","    elif layer ==-2:\n","        for l in range(nlayer):\n","            eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_multilingual_'+str(nsamples)+'_'+str(l)+'.pt', False)\n","    else:\n","        for l in range(nlayer):\n","            if l==layer:\n","                eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_multilingual_'+str(nsamples)+'_'+str(l)+'.pt', True)\n","            else:\n","                eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_multilingual_'+str(nsamples)+'_'+str(l)+'.pt', False)\n","    return eigvecs_dict\n","\n","import pickle\n","for l in range(-2,nlayer):\n","    d = get_eigvecs_dict(l)\n","    df2=open('/content/eigvecs_dict_'+str(l)+'.txt','wb')\n","    pickle.dump(d,df2)\n","    df2.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XTFMcZ4C95ZX","colab_type":"code","outputId":"fbc3fc44-6826-4ce6-bd05-e490c1e1035a","executionInfo":{"status":"ok","timestamp":1588248244747,"user_tz":-120,"elapsed":48582,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python run_language_modeling_densray.py \\\n","    --output_dir=output \\\n","    --model_type=bert \\\n","    --model_name_or_path=bert-base-multilingual-uncased \\\n","    --eigvecs_dict=/content/eigvecs_dict_-2.txt \\\n","    --train_data_file=/content/wikitext-2/wiki.train.tokens \\\n","    --do_eval \\\n","    --eval_data_file=/content/wikitext-2/wiki.test.tokens \\\n","    --mlm "],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-04-30 12:03:18.327996: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","04/30/2020 12:03:20 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","04/30/2020 12:03:20 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased-config.json from cache at /root/.cache/torch/transformers/33b56ce0f312e47e4d77a57791a4fc6233ae4a560dd2bdd186107058294e58ab.fcb1786f49c279f0e0f158c9972b9bd9f6c0edb5d893dcb9b530d714d86f0edc\n","04/30/2020 12:03:20 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"directionality\": \"bidi\",\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 105879\n","}\n","\n","04/30/2020 12:03:20 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased-vocab.txt from cache at /root/.cache/torch/transformers/bb773818882b0524dc53a1b31a2cc95bc489f000e7e19773ba07846011a6c711.535306b226c42cebebbc0dabc83b92ab11260e9919e21e2ab0beb301f267b4c7\n","04/30/2020 12:03:21 - INFO - densray_bert -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/cc4042a0d6f70eae595ea0e6d49521b17bd6251f973b3e37d303ce7945b90eed.54b4dad9cc3db9aa8448458b782d11ab07c80dedb951906fd2f684a00ecdb1ee\n","04/30/2020 12:03:30 - INFO - densray_bert -   Weights of BertForMaskedLM_1 not initialized from pretrained model: ['cls.predictions.decoder.bias']\n","04/30/2020 12:03:30 - INFO - densray_bert -   Weights from pretrained model not used in BertForMaskedLM_1: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","04/30/2020 12:03:34 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=False, eigvecs_dict={'0': ('/content/drive/My Drive/eigvecs_multilingual_50000_0.pt', False), '1': ('/content/drive/My Drive/eigvecs_multilingual_50000_1.pt', False), '2': ('/content/drive/My Drive/eigvecs_multilingual_50000_2.pt', False), '3': ('/content/drive/My Drive/eigvecs_multilingual_50000_3.pt', False), '4': ('/content/drive/My Drive/eigvecs_multilingual_50000_4.pt', False), '5': ('/content/drive/My Drive/eigvecs_multilingual_50000_5.pt', False), '6': ('/content/drive/My Drive/eigvecs_multilingual_50000_6.pt', False), '7': ('/content/drive/My Drive/eigvecs_multilingual_50000_7.pt', False), '8': ('/content/drive/My Drive/eigvecs_multilingual_50000_8.pt', False), '9': ('/content/drive/My Drive/eigvecs_multilingual_50000_9.pt', False), '10': ('/content/drive/My Drive/eigvecs_multilingual_50000_10.pt', False), '11': ('/content/drive/My Drive/eigvecs_multilingual_50000_11.pt', False)}, eval_all_checkpoints=False, eval_data_file='/content/wikitext-2/wiki.test.tokens', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path='bert-base-multilingual-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='/content/wikitext-2/wiki.train.tokens', warmup_steps=0, weight_decay=0.0)\n","04/30/2020 12:03:34 - INFO - __main__ -   Evaluate the following checkpoints: ['output']\n","04/30/2020 12:03:34 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","04/30/2020 12:03:34 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"directionality\": \"bidi\",\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 105879\n","}\n","\n","04/30/2020 12:03:34 - INFO - densray_bert -   loading weights file output/pytorch_model.bin\n","04/30/2020 12:03:43 - INFO - __main__ -   ***** Running evaluation  *****\n","04/30/2020 12:03:43 - INFO - __main__ -     Num examples = 605\n","04/30/2020 12:03:43 - INFO - __main__ -     Batch size = 4\n","Evaluating: 100% 152/152 [00:19<00:00,  7.78it/s]\n","04/30/2020 12:04:03 - INFO - __main__ -   ***** Eval results  *****\n","04/30/2020 12:04:03 - INFO - __main__ -     perplexity = tensor(3.5742)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"k4Jc2OG62bOS","colab_type":"code","outputId":"a816637b-c1f5-4cac-ae24-00d479e1dd1d","executionInfo":{"status":"ok","timestamp":1588248196157,"user_tz":-120,"elapsed":48371,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python run_language_modeling_densray.py \\\n","    --output_dir=output \\\n","    --model_type=bert \\\n","    --model_name_or_path=bert-base-multilingual-uncased \\\n","    --eigvecs_dict=/content/eigvecs_dict_5.txt \\\n","    --train_data_file=/content/wikitext-2/wiki.train.tokens \\\n","    --do_eval \\\n","    --eval_data_file=/content/wikitext-2/wiki.test.tokens \\\n","    --mlm "],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-04-30 12:02:29.748242: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","04/30/2020 12:02:31 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","04/30/2020 12:02:31 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased-config.json from cache at /root/.cache/torch/transformers/33b56ce0f312e47e4d77a57791a4fc6233ae4a560dd2bdd186107058294e58ab.fcb1786f49c279f0e0f158c9972b9bd9f6c0edb5d893dcb9b530d714d86f0edc\n","04/30/2020 12:02:31 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"directionality\": \"bidi\",\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 105879\n","}\n","\n","04/30/2020 12:02:32 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased-vocab.txt from cache at /root/.cache/torch/transformers/bb773818882b0524dc53a1b31a2cc95bc489f000e7e19773ba07846011a6c711.535306b226c42cebebbc0dabc83b92ab11260e9919e21e2ab0beb301f267b4c7\n","04/30/2020 12:02:32 - INFO - densray_bert -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/cc4042a0d6f70eae595ea0e6d49521b17bd6251f973b3e37d303ce7945b90eed.54b4dad9cc3db9aa8448458b782d11ab07c80dedb951906fd2f684a00ecdb1ee\n","04/30/2020 12:02:45 - INFO - densray_bert -   Weights of BertForMaskedLM_1 not initialized from pretrained model: ['cls.predictions.decoder.bias']\n","04/30/2020 12:02:45 - INFO - densray_bert -   Weights from pretrained model not used in BertForMaskedLM_1: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","04/30/2020 12:02:46 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=False, eigvecs_dict={'0': ('/content/drive/My Drive/eigvecs_multilingual_50000_0.pt', False), '1': ('/content/drive/My Drive/eigvecs_multilingual_50000_1.pt', False), '2': ('/content/drive/My Drive/eigvecs_multilingual_50000_2.pt', False), '3': ('/content/drive/My Drive/eigvecs_multilingual_50000_3.pt', False), '4': ('/content/drive/My Drive/eigvecs_multilingual_50000_4.pt', False), '5': ('/content/drive/My Drive/eigvecs_multilingual_50000_5.pt', True), '6': ('/content/drive/My Drive/eigvecs_multilingual_50000_6.pt', False), '7': ('/content/drive/My Drive/eigvecs_multilingual_50000_7.pt', False), '8': ('/content/drive/My Drive/eigvecs_multilingual_50000_8.pt', False), '9': ('/content/drive/My Drive/eigvecs_multilingual_50000_9.pt', False), '10': ('/content/drive/My Drive/eigvecs_multilingual_50000_10.pt', False), '11': ('/content/drive/My Drive/eigvecs_multilingual_50000_11.pt', False)}, eval_all_checkpoints=False, eval_data_file='/content/wikitext-2/wiki.test.tokens', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path='bert-base-multilingual-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='/content/wikitext-2/wiki.train.tokens', warmup_steps=0, weight_decay=0.0)\n","04/30/2020 12:02:46 - INFO - __main__ -   Evaluate the following checkpoints: ['output']\n","04/30/2020 12:02:46 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","04/30/2020 12:02:46 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"directionality\": \"bidi\",\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 105879\n","}\n","\n","04/30/2020 12:02:46 - INFO - densray_bert -   loading weights file output/pytorch_model.bin\n","04/30/2020 12:02:55 - INFO - __main__ -   ***** Running evaluation  *****\n","04/30/2020 12:02:55 - INFO - __main__ -     Num examples = 605\n","04/30/2020 12:02:55 - INFO - __main__ -     Batch size = 4\n","Evaluating: 100% 152/152 [00:19<00:00,  7.76it/s]\n","04/30/2020 12:03:15 - INFO - __main__ -   ***** Eval results  *****\n","04/30/2020 12:03:15 - INFO - __main__ -     perplexity = tensor(3.5773)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cC4W5T_dFTB0","colab_type":"text"},"source":["# CH"]},{"cell_type":"code","metadata":{"id":"UqF6hkkTFYN0","colab_type":"code","colab":{}},"source":["import re\n","\n","class Template_ch:\n","    def __init__(self, path='/content/professions_ch.json'):\n","        with open(path,'r',encoding='utf8') as f:\n","            titles = f.read().split()\n","        self.lines = [tokenizer.mask_token+'是一个'+i+'。' for i in titles]\n","        self.examples = tokenizer.batch_encode_plus(self.lines, add_special_tokens=True, max_length=128)[\"input_ids\"]\n","        self.getbaseline()\n","    \n","    def getbaseline(self):\n","        self.baseline = []\n","        for i in self.examples:\n","            i = torch.tensor(i, dtype=torch.long).unsqueeze(0).to(device)\n","            output = model(i)\n","            mask_hidden_state = output[0].squeeze(0)[1]\n","            softmax = torch.nn.Softmax(dim=0)\n","            torch.set_grad_enabled(False)\n","            probs = softmax(mask_hidden_state)\n","            # get probability of token 'he'\n","            he_id = tokenizer.convert_tokens_to_ids('他')\n","            #print('he probability', probs[he_id].item())\n","            # get probability of token 'she'\n","            she_id = tokenizer.convert_tokens_to_ids('她')\n","            #print('she probability', probs[she_id].item())\n","            self.baseline.append([probs[he_id].item(), probs[she_id].item()])\n","template_ch = Template_ch('/content/professions_ch.txt')     "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"43tlLaANMCoF","colab_type":"code","outputId":"a439d13f-1acf-4c18-ced8-e5c975cddd59","executionInfo":{"status":"ok","timestamp":1588234095003,"user_tz":-120,"elapsed":202330,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":248}},"source":["predictions_ch = eval(temp=template_ch, he='他', she='她')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 302/302 [00:05<00:00, 55.21it/s]\n","100%|██████████| 302/302 [00:04<00:00, 62.51it/s]\n","100%|██████████| 302/302 [00:04<00:00, 61.93it/s]\n","100%|██████████| 302/302 [00:04<00:00, 61.88it/s]\n","100%|██████████| 302/302 [00:04<00:00, 61.84it/s]\n","100%|██████████| 302/302 [00:04<00:00, 61.51it/s]\n","100%|██████████| 302/302 [00:04<00:00, 61.97it/s]\n","100%|██████████| 302/302 [00:04<00:00, 61.97it/s]\n","100%|██████████| 302/302 [00:04<00:00, 62.34it/s]\n","100%|██████████| 302/302 [00:04<00:00, 61.60it/s]\n","100%|██████████| 302/302 [00:04<00:00, 62.47it/s]\n","100%|██████████| 302/302 [00:04<00:00, 61.68it/s]\n","100%|██████████| 302/302 [00:04<00:00, 62.46it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"EyhvHXt5MKcc","colab_type":"code","outputId":"2e1dc70a-c1b8-4e76-fefc-86dae9b33cb4","executionInfo":{"status":"ok","timestamp":1588234095009,"user_tz":-120,"elapsed":201673,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":301}},"source":["print('mean(prob(he/she)) var(prob(he/she)) mean(prob(he-she)) var(prob(he-she))')\n","baseline = torch.Tensor(template_ch.baseline)\n","print(torch.mean(baseline,dim=0), torch.var(baseline,dim=0), (baseline[:,0]-baseline[:,1]).mean(), (baseline[:,0]-baseline[:,1]).var(), '\\n')\n","\n","for i in torch.Tensor(predictions_ch):\n","    print(torch.mean(i,dim=0), torch.var(i,dim=0), (i[:,0]-i[:,1]).mean(), (i[:,0]-i[:,1]).var())\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["mean(prob(he/she)) var(prob(he/she)) mean(prob(he-she)) var(prob(he-she))\n","tensor([0.2370, 0.0718]) tensor([0.0206, 0.0037]) tensor(0.1652) tensor(0.0223) \n","\n","tensor([0.0961, 0.0297]) tensor([0.0040, 0.0004]) tensor(0.0664) tensor(0.0032)\n","tensor([0.2430, 0.0738]) tensor([0.0213, 0.0037]) tensor(0.1691) tensor(0.0230)\n","tensor([0.2415, 0.0730]) tensor([0.0211, 0.0037]) tensor(0.1685) tensor(0.0229)\n","tensor([0.2417, 0.0730]) tensor([0.0213, 0.0037]) tensor(0.1687) tensor(0.0230)\n","tensor([0.2443, 0.0749]) tensor([0.0217, 0.0038]) tensor(0.1694) tensor(0.0236)\n","tensor([0.2384, 0.0742]) tensor([0.0209, 0.0038]) tensor(0.1642) tensor(0.0226)\n","tensor([0.2273, 0.0777]) tensor([0.0195, 0.0041]) tensor(0.1496) tensor(0.0211)\n","tensor([0.2319, 0.0753]) tensor([0.0200, 0.0039]) tensor(0.1566) tensor(0.0216)\n","tensor([0.2160, 0.0800]) tensor([0.0182, 0.0041]) tensor(0.1360) tensor(0.0193)\n","tensor([0.2189, 0.0736]) tensor([0.0183, 0.0034]) tensor(0.1453) tensor(0.0191)\n","tensor([0.1809, 0.0512]) tensor([0.0132, 0.0017]) tensor(0.1296) tensor(0.0128)\n","tensor([0.1472, 0.0442]) tensor([0.0086, 0.0011]) tensor(0.1029) tensor(0.0077)\n","tensor([0.2165, 0.0643]) tensor([0.0177, 0.0029]) tensor(0.1522) tensor(0.0185)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-xjclc-JTqmY","colab_type":"code","outputId":"c64a0fb9-00e1-4e84-fa70-31de859a8d3d","executionInfo":{"status":"ok","timestamp":1588234195803,"user_tz":-120,"elapsed":559,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":301}},"source":["print('mean(prob(he/she)) var(prob(he/she)) mean(prob(he-she)) var(prob(he-she))')\n","baseline = torch.Tensor(template_ch.baseline)\n","print([round(i,4) for i in torch.mean(baseline,dim=0).tolist()], [round(i,4) for i in torch.var(baseline,dim=0).tolist()], \n","      round(float((baseline[:,0]-baseline[:,1]).mean()),4), round(float((baseline[:,0]-baseline[:,1]).var()),4), '\\n')\n","\n","for i in torch.Tensor(predictions_ch):\n","    print([round(i,4) for i in torch.mean(i,dim=0).tolist()], [round(i,4) for i in torch.var(i,dim=0).tolist()], \n","          round(float((i[:,0]-i[:,1]).mean()),4), round(float((i[:,0]-i[:,1]).var()),4))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["mean(prob(he/she)) var(prob(he/she)) mean(prob(he-she)) var(prob(he-she))\n","[0.237, 0.0718] [0.0206, 0.0037] 0.1652 0.0223 \n","\n","[0.0961, 0.0297] [0.004, 0.0004] 0.0664 0.0032\n","[0.243, 0.0738] [0.0213, 0.0037] 0.1691 0.023\n","[0.2415, 0.073] [0.0211, 0.0037] 0.1685 0.0229\n","[0.2417, 0.073] [0.0213, 0.0037] 0.1687 0.023\n","[0.2443, 0.0749] [0.0217, 0.0038] 0.1694 0.0236\n","[0.2384, 0.0742] [0.0209, 0.0038] 0.1642 0.0226\n","[0.2273, 0.0777] [0.0195, 0.0041] 0.1496 0.0211\n","[0.2319, 0.0753] [0.02, 0.0039] 0.1566 0.0216\n","[0.216, 0.08] [0.0182, 0.0041] 0.136 0.0193\n","[0.2189, 0.0736] [0.0183, 0.0034] 0.1453 0.0191\n","[0.1809, 0.0512] [0.0132, 0.0017] 0.1296 0.0128\n","[0.1472, 0.0442] [0.0086, 0.0011] 0.1029 0.0077\n","[0.2165, 0.0643] [0.0177, 0.0029] 0.1522 0.0185\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bqna81S9KoaT","colab_type":"code","colab":{}},"source":["for i in range(len(template_ch.lines)):\n","    print(\"sentence: \", template_ch.lines[i])\n","    print(\"prediction: \", predictions_ch[0][i])\n","    print(\"baseline: \", template_ch.baseline[i], \"\\n\")\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1QRMD9imJCsw","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}