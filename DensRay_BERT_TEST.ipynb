{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Final_DensRay_BERT_TEST.ipynb","provenance":[{"file_id":"1QsCRMwPNffdfgjR_jvW3O83h2uyiGxi4","timestamp":1589947460129},{"file_id":"14320o-9-uc0nsejqTeNe66uhFYw4QSU9","timestamp":1589939467638},{"file_id":"1ePa9C1bq3wS5WByfi8L9hCBGqtl2HhWu","timestamp":1588134391908},{"file_id":"1c__r6mWy4-vOfdfL4tmqij72Qayz2yHY","timestamp":1586403317137},{"file_id":"1OCwvXO9cB1Ke5Bi11SvjovgCKDh6iE6M","timestamp":1586403087992},{"file_id":"1tgzcbuJrxhBeC6FnQig4Z8RLj3TD2Y-p","timestamp":1586402323174},{"file_id":"1gnY3Blunw8HAUxw8wAFCzirazvafbmQn","timestamp":1586399576485},{"file_id":"1GHdeIzOlLZLZ2RN2MohSwBfpWuNi1ogN","timestamp":1583364612376},{"file_id":"1BA0JTleU0JVbJjgrXw5ULWcTa5Nl5sGb","timestamp":1583315004957},{"file_id":"1xWrKImFLCBga34NpEp9EoaMc2AfUPXIK","timestamp":1583286864919}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"d0e3518f74e345cd89e0b4ea741f36f2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_60468b98ddd54ce2b47b04fb95a96667","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_723a24b431444cb7bd2aa55a4fe71710","IPY_MODEL_1933ab6ad05b4a9db0ab9f2f6ee948ef"]}},"60468b98ddd54ce2b47b04fb95a96667":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"723a24b431444cb7bd2aa55a4fe71710":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ce7619c6f21d455e842dbebf07145e7d","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":434,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":434,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fc9609ad4972413fb873016ee132502f"}},"1933ab6ad05b4a9db0ab9f2f6ee948ef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_95f7bfc79b574716a4af99ad12a8e0a9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 434/434 [00:26&lt;00:00, 16.3B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2e314b5b3c6d4d98a5a93e55f1afa077"}},"ce7619c6f21d455e842dbebf07145e7d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"fc9609ad4972413fb873016ee132502f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"95f7bfc79b574716a4af99ad12a8e0a9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2e314b5b3c6d4d98a5a93e55f1afa077":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dac8db1fdb5c48d08075e228848b8459":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ed2ccea31d634c1ab15e0a15ff1a5477","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a354e09b79254a47a36bdbf0fe0f0062","IPY_MODEL_c1c12e1e61a64f4cbb919ff9a4dd116a"]}},"ed2ccea31d634c1ab15e0a15ff1a5477":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a354e09b79254a47a36bdbf0fe0f0062":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4bef842b8954451e9e10391d3a5a446b","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1344997306,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1344997306,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_010b4cebb6f6495aa016d2e6767a42fa"}},"c1c12e1e61a64f4cbb919ff9a4dd116a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e7cef8cad1404b218f0c45d41d1f6140","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.34G/1.34G [00:26&lt;00:00, 51.1MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_89fc76d237434a9ab1750582b0682e49"}},"4bef842b8954451e9e10391d3a5a446b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"010b4cebb6f6495aa016d2e6767a42fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e7cef8cad1404b218f0c45d41d1f6140":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"89fc76d237434a9ab1750582b0682e49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"edca32f8242e4d04bf1b4a6043a40c82":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3920174e3b964c9bac56c74aa7b5445e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2d2bf05145b84c4fb39b00ebc4614865","IPY_MODEL_6e897d21e89c49cd9cc5eed089bc042d"]}},"3920174e3b964c9bac56c74aa7b5445e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2d2bf05145b84c4fb39b00ebc4614865":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_42310a0d45d14010b870f674639de906","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d27a459481394bff900e89597b238d13"}},"6e897d21e89c49cd9cc5eed089bc042d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b8131454681f41cbb56dd7245e830924","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 2.50MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_82661f13e8034cce934eca175e94e9c0"}},"42310a0d45d14010b870f674639de906":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d27a459481394bff900e89597b238d13":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b8131454681f41cbb56dd7245e830924":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"82661f13e8034cce934eca175e94e9c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"q2O3yi9gUjY-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":655},"executionInfo":{"status":"ok","timestamp":1593642254644,"user_tz":-120,"elapsed":8956,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"outputId":"7168881e-583e-4e77-cfb1-d3a6c2ca6ebe"},"source":["!pip install transformers==2.8.0"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting transformers==2.8.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n","\u001b[K     |████████████████████████████████| 573kB 2.9MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (4.41.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2019.12.20)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 13.4MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.7)\n","Collecting tokenizers==0.5.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n","\u001b[K     |████████████████████████████████| 3.7MB 16.0MB/s \n","\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.14.9)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (3.0.12)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 28.3MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.18.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (1.24.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (0.15.1)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (0.3.3)\n","Requirement already satisfied: botocore<1.18.0,>=1.17.9 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (1.17.9)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (0.10.0)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.9->boto3->transformers==2.8.0) (2.8.1)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.9->boto3->transformers==2.8.0) (0.15.2)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=a7e4b677ffccfbc34a080e2b37187d461bfaabe0b3b90a5ffdc0d7de03d2705c\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.5.2 transformers-2.8.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LALnwVo3yRML","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1593574791967,"user_tz":-120,"elapsed":10316,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"outputId":"308000dd-76dd-4dde-be36-da60fe650e81"},"source":["!wget https://raw.githubusercontent.com/huggingface/transformers/v2.8.0/examples/run_language_modeling.py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2020-07-01 03:39:48--  https://raw.githubusercontent.com/huggingface/transformers/v2.8.0/examples/run_language_modeling.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 34328 (34K) [text/plain]\n","Saving to: ‘run_language_modeling.py’\n","\n","\rrun_language_modeli   0%[                    ]       0  --.-KB/s               \rrun_language_modeli 100%[===================>]  33.52K  --.-KB/s    in 0.01s   \n","\n","2020-07-01 03:39:48 (2.49 MB/s) - ‘run_language_modeling.py’ saved [34328/34328]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZOCrXcMzyTNi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":290},"executionInfo":{"status":"ok","timestamp":1593574794641,"user_tz":-120,"elapsed":10406,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"outputId":"7d3cb431-ed62-4874-fbce-e3365f7c080c"},"source":["!wget https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-2-v1.zip\n","!unzip wikitext-2-v1.zip"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2020-07-01 03:39:50--  https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-2-v1.zip\n","Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.115.77\n","Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.115.77|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 4475746 (4.3M) [application/zip]\n","Saving to: ‘wikitext-2-v1.zip’\n","\n","\rwikitext-2-v1.zip     0%[                    ]       0  --.-KB/s               \rwikitext-2-v1.zip   100%[===================>]   4.27M  --.-KB/s    in 0.1s    \n","\n","2020-07-01 03:39:50 (40.8 MB/s) - ‘wikitext-2-v1.zip’ saved [4475746/4475746]\n","\n","Archive:  wikitext-2-v1.zip\n","   creating: wikitext-2/\n","  inflating: wikitext-2/wiki.test.tokens  \n","  inflating: wikitext-2/wiki.valid.tokens  \n","  inflating: wikitext-2/wiki.train.tokens  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ikGXqkSQDCwH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":120},"executionInfo":{"status":"ok","timestamp":1593642278382,"user_tz":-120,"elapsed":27727,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"outputId":"075fc66f-c226-4f86-cbf0-b9ef3e949841"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5rMiCKAusFtK","colab_type":"text"},"source":["# Config"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lyUbLYhu3m4b","scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["d0e3518f74e345cd89e0b4ea741f36f2","60468b98ddd54ce2b47b04fb95a96667","723a24b431444cb7bd2aa55a4fe71710","1933ab6ad05b4a9db0ab9f2f6ee948ef","ce7619c6f21d455e842dbebf07145e7d","fc9609ad4972413fb873016ee132502f","95f7bfc79b574716a4af99ad12a8e0a9","2e314b5b3c6d4d98a5a93e55f1afa077","dac8db1fdb5c48d08075e228848b8459","ed2ccea31d634c1ab15e0a15ff1a5477","a354e09b79254a47a36bdbf0fe0f0062","c1c12e1e61a64f4cbb919ff9a4dd116a","4bef842b8954451e9e10391d3a5a446b","010b4cebb6f6495aa016d2e6767a42fa","e7cef8cad1404b218f0c45d41d1f6140","89fc76d237434a9ab1750582b0682e49","edca32f8242e4d04bf1b4a6043a40c82","3920174e3b964c9bac56c74aa7b5445e","2d2bf05145b84c4fb39b00ebc4614865","6e897d21e89c49cd9cc5eed089bc042d","42310a0d45d14010b870f674639de906","d27a459481394bff900e89597b238d13","b8131454681f41cbb56dd7245e830924","82661f13e8034cce934eca175e94e9c0"]},"executionInfo":{"status":"ok","timestamp":1593643608347,"user_tz":-120,"elapsed":42066,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"outputId":"19d579c9-3dd8-4e3b-ae72-185739687633"},"source":["import torch\n","import transformers\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","config = 'large'\n","nlayer = 12 if config == 'base' else 24\n","nsamples = 5000 if config == 'base' else 10000\n","\n","model = transformers.BertForMaskedLM.from_pretrained('bert-'+config+'-uncased', output_hidden_states=True).to(device)\n","tokenizer = transformers.BertTokenizer.from_pretrained('bert-'+config+'-uncased')\n","# turn on eval mode\n","model.eval()"],"execution_count":42,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d0e3518f74e345cd89e0b4ea741f36f2","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=434.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dac8db1fdb5c48d08075e228848b8459","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1344997306.0, style=ProgressStyle(descr…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"edca32f8242e4d04bf1b4a6043a40c82","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["BertForMaskedLM(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n","      (position_embeddings): Embedding(512, 1024)\n","      (token_type_embeddings): Embedding(2, 1024)\n","      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (12): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (13): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (14): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (15): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (16): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (17): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (18): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (19): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (20): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (21): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (22): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (23): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (cls): BertOnlyMLMHead(\n","    (predictions): BertLMPredictionHead(\n","      (transform): BertPredictionHeadTransform(\n","        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","      )\n","      (decoder): Linear(in_features=1024, out_features=30522, bias=True)\n","    )\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"markdown","metadata":{"id":"azdjJRdSsVsC","colab_type":"text"},"source":["# Templates"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6kYCoJcaL1j0","colab":{},"executionInfo":{"status":"ok","timestamp":1593643617641,"user_tz":-120,"elapsed":49736,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}}},"source":["import re\n","\n","class Template:\n","    def __init__(self, path='/content/drive/My Drive/professions.json'):\n","        with open(path,'r',encoding='utf8') as f:\n","            titles = re.sub('[^a-z_]',' ',f.read()).split()\n","        self.lines = [re.sub('_',' ',tokenizer.mask_token+' is a '+i+' .') for i in titles]\n","        self.examples = tokenizer.batch_encode_plus(self.lines, add_special_tokens=True, max_length=128)[\"input_ids\"]\n","        self.getbaseline()\n","    \n","    def getbaseline(self):\n","        self.baseline = []\n","        for i in self.examples:\n","            i = torch.tensor(i, dtype=torch.long).unsqueeze(0).to(device)\n","            output = model(i)\n","            mask_hidden_state = output[0].squeeze(0)[1]\n","            softmax = torch.nn.Softmax(dim=0)\n","            torch.set_grad_enabled(False)\n","            probs = softmax(mask_hidden_state)\n","            # get probability of token 'he'\n","            he_id = tokenizer.convert_tokens_to_ids('he')\n","            #print('he probability', probs[he_id].item())\n","            # get probability of token 'she'\n","            she_id = tokenizer.convert_tokens_to_ids('she')\n","            #print('she probability', probs[she_id].item())\n","            self.baseline.append([probs[he_id].item(), probs[she_id].item()])\n","        \n","template = Template('/content/drive/My Drive/professions.json')"],"execution_count":43,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vy25YU_Nsbh3","colab_type":"text"},"source":["# Eval"]},{"cell_type":"code","metadata":{"id":"bmk0ozKp-8eX","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593643706735,"user_tz":-120,"elapsed":583,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}}},"source":["def get_eigvecs_dict(layer=-1):\n","    eigvecs_dict = {}\n","    #-1:apply to all layers\n","    if layer == -1:\n","        for l in range(nlayer):\n","            eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(l)+'.pt', True)\n","    elif layer ==-2:\n","        for l in range(nlayer):\n","            eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(l)+'.pt', False)\n","    else:\n","        for l in range(nlayer):\n","            if l==layer:\n","                eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(l)+'.pt', True)\n","            else:\n","                eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(l)+'.pt', False)\n","    return eigvecs_dict\n"],"execution_count":48,"outputs":[]},{"cell_type":"code","metadata":{"id":"Eq0TZyRiigjA","colab_type":"code","colab":{}},"source":["!find /content/ -name '*eigvecs*' | xargs  rm -rf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Lm8trYf6idU","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593643618430,"user_tz":-120,"elapsed":777,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}}},"source":["def get_eigvecs_dict(layer=-1):\n","    eigvecs_dict = {}\n","    #-1:apply to all layers\n","    if layer == -1:\n","        for l in range(nlayer):\n","            eigvecs_dict[str(l)] = ('/content/drive/My Drive/negc'+config+'_'+str(nsamples)+'_'+str(l)+'.pt', True)\n","    elif layer ==-2:\n","        for l in range(nlayer):\n","            eigvecs_dict[str(l)] = ('/content/drive/My Drive/negc'+config+'_'+str(nsamples)+'_'+str(l)+'.pt', False)\n","    else:\n","        for l in range(nlayer):\n","            if l==layer:\n","                eigvecs_dict[str(l)] = ('/content/drive/My Drive/negc'+config+'_'+str(nsamples)+'_'+str(l)+'.pt', True)\n","            else:\n","                eigvecs_dict[str(l)] = ('/content/drive/My Drive/negc'+config+'_'+str(nsamples)+'_'+str(l)+'.pt', False)\n","    return eigvecs_dict\n"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"id":"uytbjIFG86yW","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593643892825,"user_tz":-120,"elapsed":801,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}}},"source":["def get_eigvecs_dict(layer=-1):\n","    eigvecs_dict = {}\n","    #-1:apply to all layers\n","    if layer == -1:\n","        for l in range(nlayer):\n","            eigvecs_dict[str(l)] = ('/content/drive/My Drive/pc1'+config+'_'+str(nsamples)+'_'+str(l)+'.pt', True)\n","    elif layer ==-2:\n","        for l in range(nlayer):\n","            eigvecs_dict[str(l)] = ('/content/drive/My Drive/pc1'+config+'_'+str(nsamples)+'_'+str(l)+'.pt', False)\n","    else:\n","        for l in range(nlayer):\n","            if l==layer:\n","                eigvecs_dict[str(l)] = ('/content/drive/My Drive/pc1'+config+'_'+str(nsamples)+'_'+str(l)+'.pt', True)\n","            else:\n","                eigvecs_dict[str(l)] = ('/content/drive/My Drive/pc1'+config+'_'+str(nsamples)+'_'+str(l)+'.pt', False)\n","    return eigvecs_dict\n"],"execution_count":53,"outputs":[]},{"cell_type":"code","metadata":{"id":"MUYs-VS6tg-n","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1593643940232,"user_tz":-120,"elapsed":43676,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"outputId":"b2c29ca4-f6bd-421c-ec07-e164064ef617"},"source":["import hard_bert as bbert\n","import tqdm\n","import numpy as np\n","\n","def eval(temp=Template(), he='he', she='she'):\n","    predictions = []\n","    for l in range(-1,0):\n","        # get model\n","        model = bbert.BertForMaskedLM_1.from_pretrained('bert-'+config+'-uncased', eigvecs_dict=get_eigvecs_dict(l)).to(device)\n","        model.eval() \n","        # eval\n","        prediction = []\n","        for i in tqdm.trange(len(temp.examples)):\n","            vec = torch.tensor(temp.examples[i], dtype=torch.long).unsqueeze(0).to(device)\n","            output = model(vec)\n","            mask_hidden_state = output[0].squeeze(0)[1]\n","            softmax = torch.nn.Softmax(dim=0)\n","            torch.set_grad_enabled(False)\n","            probs = softmax(mask_hidden_state)\n","            he_id = tokenizer.convert_tokens_to_ids('he')\n","            she_id = tokenizer.convert_tokens_to_ids('she')\n","            prediction.append([probs[he_id].item(), probs[she_id].item()])\n","        predictions.append(prediction)\n","    return predictions\n","predictions = eval(template)"],"execution_count":54,"outputs":[{"output_type":"stream","text":["100%|██████████| 320/320 [00:11<00:00, 29.04it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"nkjX8uf42fqe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":84},"executionInfo":{"status":"ok","timestamp":1593643940233,"user_tz":-120,"elapsed":42238,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"outputId":"41435cdc-9818-4263-8960-f31b01caa789"},"source":["print('mean(prob(he/she)) mean(prob(he-she)) mean_sum(he+she) logpmax-logpmin var')\n","baseline = torch.Tensor(template.baseline)\n","print('bert-'+config,'&',[round(i,2) for i in torch.mean(baseline,dim=0).tolist()][0],'&', [round(i,2) for i in torch.mean(baseline,dim=0).tolist()][1],'&',\n","      np.round(torch.mean(baseline,dim=0).sum().numpy(),2), '&', \n","      np.round((torch.log(torch.max(baseline,dim=1)[0].data)-torch.log(torch.min(baseline,dim=1)[0].data)).mean().numpy(),2), '&', np.round((torch.log(torch.max(baseline,dim=1)[0].data)-torch.log(torch.min(baseline,dim=1)[0].data)).var().numpy(),2),'\\n')\n","\n","for p in torch.Tensor(predictions):\n","    print('bert-'+config+'-L','&',[round(i,2) for i in torch.mean(p,dim=0).tolist()][0],'&', [round(i,2) for i in torch.mean(p,dim=0).tolist()][1],'&',\n","      np.round(torch.mean(p,dim=0).sum().numpy(),2), '&', np.round((torch.log(torch.max(p,dim=1)[0].data)-torch.log(torch.min(p,dim=1)[0].data)).mean().numpy(),2)\n","      , '&', np.round((torch.log(torch.max(p,dim=1)[0].data)-torch.log(torch.min(p,dim=1)[0].data)).var().numpy(),2))\n","\n","\n","#for i in range(len(template.lines)):\n","#    print(\"sentence: \", template.lines[i])\n","#    print(\"prediction: \", predictions[-1][i])\n","#    print(\"baseline: \", template.baseline[i], \"\\n\")"],"execution_count":55,"outputs":[{"output_type":"stream","text":["mean(prob(he/she)) mean(prob(he-she)) mean_sum(he+she) logpmax-logpmin var\n","bert-large & 0.63 & 0.19 & 0.82 & 1.82 & 1.3 \n","\n","bert-large-L & 0.4 & 0.23 & 0.63 & 0.69 & 0.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"HTTDYsDcJEec","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1593645090925,"user_tz":-120,"elapsed":616,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"outputId":"31393525-da95-4b5e-a5c6-930e29265bc7"},"source":["np.log(0.51)-np.log(0.18)"],"execution_count":75,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.041453874828161"]},"metadata":{"tags":[]},"execution_count":75}]},{"cell_type":"markdown","metadata":{"id":"Y0UN4czirx3Y","colab_type":"text"},"source":["1. Prepare a template sentence\n","e.g.“[TARGET] is a [ATTRIBUTE]”\n","2. Replace [TARGET] with [MASK] and compute ptgt=P([MASK]=[TARGET]| sentence)\n","3. Replace both [TARGET] and [ATTRIBUTE]\n","with [MASK], and compute prior probability\n","pprior=P([MASK]=[TARGET]| sentence)\n","4. Compute the association as log ptgt\n","pprior"]},{"cell_type":"code","metadata":{"id":"jSrGmc89rwyq","colab_type":"code","colab":{}},"source":["import re\n","\n","class Template_log:\n","    def __init__(self, path='/content/drive/My Drive/professions.json'):\n","        with open(path,'r',encoding='utf8') as f:\n","            titles = re.sub('[^a-z_]',' ',f.read()).split()\n","        self.lines_prior = [re.sub('_',' ',tokenizer.mask_token+' is a '+tokenizer.mask_token+' .')]\n","        self.examples_prior = tokenizer.batch_encode_plus(self.lines_prior, add_special_tokens=True, max_length=128)[\"input_ids\"]\n","        self.getbaseline()\n","    \n","    def getbaseline(self):\n","        def get_probs(example=self.examples_prior):\n","            baseline = []\n","            for i in example:\n","                i = torch.tensor(i, dtype=torch.long).unsqueeze(0).to(device)\n","                output = model(i)\n","                mask_hidden_state = output[0].squeeze(0)[1]\n","                softmax = torch.nn.Softmax(dim=0)\n","                torch.set_grad_enabled(False)\n","                probs = softmax(mask_hidden_state)\n","                # get probability of token 'he'\n","                he_id = tokenizer.convert_tokens_to_ids('he')\n","                #print('he probability', probs[he_id].item())\n","                # get probability of token 'she'\n","                she_id = tokenizer.convert_tokens_to_ids('she')\n","                #print('she probability', probs[she_id].item())\n","                baseline.append([probs[he_id].item(), probs[she_id].item()])\n","            return baseline\n","        self.baseline_prior = get_probs(self.examples_prior)\n","        \n","template_log = Template_log('/content/drive/My Drive/professions.json')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rcdoQkqXvXZU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1592287738078,"user_tz":-120,"elapsed":863,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"outputId":"2ad8839c-e76c-483b-bbdd-71c21f38b2ac"},"source":["template_log.baseline_prior"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[0.5546255111694336, 0.16165059804916382]]"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"szRKf63Du_Wj","colab_type":"code","colab":{}},"source":["import densray_bert as bbert\n","import tqdm\n","\n","def eval_log(temp=Template(), he='he', she='she'):\n","    predictions = []\n","    for l in range(-2,nlayer):\n","        # get model\n","        model = bbert.BertForMaskedLM_1.from_pretrained('bert-'+config+'-uncased', eigvecs_dict=get_eigvecs_dict(l)).to(device)\n","        model.eval() \n","        # eval\n","        prediction = []\n","        for i in tqdm.trange(len(temp.examples)):\n","            vec = torch.tensor(temp.examples[i], dtype=torch.long).unsqueeze(0).to(device)\n","            output = model(vec)\n","            mask_hidden_state = output[0].squeeze(0)[1]\n","            softmax = torch.nn.Softmax(dim=0)\n","            torch.set_grad_enabled(False)\n","            probs = softmax(mask_hidden_state)\n","            he_id = tokenizer.convert_tokens_to_ids('he')\n","            she_id = tokenizer.convert_tokens_to_ids('she')\n","            prediction.append([probs[he_id].item(), probs[she_id].item()])\n","        predictions.append(prediction)\n","    return predictions\n","predictions = eval_log(template)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kQT9x8blsm-h","colab_type":"text"},"source":["# Ppl on Wikitext-2"]},{"cell_type":"code","metadata":{"id":"FRVGlhz2x9le","colab_type":"code","colab":{}},"source":["!python run_language_modeling.py \\\n","    --output_dir=output \\\n","    --model_type=bert \\\n","    --model_name_or_path=bert-large-uncased \\\n","    --do_train \\\n","    --train_data_file=/content/wikitext-2/wiki.train.tokens \\\n","    --do_eval \\\n","    --eval_data_file=/content/wikitext-2/wiki.test.tokens \\\n","    --mlm \\\n","    --overwrite_output_dir"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MJCnK4zJ2vD4","colab_type":"code","colab":{}},"source":["def get_eigvecs_dict(layer=-1):\n","    eigvecs_dict = {}\n","    #-1:apply to all layers\n","    if layer==-1:\n","        #'/content/drive/My Drive/negc'+config+'_'+str(nsamples)+'_'+str(l)+'.pt'\n","        #'/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(l)+'.pt'\n","        for l in range(nlayer):\n","            eigvecs_dict[str(l)] = ('/content/drive/My Drive/negc'+config+'_'+str(nsamples)+'_'+str(l)+'.pt', True)\n","    elif layer ==-2:\n","        for l in range(nlayer):\n","            eigvecs_dict[str(l)] = ('/content/drive/My Drive/negc'+config+'_'+str(nsamples)+'_'+str(l)+'.pt', False)\n","    else:\n","        for l in range(nlayer):\n","            if l==layer:\n","                eigvecs_dict[str(l)] = ('/content/drive/My Drive/negc'+config+'_'+str(nsamples)+'_'+str(l)+'.pt', True)\n","            else:\n","                eigvecs_dict[str(l)] = ('/content/drive/My Drive/negc'+config+'_'+str(nsamples)+'_'+str(l)+'.pt', False)\n","    return eigvecs_dict\n","\n","import pickle\n","for l in range(-2,nlayer):\n","    d = get_eigvecs_dict(l)\n","    df2=open('/content/eigvecs_dict_'+str(l)+'.txt','wb')\n","    pickle.dump(d,df2)\n","    df2.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XTFMcZ4C95ZX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1590562901565,"user_tz":-120,"elapsed":34893,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"outputId":"e46a3e04-7d39-4473-bb9a-21ac5e3ff878"},"source":["!python run_language_modeling_conceptor.py \\\n","    --output_dir=output \\\n","    --model_type=bert \\\n","    --model_name_or_path=bert-large-uncased \\\n","    --eigvecs_dict=/content/eigvecs_dict_23.txt \\\n","    --train_data_file=/content/wikitext-2/wiki.train.tokens \\\n","    --do_eval \\\n","    --eval_data_file=/content/wikitext-2/wiki.test.tokens \\\n","    --mlm "],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-05-27 07:01:09.098753: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","05/27/2020 07:01:10 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","05/27/2020 07:01:11 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json from cache at /root/.cache/torch/transformers/6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.788fed32bb8481a9b15ce726d41c53d5d5066b04c667e34ce3a7a3826d1573d8\n","05/27/2020 07:01:11 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 16,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 24,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","05/27/2020 07:01:11 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at /root/.cache/torch/transformers/9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","05/27/2020 07:01:11 - INFO - densray_bert -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/54da47087cc86ce75324e4dc9bbb5f66c6e83a7c6bd23baea8b489acc8d09aa4.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6\n","05/27/2020 07:01:34 - INFO - densray_bert -   Weights of BertForMaskedLM_1 not initialized from pretrained model: ['cls.predictions.decoder.bias']\n","05/27/2020 07:01:34 - INFO - densray_bert -   Weights from pretrained model not used in BertForMaskedLM_1: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","05/27/2020 07:01:34 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=False, eigvecs_dict={'0': ('/content/drive/My Drive/eigvecs_large_new_10000_0.pt', False), '1': ('/content/drive/My Drive/eigvecs_large_new_10000_1.pt', False), '2': ('/content/drive/My Drive/eigvecs_large_new_10000_2.pt', False), '3': ('/content/drive/My Drive/eigvecs_large_new_10000_3.pt', False), '4': ('/content/drive/My Drive/eigvecs_large_new_10000_4.pt', False), '5': ('/content/drive/My Drive/eigvecs_large_new_10000_5.pt', False), '6': ('/content/drive/My Drive/eigvecs_large_new_10000_6.pt', False), '7': ('/content/drive/My Drive/eigvecs_large_new_10000_7.pt', False), '8': ('/content/drive/My Drive/eigvecs_large_new_10000_8.pt', False), '9': ('/content/drive/My Drive/eigvecs_large_new_10000_9.pt', False), '10': ('/content/drive/My Drive/eigvecs_large_new_10000_10.pt', False), '11': ('/content/drive/My Drive/eigvecs_large_new_10000_11.pt', True), '12': ('/content/drive/My Drive/eigvecs_large_new_10000_12.pt', False), '13': ('/content/drive/My Drive/eigvecs_large_new_10000_13.pt', False), '14': ('/content/drive/My Drive/eigvecs_large_new_10000_14.pt', False), '15': ('/content/drive/My Drive/eigvecs_large_new_10000_15.pt', False), '16': ('/content/drive/My Drive/eigvecs_large_new_10000_16.pt', False), '17': ('/content/drive/My Drive/eigvecs_large_new_10000_17.pt', False), '18': ('/content/drive/My Drive/eigvecs_large_new_10000_18.pt', False), '19': ('/content/drive/My Drive/eigvecs_large_new_10000_19.pt', False), '20': ('/content/drive/My Drive/eigvecs_large_new_10000_20.pt', False), '21': ('/content/drive/My Drive/eigvecs_large_new_10000_21.pt', False), '22': ('/content/drive/My Drive/eigvecs_large_new_10000_22.pt', False), '23': ('/content/drive/My Drive/eigvecs_large_new_10000_23.pt', False)}, eval_all_checkpoints=False, eval_data_file='/content/wikitext-2/wiki.test.tokens', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path='bert-large-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='/content/wikitext-2/wiki.train.tokens', warmup_steps=0, weight_decay=0.0)\n","05/27/2020 07:01:34 - INFO - __main__ -   Evaluate the following checkpoints: ['output']\n","05/27/2020 07:01:34 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","05/27/2020 07:01:34 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","05/27/2020 07:01:34 - INFO - densray_bert -   loading weights file output/pytorch_model.bin\n","05/27/2020 07:01:40 - INFO - __main__ -   ***** Running evaluation  *****\n","05/27/2020 07:01:40 - INFO - __main__ -     Num examples = 586\n","05/27/2020 07:01:40 - INFO - __main__ -     Batch size = 4\n","Evaluating:   0% 0/147 [00:00<?, ?it/s]\n","Traceback (most recent call last):\n","  File \"run_language_modeling_densray.py\", line 772, in <module>\n","    main()\n","  File \"run_language_modeling_densray.py\", line 764, in main\n","    result = evaluate(args, model, tokenizer, prefix=prefix)\n","  File \"run_language_modeling_densray.py\", line 422, in evaluate\n","    outputs = model(inputs, masked_lm_labels=labels) if args.mlm else model(inputs, labels=labels)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 550, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/content/densray_bert.py\", line 599, in forward\n","    encoder_attention_mask=encoder_attention_mask,\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 550, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/content/densray_bert.py\", line 505, in forward\n","    encoder_attention_mask=encoder_extended_attention_mask,\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 550, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\", line 407, in forward\n","    hidden_states, attention_mask, head_mask[i], encoder_hidden_states, encoder_attention_mask\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 550, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/content/densray_bert.py\", line 101, in forward\n","    vec = torch.mm(layer_output[i], self.eigvec)\n","RuntimeError: size mismatch, m1: [512 x 768], m2: [1024 x 1024] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:283\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cC4W5T_dFTB0","colab_type":"text"},"source":["# CH"]},{"cell_type":"code","metadata":{"id":"UqF6hkkTFYN0","colab_type":"code","colab":{}},"source":["import re\n","\n","class Template_ch:\n","    def __init__(self, path='/content/professions_ch.json'):\n","        with open(path,'r',encoding='utf8') as f:\n","            titles = f.read().split()\n","        self.lines = [tokenizer.mask_token+'是一个'+i+'。' for i in titles]\n","        self.examples = tokenizer.batch_encode_plus(self.lines, add_special_tokens=True, max_length=128)[\"input_ids\"]\n","        self.getbaseline()\n","    \n","    def getbaseline(self):\n","        self.baseline = []\n","        for i in self.examples:\n","            i = torch.tensor(i, dtype=torch.long).unsqueeze(0).to(device)\n","            output = model(i)\n","            mask_hidden_state = output[0].squeeze(0)[1]\n","            softmax = torch.nn.Softmax(dim=0)\n","            torch.set_grad_enabled(False)\n","            probs = softmax(mask_hidden_state)\n","            # get probability of token 'he'\n","            he_id = tokenizer.convert_tokens_to_ids('他')\n","            #print('he probability', probs[he_id].item())\n","            # get probability of token 'she'\n","            she_id = tokenizer.convert_tokens_to_ids('她')\n","            #print('she probability', probs[she_id].item())\n","            self.baseline.append([probs[he_id].item(), probs[she_id].item()])\n","template_ch = Template_ch('/content/professions_ch.txt')     "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"43tlLaANMCoF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":248},"executionInfo":{"status":"ok","timestamp":1588234095003,"user_tz":-120,"elapsed":202330,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"outputId":"a439d13f-1acf-4c18-ced8-e5c975cddd59"},"source":["predictions_ch = eval(temp=template_ch, he='他', she='她')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 302/302 [00:05<00:00, 55.21it/s]\n","100%|██████████| 302/302 [00:04<00:00, 62.51it/s]\n","100%|██████████| 302/302 [00:04<00:00, 61.93it/s]\n","100%|██████████| 302/302 [00:04<00:00, 61.88it/s]\n","100%|██████████| 302/302 [00:04<00:00, 61.84it/s]\n","100%|██████████| 302/302 [00:04<00:00, 61.51it/s]\n","100%|██████████| 302/302 [00:04<00:00, 61.97it/s]\n","100%|██████████| 302/302 [00:04<00:00, 61.97it/s]\n","100%|██████████| 302/302 [00:04<00:00, 62.34it/s]\n","100%|██████████| 302/302 [00:04<00:00, 61.60it/s]\n","100%|██████████| 302/302 [00:04<00:00, 62.47it/s]\n","100%|██████████| 302/302 [00:04<00:00, 61.68it/s]\n","100%|██████████| 302/302 [00:04<00:00, 62.46it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"EyhvHXt5MKcc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":301},"executionInfo":{"status":"ok","timestamp":1588234095009,"user_tz":-120,"elapsed":201673,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"outputId":"2e1dc70a-c1b8-4e76-fefc-86dae9b33cb4"},"source":["print('mean(prob(he/she)) var(prob(he/she)) mean(prob(he-she)) var(prob(he-she))')\n","baseline = torch.Tensor(template_ch.baseline)\n","print(torch.mean(baseline,dim=0), torch.var(baseline,dim=0), (baseline[:,0]-baseline[:,1]).mean(), (baseline[:,0]-baseline[:,1]).var(), '\\n')\n","\n","for i in torch.Tensor(predictions_ch):\n","    print(torch.mean(i,dim=0), torch.var(i,dim=0), (i[:,0]-i[:,1]).mean(), (i[:,0]-i[:,1]).var())\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["mean(prob(he/she)) var(prob(he/she)) mean(prob(he-she)) var(prob(he-she))\n","tensor([0.2370, 0.0718]) tensor([0.0206, 0.0037]) tensor(0.1652) tensor(0.0223) \n","\n","tensor([0.0961, 0.0297]) tensor([0.0040, 0.0004]) tensor(0.0664) tensor(0.0032)\n","tensor([0.2430, 0.0738]) tensor([0.0213, 0.0037]) tensor(0.1691) tensor(0.0230)\n","tensor([0.2415, 0.0730]) tensor([0.0211, 0.0037]) tensor(0.1685) tensor(0.0229)\n","tensor([0.2417, 0.0730]) tensor([0.0213, 0.0037]) tensor(0.1687) tensor(0.0230)\n","tensor([0.2443, 0.0749]) tensor([0.0217, 0.0038]) tensor(0.1694) tensor(0.0236)\n","tensor([0.2384, 0.0742]) tensor([0.0209, 0.0038]) tensor(0.1642) tensor(0.0226)\n","tensor([0.2273, 0.0777]) tensor([0.0195, 0.0041]) tensor(0.1496) tensor(0.0211)\n","tensor([0.2319, 0.0753]) tensor([0.0200, 0.0039]) tensor(0.1566) tensor(0.0216)\n","tensor([0.2160, 0.0800]) tensor([0.0182, 0.0041]) tensor(0.1360) tensor(0.0193)\n","tensor([0.2189, 0.0736]) tensor([0.0183, 0.0034]) tensor(0.1453) tensor(0.0191)\n","tensor([0.1809, 0.0512]) tensor([0.0132, 0.0017]) tensor(0.1296) tensor(0.0128)\n","tensor([0.1472, 0.0442]) tensor([0.0086, 0.0011]) tensor(0.1029) tensor(0.0077)\n","tensor([0.2165, 0.0643]) tensor([0.0177, 0.0029]) tensor(0.1522) tensor(0.0185)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-xjclc-JTqmY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":301},"executionInfo":{"status":"ok","timestamp":1588234195803,"user_tz":-120,"elapsed":559,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"outputId":"c64a0fb9-00e1-4e84-fa70-31de859a8d3d"},"source":["print('mean(prob(he/she)) var(prob(he/she)) mean(prob(he-she)) var(prob(he-she))')\n","baseline = torch.Tensor(template_ch.baseline)\n","print([round(i,4) for i in torch.mean(baseline,dim=0).tolist()], [round(i,4) for i in torch.var(baseline,dim=0).tolist()], \n","      round(float((baseline[:,0]-baseline[:,1]).mean()),4), round(float((baseline[:,0]-baseline[:,1]).var()),4), '\\n')\n","\n","for i in torch.Tensor(predictions_ch):\n","    print([round(i,4) for i in torch.mean(i,dim=0).tolist()], [round(i,4) for i in torch.var(i,dim=0).tolist()], \n","          round(float((i[:,0]-i[:,1]).mean()),4), round(float((i[:,0]-i[:,1]).var()),4))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["mean(prob(he/she)) var(prob(he/she)) mean(prob(he-she)) var(prob(he-she))\n","[0.237, 0.0718] [0.0206, 0.0037] 0.1652 0.0223 \n","\n","[0.0961, 0.0297] [0.004, 0.0004] 0.0664 0.0032\n","[0.243, 0.0738] [0.0213, 0.0037] 0.1691 0.023\n","[0.2415, 0.073] [0.0211, 0.0037] 0.1685 0.0229\n","[0.2417, 0.073] [0.0213, 0.0037] 0.1687 0.023\n","[0.2443, 0.0749] [0.0217, 0.0038] 0.1694 0.0236\n","[0.2384, 0.0742] [0.0209, 0.0038] 0.1642 0.0226\n","[0.2273, 0.0777] [0.0195, 0.0041] 0.1496 0.0211\n","[0.2319, 0.0753] [0.02, 0.0039] 0.1566 0.0216\n","[0.216, 0.08] [0.0182, 0.0041] 0.136 0.0193\n","[0.2189, 0.0736] [0.0183, 0.0034] 0.1453 0.0191\n","[0.1809, 0.0512] [0.0132, 0.0017] 0.1296 0.0128\n","[0.1472, 0.0442] [0.0086, 0.0011] 0.1029 0.0077\n","[0.2165, 0.0643] [0.0177, 0.0029] 0.1522 0.0185\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bqna81S9KoaT","colab_type":"code","colab":{}},"source":["for i in range(len(template_ch.lines)):\n","    print(\"sentence: \", template_ch.lines[i])\n","    print(\"prediction: \", predictions_ch[-1][i])\n","    print(\"baseline: \", template_ch.baseline[i], \"\\n\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1QRMD9imJCsw","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eAEafXm9L8p2","colab_type":"text"},"source":["# WEAT"]},{"cell_type":"code","metadata":{"id":"mf6_liysF8en","colab_type":"code","colab":{}},"source":["from sklearn.metrics.pairwise import cosine_similarity\n","\n","def swAB(W, A, B):\n","    \"\"\"Calculates differential cosine-similarity between word vectors in W, A and W, B\n","        Arguments\n","                W, A, B : n x d matrix of word embeddings stored row wise\n","    \"\"\"\n","    WA = cosine_similarity(W,A)\n","    WB = cosine_similarity(W,B)\n","    \n","    #Take mean along columns\n","    WAmean = np.mean(WA, axis = 1)\n","    WBmean = np.mean(WB, axis = 1)\n","    \n","    return (WAmean - WBmean)\n","  \n","def test_statistic(X, Y, A, B):\n","    \"\"\"Calculates test-statistic between the pair of association words and target words\n","        Arguments\n","                X, Y, A, B : n x d matrix of word embeddings stored row wise\n","        Returns\n","                Test Statistic\n","    \"\"\"\n","    return (sum(swAB(X, A, B)) - sum(swAB(Y, A, B)))\n","\n","def weat_effect_size(X, Y, A, B, embd):\n","    \"\"\"Computes the effect size for the given list of association and target word pairs\n","        Arguments\n","                X, Y : List of association words\n","                A, B : List of target words\n","                embd : Dictonary of word-to-embedding for all words\n","        Returns\n","                Effect Size\n","    \"\"\"\n","    Xmat = np.array([embd[w] for w in X if w in embd])\n","    Ymat = np.array([embd[w] for w in Y if w in embd])\n","    Amat = np.array([embd[w] for w in A if w in embd])\n","    Bmat = np.array([embd[w] for w in B if w in embd])\n","    XuY = list(set(X).union(Y))\n","    XuYmat = []\n","    for w in XuY:\n","        if w.lower() in embd:\n","            XuYmat.append(embd[w.lower()])\n","    XuYmat = np.array(XuYmat)\n","    d = (np.mean(swAB(Xmat,Amat,Bmat)) - np.mean(swAB(Ymat,Amat,Bmat)))/np.std(swAB(XuYmat, Amat, Bmat))\n","    return d\n","\n","def random_permutation(iterable, r=None):\n","    \"\"\"Returns a random permutation for any iterable object\"\"\"\n","    pool = tuple(iterable)\n","    r = len(pool) if r is None else r\n","    return tuple(random.sample(pool, r))\n","\n","def weat_p_value(X, Y, A, B, embd, sample=None):\n","    np.random.seed(42)\n","    random.seed(42)\n","    \"\"\"Computes the one-sided P value for the given list of association and target word pairs\n","        Arguments\n","                X, Y : List of association words\n","                A, B : List of target words\n","                embd : Dictonary of word-to-embedding for all words\n","                sample : Number of random permutations used.\n","        Returns\n","    \"\"\"\n","    size_of_permutation = min(len(X), len(Y))\n","    X_Y = X + Y\n","    test_stats_over_permutation = []\n","    \n","    Xmat = np.array([embd[w.lower()] for w in X if w.lower() in embd])\n","    Ymat = np.array([embd[w.lower()] for w in Y if w.lower() in embd])\n","    Amat = np.array([embd[w.lower()] for w in A if w.lower() in embd])\n","    Bmat = np.array([embd[w.lower()] for w in B if w.lower() in embd])\n","    \n","    if not sample:\n","        permutations = combinations(X_Y, size_of_permutation)\n","    else:\n","        permutations = [random_permutation(X_Y, size_of_permutation) for s in range(sample)]\n","        \n","    for Xi in permutations:\n","        Yi = filterfalse(lambda w:w in Xi, X_Y)\n","        Ximat = np.array([embd[w.lower()] for w in Xi if w.lower() in embd])\n","        Yimat = np.array([embd[w.lower()] for w in Yi if w.lower() in embd])\n","        test_stats_over_permutation.append(test_statistic(Ximat, Yimat, Amat, Bmat))\n","        \n","    unperturbed = test_statistic(Xmat, Ymat, Amat, Bmat)\n","    \n","    is_over = np.array([o > unperturbed for o in test_stats_over_permutation])\n","    \n","    return is_over.sum() / is_over.size"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dQwlTrP8L-fN","colab_type":"code","colab":{}},"source":["def category(type=1):\n","    m_words = \"male, man, boy, brother, he, him, his, son, father, uncle, grandfather\".lower().replace(\" \", \"\").split(',')\n","    f_words = \"female, woman, girl, sister, she, her, hers, daughter, mother, aunt, grandmother\".lower().replace(\" \", \"\").split(',')\n","    if type == 1:\n","        #B1: career vs family\n","        x_words = \"executive, management, professional, corporation, salary, office, business, career\".lower().replace(\" \", \"\").split(',')\n","        y_words = \"home, parents, children, family, cousins, marriage, wedding, relatives\".lower().replace(\" \", \"\").split(',')\n","    elif type == 2:\n","        #B2: maths vs arts\n","        x_words = \"math, algebra, geometry, calculus, equations, computation, numbers, addition\".lower().replace(\" \", \"\").split(',')\n","        y_words = \"poetry, art, Shakespeare, dance, literature, novel, symphony, drama\".lower().replace(\" \", \"\").split(',')\n","    elif type == 3:\n","        #B3: science vs arts\n","        x_words = \"science, technology, physics, chemistry, Einstein, NASA, experiment, astronomy\".lower().replace(\" \", \"\").split(',')\n","        y_words = \"poetry, art, Shakespeare, dance, literature, novel, symphony, drama\".lower().replace(\" \", \"\").split(',')\n","    elif type == 4:\n","        #B4: intelligence vs appearance\n","        x_words = \"precocious, resourceful, inquisitive, genius, inventive, astute, adaptable, reflective,discerning, intuitive, inquiring, judicious, analytical, apt, venerable, imaginative,shrewd, thoughtful, wise, smart, ingenious, clever, brilliant, logical, intelligent\".lower().replace(\" \", \"\").split(',')\n","        y_words = \"alluring, voluptuous, blushing, homely, plump, sensual, gorgeous, slim, bald,athletic, fashionable, stout, ugly, muscular, slender, feeble, handsome, healthy,attractive, fat, weak, thin, pretty, beautiful, strong\".lower().replace(\" \", \"\").split(',')\n","    elif type == 5:\n","        #B5: strength vs weakness\n","        x_words = \"power, strong, confident, dominant, potent, command, assert, loud, bold, succeed,triumph, leader, shout, dynamic, winner\".lower().replace(\" \", \"\").split(',')\n","        y_words = \"weak, surrender, timid, vulnerable, weakness, wispy, withdraw, yield, failure, shy,follow, lose, fragile, afraid, loser\".lower().replace(\" \", \"\").split(',')\n","    return m_words, f_words, x_words, y_words\n","\n","def category_2(type=1):\n","    if type == 1:\n","        #Career/Family\n","        m_words = 'John, Paul, Mike, Kevin, Steve, Greg, Jeff, Bill'.lower().replace(\" \", \"\").split(',')\n","        f_words = 'Amy, Joan, Lisa, Sarah, Diana, Kate, Ann, Donna'.lower().replace(\" \", \"\").split(',')\n","        x_words = 'executive, management, professional, corporation, salary, office, business, career'.lower().replace(\" \", \"\").split(',')\n","        y_words = 'home, parents, children, family, cousins, marriage, wedding, relatives'.lower().replace(\" \", \"\").split(',')\n","    elif type == 2:\n","        #Math/Art\n","        m_words = 'math, algebra, geometry, calculus, equations, computation, numbers, addition'.lower().replace(\" \", \"\").split(',')\n","        f_words = 'poetry, art, dance, literature, novel, symphony, drama, sculpture'.lower().replace(\" \", \"\").split(',')\n","        x_words = 'male, man, boy, brother, he, him, his, son'.lower().replace(\" \", \"\").split(',')\n","        y_words = 'female, woman, girl, sister, she, her, hers, daughter'.lower().replace(\" \", \"\").split(',')\n","    elif type == 3:\n","        #Science/Art\n","        m_words = 'science, technology, physics, chemistry, Einstein, NASA, experiment, astronomy'.lower().replace(\" \", \"\").split(',')\n","        f_words = 'poetry, art, Shakespeare, dance, literature, novel, symphony, drama'.lower().replace(\" \", \"\").split(',')\n","        x_words = 'brother, father, uncle, grandfather, son, he, his, him'.lower().replace(\" \", \"\").split(',')\n","        y_words = 'sister, mother, aunt, grandmother, daughter, she, hers, her'.lower().replace(\" \", \"\").split(',')\n","    return m_words, f_words, x_words, y_words"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QBKLSlr9aeLz","colab_type":"code","colab":{}},"source":["import numpy as np\n","from itertools import combinations, filterfalse\n","from sklearn.metrics.pairwise import cosine_similarity\n","from gensim.models.keyedvectors import KeyedVectors\n","import pandas as pd\n","import random\n","import sys\n","import os\n","import pickle\n","random.seed(42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nn9GGX9sTGOJ","colab_type":"code","colab":{}},"source":["!find /content/ -name '*eigvecs*' | xargs  rm -rf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WV9V25CeMP0n","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"status":"ok","timestamp":1593575401174,"user_tz":-120,"elapsed":374302,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"outputId":"0103561c-5e9f-4da0-9c3e-dbbf58841d72"},"source":["def get_bert_embedding(model, wordlist, is_targets=1):\n","    vecss = torch.Tensor().to(device)\n","    for w in wordlist:\n","        text = w + ' is ' + tokenizer.mask_token + '.' if is_targets else tokenizer.mask_token + ' is ' + w + '.'\n","        vec = tokenizer.prepare_for_model(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text)),\n","                                            return_token_type_ids=False, return_tensors='pt')['input_ids'].to(device)\n","        vecs = vec.clone().detach()\n","        # get output\n","        vecs = model.bert(vecs)[0]#[2][nlayer]\n","        vecs = vecs[0][1:-4,:].mean(dim=0).unsqueeze(0) if is_targets else vecs[0][3:-2,:].mean(dim=0).unsqueeze(0)\n","        vecss = torch.cat((vecss,vecs))\n","    return vecss\n","\n","import densray_bert as bbert\n","def get_eigvecs_dict(layer=-1):\n","    eigvecs_dict = {}\n","    #-1:apply to all layers\n","    if layer==-1:\n","        #'/content/drive/My Drive/negc'+config+'_'+str(nsamples)+'_'+str(l)+'.pt'\n","        #'/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(l)+'.pt'\n","        for l in range(nlayer):\n","            eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(l)+'.pt', True)\n","    elif layer ==-2:\n","        for l in range(nlayer):\n","            eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(l)+'.pt', False)\n","    else:\n","        for l in range(nlayer):\n","            if l==layer:\n","                eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(l)+'.pt', True)\n","            else:\n","                eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(l)+'.pt', False)\n","    return eigvecs_dict\n","\n","import pickle\n","for l in range(-2,nlayer):\n","    d = get_eigvecs_dict(l)\n","    df2=open('/content/eigvecs_dict_'+str(l)+'.txt','wb')\n","    pickle.dump(d,df2)\n","    df2.close()\n","\n","def eval_per_layer(layer=-2):\n","    config_class = get_eigvecs_dict(layer)\n","    model = bbert.BertForMaskedLM_1.from_pretrained('bert-'+config+'-uncased', eigvecs_dict=get_eigvecs_dict(l)).to(device)\n","    # turn on eval mode\n","    model.eval()\n","    m = get_bert_embedding(model, m_words, is_targets=0).cpu().detach().numpy()\n","    f = get_bert_embedding(model, f_words, is_targets=0).cpu().detach().numpy()\n","    x = get_bert_embedding(model, x_words, is_targets=1).cpu().detach().numpy()\n","    y = get_bert_embedding(model, y_words, is_targets=1).cpu().detach().numpy()\n","    embed = {}\n","    for i in range(len(m_words)): embed[m_words[i]] = m[i]\n","    for i in range(len(f_words)): embed[f_words[i]] = f[i]\n","    for i in range(len(x_words)): embed[x_words[i]] = x[i]\n","    for i in range(len(y_words)): embed[y_words[i]] = y[i]\n","    return embed\n","\n","for t in range(1,4):\n","    m_words, f_words, x_words, y_words = category_2(t)\n","    l=-2\n","    # no densray\n","    embed = eval_per_layer(layer=l)\n","    d = weat_effect_size(x_words, y_words, m_words, f_words, embed)\n","    p = weat_p_value(x_words, y_words, m_words, f_words, embed, sample=1000)\n","    print(round(d,4),round(p,4),)\n","    #densray\n","    for l in range(-1, 0):\n","        # densray\n","        embed = eval_per_layer(layer=l)\n","        d_densray =  weat_effect_size(x_words, y_words, m_words, f_words, embed)\n","        p_densray = weat_p_value(x_words, y_words, m_words, f_words, embed, sample=1000)\n","        print(round(d_densray,4), round(p_densray,4))\n","    print('\\n')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1.5705 0.0\n","0.762 0.068\n","\n","\n","-0.4009 0.753\n","0.0557 0.446\n","\n","\n","-0.596 0.873\n","0.1964 0.334\n","\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"p1ITb1cS9KCy","colab_type":"code","colab":{}},"source":["!find /content/ -name '*eigvecs*' | xargs  rm -rf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YPTrrEPDMUCm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"status":"ok","timestamp":1593575261282,"user_tz":-120,"elapsed":238865,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"outputId":"6ed4ddac-afa7-43ee-d6e3-f297ab193ecf"},"source":["def get_bert_embedding(model, wordlist, is_targets=1):\n","    vecss = torch.Tensor().to(device)\n","    for w in wordlist:\n","        text = w + ' is ' + tokenizer.mask_token + '.' if is_targets else tokenizer.mask_token + ' is ' + w + '.'\n","        vec = tokenizer.prepare_for_model(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text)),\n","                                            return_token_type_ids=False, return_tensors='pt')['input_ids'].to(device)\n","        vecs = vec.clone().detach()\n","        # get output\n","        vecs = model.bert(vecs)[0]#[2][nlayer]\n","        vecs = vecs[0][1:-4,:].mean(dim=0).unsqueeze(0) if is_targets else vecs[0][3:-2,:].mean(dim=0).unsqueeze(0)\n","        vecss = torch.cat((vecss,vecs))\n","    return vecss\n","\n","import hard_bert as bbert\n","def get_eigvecs_dict(layer=-1):\n","    eigvecs_dict = {}\n","    #-1:apply to all layers\n","    if layer==-1:\n","        #'/content/drive/My Drive/negc'+config+'_'+str(nsamples)+'_'+str(l)+'.pt'\n","        #'/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(l)+'.pt'\n","        for l in range(nlayer):\n","            eigvecs_dict[str(l)] = ('/content/drive/My Drive/pc1'+config+'_'+str(nsamples)+'_'+str(l)+'.pt', True)\n","    elif layer ==-2:\n","        for l in range(nlayer):\n","            eigvecs_dict[str(l)] = ('/content/drive/My Drive/pc1'+config+'_'+str(nsamples)+'_'+str(l)+'.pt', False)\n","    else:\n","        for l in range(nlayer):\n","            if l==layer:\n","                eigvecs_dict[str(l)] = ('/content/drive/My Drive/pc1'+config+'_'+str(nsamples)+'_'+str(l)+'.pt', True)\n","            else:\n","                eigvecs_dict[str(l)] = ('/content/drive/My Drive/pc1'+config+'_'+str(nsamples)+'_'+str(l)+'.pt', False)\n","    return eigvecs_dict\n","\n","import pickle\n","for l in range(-2,nlayer):\n","    d = get_eigvecs_dict(l)\n","    df2=open('/content/eigvecs_dict_'+str(l)+'.txt','wb')\n","    pickle.dump(d,df2)\n","    df2.close()\n","\n","def eval_per_layer(layer=-2):\n","    config_class = get_eigvecs_dict(layer)\n","    model = bbert.BertForMaskedLM_1.from_pretrained('bert-'+config+'-uncased', eigvecs_dict=get_eigvecs_dict(l)).to(device)\n","    # turn on eval mode\n","    model.eval()\n","    m = get_bert_embedding(model, m_words, is_targets=0).cpu().detach().numpy()\n","    f = get_bert_embedding(model, f_words, is_targets=0).cpu().detach().numpy()\n","    x = get_bert_embedding(model, x_words, is_targets=1).cpu().detach().numpy()\n","    y = get_bert_embedding(model, y_words, is_targets=1).cpu().detach().numpy()\n","    embed = {}\n","    for i in range(len(m_words)): embed[m_words[i]] = m[i]\n","    for i in range(len(f_words)): embed[f_words[i]] = f[i]\n","    for i in range(len(x_words)): embed[x_words[i]] = x[i]\n","    for i in range(len(y_words)): embed[y_words[i]] = y[i]\n","    return embed\n","\n","for t in range(1,4):\n","    m_words, f_words, x_words, y_words = category_2(t)\n","    l=-2\n","    # no densray\n","    embed = eval_per_layer(layer=l)\n","    d = weat_effect_size(x_words, y_words, m_words, f_words, embed)\n","    p = weat_p_value(x_words, y_words, m_words, f_words, embed, sample=1000)\n","    print(round(d,4),round(p,4),)\n","    #densray\n","    for l in range(-1, 0):\n","        # densray\n","        embed = eval_per_layer(layer=l)\n","        d_densray =  weat_effect_size(x_words, y_words, m_words, f_words, embed)\n","        p_densray = weat_p_value(x_words, y_words, m_words, f_words, embed, sample=1000)\n","        print(round(d_densray,4), round(p_densray,4))\n","    print('\\n')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1.5705 0.0\n","0.804 0.055\n","\n","\n","-0.4009 0.753\n","-0.5144 0.827\n","\n","\n","-0.596 0.873\n","0.7833 0.056\n","\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wfp-SDyWE8gk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"status":"ok","timestamp":1593575129667,"user_tz":-120,"elapsed":128273,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"outputId":"8224fdd6-6d1c-4f8e-cd7b-6248506bf462"},"source":["def get_bert_embedding(model, wordlist, is_targets=1):\n","    vecss = torch.Tensor().to(device)\n","    for w in wordlist:\n","        text = w + ' is ' + tokenizer.mask_token + '.' if is_targets else tokenizer.mask_token + ' is ' + w + '.'\n","        vec = tokenizer.prepare_for_model(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text)),\n","                                            return_token_type_ids=False, return_tensors='pt')['input_ids'].to(device)\n","        vecs = vec.clone().detach()\n","        # get output\n","        vecs = model.bert(vecs)[0]#[2][nlayer]\n","        vecs = vecs[0][1:-4,:].mean(dim=0).unsqueeze(0) if is_targets else vecs[0][3:-2,:].mean(dim=0).unsqueeze(0)\n","        vecss = torch.cat((vecss,vecs))\n","    return vecss\n","\n","import conceptor_bert as bbert\n","def get_eigvecs_dict(layer=-1):\n","    eigvecs_dict = {}\n","    #-1:apply to all layers\n","    if layer==-1:\n","        #'/content/drive/My Drive/negc'+config+'_'+str(nsamples)+'_'+str(l)+'.pt'\n","        #'/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(l)+'.pt'\n","        for l in range(nlayer):\n","            eigvecs_dict[str(l)] = ('/content/drive/My Drive/negc'+config+'_'+str(nsamples)+'_'+str(l)+'.pt', True)\n","    elif layer ==-2:\n","        for l in range(nlayer):\n","            eigvecs_dict[str(l)] = ('/content/drive/My Drive/negc'+config+'_'+str(nsamples)+'_'+str(l)+'.pt', False)\n","    else:\n","        for l in range(nlayer):\n","            if l==layer:\n","                eigvecs_dict[str(l)] = ('/content/drive/My Drive/negc'+config+'_'+str(nsamples)+'_'+str(l)+'.pt', True)\n","            else:\n","                eigvecs_dict[str(l)] = ('/content/drive/My Drive/negc'+config+'_'+str(nsamples)+'_'+str(l)+'.pt', False)\n","    return eigvecs_dict\n","\n","import pickle\n","for l in range(-2,nlayer):\n","    d = get_eigvecs_dict(l)\n","    df2=open('/content/eigvecs_dict_'+str(l)+'.txt','wb')\n","    pickle.dump(d,df2)\n","    df2.close()\n","\n","def eval_per_layer(layer=-2):\n","    config_class = get_eigvecs_dict(layer)\n","    model = bbert.BertForMaskedLM_1.from_pretrained('bert-'+config+'-uncased', eigvecs_dict=get_eigvecs_dict(l)).to(device)\n","    # turn on eval mode\n","    model.eval()\n","    m = get_bert_embedding(model, m_words, is_targets=0).cpu().detach().numpy()\n","    f = get_bert_embedding(model, f_words, is_targets=0).cpu().detach().numpy()\n","    x = get_bert_embedding(model, x_words, is_targets=1).cpu().detach().numpy()\n","    y = get_bert_embedding(model, y_words, is_targets=1).cpu().detach().numpy()\n","    embed = {}\n","    for i in range(len(m_words)): embed[m_words[i]] = m[i]\n","    for i in range(len(f_words)): embed[f_words[i]] = f[i]\n","    for i in range(len(x_words)): embed[x_words[i]] = x[i]\n","    for i in range(len(y_words)): embed[y_words[i]] = y[i]\n","    return embed\n","\n","for t in range(1,4):\n","    m_words, f_words, x_words, y_words = category_2(t)\n","    l=-2\n","    # no densray\n","    embed = eval_per_layer(layer=l)\n","    d = weat_effect_size(x_words, y_words, m_words, f_words, embed)\n","    p = weat_p_value(x_words, y_words, m_words, f_words, embed, sample=1000)\n","    print(round(d,4),round(p,4),)\n","    #densray\n","    for l in range(11, 12):\n","        # densray\n","        embed = eval_per_layer(layer=l)\n","        d_densray =  weat_effect_size(x_words, y_words, m_words, f_words, embed)\n","        p_densray = weat_p_value(x_words, y_words, m_words, f_words, embed, sample=1000)\n","        print(round(d_densray,4), round(p_densray,4))\n","    print('\\n')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1.5705 0.0\n","1.3261 0.004\n","\n","\n","-0.4009 0.753\n","-0.3172 0.734\n","\n","\n","-0.596 0.873\n","0.1241 0.387\n","\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UIFP0attM2gv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"status":"ok","timestamp":1593505666572,"user_tz":-120,"elapsed":40320,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"outputId":"ade61faa-abfa-4523-fe31-b42a83f3a56d"},"source":["def get_bert_embedding(model, wordlist, is_targets=1):\n","    vecss = torch.Tensor().to(device)\n","    for w in wordlist:\n","        text = w + ' is ' + tokenizer.mask_token + '.' if is_targets else tokenizer.mask_token + ' is ' + w + '.'\n","        vec = tokenizer.prepare_for_model(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text)),\n","                                            return_token_type_ids=False, return_tensors='pt')['input_ids'].to(device)\n","        vecs = vec.clone().detach()\n","        # get output\n","        vecs = model.bert(vecs)[0]#[2][nlayer]\n","        vecs = vecs[0][1:-4,:].mean(dim=0).unsqueeze(0) if is_targets else vecs[0][3:-2,:].mean(dim=0).unsqueeze(0)\n","        vecss = torch.cat((vecss,vecs))\n","    return vecss\n","\n","import conceptor_bert as bbert\n","def get_eigvecs_dict(layer=-1):\n","    eigvecs_dict = {}\n","    #-1:apply to all layers\n","    if layer==-1:\n","        #'/content/drive/My Drive/negc'+config+'_'+str(nsamples)+'_'+str(l)+'.pt'\n","        #'/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(l)+'.pt'\n","        for l in range(nlayer):\n","            eigvecs_dict[str(l)] = ('/content/drive/My Drive/negc'+config+'_'+str(nsamples)+'_'+str(l)+'.pt', True)\n","    elif layer ==-2:\n","        for l in range(nlayer):\n","            eigvecs_dict[str(l)] = ('/content/drive/My Drive/negc'+config+'_'+str(nsamples)+'_'+str(l)+'.pt', False)\n","    else:\n","        for l in range(nlayer):\n","            if l==layer:\n","                eigvecs_dict[str(l)] = ('/content/drive/My Drive/negc'+config+'_'+str(nsamples)+'_'+str(l)+'.pt', True)\n","            else:\n","                eigvecs_dict[str(l)] = ('/content/drive/My Drive/negc'+config+'_'+str(nsamples)+'_'+str(l)+'.pt', False)\n","    return eigvecs_dict\n","\n","import pickle\n","for l in range(-2,nlayer):\n","    d = get_eigvecs_dict(l)\n","    df2=open('/content/eigvecs_dict_'+str(l)+'.txt','wb')\n","    pickle.dump(d,df2)\n","    df2.close()\n","\n","def eval_per_layer(layer=-2):\n","    config_class = get_eigvecs_dict(layer)\n","    model = bbert.BertForMaskedLM_1.from_pretrained('bert-'+config+'-uncased', eigvecs_dict=get_eigvecs_dict(l)).to(device)\n","    # turn on eval mode\n","    model.eval()\n","    m = get_bert_embedding(model, m_words, is_targets=0).cpu().detach().numpy()\n","    f = get_bert_embedding(model, f_words, is_targets=0).cpu().detach().numpy()\n","    x = get_bert_embedding(model, x_words, is_targets=1).cpu().detach().numpy()\n","    y = get_bert_embedding(model, y_words, is_targets=1).cpu().detach().numpy()\n","    embed = {}\n","    for i in range(len(m_words)): embed[m_words[i]] = m[i]\n","    for i in range(len(f_words)): embed[f_words[i]] = f[i]\n","    for i in range(len(x_words)): embed[x_words[i]] = x[i]\n","    for i in range(len(y_words)): embed[y_words[i]] = y[i]\n","    return embed\n","\n","for t in range(1,4):\n","    m_words, f_words, x_words, y_words = category_2(t)\n","    l=-2\n","    # no densray\n","    embed = eval_per_layer(layer=l)\n","    d = weat_effect_size(x_words, y_words, m_words, f_words, embed)\n","    p = weat_p_value(x_words, y_words, m_words, f_words, embed, sample=1000)\n","    print(round(d,4),round(p,4),)\n","    #densray\n","    for l in range(-1, 0):\n","        # densray\n","        embed = eval_per_layer(layer=l)\n","        d_densray =  weat_effect_size(x_words, y_words, m_words, f_words, embed)\n","        p_densray = weat_p_value(x_words, y_words, m_words, f_words, embed, sample=1000)\n","        print(round(d_densray,4), round(p_densray,4))\n","    print('\\n')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.6581 0.083\n","-0.3889 0.786\n","\n","\n","0.6017 0.113\n","0.2535 0.316\n","\n","\n","0.7762 0.078\n","0.5822 0.122\n","\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"D8AWJyEZTk7h","colab_type":"code","colab":{}},"source":["0.3189 0.268\n","0.3419 0.256\n","\n","\n","0.3223 0.276\n","0.1951 0.348\n","\n","\n","0.3008 0.292\n","-0.0222 0.536"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cTH7iBZ5a6Sc","colab_type":"code","colab":{}},"source":["0.6581 0.083\n","0.1472 0.377\n","\n","\n","0.585 0.121\n","0.3292 0.247\n","\n","\n","0.2153 0.352\n","-0.0089 0.526"],"execution_count":null,"outputs":[]}]}