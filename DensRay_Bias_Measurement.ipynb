{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DensRay_Bias_Measurement.ipynb","provenance":[{"file_id":"1kucQWqQDONbcXtYGg5Y0L_AI90pl2u6K","timestamp":1592289410481},{"file_id":"1QsCRMwPNffdfgjR_jvW3O83h2uyiGxi4","timestamp":1589947460129},{"file_id":"14320o-9-uc0nsejqTeNe66uhFYw4QSU9","timestamp":1589939467638},{"file_id":"1ePa9C1bq3wS5WByfi8L9hCBGqtl2HhWu","timestamp":1588134391908},{"file_id":"1c__r6mWy4-vOfdfL4tmqij72Qayz2yHY","timestamp":1586403317137},{"file_id":"1OCwvXO9cB1Ke5Bi11SvjovgCKDh6iE6M","timestamp":1586403087992},{"file_id":"1tgzcbuJrxhBeC6FnQig4Z8RLj3TD2Y-p","timestamp":1586402323174},{"file_id":"1gnY3Blunw8HAUxw8wAFCzirazvafbmQn","timestamp":1586399576485},{"file_id":"1GHdeIzOlLZLZ2RN2MohSwBfpWuNi1ogN","timestamp":1583364612376},{"file_id":"1BA0JTleU0JVbJjgrXw5ULWcTa5Nl5sGb","timestamp":1583315004957},{"file_id":"1xWrKImFLCBga34NpEp9EoaMc2AfUPXIK","timestamp":1583286864919}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"2304075d054749e3a883d7c80fbd57b7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_84e7517e44644f79a20d88818dc10c2a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3217e3a8d3934590a9c3ef1d8e5b36eb","IPY_MODEL_f14fdbfba74b4b5fb2b9d01ac1818d97"]}},"84e7517e44644f79a20d88818dc10c2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3217e3a8d3934590a9c3ef1d8e5b36eb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ac480a834dbf4467aa4ca4274935e965","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":433,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":433,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_84c49ec063734ff3b66595d7cfee1ffc"}},"f14fdbfba74b4b5fb2b9d01ac1818d97":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0b8741d3d1df4af781a2bcf028ead245","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 433/433 [00:30&lt;00:00, 14.2B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a7b416e5953c4cc58978f10726cff5a9"}},"ac480a834dbf4467aa4ca4274935e965":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"84c49ec063734ff3b66595d7cfee1ffc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0b8741d3d1df4af781a2bcf028ead245":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a7b416e5953c4cc58978f10726cff5a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5eb051f8fbeb42d99e41a6c7e1d7bc41":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_27a4615064ad47539bfcddbd3e323284","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a2d5cce6d7834e05beb7e2d9ac980985","IPY_MODEL_93aaad5fdcd14f3fa5df2875626ed8fe"]}},"27a4615064ad47539bfcddbd3e323284":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a2d5cce6d7834e05beb7e2d9ac980985":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3ebaa37cd7d34621811365949f0bc06d","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":440473133,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440473133,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3d5ca8b7dc87403cb23d5f1702dc8fed"}},"93aaad5fdcd14f3fa5df2875626ed8fe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d799ce0d3c28446c9b988b09d3f3265e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 440M/440M [00:08&lt;00:00, 50.6MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_be4d7aa70d364b2daeecbe4b8e65fb05"}},"3ebaa37cd7d34621811365949f0bc06d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3d5ca8b7dc87403cb23d5f1702dc8fed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d799ce0d3c28446c9b988b09d3f3265e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"be4d7aa70d364b2daeecbe4b8e65fb05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cc7a1a4800d64f9a929dd7c2456cdea0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f1f372bff0944277892454bcb50e6456","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4c7940b142d149e4873957bcb39ea9da","IPY_MODEL_1ea0911aabb8413c944a82638712d7a0"]}},"f1f372bff0944277892454bcb50e6456":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4c7940b142d149e4873957bcb39ea9da":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_29123d15b1d646f689bb11692edb5ae3","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_77ab6758327b434aadbafc14f4f7990f"}},"1ea0911aabb8413c944a82638712d7a0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4b1dc6d8cb7249c5909cbb18b3098f33","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 1.62MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_64991fc0c32d4786b67350b559b26c29"}},"29123d15b1d646f689bb11692edb5ae3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"77ab6758327b434aadbafc14f4f7990f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4b1dc6d8cb7249c5909cbb18b3098f33":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"64991fc0c32d4786b67350b559b26c29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"q2O3yi9gUjY-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":665},"executionInfo":{"status":"ok","timestamp":1593597688427,"user_tz":-120,"elapsed":8196,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"outputId":"c8c8882b-e64a-4222-cb4e-7d792d3b7bea"},"source":["!pip install transformers==2.8.0"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting transformers==2.8.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n","\r\u001b[K     |▋                               | 10kB 27.2MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 2.1MB/s eta 0:00:01\r\u001b[K     |█▊                              | 30kB 2.8MB/s eta 0:00:01\r\u001b[K     |██▎                             | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |███                             | 51kB 2.5MB/s eta 0:00:01\r\u001b[K     |███▌                            | 61kB 2.8MB/s eta 0:00:01\r\u001b[K     |████                            | 71kB 3.1MB/s eta 0:00:01\r\u001b[K     |████▋                           | 81kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 92kB 3.6MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 102kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 112kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████                         | 122kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 133kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 143kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 153kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 163kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 174kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 184kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 194kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 204kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 215kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 225kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 235kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 245kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 256kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 266kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 276kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 286kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 296kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 307kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 317kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 327kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 337kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 348kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 358kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 368kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 378kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 389kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 399kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 409kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 419kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 430kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 440kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 450kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 460kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 471kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 481kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 491kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 501kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 512kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 522kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 532kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 542kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 552kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 563kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 573kB 3.5MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.7)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.18.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (4.41.1)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 16.5MB/s \n","\u001b[?25hCollecting tokenizers==0.5.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n","\u001b[K     |████████████████████████████████| 3.7MB 24.6MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (3.0.12)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2.23.0)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.14.9)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2019.12.20)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 45.8MB/s \n","\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2.9)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (0.3.3)\n","Requirement already satisfied: botocore<1.18.0,>=1.17.9 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (1.17.9)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (0.10.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (0.15.1)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.9->boto3->transformers==2.8.0) (2.8.1)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.9->boto3->transformers==2.8.0) (0.15.2)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=ecb59cfabf1f0bb2dd62a515a8d3af232275bd7ce40119993b170f5e4200abcc\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.5.2 transformers-2.8.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ikGXqkSQDCwH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1593597712192,"user_tz":-120,"elapsed":30898,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"outputId":"454ba5f8-e091-461a-d255-4a12e7561710"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5rMiCKAusFtK","colab_type":"text"},"source":["# Config"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lyUbLYhu3m4b","scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["2304075d054749e3a883d7c80fbd57b7","84e7517e44644f79a20d88818dc10c2a","3217e3a8d3934590a9c3ef1d8e5b36eb","f14fdbfba74b4b5fb2b9d01ac1818d97","ac480a834dbf4467aa4ca4274935e965","84c49ec063734ff3b66595d7cfee1ffc","0b8741d3d1df4af781a2bcf028ead245","a7b416e5953c4cc58978f10726cff5a9","5eb051f8fbeb42d99e41a6c7e1d7bc41","27a4615064ad47539bfcddbd3e323284","a2d5cce6d7834e05beb7e2d9ac980985","93aaad5fdcd14f3fa5df2875626ed8fe","3ebaa37cd7d34621811365949f0bc06d","3d5ca8b7dc87403cb23d5f1702dc8fed","d799ce0d3c28446c9b988b09d3f3265e","be4d7aa70d364b2daeecbe4b8e65fb05","cc7a1a4800d64f9a929dd7c2456cdea0","f1f372bff0944277892454bcb50e6456","4c7940b142d149e4873957bcb39ea9da","1ea0911aabb8413c944a82638712d7a0","29123d15b1d646f689bb11692edb5ae3","77ab6758327b434aadbafc14f4f7990f","4b1dc6d8cb7249c5909cbb18b3098f33","64991fc0c32d4786b67350b559b26c29"]},"executionInfo":{"status":"ok","timestamp":1593597748010,"user_tz":-120,"elapsed":36610,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"outputId":"6778a5f0-b3c3-43de-d0ff-60b4f146ea10"},"source":["import torch\n","import transformers\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","config = 'base'\n","nlayer = 12 if config == 'base' else 24\n","nsamples = 5000 if config == 'base' else 10000\n","\n","model = transformers.BertForMaskedLM.from_pretrained('bert-'+config+'-uncased', output_hidden_states=True).to(device)\n","tokenizer = transformers.BertTokenizer.from_pretrained('bert-'+config+'-uncased')\n","# turn on eval mode\n","model.eval()"],"execution_count":4,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2304075d054749e3a883d7c80fbd57b7","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5eb051f8fbeb42d99e41a6c7e1d7bc41","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cc7a1a4800d64f9a929dd7c2456cdea0","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["BertForMaskedLM(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (cls): BertOnlyMLMHead(\n","    (predictions): BertLMPredictionHead(\n","      (transform): BertPredictionHeadTransform(\n","        (dense): Linear(in_features=768, out_features=768, bias=True)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      )\n","      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n","    )\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"azdjJRdSsVsC","colab_type":"text"},"source":["# Templates"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6kYCoJcaL1j0","colab":{}},"source":["import re\n","\n","class Template_log:\n","    def __init__(self, path='/content/drive/My Drive/professions.json'):\n","        with open(path,'r',encoding='utf8') as f:\n","            titles = re.sub('[^a-z_]',' ',f.read()).split()\n","        self.lines_prior = [re.sub('_',' ',tokenizer.mask_token+' is a '+tokenizer.mask_token+' .')]\n","        self.examples_prior = tokenizer.batch_encode_plus(self.lines_prior, add_special_tokens=True, max_length=128)[\"input_ids\"]\n","        self.getbaseline()\n","    \n","    def getbaseline(self):\n","        def get_probs(example=self.examples_prior):\n","            baseline = []\n","            for i in example:\n","                i = torch.tensor(i, dtype=torch.long).unsqueeze(0).to(device)\n","                output = model(i)\n","                mask_hidden_state = output[0].squeeze(0)[1]\n","                softmax = torch.nn.Softmax(dim=0)\n","                torch.set_grad_enabled(False)\n","                probs = softmax(mask_hidden_state)\n","                # get probability of token 'he'\n","                he_id = tokenizer.convert_tokens_to_ids('he')\n","                #print('he probability', probs[he_id].item())\n","                # get probability of token 'she'\n","                she_id = tokenizer.convert_tokens_to_ids('she')\n","                #print('she probability', probs[she_id].item())\n","                baseline.append([probs[he_id].item(), probs[she_id].item()])\n","            return baseline\n","        self.baseline_prior = get_probs(self.examples_prior)\n","        \n","template_log = Template_log('/content/drive/My Drive/professions.json')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"idNERuLU8gjd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593597758473,"user_tz":-120,"elapsed":30174,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"outputId":"7adb0189-6ffe-4a9b-e6d9-6f61f0402373"},"source":["import re\n","def get_eigvecs_dict(layer=-1):\n","    eigvecs_dict = {}\n","    #-1:apply to all layers\n","    if layer == -1:\n","        for l in range(nlayer):\n","            eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(l)+'.pt', True)\n","    elif layer ==-2:\n","        for l in range(nlayer):\n","            eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(l)+'.pt', False)\n","    else:\n","        for l in range(nlayer):\n","            if l==layer:\n","                eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(l)+'.pt', True)\n","            else:\n","                eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(l)+'.pt', False)\n","    return eigvecs_dict\n","\n","import densray_bert as bbert\n","class Template_log2:\n","    def __init__(self, path='/content/drive/My Drive/professions.json'):\n","        with open(path,'r',encoding='utf8') as f:\n","            titles = re.sub('[^a-z_]',' ',f.read()).split()\n","        self.lines_prior = [re.sub('_',' ',tokenizer.mask_token+' is a '+tokenizer.mask_token+' .')]\n","        self.examples_prior = tokenizer.batch_encode_plus(self.lines_prior, add_special_tokens=True, max_length=128)[\"input_ids\"]\n","        self.getbaseline()\n","    \n","    def getbaseline(self):\n","        def get_probs(example=self.examples_prior):\n","            model = bbert.BertForMaskedLM_1.from_pretrained('bert-'+config+'-uncased', eigvecs_dict=get_eigvecs_dict(-1)).to(device)\n","            baseline = []\n","            for i in example:\n","                i = torch.tensor(i, dtype=torch.long).unsqueeze(0).to(device)\n","                output = model(i)\n","                mask_hidden_state = output[0].squeeze(0)[1]\n","                softmax = torch.nn.Softmax(dim=0)\n","                torch.set_grad_enabled(False)\n","                probs = softmax(mask_hidden_state)\n","                # get probability of token 'he'\n","                he_id = tokenizer.convert_tokens_to_ids('he')\n","                #print('he probability', probs[he_id].item())\n","                # get probability of token 'she'\n","                she_id = tokenizer.convert_tokens_to_ids('she')\n","                #print('she probability', probs[she_id].item())\n","                baseline.append([probs[he_id].item(), probs[she_id].item()])\n","            return baseline\n","        self.baseline_prior = get_probs(self.examples_prior)\n","        \n","template_log2 = Template_log2('/content/drive/My Drive/professions.json')\n","template_log2.baseline_prior"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[0.3955686092376709, 0.30111071467399597]]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"q7OPIRYxMu_c","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":163},"executionInfo":{"status":"error","timestamp":1593597758784,"user_tz":-120,"elapsed":30290,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"outputId":"32785766-b201-4c34-c2b5-747053fbfafd"},"source":["template_log.baseline_prior"],"execution_count":6,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-2b3a36bfbeac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtemplate_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbaseline_prior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'template_log' is not defined"]}]},{"cell_type":"code","metadata":{"id":"YJN4Ha2UM5c3","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1593597758771,"user_tz":-120,"elapsed":30124,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}}},"source":["template_log.baseline_prior[0][0]-template_log.baseline_prior[0][1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C15a-zFoDf2l","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1593597758776,"user_tz":-120,"elapsed":29978,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}}},"source":["import re\n","\n","class Template2:\n","    def __init__(self, path='/content/drive/My Drive/professions.json'):\n","        with open(path,'r',encoding='utf8') as f:\n","            titles = re.sub('[^a-z_]',' ',f.read()).split()\n","        self.lines = [re.sub('_',' ',' he is a '+i+' .') for i in titles] #5-6 tokens\n","        self.examples = tokenizer.batch_encode_plus(self.lines, add_special_tokens=True, max_length=128)[\"input_ids\"]\n","        self.lines2 = [re.sub('_',' ',' she is a '+i+' .') for i in titles]\n","        self.examples2 = tokenizer.batch_encode_plus(self.lines2, add_special_tokens=True, max_length=128)[\"input_ids\"]\n","        self.getbaseline()\n","\n","    def getbaseline(self):\n","        eigvec = torch.load('/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(nlayer-1)+'.pt').to(device)\n","        self.baseline = []\n","        m=0\n","        f=0\n","        for i in range(len(self.examples)):\n","            vec = torch.tensor(self.examples[i], dtype=torch.long).unsqueeze(0).to(device)\n","            #####get embedding of last layer\n","            output = model(vec)[1][-1][0][1:-1]\n","            bias = torch.mm(output, eigvec)[:, 0]\n","            vec2 = torch.tensor(self.examples2[i], dtype=torch.long).unsqueeze(0).to(device)\n","            #####get embedding of last layer\n","            output2 = model(vec2)[1][-1][0][1:-1]\n","            bias2 = torch.mm(output2, eigvec)[:, 0]\n","            self.baseline.append([bias[0], bias2[0]])\n","        \n","template2 = Template2('/content/drive/My Drive/professions.json')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jnI25YenI0UC","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1593597758779,"user_tz":-120,"elapsed":29824,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}}},"source":["import numpy as np\n","lines = ['[MASK] is a nurse .'] #5-6 tokens\n","print(lines[0])\n","i = tokenizer.batch_encode_plus(lines, add_special_tokens=True, max_length=128)[\"input_ids\"]\n","vec = torch.tensor(i[0], dtype=torch.long).unsqueeze(0).to(device)\n","output = model(vec)\n","eigvec = torch.load('/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(nlayer-1)+'.pt').to(device)\n","bias = torch.mm(output[1][-1][0], eigvec)[:, 0]\n","print(np.round(np.array(bias.tolist()),2))\n","print(np.round(np.array(bias.tolist()).mean(),2))\n","print(np.round(np.array(bias.tolist())[1:-1].mean(),2),'\\n')\n","\n","\n","lines = ['he is a nurse .'] #5-6 tokens\n","print(lines[0])\n","i = tokenizer.batch_encode_plus(lines, add_special_tokens=True, max_length=128)[\"input_ids\"]\n","vec = torch.tensor(i[0], dtype=torch.long).unsqueeze(0).to(device)\n","output = model(vec)\n","eigvec = torch.load('/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(nlayer-1)+'.pt').to(device)\n","bias = torch.mm(output[1][-1][0], eigvec)[:, 0]\n","print(np.round(np.array(bias.tolist()),2))\n","print(np.round(np.array(bias.tolist()).mean(),2))\n","print(np.round(np.array(bias.tolist())[1:-1].mean(),2),'\\n')\n","\n","lines = ['she is a nurse .'] #5-6 tokens\n","print(lines[0])\n","i = tokenizer.batch_encode_plus(lines, add_special_tokens=True, max_length=128)[\"input_ids\"]\n","vec = torch.tensor(i[0], dtype=torch.long).unsqueeze(0).to(device)\n","output = model(vec)\n","eigvec = torch.load('/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(nlayer-1)+'.pt').to(device)\n","bias = torch.mm(output[1][-1][0], eigvec)[:, 0]\n","print(np.round(np.array(bias.tolist()),2))\n","print(np.round(np.array(bias.tolist()).mean(),2))\n","print(np.round(np.array(bias.tolist())[1:-1].mean(),2),'\\n')\n","\n","lines = [tokenizer.mask_token+ ' is a nurse .']\n","i = tokenizer.batch_encode_plus(lines, add_special_tokens=True, max_length=128)[\"input_ids\"]\n","\n","vec = torch.tensor(i[0], dtype=torch.long).unsqueeze(0).to(device)\n","output = model(vec)\n","mask_hidden_state = output[0].squeeze(0)[1]\n","softmax = torch.nn.Softmax(dim=0)\n","torch.set_grad_enabled(False)\n","probs = softmax(mask_hidden_state)\n","# get probability of token 'he'\n","he_id = tokenizer.convert_tokens_to_ids('he')\n","#print('he probability', probs[he_id].item())\n","# get probability of token 'she'\n","she_id = tokenizer.convert_tokens_to_ids('she')\n","#print('she probability', probs[she_id].item())\n","he_log = np.log(probs[he_id].item())-np.log(template_log.baseline_prior[0][0])\n","she_log = np.log(probs[she_id].item())-np.log(template_log.baseline_prior[0][1])\n","print(he_log,she_log,he_log-she_log)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HSSREqMm0BuA","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1593597758780,"user_tz":-120,"elapsed":29695,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}}},"source":["import numpy as np\n","lines = ['[MASK] is a professor .'] #5-6 tokens\n","print(lines[0])\n","i = tokenizer.batch_encode_plus(lines, add_special_tokens=True, max_length=128)[\"input_ids\"]\n","vec = torch.tensor(i[0], dtype=torch.long).unsqueeze(0).to(device)\n","output = model(vec)\n","eigvec = torch.load('/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(nlayer-1)+'.pt').to(device)\n","bias = torch.mm(output[1][-1][0], eigvec)[:, 0]\n","print(np.round(np.array(bias.tolist()),2))\n","print(np.round(np.array(bias.tolist()).mean(),2))\n","print(np.round(np.array(bias.tolist())[1:-1].mean(),2),'\\n')\n","\n","\n","lines = ['he is a professor .'] #5-6 tokens\n","print(lines[0])\n","i = tokenizer.batch_encode_plus(lines, add_special_tokens=True, max_length=128)[\"input_ids\"]\n","vec = torch.tensor(i[0], dtype=torch.long).unsqueeze(0).to(device)\n","output = model(vec)\n","eigvec = torch.load('/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(nlayer-1)+'.pt').to(device)\n","bias = torch.mm(output[1][-1][0], eigvec)[:, 0]\n","print(np.round(np.array(bias.tolist()),2))\n","print(np.round(np.array(bias.tolist()).mean(),2))\n","print(np.round(np.array(bias.tolist())[1:-1].mean(),2),'\\n')\n","\n","lines = ['she is a professor .'] #5-6 tokens\n","print(lines[0])\n","i = tokenizer.batch_encode_plus(lines, add_special_tokens=True, max_length=128)[\"input_ids\"]\n","vec = torch.tensor(i[0], dtype=torch.long).unsqueeze(0).to(device)\n","output = model(vec)\n","eigvec = torch.load('/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(nlayer-1)+'.pt').to(device)\n","bias = torch.mm(output[1][-1][0], eigvec)[:, 0]\n","print(np.round(np.array(bias.tolist()),2))\n","print(np.round(np.array(bias.tolist()).mean(),2))\n","print(np.round(np.array(bias.tolist())[1:-1].mean(),2),'\\n')\n","\n","lines = [tokenizer.mask_token+ ' is a professor .']\n","i = tokenizer.batch_encode_plus(lines, add_special_tokens=True, max_length=128)[\"input_ids\"]\n","\n","vec = torch.tensor(i[0], dtype=torch.long).unsqueeze(0).to(device)\n","output = model(vec)\n","mask_hidden_state = output[0].squeeze(0)[1]\n","softmax = torch.nn.Softmax(dim=0)\n","torch.set_grad_enabled(False)\n","probs = softmax(mask_hidden_state)\n","# get probability of token 'he'\n","he_id = tokenizer.convert_tokens_to_ids('he')\n","#print('he probability', probs[he_id].item())\n","# get probability of token 'she'\n","she_id = tokenizer.convert_tokens_to_ids('she')\n","#print('she probability', probs[she_id].item())\n","he_log = np.log(probs[he_id].item())-np.log(template_log.baseline_prior[0][0])\n","she_log = np.log(probs[she_id].item())-np.log(template_log.baseline_prior[0][1])\n","print(he_log,she_log,he_log-she_log)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H-gRoEtgDi6m","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1593597758781,"user_tz":-120,"elapsed":29579,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}}},"source":["import numpy as np\n","lines = ['[MASK] is a doctor.'] #5-6 tokens\n","print(lines[0])\n","i = tokenizer.batch_encode_plus(lines, add_special_tokens=True, max_length=128)[\"input_ids\"]\n","vec = torch.tensor(i[0], dtype=torch.long).unsqueeze(0).to(device)\n","output = model(vec)\n","eigvec = torch.load('/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(nlayer-1)+'.pt').to(device)\n","output[1][-1][0,1:-1,:].shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J2-yiCCow3OH","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1593597758781,"user_tz":-120,"elapsed":26912,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}}},"source":["import numpy as np\n","lines = ['[MASK] is a doctor .'] #5-6 tokens\n","print(lines[0])\n","i = tokenizer.batch_encode_plus(lines, add_special_tokens=True, max_length=128)[\"input_ids\"]\n","vec = torch.tensor(i[0], dtype=torch.long).unsqueeze(0).to(device)\n","output = model(vec)\n","eigvec = torch.load('/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(nlayer-1)+'.pt').to(device)\n","bias = torch.mm(output[1][-1][0], eigvec)[:, 0]\n","print(np.round(np.array(bias.tolist()),2))\n","print(np.round(np.array(bias.tolist()).mean(),2))\n","print(np.round(np.array(bias.tolist())[1:-1].mean(),2),'\\n')\n","\n","\n","lines = ['he is a doctor .'] #5-6 tokens\n","print(lines[0])\n","i = tokenizer.batch_encode_plus(lines, add_special_tokens=True, max_length=128)[\"input_ids\"]\n","vec = torch.tensor(i[0], dtype=torch.long).unsqueeze(0).to(device)\n","output = model(vec)\n","eigvec = torch.load('/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(nlayer-1)+'.pt').to(device)\n","bias = torch.mm(output[1][-1][0], eigvec)[:, 0]\n","print(np.round(np.array(bias.tolist()),2))\n","print(np.round(np.array(bias.tolist()).mean(),2))\n","print(np.round(np.array(bias.tolist())[1:-1].mean(),2),'\\n')\n","\n","lines = ['she is a doctor .'] #5-6 tokens\n","print(lines[0])\n","i = tokenizer.batch_encode_plus(lines, add_special_tokens=True, max_length=128)[\"input_ids\"]\n","vec = torch.tensor(i[0], dtype=torch.long).unsqueeze(0).to(device)\n","output = model(vec)\n","eigvec = torch.load('/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(nlayer-1)+'.pt').to(device)\n","bias = torch.mm(output[1][-1][0], eigvec)[:, 0]\n","print(np.round(np.array(bias.tolist()),2))\n","print(np.round(np.array(bias.tolist()).mean(),2))\n","print(np.round(np.array(bias.tolist())[1:-1].mean(),2),'\\n')\n","\n","lines = [tokenizer.mask_token+ ' is a doctor .']\n","i = tokenizer.batch_encode_plus(lines, add_special_tokens=True, max_length=128)[\"input_ids\"]\n","\n","vec = torch.tensor(i[0], dtype=torch.long).unsqueeze(0).to(device)\n","output = model(vec)\n","mask_hidden_state = output[0].squeeze(0)[1]\n","softmax = torch.nn.Softmax(dim=0)\n","torch.set_grad_enabled(False)\n","probs = softmax(mask_hidden_state)\n","# get probability of token 'he'\n","he_id = tokenizer.convert_tokens_to_ids('he')\n","#print('he probability', probs[he_id].item())\n","# get probability of token 'she'\n","she_id = tokenizer.convert_tokens_to_ids('she')\n","#print('she probability', probs[she_id].item())\n","he_log = np.log(probs[he_id].item())-np.log(template_log.baseline_prior[0][0])\n","she_log = np.log(probs[she_id].item())-np.log(template_log.baseline_prior[0][1])\n","print(he_log,she_log,he_log-she_log)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Djkax-270U47","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1593597758782,"user_tz":-120,"elapsed":26339,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}}},"source":["import numpy as np\n","lines = ['what is going on.'] #5-6 tokens\n","print(lines[0])\n","i = tokenizer.batch_encode_plus(lines, add_special_tokens=True, max_length=128)[\"input_ids\"]\n","vec = torch.tensor(i[0], dtype=torch.long).unsqueeze(0).to(device)\n","output = model(vec)\n","eigvec = torch.load('/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(nlayer-1)+'.pt').to(device)\n","bias = torch.mm(output[1][-1][0], eigvec)[:, 0]\n","print(np.round(np.array(bias.tolist()),2))\n","print(np.round(np.array(bias.tolist()).mean(),2))\n","print(np.round(np.array(bias.tolist())[1:-1].mean(),2),'\\n')\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CPrRAGg2z8d1","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1593597758782,"user_tz":-120,"elapsed":25787,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}}},"source":["import numpy as np\n","lines = ['[MASK] is a singer .'] #5-6 tokens\n","print(lines[0])\n","i = tokenizer.batch_encode_plus(lines, add_special_tokens=True, max_length=128)[\"input_ids\"]\n","vec = torch.tensor(i[0], dtype=torch.long).unsqueeze(0).to(device)\n","output = model(vec)\n","eigvec = torch.load('/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(nlayer-1)+'.pt').to(device)\n","bias = torch.mm(output[1][-1][0], eigvec)[:, 0]\n","print(np.round(np.array(bias.tolist()),2))\n","print(np.round(np.array(bias.tolist()).mean(),2))\n","print(np.round(np.array(bias.tolist())[1:-1].mean(),2),'\\n')\n","\n","\n","lines = ['he is a singer .'] #5-6 tokens\n","print(lines[0])\n","i = tokenizer.batch_encode_plus(lines, add_special_tokens=True, max_length=128)[\"input_ids\"]\n","vec = torch.tensor(i[0], dtype=torch.long).unsqueeze(0).to(device)\n","output = model(vec)\n","eigvec = torch.load('/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(nlayer-1)+'.pt').to(device)\n","bias = torch.mm(output[1][-1][0], eigvec)[:, 0]\n","print(np.round(np.array(bias.tolist()),2))\n","print(np.round(np.array(bias.tolist()).mean(),2))\n","print(np.round(np.array(bias.tolist())[1:-1].mean(),2),'\\n')\n","\n","lines = ['she is a singer .'] #5-6 tokens\n","print(lines[0])\n","i = tokenizer.batch_encode_plus(lines, add_special_tokens=True, max_length=128)[\"input_ids\"]\n","vec = torch.tensor(i[0], dtype=torch.long).unsqueeze(0).to(device)\n","output = model(vec)\n","eigvec = torch.load('/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(nlayer-1)+'.pt').to(device)\n","bias = torch.mm(output[1][-1][0], eigvec)[:, 0]\n","print(np.round(np.array(bias.tolist()),2))\n","print(np.round(np.array(bias.tolist()).mean(),2))\n","print(np.round(np.array(bias.tolist())[1:-1].mean(),2),'\\n')\n","\n","lines = [tokenizer.mask_token+ ' is a singer .']\n","i = tokenizer.batch_encode_plus(lines, add_special_tokens=True, max_length=128)[\"input_ids\"]\n","\n","vec = torch.tensor(i[0], dtype=torch.long).unsqueeze(0).to(device)\n","output = model(vec)\n","mask_hidden_state = output[0].squeeze(0)[1]\n","softmax = torch.nn.Softmax(dim=0)\n","torch.set_grad_enabled(False)\n","probs = softmax(mask_hidden_state)\n","# get probability of token 'he'\n","he_id = tokenizer.convert_tokens_to_ids('he')\n","#print('he probability', probs[he_id].item())\n","# get probability of token 'she'\n","she_id = tokenizer.convert_tokens_to_ids('she')\n","#print('she probability', probs[she_id].item())\n","he_log = np.log(probs[he_id].item())-np.log(template_log.baseline_prior[0][0])\n","she_log = np.log(probs[she_id].item())-np.log(template_log.baseline_prior[0][1])\n","print(he_log,she_log,he_log-she_log)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pYjWGc1Szdv-","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1593597758783,"user_tz":-120,"elapsed":25529,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}}},"source":["bias.tolist()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LdjTdPtG5bvi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1593597947049,"user_tz":-120,"elapsed":553,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"outputId":"1bdd07cc-bc5d-49b3-a4e5-bdb7575ab87f"},"source":["import numpy as np\n","lines = [' the professor asked the nurse.'] #5-6 tokens\n","print(lines[0])\n","i = tokenizer.batch_encode_plus(lines, add_special_tokens=True, max_length=128)[\"input_ids\"]\n","vec = torch.tensor(i[0], dtype=torch.long).unsqueeze(0).to(device)\n","output = model(vec)\n","eigvec = torch.load('/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(nlayer-1)+'.pt').to(device)\n","bias = torch.mm(output[1][-1][0], eigvec)[:, 0]\n","print(np.round(np.array(bias.tolist()),2))\n","print(np.round(np.array(bias.tolist()).mean(),2))\n","print(np.round(np.array(bias.tolist())[1:-1].mean(),2),'\\n')\n"],"execution_count":14,"outputs":[{"output_type":"stream","text":[" the professor asked the nurse.\n","[-0.47 -1.3  -0.25  0.24  1.28  2.19  0.45  0.75]\n","0.36\n","0.43 \n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Vy25YU_Nsbh3","colab_type":"text"},"source":["# Eval"]},{"cell_type":"code","metadata":{"id":"bmk0ozKp-8eX","colab_type":"code","colab":{}},"source":["def get_eigvecs_dict(layer=-1):\n","    eigvecs_dict = {}\n","    #-1:apply to all layers\n","    if layer == -1:\n","        for l in range(nlayer):\n","            eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(l)+'.pt', True)\n","    elif layer ==-2:\n","        for l in range(nlayer):\n","            eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(l)+'.pt', False)\n","    else:\n","        for l in range(nlayer):\n","            if l==layer:\n","                eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(l)+'.pt', True)\n","            else:\n","                eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(l)+'.pt', False)\n","    return eigvecs_dict\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Eq0TZyRiigjA","colab_type":"code","colab":{}},"source":["!find /content/ -name '*eigvecs*' | xargs  rm -rf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Lm8trYf6idU","colab_type":"code","colab":{}},"source":["def get_eigvecs_dict(layer=-1):\n","    eigvecs_dict = {}\n","    #-1:apply to all layers\n","    if layer == -1:\n","        for l in range(nlayer):\n","            eigvecs_dict[str(l)] = ('/content/drive/My Drive/pc1'+config+'_'+str(nsamples)+'_'+str(l)+'.pt', True)\n","    elif layer ==-2:\n","        for l in range(nlayer):\n","            eigvecs_dict[str(l)] = ('/content/drive/My Drive/pc1'+config+'_'+str(nsamples)+'_'+str(l)+'.pt', False)\n","    else:\n","        for l in range(nlayer):\n","            if l==layer:\n","                eigvecs_dict[str(l)] = ('/content/drive/My Drive/pc1'+config+'_'+str(nsamples)+'_'+str(l)+'.pt', True)\n","            else:\n","                eigvecs_dict[str(l)] = ('/content/drive/My Drive/pc1'+config+'_'+str(nsamples)+'_'+str(l)+'.pt', False)\n","    return eigvecs_dict\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MUYs-VS6tg-n","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1592895854263,"user_tz":-120,"elapsed":25542,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"outputId":"19f08efc-b25d-4a87-e186-59e00d365719"},"source":["import hard_bert as bbert\n","import tqdm\n","import re\n","\n","class Template:\n","    def __init__(self, path='/content/drive/My Drive/professions.json'):\n","        with open(path,'r',encoding='utf8') as f:\n","            titles = re.sub('[^a-z_]',' ',f.read()).split()\n","        self.lines = [re.sub('_',' ',tokenizer.mask_token+' is a '+i+' .') for i in titles]\n","        self.examples = tokenizer.batch_encode_plus(self.lines, add_special_tokens=True, max_length=128)[\"input_ids\"]\n","        self.getbaseline()\n","    \n","    def getbaseline(self):\n","        self.baseline = []\n","        for i in self.examples:\n","            i = torch.tensor(i, dtype=torch.long).unsqueeze(0).to(device)\n","            output = model(i)\n","            mask_hidden_state = output[0].squeeze(0)[1]\n","            softmax = torch.nn.Softmax(dim=0)\n","            torch.set_grad_enabled(False)\n","            probs = softmax(mask_hidden_state)\n","            # get probability of token 'he'\n","            he_id = tokenizer.convert_tokens_to_ids('he')\n","            #print('he probability', probs[he_id].item())\n","            # get probability of token 'she'\n","            she_id = tokenizer.convert_tokens_to_ids('she')\n","            #print('she probability', probs[she_id].item())\n","            self.baseline.append([probs[he_id].item(), probs[she_id].item()])\n","        \n","template = Template('/content/drive/My Drive/professions.json')\n","\n","\n","def eval(temp=Template(), he='he', she='she'):\n","    predictions = []\n","    for l in range(-2,0):\n","        # get model\n","        model = bbert.BertForMaskedLM_1.from_pretrained('bert-'+config+'-uncased', eigvecs_dict=get_eigvecs_dict(l)).to(device)\n","        model.eval() \n","        # eval\n","        prediction = []\n","        for i in tqdm.trange(len(temp.examples)):\n","            vec = torch.tensor(temp.examples[i], dtype=torch.long).unsqueeze(0).to(device)\n","            output = model(vec)\n","            mask_hidden_state = output[0].squeeze(0)[1]\n","            softmax = torch.nn.Softmax(dim=0)\n","            torch.set_grad_enabled(False)\n","            probs = softmax(mask_hidden_state)\n","            he_id = tokenizer.convert_tokens_to_ids('he')\n","            she_id = tokenizer.convert_tokens_to_ids('she')\n","            prediction.append([probs[he_id].item(), probs[she_id].item()])\n","        predictions.append(prediction)\n","    return predictions\n","predictions = eval(template)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 320/320 [00:02<00:00, 113.28it/s]\n","100%|██████████| 320/320 [00:03<00:00, 100.33it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"r4gz2x_gyAl3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":106},"executionInfo":{"status":"ok","timestamp":1592895854867,"user_tz":-120,"elapsed":591,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"outputId":"59ba8f6e-7854-4814-c836-e9706791fbbc"},"source":["print('log(p_tgt/p_prior), diff')\n","baseline = torch.Tensor(template.baseline)\n","print((torch.log(baseline[:,0]/template_log.baseline_prior[0][0])).mean()-(torch.log(baseline[:,1]/template_log.baseline_prior[0][1])).mean(), '\\n')\n","\n","\n","for i in torch.Tensor(predictions):\n","    print((torch.log(i[:,0])-np.log(template_log2.baseline_prior[0][0])).mean()-(torch.log(i[:,1])-np.log(template_log2.baseline_prior[0][1])).mean(), round(float((i[:,0]-i[:,1]).mean()),4))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["log(p_tgt/p_prior), diff\n","tensor(0.3333) \n","\n","tensor(0.8411) 0.472\n","tensor(-0.8717) -0.0733\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nkjX8uf42fqe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":319},"executionInfo":{"status":"ok","timestamp":1592286524138,"user_tz":-120,"elapsed":159706,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"outputId":"69c388eb-438e-4384-a06c-0bdd9f8d6ab1"},"source":["print('mean(prob(he/she)) var(prob(he/she)) mean(prob(he-she)) var(prob(he-she))')\n","baseline = torch.Tensor(template.baseline)\n","print('bert-'+config,'&',[round(i,4) for i in torch.mean(baseline,dim=0).tolist()][0],'&', [round(i,4) for i in torch.mean(baseline,dim=0).tolist()][1],'&',\n","      round(float((baseline[:,0]-baseline[:,1]).mean()),4), '&', round(float((baseline[:,0]-baseline[:,1]).var()),4), '\\n')\n","\n","for i in torch.Tensor(predictions):\n","    print('bert-'+config+'-L','&',[round(i,4) for i in torch.mean(i,dim=0).tolist()][0],'&', [round(i,4) for i in torch.mean(i,dim=0).tolist()][1],'&',\n","          round(float((i[:,0]-i[:,1]).mean()),4), '&', round(float((i[:,0]-i[:,1]).var()),4))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["mean(prob(he/she)) var(prob(he/she)) mean(prob(he-she)) var(prob(he-she))\n","bert-base & 0.6594 & 0.1874 & 0.472 & 0.16 \n","\n","bert-base-L & 0.6594 & 0.1874 & 0.472 & 0.16\n","bert-base-L & 0.4811 & 0.3746 & 0.1065 & 0.0182\n","bert-base-L & 0.6744 & 0.1734 & 0.501 & 0.1108\n","bert-base-L & 0.6769 & 0.17 & 0.5069 & 0.1036\n","bert-base-L & 0.6658 & 0.1812 & 0.4846 & 0.1025\n","bert-base-L & 0.5884 & 0.2522 & 0.3362 & 0.1292\n","bert-base-L & 0.5575 & 0.2808 & 0.2768 & 0.1205\n","bert-base-L & 0.4495 & 0.3918 & 0.0577 & 0.1232\n","bert-base-L & 0.3606 & 0.4809 & -0.1203 & 0.117\n","bert-base-L & 0.2776 & 0.5715 & -0.2938 & 0.0641\n","bert-base-L & 0.2577 & 0.5937 & -0.336 & 0.0758\n","bert-base-L & 0.3625 & 0.4743 & -0.1118 & 0.0796\n","bert-base-L & 0.5041 & 0.3269 & 0.1773 & 0.0531\n","bert-base-L & 0.5612 & 0.246 & 0.3153 & 0.027\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"HTTDYsDcJEec","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592286698718,"user_tz":-120,"elapsed":776,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"outputId":"c828808a-ea83-42cd-c0fa-fd6de743daa9"},"source":["for i in range(len(template.lines)):\n","    print(\"sentence: \", template.lines[i])\n","    print(\"prediction: \", predictions[1][i])\n","    print(\"baseline: \", template.baseline[i], \"\\n\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["sentence:  [MASK] is a accountant .\n","prediction:  [0.5004874467849731, 0.4207514822483063]\n","baseline:  [0.7863401770591736, 0.13790035247802734] \n","\n","sentence:  [MASK] is a acquaintance .\n","prediction:  [0.5602498650550842, 0.2790326774120331]\n","baseline:  [0.48351961374282837, 0.3089848458766937] \n","\n","sentence:  [MASK] is a actor .\n","prediction:  [0.44134995341300964, 0.4274439811706543]\n","baseline:  [0.8884313702583313, 0.01600102335214615] \n","\n","sentence:  [MASK] is a actress .\n","prediction:  [0.4363904893398285, 0.45349615812301636]\n","baseline:  [0.05418592691421509, 0.8087123036384583] \n","\n","sentence:  [MASK] is a adjunct professor .\n","prediction:  [0.399289071559906, 0.5161599516868591]\n","baseline:  [0.7231859564781189, 0.19427438080310822] \n","\n","sentence:  [MASK] is a administrator .\n","prediction:  [0.4831947088241577, 0.3984845280647278]\n","baseline:  [0.6296999454498291, 0.233728289604187] \n","\n","sentence:  [MASK] is a adventurer .\n","prediction:  [0.5428436994552612, 0.30896925926208496]\n","baseline:  [0.7098377346992493, 0.09561648219823837] \n","\n","sentence:  [MASK] is a advocate .\n","prediction:  [0.4056622087955475, 0.4502870440483093]\n","baseline:  [0.6312933564186096, 0.21207740902900696] \n","\n","sentence:  [MASK] is a aide .\n","prediction:  [0.5053570866584778, 0.3741588592529297]\n","baseline:  [0.5201811790466309, 0.33102336525917053] \n","\n","sentence:  [MASK] is a alderman .\n","prediction:  [0.47363701462745667, 0.47338414192199707]\n","baseline:  [0.8334311842918396, 0.11344292759895325] \n","\n","sentence:  [MASK] is a alter ego .\n","prediction:  [0.4280931353569031, 0.218557670712471]\n","baseline:  [0.5607700943946838, 0.05235445126891136] \n","\n","sentence:  [MASK] is a ambassador .\n","prediction:  [0.43586310744285583, 0.5346085429191589]\n","baseline:  [0.6949834823608398, 0.2816193401813507] \n","\n","sentence:  [MASK] is a analyst .\n","prediction:  [0.5013352632522583, 0.4120293855667114]\n","baseline:  [0.7757007479667664, 0.12166804820299149] \n","\n","sentence:  [MASK] is a anthropologist .\n","prediction:  [0.40392962098121643, 0.4461616277694702]\n","baseline:  [0.38480111956596375, 0.4578350782394409] \n","\n","sentence:  [MASK] is a archaeologist .\n","prediction:  [0.5184938907623291, 0.36664408445358276]\n","baseline:  [0.6722234487533569, 0.19655591249465942] \n","\n","sentence:  [MASK] is a archbishop .\n","prediction:  [0.5057998299598694, 0.44020572304725647]\n","baseline:  [0.9580525755882263, 0.010512324050068855] \n","\n","sentence:  [MASK] is a architect .\n","prediction:  [0.45552074909210205, 0.4370814263820648]\n","baseline:  [0.7817776799201965, 0.11568274348974228] \n","\n","sentence:  [MASK] is a artist .\n","prediction:  [0.4668605327606201, 0.4195108115673065]\n","baseline:  [0.566547155380249, 0.3188125789165497] \n","\n","sentence:  [MASK] is a artiste .\n","prediction:  [0.4797210693359375, 0.3748909533023834]\n","baseline:  [0.4436742663383484, 0.4145326614379883] \n","\n","sentence:  [MASK] is a assassin .\n","prediction:  [0.5923029184341431, 0.27525290846824646]\n","baseline:  [0.6383970379829407, 0.19118370115756989] \n","\n","sentence:  [MASK] is a assistant professor .\n","prediction:  [0.38150572776794434, 0.590541660785675]\n","baseline:  [0.7172816395759583, 0.25531914830207825] \n","\n","sentence:  [MASK] is a associate dean .\n","prediction:  [0.4304022490978241, 0.506459653377533]\n","baseline:  [0.7162907123565674, 0.21926282346248627] \n","\n","sentence:  [MASK] is a associate professor .\n","prediction:  [0.3969211280345917, 0.5658893585205078]\n","baseline:  [0.7874149084091187, 0.1794833391904831] \n","\n","sentence:  [MASK] is a astronaut .\n","prediction:  [0.5156991481781006, 0.3584226667881012]\n","baseline:  [0.7535491585731506, 0.10260633379220963] \n","\n","sentence:  [MASK] is a astronomer .\n","prediction:  [0.5177472233772278, 0.3750436007976532]\n","baseline:  [0.7692624926567078, 0.1122327670454979] \n","\n","sentence:  [MASK] is a athlete .\n","prediction:  [0.414517343044281, 0.43109560012817383]\n","baseline:  [0.6354860663414001, 0.19465585052967072] \n","\n","sentence:  [MASK] is a athletic director .\n","prediction:  [0.4278963804244995, 0.45992907881736755]\n","baseline:  [0.8268986940383911, 0.056975752115249634] \n","\n","sentence:  [MASK] is a attorney .\n","prediction:  [0.4579090476036072, 0.42681896686553955]\n","baseline:  [0.740231454372406, 0.1337403804063797] \n","\n","sentence:  [MASK] is a author .\n","prediction:  [0.42215973138809204, 0.4602397680282593]\n","baseline:  [0.5028862953186035, 0.3894466459751129] \n","\n","sentence:  [MASK] is a baker .\n","prediction:  [0.5421234965324402, 0.3448316752910614]\n","baseline:  [0.5479260683059692, 0.33601483702659607] \n","\n","sentence:  [MASK] is a ballerina .\n","prediction:  [0.4306517243385315, 0.2590272128582001]\n","baseline:  [0.017496827989816666, 0.721538782119751] \n","\n","sentence:  [MASK] is a ballplayer .\n","prediction:  [0.4010954797267914, 0.3073575794696808]\n","baseline:  [0.6890686750411987, 0.025616195052862167] \n","\n","sentence:  [MASK] is a banker .\n","prediction:  [0.5569766163825989, 0.4151511788368225]\n","baseline:  [0.9583951234817505, 0.01918340101838112] \n","\n","sentence:  [MASK] is a barber .\n","prediction:  [0.5949775576591492, 0.29200777411460876]\n","baseline:  [0.8621701598167419, 0.030968980863690376] \n","\n","sentence:  [MASK] is a baron .\n","prediction:  [0.6644501090049744, 0.2760860323905945]\n","baseline:  [0.9490036964416504, 0.008637522347271442] \n","\n","sentence:  [MASK] is a barrister .\n","prediction:  [0.478239506483078, 0.4355720281600952]\n","baseline:  [0.8262612223625183, 0.092021644115448] \n","\n","sentence:  [MASK] is a bartender .\n","prediction:  [0.4694918394088745, 0.27510103583335876]\n","baseline:  [0.5293781757354736, 0.15376441180706024] \n","\n","sentence:  [MASK] is a biologist .\n","prediction:  [0.4245580732822418, 0.4412705898284912]\n","baseline:  [0.7342303991317749, 0.12883901596069336] \n","\n","sentence:  [MASK] is a bishop .\n","prediction:  [0.5200877785682678, 0.4083305597305298]\n","baseline:  [0.886012077331543, 0.04717501625418663] \n","\n","sentence:  [MASK] is a bodyguard .\n","prediction:  [0.5538406372070312, 0.2941386103630066]\n","baseline:  [0.7683098912239075, 0.045487891882658005] \n","\n","sentence:  [MASK] is a bookkeeper .\n","prediction:  [0.5688352584838867, 0.30620935559272766]\n","baseline:  [0.5592787861824036, 0.3032793402671814] \n","\n","sentence:  [MASK] is a boss .\n","prediction:  [0.4698270559310913, 0.2697557806968689]\n","baseline:  [0.554378092288971, 0.10647769272327423] \n","\n","sentence:  [MASK] is a boxer .\n","prediction:  [0.4915716350078583, 0.3996163308620453]\n","baseline:  [0.8476601839065552, 0.026089247316122055] \n","\n","sentence:  [MASK] is a broadcaster .\n","prediction:  [0.41680869460105896, 0.4572651982307434]\n","baseline:  [0.730903148651123, 0.154790997505188] \n","\n","sentence:  [MASK] is a broker .\n","prediction:  [0.54583340883255, 0.36982524394989014]\n","baseline:  [0.8412545323371887, 0.06292415410280228] \n","\n","sentence:  [MASK] is a bureaucrat .\n","prediction:  [0.6440183520317078, 0.31254711747169495]\n","baseline:  [0.8768753409385681, 0.07056889683008194] \n","\n","sentence:  [MASK] is a businessman .\n","prediction:  [0.562489926815033, 0.37940090894699097]\n","baseline:  [0.9540842175483704, 0.003986472263932228] \n","\n","sentence:  [MASK] is a businesswoman .\n","prediction:  [0.5063142776489258, 0.353427916765213]\n","baseline:  [0.02176627889275551, 0.8142584562301636] \n","\n","sentence:  [MASK] is a butcher .\n","prediction:  [0.5531383156776428, 0.26867565512657166]\n","baseline:  [0.7572969198226929, 0.08213488012552261] \n","\n","sentence:  [MASK] is a butler .\n","prediction:  [0.5495023727416992, 0.19981779158115387]\n","baseline:  [0.620172917842865, 0.08865763992071152] \n","\n","sentence:  [MASK] is a cab driver .\n","prediction:  [0.5716694593429565, 0.22579120099544525]\n","baseline:  [0.7405236959457397, 0.0559927336871624] \n","\n","sentence:  [MASK] is a cabbie .\n","prediction:  [0.4514063596725464, 0.21861042082309723]\n","baseline:  [0.42835134267807007, 0.206088125705719] \n","\n","sentence:  [MASK] is a cameraman .\n","prediction:  [0.5184249877929688, 0.3069402277469635]\n","baseline:  [0.7648049592971802, 0.0449858233332634] \n","\n","sentence:  [MASK] is a campaigner .\n","prediction:  [0.34047290682792664, 0.35602498054504395]\n","baseline:  [0.4498203992843628, 0.24622444808483124] \n","\n","sentence:  [MASK] is a captain .\n","prediction:  [0.5856122970581055, 0.2664508819580078]\n","baseline:  [0.7742159366607666, 0.03851494565606117] \n","\n","sentence:  [MASK] is a cardiologist .\n","prediction:  [0.4232299327850342, 0.3821897804737091]\n","baseline:  [0.698365330696106, 0.11558837443590164] \n","\n","sentence:  [MASK] is a caretaker .\n","prediction:  [0.5238541960716248, 0.3788648843765259]\n","baseline:  [0.4777989983558655, 0.40710535645484924] \n","\n","sentence:  [MASK] is a carpenter .\n","prediction:  [0.51222163438797, 0.3432294726371765]\n","baseline:  [0.77349454164505, 0.05416379123926163] \n","\n","sentence:  [MASK] is a cartoonist .\n","prediction:  [0.4249739646911621, 0.4367246925830841]\n","baseline:  [0.8106391429901123, 0.05055200681090355] \n","\n","sentence:  [MASK] is a cellist .\n","prediction:  [0.39348071813583374, 0.5063796043395996]\n","baseline:  [0.6506332159042358, 0.25401571393013] \n","\n","sentence:  [MASK] is a chancellor .\n","prediction:  [0.4933546483516693, 0.4410596787929535]\n","baseline:  [0.809158205986023, 0.11726035922765732] \n","\n","sentence:  [MASK] is a chaplain .\n","prediction:  [0.5308420658111572, 0.37506458163261414]\n","baseline:  [0.8496028184890747, 0.051457230001688004] \n","\n","sentence:  [MASK] is a character .\n","prediction:  [0.22213849425315857, 0.14243564009666443]\n","baseline:  [0.15675082802772522, 0.08254164457321167] \n","\n","sentence:  [MASK] is a chef .\n","prediction:  [0.49904516339302063, 0.41343191266059875]\n","baseline:  [0.6524516344070435, 0.25385046005249023] \n","\n","sentence:  [MASK] is a chemist .\n","prediction:  [0.559725284576416, 0.3224206566810608]\n","baseline:  [0.7100468277931213, 0.16302023828029633] \n","\n","sentence:  [MASK] is a choreographer .\n","prediction:  [0.457926481962204, 0.45302680134773254]\n","baseline:  [0.6542418599128723, 0.2648922801017761] \n","\n","sentence:  [MASK] is a cinematographer .\n","prediction:  [0.427723228931427, 0.4344063103199005]\n","baseline:  [0.8612122535705566, 0.032987989485263824] \n","\n","sentence:  [MASK] is a citizen .\n","prediction:  [0.5399948358535767, 0.40402570366859436]\n","baseline:  [0.7041165232658386, 0.23306085169315338] \n","\n","sentence:  [MASK] is a civil servant .\n","prediction:  [0.4925689697265625, 0.4633501470088959]\n","baseline:  [0.8901603817939758, 0.06990104168653488] \n","\n","sentence:  [MASK] is a cleric .\n","prediction:  [0.5638751983642578, 0.4129713177680969]\n","baseline:  [0.9315096735954285, 0.046746402978897095] \n","\n","sentence:  [MASK] is a clerk .\n","prediction:  [0.5640360116958618, 0.3765285015106201]\n","baseline:  [0.7362962365150452, 0.20359057188034058] \n","\n","sentence:  [MASK] is a coach .\n","prediction:  [0.5131382346153259, 0.4128808379173279]\n","baseline:  [0.876731276512146, 0.04239504411816597] \n","\n","sentence:  [MASK] is a collector .\n","prediction:  [0.5059103965759277, 0.4578634202480316]\n","baseline:  [0.9060394763946533, 0.06067579984664917] \n","\n","sentence:  [MASK] is a colonel .\n","prediction:  [0.6236890554428101, 0.32391080260276794]\n","baseline:  [0.9444414377212524, 0.007421685382723808] \n","\n","sentence:  [MASK] is a columnist .\n","prediction:  [0.39573702216148376, 0.5581861734390259]\n","baseline:  [0.6210664510726929, 0.3396160304546356] \n","\n","sentence:  [MASK] is a comedian .\n","prediction:  [0.46931979060173035, 0.39367812871932983]\n","baseline:  [0.7901157736778259, 0.08631038665771484] \n","\n","sentence:  [MASK] is a comic .\n","prediction:  [0.46131229400634766, 0.28775718808174133]\n","baseline:  [0.579744815826416, 0.14629840850830078] \n","\n","sentence:  [MASK] is a commander .\n","prediction:  [0.5383093953132629, 0.3127967119216919]\n","baseline:  [0.7339867353439331, 0.07479634135961533] \n","\n","sentence:  [MASK] is a commentator .\n","prediction:  [0.43288394808769226, 0.4973633587360382]\n","baseline:  [0.8512834310531616, 0.08539744466543198] \n","\n","sentence:  [MASK] is a commissioner .\n","prediction:  [0.4539850056171417, 0.5136387348175049]\n","baseline:  [0.8906663060188293, 0.08151304721832275] \n","\n","sentence:  [MASK] is a composer .\n","prediction:  [0.44133540987968445, 0.4503628611564636]\n","baseline:  [0.7938367128372192, 0.11162412911653519] \n","\n","sentence:  [MASK] is a conductor .\n","prediction:  [0.49324432015419006, 0.4315590560436249]\n","baseline:  [0.8802553415298462, 0.04397877678275108] \n","\n","sentence:  [MASK] is a confesses .\n","prediction:  [0.03083079494535923, 0.025269607082009315]\n","baseline:  [0.038775280117988586, 0.012529563158750534] \n","\n","sentence:  [MASK] is a congressman .\n","prediction:  [0.4743179380893707, 0.46888139843940735]\n","baseline:  [0.9349629282951355, 0.02053193561732769] \n","\n","sentence:  [MASK] is a constable .\n","prediction:  [0.5838263034820557, 0.3259992301464081]\n","baseline:  [0.8193866014480591, 0.07016833871603012] \n","\n","sentence:  [MASK] is a consultant .\n","prediction:  [0.4605327248573303, 0.430176317691803]\n","baseline:  [0.6910021305084229, 0.19192571938037872] \n","\n","sentence:  [MASK] is a cop .\n","prediction:  [0.49678969383239746, 0.20869192481040955]\n","baseline:  [0.5875778198242188, 0.07176925987005234] \n","\n","sentence:  [MASK] is a correspondent .\n","prediction:  [0.46543991565704346, 0.4735705554485321]\n","baseline:  [0.6329647302627563, 0.2997725009918213] \n","\n","sentence:  [MASK] is a councilman .\n","prediction:  [0.3953504264354706, 0.5326327085494995]\n","baseline:  [0.8923190236091614, 0.04471852257847786] \n","\n","sentence:  [MASK] is a councilor .\n","prediction:  [0.44555169343948364, 0.5192441344261169]\n","baseline:  [0.7500648498535156, 0.214308962225914] \n","\n","sentence:  [MASK] is a counselor .\n","prediction:  [0.4561452567577362, 0.37523022294044495]\n","baseline:  [0.2532835900783539, 0.5749534964561462] \n","\n","sentence:  [MASK] is a critic .\n","prediction:  [0.4516553580760956, 0.48330801725387573]\n","baseline:  [0.7768011689186096, 0.15467868745326996] \n","\n","sentence:  [MASK] is a crooner .\n","prediction:  [0.4701036810874939, 0.267657071352005]\n","baseline:  [0.26096513867378235, 0.46935755014419556] \n","\n","sentence:  [MASK] is a crusader .\n","prediction:  [0.5912749171257019, 0.3071995973587036]\n","baseline:  [0.8024376034736633, 0.08537387102842331] \n","\n","sentence:  [MASK] is a curator .\n","prediction:  [0.41284656524658203, 0.5053620338439941]\n","baseline:  [0.5647870302200317, 0.35741472244262695] \n","\n","sentence:  [MASK] is a custodian .\n","prediction:  [0.5123530626296997, 0.39670267701148987]\n","baseline:  [0.7485213279724121, 0.14368142187595367] \n","\n","sentence:  [MASK] is a dad .\n","prediction:  [0.28143975138664246, 0.11808743327856064]\n","baseline:  [0.45573875308036804, 0.011533918790519238] \n","\n","sentence:  [MASK] is a dancer .\n","prediction:  [0.42445483803749084, 0.5263608694076538]\n","baseline:  [0.2202736884355545, 0.7261614799499512] \n","\n","sentence:  [MASK] is a dean .\n","prediction:  [0.48047757148742676, 0.40419426560401917]\n","baseline:  [0.7574564814567566, 0.12478506565093994] \n","\n","sentence:  [MASK] is a dentist .\n","prediction:  [0.5229012370109558, 0.4037385880947113]\n","baseline:  [0.8197697401046753, 0.10998763889074326] \n","\n","sentence:  [MASK] is a deputy .\n","prediction:  [0.38217711448669434, 0.6051665544509888]\n","baseline:  [0.8824072480201721, 0.10832590609788895] \n","\n","sentence:  [MASK] is a dermatologist .\n","prediction:  [0.46511098742485046, 0.4116020202636719]\n","baseline:  [0.7605908513069153, 0.1316802054643631] \n","\n","sentence:  [MASK] is a detective .\n","prediction:  [0.5665634870529175, 0.26885122060775757]\n","baseline:  [0.7108601331710815, 0.08782908320426941] \n","\n","sentence:  [MASK] is a diplomat .\n","prediction:  [0.46031150221824646, 0.5177296996116638]\n","baseline:  [0.9103005528450012, 0.0739416852593422] \n","\n","sentence:  [MASK] is a director .\n","prediction:  [0.43998274207115173, 0.46999236941337585]\n","baseline:  [0.7149546146392822, 0.18920831382274628] \n","\n","sentence:  [MASK] is a disc jockey .\n","prediction:  [0.5053350329399109, 0.40232381224632263]\n","baseline:  [0.7413709759712219, 0.15794095396995544] \n","\n","sentence:  [MASK] is a doctor .\n","prediction:  [0.5716395378112793, 0.31010758876800537]\n","baseline:  [0.614936888217926, 0.2319856882095337] \n","\n","sentence:  [MASK] is a doctoral student .\n","prediction:  [0.4319862723350525, 0.5094373822212219]\n","baseline:  [0.6349154114723206, 0.3168574571609497] \n","\n","sentence:  [MASK] is a drug addict .\n","prediction:  [0.4520053267478943, 0.19743148982524872]\n","baseline:  [0.38016366958618164, 0.19909986853599548] \n","\n","sentence:  [MASK] is a drummer .\n","prediction:  [0.45311808586120605, 0.3856985867023468]\n","baseline:  [0.7056029438972473, 0.11197122186422348] \n","\n","sentence:  [MASK] is a economics professor .\n","prediction:  [0.45381951332092285, 0.5195430517196655]\n","baseline:  [0.9024156928062439, 0.07739715278148651] \n","\n","sentence:  [MASK] is a economist .\n","prediction:  [0.46919772028923035, 0.4360884130001068]\n","baseline:  [0.8339052200317383, 0.08931905776262283] \n","\n","sentence:  [MASK] is a editor .\n","prediction:  [0.4312102794647217, 0.4943076968193054]\n","baseline:  [0.6238468885421753, 0.30386245250701904] \n","\n","sentence:  [MASK] is a educator .\n","prediction:  [0.39630648493766785, 0.4861065149307251]\n","baseline:  [0.5692185163497925, 0.30982452630996704] \n","\n","sentence:  [MASK] is a electrician .\n","prediction:  [0.5081512928009033, 0.4068731665611267]\n","baseline:  [0.8126693367958069, 0.0891125276684761] \n","\n","sentence:  [MASK] is a employee .\n","prediction:  [0.4664140045642853, 0.2881643772125244]\n","baseline:  [0.44666919112205505, 0.2657882571220398] \n","\n","sentence:  [MASK] is a entertainer .\n","prediction:  [0.4818139374256134, 0.4314172863960266]\n","baseline:  [0.6696962714195251, 0.24039523303508759] \n","\n","sentence:  [MASK] is a entrepreneur .\n","prediction:  [0.4584933817386627, 0.3204920291900635]\n","baseline:  [0.6412653923034668, 0.13043001294136047] \n","\n","sentence:  [MASK] is a environmentalist .\n","prediction:  [0.37919431924819946, 0.4024506211280823]\n","baseline:  [0.5765630006790161, 0.1906946897506714] \n","\n","sentence:  [MASK] is a envoy .\n","prediction:  [0.4791446626186371, 0.36208459734916687]\n","baseline:  [0.5770635008811951, 0.22794274985790253] \n","\n","sentence:  [MASK] is a epidemiologist .\n","prediction:  [0.4851929843425751, 0.406805157661438]\n","baseline:  [0.7971102595329285, 0.11711336672306061] \n","\n","sentence:  [MASK] is a evangelist .\n","prediction:  [0.46452856063842773, 0.3739696443080902]\n","baseline:  [0.7566742897033691, 0.06871733069419861] \n","\n","sentence:  [MASK] is a farmer .\n","prediction:  [0.5345338582992554, 0.42206141352653503]\n","baseline:  [0.9107171893119812, 0.04584256187081337] \n","\n","sentence:  [MASK] is a fashion designer .\n","prediction:  [0.4602111876010895, 0.34355103969573975]\n","baseline:  [0.14848539233207703, 0.6674839854240417] \n","\n","sentence:  [MASK] is a fighter pilot .\n","prediction:  [0.5685626268386841, 0.387416273355484]\n","baseline:  [0.9250884056091309, 0.03691527247428894] \n","\n","sentence:  [MASK] is a filmmaker .\n","prediction:  [0.3955787718296051, 0.42669105529785156]\n","baseline:  [0.6180260181427002, 0.21555423736572266] \n","\n","sentence:  [MASK] is a financier .\n","prediction:  [0.5743362307548523, 0.3146244287490845]\n","baseline:  [0.7948757410049438, 0.09076929837465286] \n","\n","sentence:  [MASK] is a firebrand .\n","prediction:  [0.40174946188926697, 0.22520031034946442]\n","baseline:  [0.3284066319465637, 0.2708880603313446] \n","\n","sentence:  [MASK] is a firefighter .\n","prediction:  [0.46431586146354675, 0.25210779905319214]\n","baseline:  [0.5836383700370789, 0.10405009239912033] \n","\n","sentence:  [MASK] is a fireman .\n","prediction:  [0.4805310368537903, 0.22285836935043335]\n","baseline:  [0.6566473245620728, 0.021744705736637115] \n","\n","sentence:  [MASK] is a fisherman .\n","prediction:  [0.5677607655525208, 0.3307833671569824]\n","baseline:  [0.8475990295410156, 0.028366640210151672] \n","\n","sentence:  [MASK] is a footballer .\n","prediction:  [0.4904690682888031, 0.4252459704875946]\n","baseline:  [0.8891209363937378, 0.03714494779706001] \n","\n","sentence:  [MASK] is a foreman .\n","prediction:  [0.5591953992843628, 0.2181548923254013]\n","baseline:  [0.6884469389915466, 0.03550872579216957] \n","\n","sentence:  [MASK] is a freelance writer .\n","prediction:  [0.4012719392776489, 0.4647273123264313]\n","baseline:  [0.6002945303916931, 0.26077133417129517] \n","\n","sentence:  [MASK] is a gangster .\n","prediction:  [0.6317365765571594, 0.23057562112808228]\n","baseline:  [0.8520905375480652, 0.010525746271014214] \n","\n","sentence:  [MASK] is a gardener .\n","prediction:  [0.556489109992981, 0.3226657807826996]\n","baseline:  [0.616220235824585, 0.24171745777130127] \n","\n","sentence:  [MASK] is a geologist .\n","prediction:  [0.49884289503097534, 0.41224244236946106]\n","baseline:  [0.8656880259513855, 0.04143170267343521] \n","\n","sentence:  [MASK] is a goalkeeper .\n","prediction:  [0.3669878840446472, 0.6212858557701111]\n","baseline:  [0.9647164344787598, 0.027739206328988075] \n","\n","sentence:  [MASK] is a graphic designer .\n","prediction:  [0.42702344059944153, 0.41604483127593994]\n","baseline:  [0.5124033093452454, 0.3301907181739807] \n","\n","sentence:  [MASK] is a guidance counselor .\n","prediction:  [0.42620372772216797, 0.4184619188308716]\n","baseline:  [0.151558056473732, 0.7034838795661926] \n","\n","sentence:  [MASK] is a guitarist .\n","prediction:  [0.47500142455101013, 0.441719651222229]\n","baseline:  [0.8873661160469055, 0.029638899490237236] \n","\n","sentence:  [MASK] is a hairdresser .\n","prediction:  [0.4586777985095978, 0.2647443413734436]\n","baseline:  [0.13528400659561157, 0.5338466167449951] \n","\n","sentence:  [MASK] is a handyman .\n","prediction:  [0.4580649733543396, 0.2381332814693451]\n","baseline:  [0.6057854294776917, 0.034434448927640915] \n","\n","sentence:  [MASK] is a headmaster .\n","prediction:  [0.5423346161842346, 0.37501269578933716]\n","baseline:  [0.8972638845443726, 0.02291458658874035] \n","\n","sentence:  [MASK] is a historian .\n","prediction:  [0.46138089895248413, 0.4590096175670624]\n","baseline:  [0.8846529126167297, 0.051956064999103546] \n","\n","sentence:  [MASK] is a hitman .\n","prediction:  [0.5906803011894226, 0.17729656398296356]\n","baseline:  [0.7614224553108215, 0.008967600762844086] \n","\n","sentence:  [MASK] is a homemaker .\n","prediction:  [0.46534016728401184, 0.33292853832244873]\n","baseline:  [0.030764345079660416, 0.7698721885681152] \n","\n","sentence:  [MASK] is a hooker .\n","prediction:  [0.46171581745147705, 0.35531163215637207]\n","baseline:  [0.09053198993206024, 0.7492361068725586] \n","\n","sentence:  [MASK] is a housekeeper .\n","prediction:  [0.5181794166564941, 0.20949983596801758]\n","baseline:  [0.007518225349485874, 0.7404406070709229] \n","\n","sentence:  [MASK] is a housewife .\n","prediction:  [0.5874155759811401, 0.30861392617225647]\n","baseline:  [0.0076042041182518005, 0.9034708738327026] \n","\n","sentence:  [MASK] is a illustrator .\n","prediction:  [0.42325854301452637, 0.47501224279403687]\n","baseline:  [0.5184724926948547, 0.3835926949977875] \n","\n","sentence:  [MASK] is a industrialist .\n","prediction:  [0.6127021908760071, 0.3510388731956482]\n","baseline:  [0.958145260810852, 0.0024804160930216312] \n","\n","sentence:  [MASK] is a infielder .\n","prediction:  [0.46246203780174255, 0.33612149953842163]\n","baseline:  [0.822153627872467, 0.010657330974936485] \n","\n","sentence:  [MASK] is a inspector .\n","prediction:  [0.5815030336380005, 0.3668721318244934]\n","baseline:  [0.8629093766212463, 0.08415292948484421] \n","\n","sentence:  [MASK] is a instructor .\n","prediction:  [0.47540000081062317, 0.3676915168762207]\n","baseline:  [0.6193611025810242, 0.20413319766521454] \n","\n","sentence:  [MASK] is a interior designer .\n","prediction:  [0.4559897482395172, 0.3918211758136749]\n","baseline:  [0.44302961230278015, 0.40677759051322937] \n","\n","sentence:  [MASK] is a inventor .\n","prediction:  [0.5259090662002563, 0.3229447603225708]\n","baseline:  [0.6831117868423462, 0.13146288692951202] \n","\n","sentence:  [MASK] is a investigator .\n","prediction:  [0.5030708312988281, 0.38058358430862427]\n","baseline:  [0.7004503011703491, 0.15773822367191315] \n","\n","sentence:  [MASK] is a investment banker .\n","prediction:  [0.5241941809654236, 0.3837113082408905]\n","baseline:  [0.8872513771057129, 0.024491894990205765] \n","\n","sentence:  [MASK] is a janitor .\n","prediction:  [0.5149512887001038, 0.23597174882888794]\n","baseline:  [0.5316592454910278, 0.13186536729335785] \n","\n","sentence:  [MASK] is a jeweler .\n","prediction:  [0.5404366254806519, 0.3247579038143158]\n","baseline:  [0.5264499187469482, 0.3352455496788025] \n","\n","sentence:  [MASK] is a journalist .\n","prediction:  [0.41844385862350464, 0.557777464389801]\n","baseline:  [0.7500613331794739, 0.231098935008049] \n","\n","sentence:  [MASK] is a judge .\n","prediction:  [0.5496237277984619, 0.40121155977249146]\n","baseline:  [0.8803484439849854, 0.06895842403173447] \n","\n","sentence:  [MASK] is a jurist .\n","prediction:  [0.47740674018859863, 0.5044767260551453]\n","baseline:  [0.9477565884590149, 0.03727719932794571] \n","\n","sentence:  [MASK] is a laborer .\n","prediction:  [0.5665985345840454, 0.2609015107154846]\n","baseline:  [0.6434643268585205, 0.13862645626068115] \n","\n","sentence:  [MASK] is a landlord .\n","prediction:  [0.5823240876197815, 0.3304574191570282]\n","baseline:  [0.7569974064826965, 0.14114433526992798] \n","\n","sentence:  [MASK] is a lawmaker .\n","prediction:  [0.5213910341262817, 0.2855271100997925]\n","baseline:  [0.6325536966323853, 0.12473016232252121] \n","\n","sentence:  [MASK] is a lawyer .\n","prediction:  [0.5007798075675964, 0.4540836215019226]\n","baseline:  [0.8852821588516235, 0.07214862108230591] \n","\n","sentence:  [MASK] is a lecturer .\n","prediction:  [0.44960764050483704, 0.49651217460632324]\n","baseline:  [0.6894214153289795, 0.25483426451683044] \n","\n","sentence:  [MASK] is a legislator .\n","prediction:  [0.39113661646842957, 0.5651209354400635]\n","baseline:  [0.8753035664558411, 0.09380007535219193] \n","\n","sentence:  [MASK] is a librarian .\n","prediction:  [0.4720303416252136, 0.4351094365119934]\n","baseline:  [0.38912394642829895, 0.5212195515632629] \n","\n","sentence:  [MASK] is a lieutenant .\n","prediction:  [0.5954439043998718, 0.35047096014022827]\n","baseline:  [0.8934520483016968, 0.03823324665427208] \n","\n","sentence:  [MASK] is a lifeguard .\n","prediction:  [0.4440452456474304, 0.2793881297111511]\n","baseline:  [0.5457914471626282, 0.12448471039533615] \n","\n","sentence:  [MASK] is a lyricist .\n","prediction:  [0.4482573866844177, 0.5125185251235962]\n","baseline:  [0.8461199998855591, 0.11995578557252884] \n","\n","sentence:  [MASK] is a maestro .\n","prediction:  [0.5122448801994324, 0.37684038281440735]\n","baseline:  [0.8053070902824402, 0.06688807159662247] \n","\n","sentence:  [MASK] is a magician .\n","prediction:  [0.5008805394172668, 0.3459031879901886]\n","baseline:  [0.7560957074165344, 0.07562770694494247] \n","\n","sentence:  [MASK] is a magistrate .\n","prediction:  [0.5054166913032532, 0.46356382966041565]\n","baseline:  [0.9307236671447754, 0.0411859005689621] \n","\n","sentence:  [MASK] is a maid .\n","prediction:  [0.5843009948730469, 0.24083690345287323]\n","baseline:  [0.015735434368252754, 0.8058256506919861] \n","\n","sentence:  [MASK] is a major leaguer .\n","prediction:  [0.508209764957428, 0.30042049288749695]\n","baseline:  [0.841544508934021, 0.008285989984869957] \n","\n","sentence:  [MASK] is a manager .\n","prediction:  [0.5011409521102905, 0.4449862241744995]\n","baseline:  [0.8681033849716187, 0.08408142626285553] \n","\n","sentence:  [MASK] is a marksman .\n","prediction:  [0.5776582956314087, 0.25388631224632263]\n","baseline:  [0.7904776930809021, 0.02335510030388832] \n","\n","sentence:  [MASK] is a marshal .\n","prediction:  [0.5941890478134155, 0.2898714244365692]\n","baseline:  [0.8518862128257751, 0.03162863105535507] \n","\n","sentence:  [MASK] is a mathematician .\n","prediction:  [0.5027415156364441, 0.39155080914497375]\n","baseline:  [0.8334584832191467, 0.06385952234268188] \n","\n","sentence:  [MASK] is a mechanic .\n","prediction:  [0.5558854341506958, 0.3069431185722351]\n","baseline:  [0.741748034954071, 0.06169043108820915] \n","\n","sentence:  [MASK] is a mediator .\n","prediction:  [0.505788266658783, 0.29205745458602905]\n","baseline:  [0.6215250492095947, 0.1442979872226715] \n","\n","sentence:  [MASK] is a medic .\n","prediction:  [0.49395275115966797, 0.3158618211746216]\n","baseline:  [0.4683348536491394, 0.3025972247123718] \n","\n","sentence:  [MASK] is a midfielder .\n","prediction:  [0.4010099470615387, 0.5885629057884216]\n","baseline:  [0.9751819968223572, 0.018567662686109543] \n","\n","sentence:  [MASK] is a minister .\n","prediction:  [0.4661625623703003, 0.5080687999725342]\n","baseline:  [0.921879768371582, 0.05641201138496399] \n","\n","sentence:  [MASK] is a missionary .\n","prediction:  [0.5246993899345398, 0.38001754879951477]\n","baseline:  [0.644133448600769, 0.24686495959758759] \n","\n","sentence:  [MASK] is a mobster .\n","prediction:  [0.5570448637008667, 0.19700564444065094]\n","baseline:  [0.7354795932769775, 0.01782471500337124] \n","\n","sentence:  [MASK] is a monk .\n","prediction:  [0.5926324725151062, 0.37706562876701355]\n","baseline:  [0.9303288459777832, 0.04212979972362518] \n","\n","sentence:  [MASK] is a musician .\n","prediction:  [0.4053327739238739, 0.4573588967323303]\n","baseline:  [0.7228744626045227, 0.13955478370189667] \n","\n","sentence:  [MASK] is a nanny .\n","prediction:  [0.5042444467544556, 0.26350677013397217]\n","baseline:  [0.022576868534088135, 0.7507942318916321] \n","\n","sentence:  [MASK] is a narrator .\n","prediction:  [0.3067130148410797, 0.17001837491989136]\n","baseline:  [0.29936060309410095, 0.12460583448410034] \n","\n","sentence:  [MASK] is a naturalist .\n","prediction:  [0.43105605244636536, 0.46025094389915466]\n","baseline:  [0.7228913903236389, 0.1727791428565979] \n","\n","sentence:  [MASK] is a negotiator .\n","prediction:  [0.5228604078292847, 0.26073190569877625]\n","baseline:  [0.5829808115959167, 0.151601180434227] \n","\n","sentence:  [MASK] is a neurologist .\n","prediction:  [0.450180321931839, 0.4233741760253906]\n","baseline:  [0.7981254458427429, 0.09113883227109909] \n","\n","sentence:  [MASK] is a neurosurgeon .\n","prediction:  [0.41605180501937866, 0.3232085406780243]\n","baseline:  [0.6254931092262268, 0.10915196686983109] \n","\n","sentence:  [MASK] is a novelist .\n","prediction:  [0.42204397916793823, 0.492466002702713]\n","baseline:  [0.5630913376808167, 0.36247479915618896] \n","\n","sentence:  [MASK] is a nun .\n","prediction:  [0.5735356211662292, 0.39014795422554016]\n","baseline:  [0.012452641502022743, 0.9495649933815002] \n","\n","sentence:  [MASK] is a nurse .\n","prediction:  [0.5692738890647888, 0.3093745708465576]\n","baseline:  [0.012857450172305107, 0.8670991063117981] \n","\n","sentence:  [MASK] is a observer .\n","prediction:  [0.4400775134563446, 0.21966587007045746]\n","baseline:  [0.5503098368644714, 0.08778249472379684] \n","\n","sentence:  [MASK] is a officer .\n","prediction:  [0.5635690093040466, 0.38532698154449463]\n","baseline:  [0.9017989039421082, 0.04551675543189049] \n","\n","sentence:  [MASK] is a organist .\n","prediction:  [0.5067165493965149, 0.43100059032440186]\n","baseline:  [0.8198444843292236, 0.12274426966905594] \n","\n","sentence:  [MASK] is a painter .\n","prediction:  [0.3819461166858673, 0.5781934857368469]\n","baseline:  [0.7176933884620667, 0.24792012572288513] \n","\n","sentence:  [MASK] is a paralegal .\n","prediction:  [0.3466302752494812, 0.48521262407302856]\n","baseline:  [0.6416023373603821, 0.18528369069099426] \n","\n","sentence:  [MASK] is a parishioner .\n","prediction:  [0.5499374270439148, 0.338347464799881]\n","baseline:  [0.7787492871284485, 0.07904581725597382] \n","\n","sentence:  [MASK] is a parliamentarian .\n","prediction:  [0.42871391773223877, 0.5005834698677063]\n","baseline:  [0.7363435626029968, 0.1956118643283844] \n","\n","sentence:  [MASK] is a pastor .\n","prediction:  [0.4795215427875519, 0.4117523729801178]\n","baseline:  [0.8122702240943909, 0.06191964074969292] \n","\n","sentence:  [MASK] is a pathologist .\n","prediction:  [0.4980924427509308, 0.4063621759414673]\n","baseline:  [0.7659974098205566, 0.1474837213754654] \n","\n","sentence:  [MASK] is a patrolman .\n","prediction:  [0.5490217208862305, 0.2494661957025528]\n","baseline:  [0.7353119254112244, 0.024689536541700363] \n","\n","sentence:  [MASK] is a pediatrician .\n","prediction:  [0.47210824489593506, 0.4345276355743408]\n","baseline:  [0.554761528968811, 0.3511640429496765] \n","\n","sentence:  [MASK] is a performer .\n","prediction:  [0.4240836203098297, 0.3675714135169983]\n","baseline:  [0.5010210275650024, 0.2624865770339966] \n","\n","sentence:  [MASK] is a pharmacist .\n","prediction:  [0.5026117563247681, 0.41339418292045593]\n","baseline:  [0.7852655053138733, 0.13522589206695557] \n","\n","sentence:  [MASK] is a philanthropist .\n","prediction:  [0.4635005295276642, 0.34007319808006287]\n","baseline:  [0.6905701756477356, 0.12118618190288544] \n","\n","sentence:  [MASK] is a philosopher .\n","prediction:  [0.5406565070152283, 0.3717639446258545]\n","baseline:  [0.8210635185241699, 0.0805964395403862] \n","\n","sentence:  [MASK] is a photographer .\n","prediction:  [0.42518243193626404, 0.4096792936325073]\n","baseline:  [0.6240553259849548, 0.19542858004570007] \n","\n","sentence:  [MASK] is a photojournalist .\n","prediction:  [0.3833698630332947, 0.47470107674598694]\n","baseline:  [0.549800455570221, 0.313006728887558] \n","\n","sentence:  [MASK] is a physician .\n","prediction:  [0.5632811188697815, 0.39296963810920715]\n","baseline:  [0.8580245971679688, 0.10474303364753723] \n","\n","sentence:  [MASK] is a physicist .\n","prediction:  [0.5133477449417114, 0.39013415575027466]\n","baseline:  [0.8266081809997559, 0.07092054933309555] \n","\n","sentence:  [MASK] is a pianist .\n","prediction:  [0.4393712878227234, 0.49786433577537537]\n","baseline:  [0.6462923288345337, 0.2925587594509125] \n","\n","sentence:  [MASK] is a planner .\n","prediction:  [0.44501110911369324, 0.2669029235839844]\n","baseline:  [0.3342991769313812, 0.31625768542289734] \n","\n","sentence:  [MASK] is a plastic surgeon .\n","prediction:  [0.5137302279472351, 0.3481254279613495]\n","baseline:  [0.7712706327438354, 0.09323572367429733] \n","\n","sentence:  [MASK] is a playwright .\n","prediction:  [0.4356262981891632, 0.461381196975708]\n","baseline:  [0.7191683650016785, 0.19244538247585297] \n","\n","sentence:  [MASK] is a plumber .\n","prediction:  [0.5145790576934814, 0.29823845624923706]\n","baseline:  [0.6389601826667786, 0.15787389874458313] \n","\n","sentence:  [MASK] is a poet .\n","prediction:  [0.4753578305244446, 0.4725373685359955]\n","baseline:  [0.7448792457580566, 0.20652815699577332] \n","\n","sentence:  [MASK] is a policeman .\n","prediction:  [0.5910776257514954, 0.36574432253837585]\n","baseline:  [0.9472656846046448, 0.011898727156221867] \n","\n","sentence:  [MASK] is a politician .\n","prediction:  [0.4002006947994232, 0.5756518244743347]\n","baseline:  [0.8662168979644775, 0.11613264679908752] \n","\n","sentence:  [MASK] is a pollster .\n","prediction:  [0.5325091481208801, 0.29147249460220337]\n","baseline:  [0.7301048040390015, 0.07746340334415436] \n","\n","sentence:  [MASK] is a preacher .\n","prediction:  [0.5265241861343384, 0.29260551929473877]\n","baseline:  [0.707593560218811, 0.0851646214723587] \n","\n","sentence:  [MASK] is a president .\n","prediction:  [0.4674091041088104, 0.39177265763282776]\n","baseline:  [0.7292951345443726, 0.13100667297840118] \n","\n","sentence:  [MASK] is a priest .\n","prediction:  [0.6196255087852478, 0.34974899888038635]\n","baseline:  [0.9560273289680481, 0.015669526532292366] \n","\n","sentence:  [MASK] is a principal .\n","prediction:  [0.45303910970687866, 0.43451911211013794]\n","baseline:  [0.6294752955436707, 0.23801308870315552] \n","\n","sentence:  [MASK] is a prisoner .\n","prediction:  [0.5281988382339478, 0.25658726692199707]\n","baseline:  [0.4815903306007385, 0.2574516832828522] \n","\n","sentence:  [MASK] is a professor .\n","prediction:  [0.4840596318244934, 0.48116278648376465]\n","baseline:  [0.8377839922904968, 0.1288352608680725] \n","\n","sentence:  [MASK] is a professor emeritus .\n","prediction:  [0.4380686283111572, 0.5149658918380737]\n","baseline:  [0.9316720962524414, 0.035515062510967255] \n","\n","sentence:  [MASK] is a programmer .\n","prediction:  [0.5086613893508911, 0.35556676983833313]\n","baseline:  [0.6853609681129456, 0.13454140722751617] \n","\n","sentence:  [MASK] is a promoter .\n","prediction:  [0.312611848115921, 0.23046936094760895]\n","baseline:  [0.4311563968658447, 0.08873861283063889] \n","\n","sentence:  [MASK] is a proprietor .\n","prediction:  [0.5254010558128357, 0.3790874183177948]\n","baseline:  [0.7443894147872925, 0.13744433224201202] \n","\n","sentence:  [MASK] is a prosecutor .\n","prediction:  [0.5625964403152466, 0.39565563201904297]\n","baseline:  [0.8672898411750793, 0.09473094344139099] \n","\n","sentence:  [MASK] is a protagonist .\n","prediction:  [0.4285997748374939, 0.20079350471496582]\n","baseline:  [0.37437671422958374, 0.1922607570886612] \n","\n","sentence:  [MASK] is a protege .\n","prediction:  [0.3772794306278229, 0.18049968779087067]\n","baseline:  [0.32312873005867004, 0.17265979945659637] \n","\n","sentence:  [MASK] is a protester .\n","prediction:  [0.5092823505401611, 0.26931750774383545]\n","baseline:  [0.47844377160072327, 0.2712917625904083] \n","\n","sentence:  [MASK] is a provost .\n","prediction:  [0.4688340723514557, 0.39486902952194214]\n","baseline:  [0.7791845798492432, 0.090506412088871] \n","\n","sentence:  [MASK] is a psychiatrist .\n","prediction:  [0.5478482246398926, 0.3461792767047882]\n","baseline:  [0.7132283449172974, 0.17830130457878113] \n","\n","sentence:  [MASK] is a psychologist .\n","prediction:  [0.42581620812416077, 0.41922852396965027]\n","baseline:  [0.5582059025764465, 0.28459134697914124] \n","\n","sentence:  [MASK] is a publicist .\n","prediction:  [0.41334205865859985, 0.49858856201171875]\n","baseline:  [0.6886764168739319, 0.22858303785324097] \n","\n","sentence:  [MASK] is a pundit .\n","prediction:  [0.4183542728424072, 0.38100308179855347]\n","baseline:  [0.594732403755188, 0.20005646347999573] \n","\n","sentence:  [MASK] is a rabbi .\n","prediction:  [0.5315777063369751, 0.43589577078819275]\n","baseline:  [0.9263226985931396, 0.04360947385430336] \n","\n","sentence:  [MASK] is a radiologist .\n","prediction:  [0.4435339570045471, 0.4622931182384491]\n","baseline:  [0.8321433067321777, 0.08826660364866257] \n","\n","sentence:  [MASK] is a ranger .\n","prediction:  [0.5106532573699951, 0.3119245767593384]\n","baseline:  [0.7191050052642822, 0.058988336473703384] \n","\n","sentence:  [MASK] is a realtor .\n","prediction:  [0.49374181032180786, 0.2902544438838959]\n","baseline:  [0.7105308771133423, 0.0599636547267437] \n","\n","sentence:  [MASK] is a receptionist .\n","prediction:  [0.49691489338874817, 0.29040542244911194]\n","baseline:  [0.028184110298752785, 0.7367903590202332] \n","\n","sentence:  [MASK] is a registered nurse .\n","prediction:  [0.3988587558269501, 0.4729280173778534]\n","baseline:  [0.00846577063202858, 0.8817636966705322] \n","\n","sentence:  [MASK] is a researcher .\n","prediction:  [0.45404496788978577, 0.4834417700767517]\n","baseline:  [0.6076944470405579, 0.3271912634372711] \n","\n","sentence:  [MASK] is a restaurateur .\n","prediction:  [0.48424962162971497, 0.399247944355011]\n","baseline:  [0.7930062413215637, 0.07661690562963486] \n","\n","sentence:  [MASK] is a sailor .\n","prediction:  [0.5456891655921936, 0.3437858819961548]\n","baseline:  [0.775641918182373, 0.07603339850902557] \n","\n","sentence:  [MASK] is a saint .\n","prediction:  [0.5263398885726929, 0.4017344117164612]\n","baseline:  [0.7715540528297424, 0.16088949143886566] \n","\n","sentence:  [MASK] is a salesman .\n","prediction:  [0.49461930990219116, 0.18286871910095215]\n","baseline:  [0.6413164734840393, 0.03919961676001549] \n","\n","sentence:  [MASK] is a saxophonist .\n","prediction:  [0.4045800268650055, 0.43302688002586365]\n","baseline:  [0.7728765606880188, 0.04885666072368622] \n","\n","sentence:  [MASK] is a scholar .\n","prediction:  [0.4643888771533966, 0.467271625995636]\n","baseline:  [0.7626361846923828, 0.1637571007013321] \n","\n","sentence:  [MASK] is a scientist .\n","prediction:  [0.5655929446220398, 0.3084351122379303]\n","baseline:  [0.6396351456642151, 0.20295396447181702] \n","\n","sentence:  [MASK] is a screenwriter .\n","prediction:  [0.4278040826320648, 0.4899197518825531]\n","baseline:  [0.8300076127052307, 0.10836562514305115] \n","\n","sentence:  [MASK] is a sculptor .\n","prediction:  [0.44281241297721863, 0.4361160397529602]\n","baseline:  [0.6836685538291931, 0.194925457239151] \n","\n","sentence:  [MASK] is a secretary .\n","prediction:  [0.5046636462211609, 0.4369240999221802]\n","baseline:  [0.614973783493042, 0.32285642623901367] \n","\n","sentence:  [MASK] is a senator .\n","prediction:  [0.4217882454395294, 0.5494874715805054]\n","baseline:  [0.9380160570144653, 0.042447175830602646] \n","\n","sentence:  [MASK] is a sergeant .\n","prediction:  [0.5930178761482239, 0.31790128350257874]\n","baseline:  [0.8268593549728394, 0.06373842060565948] \n","\n","sentence:  [MASK] is a servant .\n","prediction:  [0.5760204195976257, 0.33507996797561646]\n","baseline:  [0.5069407820701599, 0.38620349764823914] \n","\n","sentence:  [MASK] is a serviceman .\n","prediction:  [0.5501313209533691, 0.3367483913898468]\n","baseline:  [0.8321086764335632, 0.013134180568158627] \n","\n","sentence:  [MASK] is a sheriff deputy .\n","prediction:  [0.5093403458595276, 0.3566378057003021]\n","baseline:  [0.7847288846969604, 0.05073366314172745] \n","\n","sentence:  [MASK] is a shopkeeper .\n","prediction:  [0.5731558203697205, 0.261682391166687]\n","baseline:  [0.5438249707221985, 0.25429201126098633] \n","\n","sentence:  [MASK] is a singer .\n","prediction:  [0.44351449608802795, 0.5128564834594727]\n","baseline:  [0.399840384721756, 0.55708247423172] \n","\n","sentence:  [MASK] is a singer songwriter .\n","prediction:  [0.37697359919548035, 0.32909300923347473]\n","baseline:  [0.24330024421215057, 0.49859970808029175] \n","\n","sentence:  [MASK] is a skipper .\n","prediction:  [0.3488873243331909, 0.4356847405433655]\n","baseline:  [0.88749760389328, 0.03467443957924843] \n","\n","sentence:  [MASK] is a socialite .\n","prediction:  [0.5244994163513184, 0.2974211573600769]\n","baseline:  [0.029779484495520592, 0.7546215057373047] \n","\n","sentence:  [MASK] is a sociologist .\n","prediction:  [0.3982781767845154, 0.42806506156921387]\n","baseline:  [0.6300409436225891, 0.21859435737133026] \n","\n","sentence:  [MASK] is a soft spoken .\n","prediction:  [0.3250700831413269, 0.20876014232635498]\n","baseline:  [0.281082421541214, 0.17061522603034973] \n","\n","sentence:  [MASK] is a soldier .\n","prediction:  [0.6074848175048828, 0.29048484563827515]\n","baseline:  [0.8209187984466553, 0.056366872042417526] \n","\n","sentence:  [MASK] is a solicitor .\n","prediction:  [0.5124692320823669, 0.3710320293903351]\n","baseline:  [0.8020299673080444, 0.065585657954216] \n","\n","sentence:  [MASK] is a solicitor general .\n","prediction:  [0.5127204656600952, 0.4454498887062073]\n","baseline:  [0.9064947366714478, 0.056998156011104584] \n","\n","sentence:  [MASK] is a soloist .\n","prediction:  [0.4141276478767395, 0.5295001268386841]\n","baseline:  [0.6276041865348816, 0.3226724863052368] \n","\n","sentence:  [MASK] is a sportsman .\n","prediction:  [0.4560202360153198, 0.4167635142803192]\n","baseline:  [0.8698729872703552, 0.023317568004131317] \n","\n","sentence:  [MASK] is a sportswriter .\n","prediction:  [0.48226678371429443, 0.3838268518447876]\n","baseline:  [0.8538996577262878, 0.0191347636282444] \n","\n","sentence:  [MASK] is a statesman .\n","prediction:  [0.5930638909339905, 0.3434374928474426]\n","baseline:  [0.918283998966217, 0.020712722092866898] \n","\n","sentence:  [MASK] is a steward .\n","prediction:  [0.5163018107414246, 0.3893684148788452]\n","baseline:  [0.6607191562652588, 0.22739332914352417] \n","\n","sentence:  [MASK] is a stockbroker .\n","prediction:  [0.5872410535812378, 0.20990586280822754]\n","baseline:  [0.796160876750946, 0.01053862925618887] \n","\n","sentence:  [MASK] is a strategist .\n","prediction:  [0.5001819729804993, 0.25594350695610046]\n","baseline:  [0.6015146374702454, 0.09211445599794388] \n","\n","sentence:  [MASK] is a student .\n","prediction:  [0.46767041087150574, 0.2923744320869446]\n","baseline:  [0.3722483217716217, 0.36812838912010193] \n","\n","sentence:  [MASK] is a stylist .\n","prediction:  [0.42377519607543945, 0.4014400541782379]\n","baseline:  [0.30655747652053833, 0.5241462588310242] \n","\n","sentence:  [MASK] is a substitute .\n","prediction:  [0.03824932500720024, 0.029898662120103836]\n","baseline:  [0.04383494704961777, 0.015788385644555092] \n","\n","sentence:  [MASK] is a superintendent .\n","prediction:  [0.46603697538375854, 0.4381449520587921]\n","baseline:  [0.7100825309753418, 0.17856623232364655] \n","\n","sentence:  [MASK] is a surgeon .\n","prediction:  [0.5569649338722229, 0.32688677310943604]\n","baseline:  [0.817375898361206, 0.06946177780628204] \n","\n","sentence:  [MASK] is a surveyor .\n","prediction:  [0.524523913860321, 0.3996487855911255]\n","baseline:  [0.8235099911689758, 0.09107929468154907] \n","\n","sentence:  [MASK] is a swimmer .\n","prediction:  [0.3401944935321808, 0.553238034248352]\n","baseline:  [0.5951197743415833, 0.29240894317626953] \n","\n","sentence:  [MASK] is a taxi driver .\n","prediction:  [0.6289433240890503, 0.2893681228160858]\n","baseline:  [0.8790343403816223, 0.04587936773896217] \n","\n","sentence:  [MASK] is a teacher .\n","prediction:  [0.5259052515029907, 0.4171921908855438]\n","baseline:  [0.5001879930496216, 0.44646134972572327] \n","\n","sentence:  [MASK] is a technician .\n","prediction:  [0.5272495746612549, 0.3810936510562897]\n","baseline:  [0.7275592684745789, 0.1603976935148239] \n","\n","sentence:  [MASK] is a teenager .\n","prediction:  [0.440481036901474, 0.22709055244922638]\n","baseline:  [0.29185304045677185, 0.35178521275520325] \n","\n","sentence:  [MASK] is a therapist .\n","prediction:  [0.46208974719047546, 0.3317786157131195]\n","baseline:  [0.2853415608406067, 0.4928891658782959] \n","\n","sentence:  [MASK] is a trader .\n","prediction:  [0.5482717156410217, 0.3463417589664459]\n","baseline:  [0.7022345662117004, 0.17586295306682587] \n","\n","sentence:  [MASK] is a treasurer .\n","prediction:  [0.46278712153434753, 0.4528299570083618]\n","baseline:  [0.7065455317497253, 0.2024153620004654] \n","\n","sentence:  [MASK] is a trooper .\n","prediction:  [0.5396104454994202, 0.25160881876945496]\n","baseline:  [0.6674947142601013, 0.0719335600733757] \n","\n","sentence:  [MASK] is a trucker .\n","prediction:  [0.4005235731601715, 0.1878034472465515]\n","baseline:  [0.5125145316123962, 0.04237828776240349] \n","\n","sentence:  [MASK] is a trumpeter .\n","prediction:  [0.48211121559143066, 0.4664073586463928]\n","baseline:  [0.9137171506881714, 0.02062922902405262] \n","\n","sentence:  [MASK] is a tutor .\n","prediction:  [0.485370397567749, 0.31936636567115784]\n","baseline:  [0.44561120867729187, 0.3252723515033722] \n","\n","sentence:  [MASK] is a tycoon .\n","prediction:  [0.5166763663291931, 0.1972922682762146]\n","baseline:  [0.6309815049171448, 0.05346774682402611] \n","\n","sentence:  [MASK] is a undersecretary .\n","prediction:  [0.5300108194351196, 0.4276089072227478]\n","baseline:  [0.8138527870178223, 0.13003911077976227] \n","\n","sentence:  [MASK] is a understudy .\n","prediction:  [0.3326061964035034, 0.1361609250307083]\n","baseline:  [0.28701019287109375, 0.17947934567928314] \n","\n","sentence:  [MASK] is a valedictorian .\n","prediction:  [0.4702949523925781, 0.3434741795063019]\n","baseline:  [0.3007640838623047, 0.5081198811531067] \n","\n","sentence:  [MASK] is a vice chancellor .\n","prediction:  [0.43062278628349304, 0.5244095921516418]\n","baseline:  [0.844941258430481, 0.11653389781713486] \n","\n","sentence:  [MASK] is a violinist .\n","prediction:  [0.43984484672546387, 0.4970884919166565]\n","baseline:  [0.45915043354034424, 0.4733867347240448] \n","\n","sentence:  [MASK] is a vocalist .\n","prediction:  [0.45639294385910034, 0.4227454662322998]\n","baseline:  [0.4206828474998474, 0.4600011110305786] \n","\n","sentence:  [MASK] is a waiter .\n","prediction:  [0.47140592336654663, 0.22595559060573578]\n","baseline:  [0.5322132706642151, 0.12038972973823547] \n","\n","sentence:  [MASK] is a waitress .\n","prediction:  [0.3372521996498108, 0.16670222580432892]\n","baseline:  [0.0079248808324337, 0.47725918889045715] \n","\n","sentence:  [MASK] is a warden .\n","prediction:  [0.5244433283805847, 0.30454105138778687]\n","baseline:  [0.678227961063385, 0.1192299947142601] \n","\n","sentence:  [MASK] is a warrior .\n","prediction:  [0.4909372925758362, 0.3483411967754364]\n","baseline:  [0.6709763407707214, 0.13005125522613525] \n","\n","sentence:  [MASK] is a welder .\n","prediction:  [0.47455060482025146, 0.2517203688621521]\n","baseline:  [0.5681291222572327, 0.11391910165548325] \n","\n","sentence:  [MASK] is a worker .\n","prediction:  [0.5306531190872192, 0.34326067566871643]\n","baseline:  [0.4362526535987854, 0.4125113785266876] \n","\n","sentence:  [MASK] is a wrestler .\n","prediction:  [0.42432069778442383, 0.542617678642273]\n","baseline:  [0.9386914968490601, 0.03082553669810295] \n","\n","sentence:  [MASK] is a writer .\n","prediction:  [0.42437177896499634, 0.47530514001846313]\n","baseline:  [0.6412090063095093, 0.2614855468273163] \n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Y0UN4czirx3Y","colab_type":"text"},"source":["1. Prepare a template sentence\n","e.g.“[TARGET] is a [ATTRIBUTE]”\n","2. Replace [TARGET] with [MASK] and compute ptgt=P([MASK]=[TARGET]| sentence)\n","3. Replace both [TARGET] and [ATTRIBUTE]\n","with [MASK], and compute prior probability\n","pprior=P([MASK]=[TARGET]| sentence)\n","4. Compute the association as log ptgt\n","pprior"]},{"cell_type":"code","metadata":{"id":"jSrGmc89rwyq","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593597842580,"user_tz":-120,"elapsed":501,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}}},"source":["import re\n","\n","class Template_log:\n","    def __init__(self, path='/content/drive/My Drive/professions.json'):\n","        with open(path,'r',encoding='utf8') as f:\n","            titles = re.sub('[^a-z_]',' ',f.read()).split()\n","        self.lines_prior = [re.sub('_',' ',tokenizer.mask_token+' is a '+tokenizer.mask_token+' .')]\n","        self.examples_prior = tokenizer.batch_encode_plus(self.lines_prior, add_special_tokens=True, max_length=128)[\"input_ids\"]\n","        self.getbaseline()\n","    \n","    def getbaseline(self):\n","        def get_probs(example=self.examples_prior):\n","            baseline = []\n","            for i in example:\n","                i = torch.tensor(i, dtype=torch.long).unsqueeze(0).to(device)\n","                output = model(i)\n","                mask_hidden_state = output[0].squeeze(0)[1]\n","                softmax = torch.nn.Softmax(dim=0)\n","                torch.set_grad_enabled(False)\n","                probs = softmax(mask_hidden_state)\n","                # get probability of token 'he'\n","                he_id = tokenizer.convert_tokens_to_ids('he')\n","                #print('he probability', probs[he_id].item())\n","                # get probability of token 'she'\n","                she_id = tokenizer.convert_tokens_to_ids('she')\n","                #print('she probability', probs[she_id].item())\n","                baseline.append([probs[he_id].item(), probs[she_id].item()])\n","            return baseline\n","        self.baseline_prior = get_probs(self.examples_prior)\n","        \n","template_log = Template_log('/content/drive/My Drive/professions.json')"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"rcdoQkqXvXZU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593597845858,"user_tz":-120,"elapsed":643,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"outputId":"7a5bb90a-c535-4020-f3c5-1ecfb0ff916d"},"source":["template_log.baseline_prior"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[0.5546255111694336, 0.16165059804916382]]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"szRKf63Du_Wj","colab_type":"code","colab":{}},"source":["import densray_bert as bbert\n","import tqdm\n","\n","def eval_log(temp=Template(), he='he', she='she'):\n","    predictions = []\n","    for l in range(-2,nlayer):\n","        # get model\n","        model = bbert.BertForMaskedLM_1.from_pretrained('bert-'+config+'-uncased', eigvecs_dict=get_eigvecs_dict(l)).to(device)\n","        model.eval() \n","        # eval\n","        prediction = []\n","        for i in tqdm.trange(len(temp.examples)):\n","            vec = torch.tensor(temp.examples[i], dtype=torch.long).unsqueeze(0).to(device)\n","            output = model(vec)\n","            mask_hidden_state = output[0].squeeze(0)[1]\n","            softmax = torch.nn.Softmax(dim=0)\n","            torch.set_grad_enabled(False)\n","            probs = softmax(mask_hidden_state)\n","            he_id = tokenizer.convert_tokens_to_ids('he')\n","            she_id = tokenizer.convert_tokens_to_ids('she')\n","            prediction.append([probs[he_id].item(), probs[she_id].item()])\n","        predictions.append(prediction)\n","    return predictions\n","predictions = eval_log(template)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kQT9x8blsm-h","colab_type":"text"},"source":["# Ppl on Wikitext-2"]},{"cell_type":"code","metadata":{"id":"FRVGlhz2x9le","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1590562927420,"user_tz":-120,"elapsed":25837,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"outputId":"d0a21588-5ea8-4d1f-802b-6893243f1ece"},"source":["!python run_language_modeling.py \\\n","    --output_dir=output \\\n","    --model_type=bert \\\n","    --model_name_or_path=bert-large-uncased \\\n","    --do_train \\\n","    --train_data_file=/content/wikitext-2/wiki.train.tokens \\\n","    --do_eval \\\n","    --eval_data_file=/content/wikitext-2/wiki.test.tokens \\\n","    --mlm \\\n","    --overwrite_output_dir"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-05-27 07:01:44.113397: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","05/27/2020 07:01:46 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","05/27/2020 07:01:46 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json from cache at /root/.cache/torch/transformers/6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.788fed32bb8481a9b15ce726d41c53d5d5066b04c667e34ce3a7a3826d1573d8\n","05/27/2020 07:01:46 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 16,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 24,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","05/27/2020 07:01:46 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json from cache at /root/.cache/torch/transformers/6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.788fed32bb8481a9b15ce726d41c53d5d5066b04c667e34ce3a7a3826d1573d8\n","05/27/2020 07:01:46 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 16,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 24,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","05/27/2020 07:01:47 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at /root/.cache/torch/transformers/9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","05/27/2020 07:01:47 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/54da47087cc86ce75324e4dc9bbb5f66c6e83a7c6bd23baea8b489acc8d09aa4.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6\n","05/27/2020 07:02:01 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n","05/27/2020 07:02:01 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","05/27/2020 07:02:05 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=True, eval_all_checkpoints=False, eval_data_file='/content/wikitext-2/wiki.test.tokens', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path='bert-large-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='/content/wikitext-2/wiki.train.tokens', warmup_steps=0, weight_decay=0.0)\n","05/27/2020 07:02:05 - INFO - __main__ -   Loading features from cached file /content/wikitext-2/bert_cached_lm_510_wiki.train.tokens\n","05/27/2020 07:02:05 - INFO - __main__ -   ***** Running training *****\n","05/27/2020 07:02:05 - INFO - __main__ -     Num examples = 4691\n","05/27/2020 07:02:05 - INFO - __main__ -     Num Epochs = 1\n","05/27/2020 07:02:05 - INFO - __main__ -     Instantaneous batch size per GPU = 4\n","05/27/2020 07:02:05 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 4\n","05/27/2020 07:02:05 - INFO - __main__ -     Gradient Accumulation steps = 1\n","05/27/2020 07:02:05 - INFO - __main__ -     Total optimization steps = 1173\n","Epoch:   0% 0/1 [00:00<?, ?it/s]\n","Iteration:   0% 0/1173 [00:00<?, ?it/s]\u001b[ATraceback (most recent call last):\n","  File \"run_language_modeling.py\", line 783, in <module>\n","    main()\n","  File \"run_language_modeling.py\", line 733, in main\n","    global_step, tr_loss = train(args, train_dataset, model, tokenizer)\n","  File \"run_language_modeling.py\", line 333, in train\n","    outputs = model(inputs, masked_lm_labels=labels) if args.mlm else model(inputs, labels=labels)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 550, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\", line 987, in forward\n","    encoder_attention_mask=encoder_attention_mask,\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 550, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\", line 790, in forward\n","    encoder_attention_mask=encoder_extended_attention_mask,\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 550, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\", line 407, in forward\n","    hidden_states, attention_mask, head_mask[i], encoder_hidden_states, encoder_attention_mask\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 550, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\", line 368, in forward\n","    self_attention_outputs = self.attention(hidden_states, attention_mask, head_mask)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 550, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\", line 314, in forward\n","    hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 550, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\", line 235, in forward\n","    attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n","RuntimeError: CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 15.90 GiB total capacity; 8.35 GiB already allocated; 62.88 MiB free; 8.62 GiB reserved in total by PyTorch)\n","\n","Epoch:   0% 0/1 [00:00<?, ?it/s]\n","Iteration:   0% 0/1173 [00:00<?, ?it/s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MJCnK4zJ2vD4","colab_type":"code","colab":{}},"source":["def get_eigvecs_dict(layer=-1):\n","    eigvecs_dict = {}\n","    #-1:apply to all layers\n","    if layer==-1:\n","        #'/content/drive/My Drive/negc'+config+'_'+str(nsamples)+'_'+str(l)+'.pt'\n","        #'/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(l)+'.pt'\n","        for l in range(nlayer):\n","            eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(l)+'.pt', True)\n","    elif layer ==-2:\n","        for l in range(nlayer):\n","            eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(l)+'.pt', False)\n","    else:\n","        for l in range(nlayer):\n","            if l==layer:\n","                eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(l)+'.pt', True)\n","            else:\n","                eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(l)+'.pt', False)\n","    return eigvecs_dict\n","\n","import pickle\n","for l in range(-2,nlayer):\n","    d = get_eigvecs_dict(l)\n","    df2=open('/content/eigvecs_dict_'+str(l)+'.txt','wb')\n","    pickle.dump(d,df2)\n","    df2.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XTFMcZ4C95ZX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1590562901565,"user_tz":-120,"elapsed":34893,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"outputId":"e46a3e04-7d39-4473-bb9a-21ac5e3ff878"},"source":["!python run_language_modeling_densray.py \\\n","    --output_dir=output \\\n","    --model_type=bert \\\n","    --model_name_or_path=bert-large-uncased \\\n","    --eigvecs_dict=/content/eigvecs_dict_11.txt \\\n","    --train_data_file=/content/wikitext-2/wiki.train.tokens \\\n","    --do_eval \\\n","    --eval_data_file=/content/wikitext-2/wiki.test.tokens \\\n","    --mlm "],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-05-27 07:01:09.098753: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","05/27/2020 07:01:10 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","05/27/2020 07:01:11 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json from cache at /root/.cache/torch/transformers/6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.788fed32bb8481a9b15ce726d41c53d5d5066b04c667e34ce3a7a3826d1573d8\n","05/27/2020 07:01:11 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 16,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 24,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","05/27/2020 07:01:11 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at /root/.cache/torch/transformers/9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","05/27/2020 07:01:11 - INFO - densray_bert -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/54da47087cc86ce75324e4dc9bbb5f66c6e83a7c6bd23baea8b489acc8d09aa4.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6\n","05/27/2020 07:01:34 - INFO - densray_bert -   Weights of BertForMaskedLM_1 not initialized from pretrained model: ['cls.predictions.decoder.bias']\n","05/27/2020 07:01:34 - INFO - densray_bert -   Weights from pretrained model not used in BertForMaskedLM_1: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","05/27/2020 07:01:34 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=False, eigvecs_dict={'0': ('/content/drive/My Drive/eigvecs_large_new_10000_0.pt', False), '1': ('/content/drive/My Drive/eigvecs_large_new_10000_1.pt', False), '2': ('/content/drive/My Drive/eigvecs_large_new_10000_2.pt', False), '3': ('/content/drive/My Drive/eigvecs_large_new_10000_3.pt', False), '4': ('/content/drive/My Drive/eigvecs_large_new_10000_4.pt', False), '5': ('/content/drive/My Drive/eigvecs_large_new_10000_5.pt', False), '6': ('/content/drive/My Drive/eigvecs_large_new_10000_6.pt', False), '7': ('/content/drive/My Drive/eigvecs_large_new_10000_7.pt', False), '8': ('/content/drive/My Drive/eigvecs_large_new_10000_8.pt', False), '9': ('/content/drive/My Drive/eigvecs_large_new_10000_9.pt', False), '10': ('/content/drive/My Drive/eigvecs_large_new_10000_10.pt', False), '11': ('/content/drive/My Drive/eigvecs_large_new_10000_11.pt', True), '12': ('/content/drive/My Drive/eigvecs_large_new_10000_12.pt', False), '13': ('/content/drive/My Drive/eigvecs_large_new_10000_13.pt', False), '14': ('/content/drive/My Drive/eigvecs_large_new_10000_14.pt', False), '15': ('/content/drive/My Drive/eigvecs_large_new_10000_15.pt', False), '16': ('/content/drive/My Drive/eigvecs_large_new_10000_16.pt', False), '17': ('/content/drive/My Drive/eigvecs_large_new_10000_17.pt', False), '18': ('/content/drive/My Drive/eigvecs_large_new_10000_18.pt', False), '19': ('/content/drive/My Drive/eigvecs_large_new_10000_19.pt', False), '20': ('/content/drive/My Drive/eigvecs_large_new_10000_20.pt', False), '21': ('/content/drive/My Drive/eigvecs_large_new_10000_21.pt', False), '22': ('/content/drive/My Drive/eigvecs_large_new_10000_22.pt', False), '23': ('/content/drive/My Drive/eigvecs_large_new_10000_23.pt', False)}, eval_all_checkpoints=False, eval_data_file='/content/wikitext-2/wiki.test.tokens', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path='bert-large-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='/content/wikitext-2/wiki.train.tokens', warmup_steps=0, weight_decay=0.0)\n","05/27/2020 07:01:34 - INFO - __main__ -   Evaluate the following checkpoints: ['output']\n","05/27/2020 07:01:34 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","05/27/2020 07:01:34 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","05/27/2020 07:01:34 - INFO - densray_bert -   loading weights file output/pytorch_model.bin\n","05/27/2020 07:01:40 - INFO - __main__ -   ***** Running evaluation  *****\n","05/27/2020 07:01:40 - INFO - __main__ -     Num examples = 586\n","05/27/2020 07:01:40 - INFO - __main__ -     Batch size = 4\n","Evaluating:   0% 0/147 [00:00<?, ?it/s]\n","Traceback (most recent call last):\n","  File \"run_language_modeling_densray.py\", line 772, in <module>\n","    main()\n","  File \"run_language_modeling_densray.py\", line 764, in main\n","    result = evaluate(args, model, tokenizer, prefix=prefix)\n","  File \"run_language_modeling_densray.py\", line 422, in evaluate\n","    outputs = model(inputs, masked_lm_labels=labels) if args.mlm else model(inputs, labels=labels)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 550, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/content/densray_bert.py\", line 599, in forward\n","    encoder_attention_mask=encoder_attention_mask,\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 550, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/content/densray_bert.py\", line 505, in forward\n","    encoder_attention_mask=encoder_extended_attention_mask,\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 550, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\", line 407, in forward\n","    hidden_states, attention_mask, head_mask[i], encoder_hidden_states, encoder_attention_mask\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 550, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/content/densray_bert.py\", line 101, in forward\n","    vec = torch.mm(layer_output[i], self.eigvec)\n","RuntimeError: size mismatch, m1: [512 x 768], m2: [1024 x 1024] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:283\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cC4W5T_dFTB0","colab_type":"text"},"source":["# CH"]},{"cell_type":"code","metadata":{"id":"UqF6hkkTFYN0","colab_type":"code","colab":{}},"source":["import re\n","\n","class Template_ch:\n","    def __init__(self, path='/content/professions_ch.json'):\n","        with open(path,'r',encoding='utf8') as f:\n","            titles = f.read().split()\n","        self.lines = [tokenizer.mask_token+'是一个'+i+'。' for i in titles]\n","        self.examples = tokenizer.batch_encode_plus(self.lines, add_special_tokens=True, max_length=128)[\"input_ids\"]\n","        self.getbaseline()\n","    \n","    def getbaseline(self):\n","        self.baseline = []\n","        for i in self.examples:\n","            i = torch.tensor(i, dtype=torch.long).unsqueeze(0).to(device)\n","            output = model(i)\n","            mask_hidden_state = output[0].squeeze(0)[1]\n","            softmax = torch.nn.Softmax(dim=0)\n","            torch.set_grad_enabled(False)\n","            probs = softmax(mask_hidden_state)\n","            # get probability of token 'he'\n","            he_id = tokenizer.convert_tokens_to_ids('他')\n","            #print('he probability', probs[he_id].item())\n","            # get probability of token 'she'\n","            she_id = tokenizer.convert_tokens_to_ids('她')\n","            #print('she probability', probs[she_id].item())\n","            self.baseline.append([probs[he_id].item(), probs[she_id].item()])\n","template_ch = Template_ch('/content/professions_ch.txt')     "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"43tlLaANMCoF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":248},"executionInfo":{"status":"ok","timestamp":1588234095003,"user_tz":-120,"elapsed":202330,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"outputId":"a439d13f-1acf-4c18-ced8-e5c975cddd59"},"source":["predictions_ch = eval(temp=template_ch, he='他', she='她')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 302/302 [00:05<00:00, 55.21it/s]\n","100%|██████████| 302/302 [00:04<00:00, 62.51it/s]\n","100%|██████████| 302/302 [00:04<00:00, 61.93it/s]\n","100%|██████████| 302/302 [00:04<00:00, 61.88it/s]\n","100%|██████████| 302/302 [00:04<00:00, 61.84it/s]\n","100%|██████████| 302/302 [00:04<00:00, 61.51it/s]\n","100%|██████████| 302/302 [00:04<00:00, 61.97it/s]\n","100%|██████████| 302/302 [00:04<00:00, 61.97it/s]\n","100%|██████████| 302/302 [00:04<00:00, 62.34it/s]\n","100%|██████████| 302/302 [00:04<00:00, 61.60it/s]\n","100%|██████████| 302/302 [00:04<00:00, 62.47it/s]\n","100%|██████████| 302/302 [00:04<00:00, 61.68it/s]\n","100%|██████████| 302/302 [00:04<00:00, 62.46it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"EyhvHXt5MKcc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":301},"executionInfo":{"status":"ok","timestamp":1588234095009,"user_tz":-120,"elapsed":201673,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"outputId":"2e1dc70a-c1b8-4e76-fefc-86dae9b33cb4"},"source":["print('mean(prob(he/she)) var(prob(he/she)) mean(prob(he-she)) var(prob(he-she))')\n","baseline = torch.Tensor(template_ch.baseline)\n","print(torch.mean(baseline,dim=0), torch.var(baseline,dim=0), (baseline[:,0]-baseline[:,1]).mean(), (baseline[:,0]-baseline[:,1]).var(), '\\n')\n","\n","for i in torch.Tensor(predictions_ch):\n","    print(torch.mean(i,dim=0), torch.var(i,dim=0), (i[:,0]-i[:,1]).mean(), (i[:,0]-i[:,1]).var())\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["mean(prob(he/she)) var(prob(he/she)) mean(prob(he-she)) var(prob(he-she))\n","tensor([0.2370, 0.0718]) tensor([0.0206, 0.0037]) tensor(0.1652) tensor(0.0223) \n","\n","tensor([0.0961, 0.0297]) tensor([0.0040, 0.0004]) tensor(0.0664) tensor(0.0032)\n","tensor([0.2430, 0.0738]) tensor([0.0213, 0.0037]) tensor(0.1691) tensor(0.0230)\n","tensor([0.2415, 0.0730]) tensor([0.0211, 0.0037]) tensor(0.1685) tensor(0.0229)\n","tensor([0.2417, 0.0730]) tensor([0.0213, 0.0037]) tensor(0.1687) tensor(0.0230)\n","tensor([0.2443, 0.0749]) tensor([0.0217, 0.0038]) tensor(0.1694) tensor(0.0236)\n","tensor([0.2384, 0.0742]) tensor([0.0209, 0.0038]) tensor(0.1642) tensor(0.0226)\n","tensor([0.2273, 0.0777]) tensor([0.0195, 0.0041]) tensor(0.1496) tensor(0.0211)\n","tensor([0.2319, 0.0753]) tensor([0.0200, 0.0039]) tensor(0.1566) tensor(0.0216)\n","tensor([0.2160, 0.0800]) tensor([0.0182, 0.0041]) tensor(0.1360) tensor(0.0193)\n","tensor([0.2189, 0.0736]) tensor([0.0183, 0.0034]) tensor(0.1453) tensor(0.0191)\n","tensor([0.1809, 0.0512]) tensor([0.0132, 0.0017]) tensor(0.1296) tensor(0.0128)\n","tensor([0.1472, 0.0442]) tensor([0.0086, 0.0011]) tensor(0.1029) tensor(0.0077)\n","tensor([0.2165, 0.0643]) tensor([0.0177, 0.0029]) tensor(0.1522) tensor(0.0185)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-xjclc-JTqmY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":301},"executionInfo":{"status":"ok","timestamp":1588234195803,"user_tz":-120,"elapsed":559,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"outputId":"c64a0fb9-00e1-4e84-fa70-31de859a8d3d"},"source":["print('mean(prob(he/she)) var(prob(he/she)) mean(prob(he-she)) var(prob(he-she))')\n","baseline = torch.Tensor(template_ch.baseline)\n","print([round(i,4) for i in torch.mean(baseline,dim=0).tolist()], [round(i,4) for i in torch.var(baseline,dim=0).tolist()], \n","      round(float((baseline[:,0]-baseline[:,1]).mean()),4), round(float((baseline[:,0]-baseline[:,1]).var()),4), '\\n')\n","\n","for i in torch.Tensor(predictions_ch):\n","    print([round(i,4) for i in torch.mean(i,dim=0).tolist()], [round(i,4) for i in torch.var(i,dim=0).tolist()], \n","          round(float((i[:,0]-i[:,1]).mean()),4), round(float((i[:,0]-i[:,1]).var()),4))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["mean(prob(he/she)) var(prob(he/she)) mean(prob(he-she)) var(prob(he-she))\n","[0.237, 0.0718] [0.0206, 0.0037] 0.1652 0.0223 \n","\n","[0.0961, 0.0297] [0.004, 0.0004] 0.0664 0.0032\n","[0.243, 0.0738] [0.0213, 0.0037] 0.1691 0.023\n","[0.2415, 0.073] [0.0211, 0.0037] 0.1685 0.0229\n","[0.2417, 0.073] [0.0213, 0.0037] 0.1687 0.023\n","[0.2443, 0.0749] [0.0217, 0.0038] 0.1694 0.0236\n","[0.2384, 0.0742] [0.0209, 0.0038] 0.1642 0.0226\n","[0.2273, 0.0777] [0.0195, 0.0041] 0.1496 0.0211\n","[0.2319, 0.0753] [0.02, 0.0039] 0.1566 0.0216\n","[0.216, 0.08] [0.0182, 0.0041] 0.136 0.0193\n","[0.2189, 0.0736] [0.0183, 0.0034] 0.1453 0.0191\n","[0.1809, 0.0512] [0.0132, 0.0017] 0.1296 0.0128\n","[0.1472, 0.0442] [0.0086, 0.0011] 0.1029 0.0077\n","[0.2165, 0.0643] [0.0177, 0.0029] 0.1522 0.0185\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bqna81S9KoaT","colab_type":"code","colab":{}},"source":["for i in range(len(template_ch.lines)):\n","    print(\"sentence: \", template_ch.lines[i])\n","    print(\"prediction: \", predictions_ch[0][i])\n","    print(\"baseline: \", template_ch.baseline[i], \"\\n\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1QRMD9imJCsw","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eAEafXm9L8p2","colab_type":"text"},"source":["# WEAT"]},{"cell_type":"code","metadata":{"id":"mf6_liysF8en","colab_type":"code","colab":{}},"source":["from sklearn.metrics.pairwise import cosine_similarity\n","\n","def swAB(W, A, B):\n","    \"\"\"Calculates differential cosine-similarity between word vectors in W, A and W, B\n","        Arguments\n","                W, A, B : n x d matrix of word embeddings stored row wise\n","    \"\"\"\n","    WA = cosine_similarity(W,A)\n","    WB = cosine_similarity(W,B)\n","    \n","    #Take mean along columns\n","    WAmean = np.mean(WA, axis = 1)\n","    WBmean = np.mean(WB, axis = 1)\n","    \n","    return (WAmean - WBmean)\n","  \n","def test_statistic(X, Y, A, B):\n","    \"\"\"Calculates test-statistic between the pair of association words and target words\n","        Arguments\n","                X, Y, A, B : n x d matrix of word embeddings stored row wise\n","        Returns\n","                Test Statistic\n","    \"\"\"\n","    return (sum(swAB(X, A, B)) - sum(swAB(Y, A, B)))\n","\n","def weat_effect_size(X, Y, A, B, embd):\n","    \"\"\"Computes the effect size for the given list of association and target word pairs\n","        Arguments\n","                X, Y : List of association words\n","                A, B : List of target words\n","                embd : Dictonary of word-to-embedding for all words\n","        Returns\n","                Effect Size\n","    \"\"\"\n","    Xmat = np.array([embd[w] for w in X if w in embd])\n","    Ymat = np.array([embd[w] for w in Y if w in embd])\n","    Amat = np.array([embd[w] for w in A if w in embd])\n","    Bmat = np.array([embd[w] for w in B if w in embd])\n","    XuY = list(set(X).union(Y))\n","    XuYmat = []\n","    for w in XuY:\n","        if w.lower() in embd:\n","            XuYmat.append(embd[w.lower()])\n","    XuYmat = np.array(XuYmat)\n","    d = (np.mean(swAB(Xmat,Amat,Bmat)) - np.mean(swAB(Ymat,Amat,Bmat)))/np.std(swAB(XuYmat, Amat, Bmat))\n","    return d\n","\n","def random_permutation(iterable, r=None):\n","    \"\"\"Returns a random permutation for any iterable object\"\"\"\n","    pool = tuple(iterable)\n","    r = len(pool) if r is None else r\n","    return tuple(random.sample(pool, r))\n","\n","def weat_p_value(X, Y, A, B, embd, sample=None):\n","    np.random.seed(42)\n","    random.seed(42)\n","    \"\"\"Computes the one-sided P value for the given list of association and target word pairs\n","        Arguments\n","                X, Y : List of association words\n","                A, B : List of target words\n","                embd : Dictonary of word-to-embedding for all words\n","                sample : Number of random permutations used.\n","        Returns\n","    \"\"\"\n","    size_of_permutation = min(len(X), len(Y))\n","    X_Y = X + Y\n","    test_stats_over_permutation = []\n","    \n","    Xmat = np.array([embd[w.lower()] for w in X if w.lower() in embd])\n","    Ymat = np.array([embd[w.lower()] for w in Y if w.lower() in embd])\n","    Amat = np.array([embd[w.lower()] for w in A if w.lower() in embd])\n","    Bmat = np.array([embd[w.lower()] for w in B if w.lower() in embd])\n","    \n","    if not sample:\n","        permutations = combinations(X_Y, size_of_permutation)\n","    else:\n","        permutations = [random_permutation(X_Y, size_of_permutation) for s in range(sample)]\n","        \n","    for Xi in permutations:\n","        Yi = filterfalse(lambda w:w in Xi, X_Y)\n","        Ximat = np.array([embd[w.lower()] for w in Xi if w.lower() in embd])\n","        Yimat = np.array([embd[w.lower()] for w in Yi if w.lower() in embd])\n","        test_stats_over_permutation.append(test_statistic(Ximat, Yimat, Amat, Bmat))\n","        \n","    unperturbed = test_statistic(Xmat, Ymat, Amat, Bmat)\n","    \n","    is_over = np.array([o > unperturbed for o in test_stats_over_permutation])\n","    \n","    return is_over.sum() / is_over.size"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dQwlTrP8L-fN","colab_type":"code","colab":{}},"source":["def category(type=1):\n","    m_words = \"male, man, boy, brother, he, him, his, son, father, uncle, grandfather\".lower().replace(\" \", \"\").split(',')\n","    f_words = \"female, woman, girl, sister, she, her, hers, daughter, mother, aunt, grandmother\".lower().replace(\" \", \"\").split(',')\n","    if type == 1:\n","        #B1: career vs family\n","        x_words = \"executive, management, professional, corporation, salary, office, business, career\".lower().replace(\" \", \"\").split(',')\n","        y_words = \"home, parents, children, family, cousins, marriage, wedding, relatives\".lower().replace(\" \", \"\").split(',')\n","    elif type == 2:\n","        #B2: maths vs arts\n","        x_words = \"math, algebra, geometry, calculus, equations, computation, numbers, addition\".lower().replace(\" \", \"\").split(',')\n","        y_words = \"poetry, art, Shakespeare, dance, literature, novel, symphony, drama\".lower().replace(\" \", \"\").split(',')\n","    elif type == 3:\n","        #B3: science vs arts\n","        x_words = \"science, technology, physics, chemistry, Einstein, NASA, experiment, astronomy\".lower().replace(\" \", \"\").split(',')\n","        y_words = \"poetry, art, Shakespeare, dance, literature, novel, symphony, drama\".lower().replace(\" \", \"\").split(',')\n","    elif type == 4:\n","        #B4: intelligence vs appearance\n","        x_words = \"precocious, resourceful, inquisitive, genius, inventive, astute, adaptable, reflective,discerning, intuitive, inquiring, judicious, analytical, apt, venerable, imaginative,shrewd, thoughtful, wise, smart, ingenious, clever, brilliant, logical, intelligent\".lower().replace(\" \", \"\").split(',')\n","        y_words = \"alluring, voluptuous, blushing, homely, plump, sensual, gorgeous, slim, bald,athletic, fashionable, stout, ugly, muscular, slender, feeble, handsome, healthy,attractive, fat, weak, thin, pretty, beautiful, strong\".lower().replace(\" \", \"\").split(',')\n","    elif type == 5:\n","        #B5: strength vs weakness\n","        x_words = \"power, strong, confident, dominant, potent, command, assert, loud, bold, succeed,triumph, leader, shout, dynamic, winner\".lower().replace(\" \", \"\").split(',')\n","        y_words = \"weak, surrender, timid, vulnerable, weakness, wispy, withdraw, yield, failure, shy,follow, lose, fragile, afraid, loser\".lower().replace(\" \", \"\").split(',')\n","    return m_words, f_words, x_words, y_words\n","\n","def category_2(type=1):\n","    if type == 1:\n","        #Career/Family\n","        m_words = 'John, Paul, Mike, Kevin, Steve, Greg, Jeff, Bill'.lower().replace(\" \", \"\").split(',')\n","        f_words = 'Amy, Joan, Lisa, Sarah, Diana, Kate, Ann, Donna'.lower().replace(\" \", \"\").split(',')\n","        x_words = 'executive, management, professional, corporation, salary, office, business, career'.lower().replace(\" \", \"\").split(',')\n","        y_words = 'home, parents, children, family, cousins, marriage, wedding, relatives'.lower().replace(\" \", \"\").split(',')\n","    elif type == 2:\n","        #Math/Art\n","        m_words = 'math, algebra, geometry, calculus, equations, computation, numbers, addition'.lower().replace(\" \", \"\").split(',')\n","        f_words = 'poetry, art, dance, literature, novel, symphony, drama, sculpture'.lower().replace(\" \", \"\").split(',')\n","        x_words = 'male, man, boy, brother, he, him, his, son'.lower().replace(\" \", \"\").split(',')\n","        y_words = 'female, woman, girl, sister, she, her, hers, daughter'.lower().replace(\" \", \"\").split(',')\n","    elif type == 3:\n","        #Science/Art\n","        m_words = 'science, technology, physics, chemistry, Einstein, NASA, experiment, astronomy'.lower().replace(\" \", \"\").split(',')\n","        f_words = 'poetry, art, Shakespeare, dance, literature, novel, symphony, drama'.lower().replace(\" \", \"\").split(',')\n","        x_words = 'brother, father, uncle, grandfather, son, he, his, him'.lower().replace(\" \", \"\").split(',')\n","        y_words = 'sister, mother, aunt, grandmother, daughter, she, hers, her'.lower().replace(\" \", \"\").split(',')\n","    return m_words, f_words, x_words, y_words"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QBKLSlr9aeLz","colab_type":"code","colab":{}},"source":["import numpy as np\n","from itertools import combinations, filterfalse\n","from sklearn.metrics.pairwise import cosine_similarity\n","from gensim.models.keyedvectors import KeyedVectors\n","import pandas as pd\n","import random\n","import sys\n","import os\n","import pickle\n","random.seed(42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nn9GGX9sTGOJ","colab_type":"code","colab":{}},"source":["!find /content/ -name '*eigvecs*' | xargs  rm -rf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WV9V25CeMP0n","colab_type":"code","colab":{}},"source":["def get_bert_embedding(model, wordlist, is_targets=1):\n","    vecss = torch.Tensor().to(device)\n","    for w in wordlist:\n","        text = w + ' is ' + tokenizer.mask_token + '.' if is_targets else tokenizer.mask_token + ' is ' + w + '.'\n","        vec = tokenizer.prepare_for_model(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text)),\n","                                            return_token_type_ids=False, return_tensors='pt')['input_ids'].to(device)\n","        vecs = vec.clone().detach()\n","        # get output\n","        vecs = model.bert(vecs)[0]#[2][nlayer]\n","        vecs = vecs[0][1:-4,:].mean(dim=0).unsqueeze(0) if is_targets else vecs[0][3:-2,:].mean(dim=0).unsqueeze(0)\n","        vecss = torch.cat((vecss,vecs))\n","    return vecss\n","\n","import densray_bert as bbert\n","def get_eigvecs_dict(layer=-1):\n","    eigvecs_dict = {}\n","    #-1:apply to all layers\n","    if layer==-1:\n","        #'/content/drive/My Drive/negc'+config+'_'+str(nsamples)+'_'+str(l)+'.pt'\n","        #'/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(l)+'.pt'\n","        for l in range(nlayer):\n","            eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(l)+'.pt', True)\n","    elif layer ==-2:\n","        for l in range(nlayer):\n","            eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(l)+'.pt', False)\n","    else:\n","        for l in range(nlayer):\n","            if l==layer:\n","                eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(l)+'.pt', True)\n","            else:\n","                eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_'+config+'_new_'+str(nsamples)+'_'+str(l)+'.pt', False)\n","    return eigvecs_dict\n","\n","import pickle\n","for l in range(-2,nlayer):\n","    d = get_eigvecs_dict(l)\n","    df2=open('/content/eigvecs_dict_'+str(l)+'.txt','wb')\n","    pickle.dump(d,df2)\n","    df2.close()\n","\n","def eval_per_layer(layer=-2):\n","    config_class = get_eigvecs_dict(layer)\n","    model = bbert.BertForMaskedLM_1.from_pretrained('bert-'+config+'-uncased', eigvecs_dict=get_eigvecs_dict(l)).to(device)\n","    # turn on eval mode\n","    model.eval()\n","    m = get_bert_embedding(model, m_words, is_targets=0).cpu().detach().numpy()\n","    f = get_bert_embedding(model, f_words, is_targets=0).cpu().detach().numpy()\n","    x = get_bert_embedding(model, x_words, is_targets=1).cpu().detach().numpy()\n","    y = get_bert_embedding(model, y_words, is_targets=1).cpu().detach().numpy()\n","    embed = {}\n","    for i in range(len(m_words)): embed[m_words[i]] = m[i]\n","    for i in range(len(f_words)): embed[f_words[i]] = f[i]\n","    for i in range(len(x_words)): embed[x_words[i]] = x[i]\n","    for i in range(len(y_words)): embed[y_words[i]] = y[i]\n","    return embed"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YPTrrEPDMUCm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"status":"ok","timestamp":1593501128500,"user_tz":-120,"elapsed":47681,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"outputId":"a0634872-c1dd-4068-90a4-1b160261545d"},"source":["for t in range(1,4):\n","    m_words, f_words, x_words, y_words = category_2(t)\n","    l=-2\n","    # no densray\n","    embed = eval_per_layer(layer=l)\n","    d = weat_effect_size(x_words, y_words, m_words, f_words, embed)\n","    p = weat_p_value(x_words, y_words, m_words, f_words, embed, sample=1000)\n","    print(round(d,4),round(p,4),)\n","    #densray\n","    for l in range(-1, 0):\n","        # densray\n","        embed = eval_per_layer(layer=l)\n","        d_densray =  weat_effect_size(x_words, y_words, m_words, f_words, embed)\n","        p_densray = weat_p_value(x_words, y_words, m_words, f_words, embed, sample=1000)\n","        print(round(d_densray,4), round(p_densray,4))\n","    print('\\n')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.6581 0.083\n","0.6218 0.115\n","\n","\n","0.6017 0.113\n","0.0863 0.446\n","\n","\n","0.7762 0.078\n","0.025 0.472\n","\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"D8AWJyEZTk7h","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}