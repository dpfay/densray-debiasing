{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DensRay_BERT-base_Wikitext.ipynb","provenance":[],"toc_visible":true,"machine_shape":"hm","mount_file_id":"1yJM30S1-b-Ih_A5Km4mjTUGhvH2SI30O","authorship_tag":"ABX9TyOAgm4HD0Vt/D/aHQPwoEB3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"7-nB8AzZgm0n","colab_type":"code","outputId":"79d7631a-c33a-4cff-cec3-52d69da6403b","executionInfo":{"status":"ok","timestamp":1589952048600,"user_tz":-120,"elapsed":6649,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":212}},"source":["!wget https://raw.githubusercontent.com/huggingface/transformers/v2.8.0/examples/run_language_modeling.py"],"execution_count":1,"outputs":[{"output_type":"stream","text":["--2020-05-20 05:20:43--  https://raw.githubusercontent.com/huggingface/transformers/v2.8.0/examples/run_language_modeling.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 34328 (34K) [text/plain]\n","Saving to: ‘run_language_modeling.py’\n","\n","\rrun_language_modeli   0%[                    ]       0  --.-KB/s               \rrun_language_modeli 100%[===================>]  33.52K  --.-KB/s    in 0.01s   \n","\n","2020-05-20 05:20:44 (2.24 MB/s) - ‘run_language_modeling.py’ saved [34328/34328]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_HddjZNSyL95","colab_type":"code","outputId":"db335d43-f39f-4275-89d1-f1b02827834b","executionInfo":{"status":"ok","timestamp":1589952055819,"user_tz":-120,"elapsed":12073,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":301}},"source":["!wget https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-2-v1.zip\n","!unzip wikitext-2-v1.zip"],"execution_count":2,"outputs":[{"output_type":"stream","text":["--2020-05-20 05:20:47--  https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-2-v1.zip\n","Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.137.78\n","Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.137.78|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 4475746 (4.3M) [application/zip]\n","Saving to: ‘wikitext-2-v1.zip’\n","\n","wikitext-2-v1.zip   100%[===================>]   4.27M  2.96MB/s    in 1.4s    \n","\n","2020-05-20 05:20:49 (2.96 MB/s) - ‘wikitext-2-v1.zip’ saved [4475746/4475746]\n","\n","Archive:  wikitext-2-v1.zip\n","   creating: wikitext-2/\n","  inflating: wikitext-2/wiki.test.tokens  \n","  inflating: wikitext-2/wiki.valid.tokens  \n","  inflating: wikitext-2/wiki.train.tokens  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fpKMOM6om3Tl","colab_type":"code","outputId":"05c89c52-b279-4e1d-e49b-23899360b7a7","executionInfo":{"status":"ok","timestamp":1589952063687,"user_tz":-120,"elapsed":18484,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":712}},"source":["!pip install transformers==2.8.0"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting transformers==2.8.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n","\u001b[K     |████████████████████████████████| 573kB 2.8MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (4.41.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (3.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2019.12.20)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/88/49e772d686088e1278766ad68a463513642a2a877487decbd691dec02955/sentencepiece-0.1.90-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 12.9MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 16.4MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (2.23.0)\n","Collecting tokenizers==0.5.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n","\u001b[K     |████████████████████████████████| 3.7MB 25.2MB/s \n","\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.13.10)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (0.7)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.8.0) (1.18.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.8.0) (0.15.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2020.4.5.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.8.0) (2.9)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (0.3.3)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (0.10.0)\n","Requirement already satisfied: botocore<1.17.0,>=1.16.10 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.8.0) (1.16.10)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.10->boto3->transformers==2.8.0) (2.8.1)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.10->boto3->transformers==2.8.0) (0.15.2)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=be943dca37e4cd4410ca41e00cb18775ce7d07acfbaa7814f8717750f6339e9c\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.90 tokenizers-0.5.2 transformers-2.8.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3iEUh71Miw7p","colab_type":"code","outputId":"a6d15e64-07a7-4ce8-95d2-43c2e39c9b49","executionInfo":{"status":"ok","timestamp":1589952538588,"user_tz":-120,"elapsed":487593,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python run_language_modeling.py \\\n","    --output_dir=output \\\n","    --model_type=bert \\\n","    --model_name_or_path=bert-base-uncased \\\n","    --do_train \\\n","    --train_data_file=/content/wikitext-2/wiki.train.tokens \\\n","    --do_eval \\\n","    --eval_data_file=/content/wikitext-2/wiki.test.tokens \\\n","    --mlm \\\n","    --overwrite_output_dir"],"execution_count":4,"outputs":[{"output_type":"stream","text":["2020-05-20 05:21:06.809208: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","05/20/2020 05:21:08 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","05/20/2020 05:21:09 - INFO - filelock -   Lock 140347577338456 acquired on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n","05/20/2020 05:21:09 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpiez5nwdz\n","Downloading: 100% 433/433 [00:00<00:00, 406kB/s]\n","05/20/2020 05:21:10 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json in cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","05/20/2020 05:21:10 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","05/20/2020 05:21:10 - INFO - filelock -   Lock 140347577338456 released on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n","05/20/2020 05:21:10 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","05/20/2020 05:21:10 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","05/20/2020 05:21:10 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","05/20/2020 05:21:10 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","05/20/2020 05:21:11 - INFO - filelock -   Lock 140347577822400 acquired on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n","05/20/2020 05:21:11 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp_iq5h0py\n","Downloading: 100% 232k/232k [00:00<00:00, 316kB/s]\n","05/20/2020 05:21:13 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt in cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","05/20/2020 05:21:13 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","05/20/2020 05:21:13 - INFO - filelock -   Lock 140347577822400 released on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n","05/20/2020 05:21:13 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","05/20/2020 05:21:14 - INFO - filelock -   Lock 140347577336832 acquired on /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n","05/20/2020 05:21:14 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpo5dxhtsf\n","Downloading: 100% 440M/440M [00:30<00:00, 14.2MB/s]\n","05/20/2020 05:21:45 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin in cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","05/20/2020 05:21:45 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","05/20/2020 05:21:45 - INFO - filelock -   Lock 140347577336832 released on /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n","05/20/2020 05:21:45 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","05/20/2020 05:21:49 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n","05/20/2020 05:21:49 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","05/20/2020 05:22:06 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=True, eval_all_checkpoints=False, eval_data_file='/content/wikitext-2/wiki.test.tokens', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='/content/wikitext-2/wiki.train.tokens', warmup_steps=0, weight_decay=0.0)\n","05/20/2020 05:22:06 - INFO - __main__ -   Creating features from dataset file at /content/wikitext-2\n","05/20/2020 05:22:40 - INFO - __main__ -   Saving features into cached file /content/wikitext-2/bert_cached_lm_510_wiki.train.tokens\n","05/20/2020 05:22:40 - INFO - __main__ -   ***** Running training *****\n","05/20/2020 05:22:40 - INFO - __main__ -     Num examples = 4691\n","05/20/2020 05:22:40 - INFO - __main__ -     Num Epochs = 1\n","05/20/2020 05:22:40 - INFO - __main__ -     Instantaneous batch size per GPU = 4\n","05/20/2020 05:22:40 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 4\n","05/20/2020 05:22:40 - INFO - __main__ -     Gradient Accumulation steps = 1\n","05/20/2020 05:22:40 - INFO - __main__ -     Total optimization steps = 1173\n","Epoch:   0% 0/1 [00:00<?, ?it/s]\n","Iteration:   0% 0/1173 [00:00<?, ?it/s]\u001b[A/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha)\n","\n","Iteration:   0% 1/1173 [00:00<14:05,  1.39it/s]\u001b[A\n","Iteration:   0% 2/1173 [00:01<11:33,  1.69it/s]\u001b[A\n","Iteration:   0% 3/1173 [00:01<09:48,  1.99it/s]\u001b[A\n","Iteration:   0% 4/1173 [00:01<08:34,  2.27it/s]\u001b[A\n","Iteration:   0% 5/1173 [00:01<07:41,  2.53it/s]\u001b[A\n","Iteration:   1% 6/1173 [00:02<07:04,  2.75it/s]\u001b[A\n","Iteration:   1% 7/1173 [00:02<06:38,  2.93it/s]\u001b[A\n","Iteration:   1% 8/1173 [00:02<06:20,  3.07it/s]\u001b[A\n","Iteration:   1% 9/1173 [00:03<06:06,  3.18it/s]\u001b[A\n","Iteration:   1% 10/1173 [00:03<05:57,  3.25it/s]\u001b[A\n","Iteration:   1% 11/1173 [00:03<05:51,  3.30it/s]\u001b[A\n","Iteration:   1% 12/1173 [00:03<05:48,  3.34it/s]\u001b[A\n","Iteration:   1% 13/1173 [00:04<05:45,  3.36it/s]\u001b[A\n","Iteration:   1% 14/1173 [00:04<05:43,  3.38it/s]\u001b[A\n","Iteration:   1% 15/1173 [00:04<05:41,  3.40it/s]\u001b[A\n","Iteration:   1% 16/1173 [00:05<05:39,  3.41it/s]\u001b[A\n","Iteration:   1% 17/1173 [00:05<05:38,  3.42it/s]\u001b[A\n","Iteration:   2% 18/1173 [00:05<05:37,  3.42it/s]\u001b[A\n","Iteration:   2% 19/1173 [00:05<05:37,  3.42it/s]\u001b[A\n","Iteration:   2% 20/1173 [00:06<05:36,  3.43it/s]\u001b[A\n","Iteration:   2% 21/1173 [00:06<05:35,  3.44it/s]\u001b[A\n","Iteration:   2% 22/1173 [00:06<05:34,  3.44it/s]\u001b[A\n","Iteration:   2% 23/1173 [00:07<05:35,  3.42it/s]\u001b[A\n","Iteration:   2% 24/1173 [00:07<05:35,  3.43it/s]\u001b[A\n","Iteration:   2% 25/1173 [00:07<05:34,  3.43it/s]\u001b[A\n","Iteration:   2% 26/1173 [00:08<05:35,  3.42it/s]\u001b[A\n","Iteration:   2% 27/1173 [00:08<05:34,  3.43it/s]\u001b[A\n","Iteration:   2% 28/1173 [00:08<05:33,  3.43it/s]\u001b[A\n","Iteration:   2% 29/1173 [00:08<05:32,  3.44it/s]\u001b[A\n","Iteration:   3% 30/1173 [00:09<05:32,  3.44it/s]\u001b[A\n","Iteration:   3% 31/1173 [00:09<05:32,  3.44it/s]\u001b[A\n","Iteration:   3% 32/1173 [00:09<05:32,  3.43it/s]\u001b[A\n","Iteration:   3% 33/1173 [00:10<05:32,  3.43it/s]\u001b[A\n","Iteration:   3% 34/1173 [00:10<05:31,  3.43it/s]\u001b[A\n","Iteration:   3% 35/1173 [00:10<05:31,  3.43it/s]\u001b[A\n","Iteration:   3% 36/1173 [00:10<05:31,  3.43it/s]\u001b[A\n","Iteration:   3% 37/1173 [00:11<05:30,  3.44it/s]\u001b[A\n","Iteration:   3% 38/1173 [00:11<05:30,  3.44it/s]\u001b[A\n","Iteration:   3% 39/1173 [00:11<05:29,  3.44it/s]\u001b[A\n","Iteration:   3% 40/1173 [00:12<05:29,  3.44it/s]\u001b[A\n","Iteration:   3% 41/1173 [00:12<05:29,  3.44it/s]\u001b[A\n","Iteration:   4% 42/1173 [00:12<05:29,  3.43it/s]\u001b[A\n","Iteration:   4% 43/1173 [00:12<05:30,  3.42it/s]\u001b[A\n","Iteration:   4% 44/1173 [00:13<05:29,  3.43it/s]\u001b[A\n","Iteration:   4% 45/1173 [00:13<05:28,  3.43it/s]\u001b[A\n","Iteration:   4% 46/1173 [00:13<05:28,  3.43it/s]\u001b[A\n","Iteration:   4% 47/1173 [00:14<05:27,  3.44it/s]\u001b[A\n","Iteration:   4% 48/1173 [00:14<05:28,  3.43it/s]\u001b[A\n","Iteration:   4% 49/1173 [00:14<05:27,  3.43it/s]\u001b[A\n","Iteration:   4% 50/1173 [00:14<05:27,  3.43it/s]\u001b[A\n","Iteration:   4% 51/1173 [00:15<05:26,  3.43it/s]\u001b[A\n","Iteration:   4% 52/1173 [00:15<05:26,  3.43it/s]\u001b[A\n","Iteration:   5% 53/1173 [00:15<05:26,  3.43it/s]\u001b[A\n","Iteration:   5% 54/1173 [00:16<05:25,  3.43it/s]\u001b[A\n","Iteration:   5% 55/1173 [00:16<05:25,  3.43it/s]\u001b[A\n","Iteration:   5% 56/1173 [00:16<05:25,  3.43it/s]\u001b[A\n","Iteration:   5% 57/1173 [00:17<05:24,  3.44it/s]\u001b[A\n","Iteration:   5% 58/1173 [00:17<05:24,  3.44it/s]\u001b[A\n","Iteration:   5% 59/1173 [00:17<05:23,  3.44it/s]\u001b[A\n","Iteration:   5% 60/1173 [00:17<05:23,  3.44it/s]\u001b[A\n","Iteration:   5% 61/1173 [00:18<05:23,  3.44it/s]\u001b[A\n","Iteration:   5% 62/1173 [00:18<05:23,  3.43it/s]\u001b[A\n","Iteration:   5% 63/1173 [00:18<05:23,  3.43it/s]\u001b[A\n","Iteration:   5% 64/1173 [00:19<05:23,  3.43it/s]\u001b[A\n","Iteration:   6% 65/1173 [00:19<05:23,  3.43it/s]\u001b[A\n","Iteration:   6% 66/1173 [00:19<05:22,  3.43it/s]\u001b[A\n","Iteration:   6% 67/1173 [00:19<05:21,  3.44it/s]\u001b[A\n","Iteration:   6% 68/1173 [00:20<05:21,  3.44it/s]\u001b[A\n","Iteration:   6% 69/1173 [00:20<05:20,  3.45it/s]\u001b[A\n","Iteration:   6% 70/1173 [00:20<05:20,  3.44it/s]\u001b[A\n","Iteration:   6% 71/1173 [00:21<05:20,  3.43it/s]\u001b[A\n","Iteration:   6% 72/1173 [00:21<05:20,  3.43it/s]\u001b[A\n","Iteration:   6% 73/1173 [00:21<05:20,  3.44it/s]\u001b[A\n","Iteration:   6% 74/1173 [00:21<05:19,  3.43it/s]\u001b[A\n","Iteration:   6% 75/1173 [00:22<05:19,  3.44it/s]\u001b[A\n","Iteration:   6% 76/1173 [00:22<05:18,  3.44it/s]\u001b[A\n","Iteration:   7% 77/1173 [00:22<05:19,  3.44it/s]\u001b[A\n","Iteration:   7% 78/1173 [00:23<05:18,  3.43it/s]\u001b[A\n","Iteration:   7% 79/1173 [00:23<05:18,  3.44it/s]\u001b[A\n","Iteration:   7% 80/1173 [00:23<05:18,  3.43it/s]\u001b[A\n","Iteration:   7% 81/1173 [00:24<05:18,  3.43it/s]\u001b[A\n","Iteration:   7% 82/1173 [00:24<05:17,  3.43it/s]\u001b[A\n","Iteration:   7% 83/1173 [00:24<05:18,  3.43it/s]\u001b[A\n","Iteration:   7% 84/1173 [00:24<05:17,  3.43it/s]\u001b[A\n","Iteration:   7% 85/1173 [00:25<05:16,  3.43it/s]\u001b[A\n","Iteration:   7% 86/1173 [00:25<05:16,  3.44it/s]\u001b[A\n","Iteration:   7% 87/1173 [00:25<05:16,  3.43it/s]\u001b[A\n","Iteration:   8% 88/1173 [00:26<05:15,  3.44it/s]\u001b[A\n","Iteration:   8% 89/1173 [00:26<05:14,  3.44it/s]\u001b[A\n","Iteration:   8% 90/1173 [00:26<05:15,  3.44it/s]\u001b[A\n","Iteration:   8% 91/1173 [00:26<05:15,  3.43it/s]\u001b[A\n","Iteration:   8% 92/1173 [00:27<05:14,  3.43it/s]\u001b[A\n","Iteration:   8% 93/1173 [00:27<05:14,  3.43it/s]\u001b[A\n","Iteration:   8% 94/1173 [00:27<05:14,  3.43it/s]\u001b[A\n","Iteration:   8% 95/1173 [00:28<05:13,  3.44it/s]\u001b[A\n","Iteration:   8% 96/1173 [00:28<05:13,  3.44it/s]\u001b[A\n","Iteration:   8% 97/1173 [00:28<05:12,  3.44it/s]\u001b[A\n","Iteration:   8% 98/1173 [00:28<05:12,  3.44it/s]\u001b[A\n","Iteration:   8% 99/1173 [00:29<05:12,  3.43it/s]\u001b[A\n","Iteration:   9% 100/1173 [00:29<05:12,  3.43it/s]\u001b[A\n","Iteration:   9% 101/1173 [00:29<05:12,  3.43it/s]\u001b[A\n","Iteration:   9% 102/1173 [00:30<05:11,  3.44it/s]\u001b[A\n","Iteration:   9% 103/1173 [00:30<05:11,  3.43it/s]\u001b[A\n","Iteration:   9% 104/1173 [00:30<05:11,  3.43it/s]\u001b[A\n","Iteration:   9% 105/1173 [00:31<05:10,  3.43it/s]\u001b[A\n","Iteration:   9% 106/1173 [00:31<05:09,  3.44it/s]\u001b[A\n","Iteration:   9% 107/1173 [00:31<05:10,  3.44it/s]\u001b[A\n","Iteration:   9% 108/1173 [00:31<05:09,  3.44it/s]\u001b[A\n","Iteration:   9% 109/1173 [00:32<05:09,  3.44it/s]\u001b[A\n","Iteration:   9% 110/1173 [00:32<05:09,  3.43it/s]\u001b[A\n","Iteration:   9% 111/1173 [00:32<05:09,  3.43it/s]\u001b[A\n","Iteration:  10% 112/1173 [00:33<05:09,  3.42it/s]\u001b[A\n","Iteration:  10% 113/1173 [00:33<05:08,  3.43it/s]\u001b[A\n","Iteration:  10% 114/1173 [00:33<05:08,  3.43it/s]\u001b[A\n","Iteration:  10% 115/1173 [00:33<05:07,  3.44it/s]\u001b[A\n","Iteration:  10% 116/1173 [00:34<05:07,  3.44it/s]\u001b[A\n","Iteration:  10% 117/1173 [00:34<05:07,  3.44it/s]\u001b[A\n","Iteration:  10% 118/1173 [00:34<05:06,  3.44it/s]\u001b[A\n","Iteration:  10% 119/1173 [00:35<05:06,  3.43it/s]\u001b[A\n","Iteration:  10% 120/1173 [00:35<05:06,  3.44it/s]\u001b[A\n","Iteration:  10% 121/1173 [00:35<05:05,  3.44it/s]\u001b[A\n","Iteration:  10% 122/1173 [00:35<05:05,  3.44it/s]\u001b[A\n","Iteration:  10% 123/1173 [00:36<05:05,  3.44it/s]\u001b[A\n","Iteration:  11% 124/1173 [00:36<05:05,  3.44it/s]\u001b[A\n","Iteration:  11% 125/1173 [00:36<05:04,  3.44it/s]\u001b[A\n","Iteration:  11% 126/1173 [00:37<05:04,  3.44it/s]\u001b[A\n","Iteration:  11% 127/1173 [00:37<05:04,  3.44it/s]\u001b[A\n","Iteration:  11% 128/1173 [00:37<05:03,  3.44it/s]\u001b[A\n","Iteration:  11% 129/1173 [00:37<05:04,  3.43it/s]\u001b[A\n","Iteration:  11% 130/1173 [00:38<05:03,  3.44it/s]\u001b[A\n","Iteration:  11% 131/1173 [00:38<05:03,  3.44it/s]\u001b[A\n","Iteration:  11% 132/1173 [00:38<05:02,  3.44it/s]\u001b[A\n","Iteration:  11% 133/1173 [00:39<05:02,  3.44it/s]\u001b[A\n","Iteration:  11% 134/1173 [00:39<05:01,  3.44it/s]\u001b[A\n","Iteration:  12% 135/1173 [00:39<05:01,  3.45it/s]\u001b[A\n","Iteration:  12% 136/1173 [00:40<05:01,  3.44it/s]\u001b[A\n","Iteration:  12% 137/1173 [00:40<05:01,  3.44it/s]\u001b[A\n","Iteration:  12% 138/1173 [00:40<05:00,  3.44it/s]\u001b[A\n","Iteration:  12% 139/1173 [00:40<05:00,  3.44it/s]\u001b[A\n","Iteration:  12% 140/1173 [00:41<05:00,  3.44it/s]\u001b[A\n","Iteration:  12% 141/1173 [00:41<05:00,  3.44it/s]\u001b[A\n","Iteration:  12% 142/1173 [00:41<04:59,  3.44it/s]\u001b[A\n","Iteration:  12% 143/1173 [00:42<04:58,  3.45it/s]\u001b[A\n","Iteration:  12% 144/1173 [00:42<04:58,  3.45it/s]\u001b[A\n","Iteration:  12% 145/1173 [00:42<04:57,  3.45it/s]\u001b[A\n","Iteration:  12% 146/1173 [00:42<04:57,  3.45it/s]\u001b[A\n","Iteration:  13% 147/1173 [00:43<04:58,  3.44it/s]\u001b[A\n","Iteration:  13% 148/1173 [00:43<04:58,  3.44it/s]\u001b[A\n","Iteration:  13% 149/1173 [00:43<04:58,  3.43it/s]\u001b[A\n","Iteration:  13% 150/1173 [00:44<04:57,  3.44it/s]\u001b[A\n","Iteration:  13% 151/1173 [00:44<04:57,  3.44it/s]\u001b[A\n","Iteration:  13% 152/1173 [00:44<04:56,  3.44it/s]\u001b[A\n","Iteration:  13% 153/1173 [00:44<04:56,  3.44it/s]\u001b[A\n","Iteration:  13% 154/1173 [00:45<04:55,  3.45it/s]\u001b[A\n","Iteration:  13% 155/1173 [00:45<04:55,  3.44it/s]\u001b[A\n","Iteration:  13% 156/1173 [00:45<04:55,  3.44it/s]\u001b[A\n","Iteration:  13% 157/1173 [00:46<04:55,  3.43it/s]\u001b[A\n","Iteration:  13% 158/1173 [00:46<04:55,  3.43it/s]\u001b[A\n","Iteration:  14% 159/1173 [00:46<04:55,  3.43it/s]\u001b[A\n","Iteration:  14% 160/1173 [00:47<04:56,  3.42it/s]\u001b[A\n","Iteration:  14% 161/1173 [00:47<04:55,  3.43it/s]\u001b[A\n","Iteration:  14% 162/1173 [00:47<04:54,  3.43it/s]\u001b[A\n","Iteration:  14% 163/1173 [00:47<04:53,  3.44it/s]\u001b[A\n","Iteration:  14% 164/1173 [00:48<04:52,  3.44it/s]\u001b[A\n","Iteration:  14% 165/1173 [00:48<04:53,  3.44it/s]\u001b[A\n","Iteration:  14% 166/1173 [00:48<04:52,  3.44it/s]\u001b[A\n","Iteration:  14% 167/1173 [00:49<04:53,  3.43it/s]\u001b[A\n","Iteration:  14% 168/1173 [00:49<04:52,  3.43it/s]\u001b[A\n","Iteration:  14% 169/1173 [00:49<04:52,  3.43it/s]\u001b[A\n","Iteration:  14% 170/1173 [00:49<04:52,  3.43it/s]\u001b[A\n","Iteration:  15% 171/1173 [00:50<04:51,  3.44it/s]\u001b[A\n","Iteration:  15% 172/1173 [00:50<04:50,  3.44it/s]\u001b[A\n","Iteration:  15% 173/1173 [00:50<04:50,  3.44it/s]\u001b[A\n","Iteration:  15% 174/1173 [00:51<04:50,  3.44it/s]\u001b[A\n","Iteration:  15% 175/1173 [00:51<04:50,  3.44it/s]\u001b[A\n","Iteration:  15% 176/1173 [00:51<04:50,  3.43it/s]\u001b[A\n","Iteration:  15% 177/1173 [00:51<04:50,  3.42it/s]\u001b[A\n","Iteration:  15% 178/1173 [00:52<04:50,  3.43it/s]\u001b[A\n","Iteration:  15% 179/1173 [00:52<04:49,  3.43it/s]\u001b[A\n","Iteration:  15% 180/1173 [00:52<04:51,  3.40it/s]\u001b[A\n","Iteration:  15% 181/1173 [00:53<04:50,  3.42it/s]\u001b[A\n","Iteration:  16% 182/1173 [00:53<04:50,  3.42it/s]\u001b[A\n","Iteration:  16% 183/1173 [00:53<04:50,  3.41it/s]\u001b[A\n","Iteration:  16% 184/1173 [00:54<04:49,  3.42it/s]\u001b[A\n","Iteration:  16% 185/1173 [00:54<04:48,  3.43it/s]\u001b[A\n","Iteration:  16% 186/1173 [00:54<04:48,  3.43it/s]\u001b[A\n","Iteration:  16% 187/1173 [00:54<04:47,  3.43it/s]\u001b[A\n","Iteration:  16% 188/1173 [00:55<04:47,  3.43it/s]\u001b[A\n","Iteration:  16% 189/1173 [00:55<04:48,  3.41it/s]\u001b[A\n","Iteration:  16% 190/1173 [00:55<04:47,  3.42it/s]\u001b[A\n","Iteration:  16% 191/1173 [00:56<04:47,  3.42it/s]\u001b[A\n","Iteration:  16% 192/1173 [00:56<04:46,  3.43it/s]\u001b[A\n","Iteration:  16% 193/1173 [00:56<04:45,  3.43it/s]\u001b[A\n","Iteration:  17% 194/1173 [00:56<04:45,  3.43it/s]\u001b[A\n","Iteration:  17% 195/1173 [00:57<04:44,  3.43it/s]\u001b[A\n","Iteration:  17% 196/1173 [00:57<04:45,  3.42it/s]\u001b[A\n","Iteration:  17% 197/1173 [00:57<04:45,  3.42it/s]\u001b[A\n","Iteration:  17% 198/1173 [00:58<04:45,  3.42it/s]\u001b[A\n","Iteration:  17% 199/1173 [00:58<04:44,  3.42it/s]\u001b[A\n","Iteration:  17% 200/1173 [00:58<04:44,  3.43it/s]\u001b[A\n","Iteration:  17% 201/1173 [00:58<04:43,  3.43it/s]\u001b[A\n","Iteration:  17% 202/1173 [00:59<04:43,  3.42it/s]\u001b[A\n","Iteration:  17% 203/1173 [00:59<04:43,  3.42it/s]\u001b[A\n","Iteration:  17% 204/1173 [00:59<04:42,  3.43it/s]\u001b[A\n","Iteration:  17% 205/1173 [01:00<04:42,  3.43it/s]\u001b[A\n","Iteration:  18% 206/1173 [01:00<04:41,  3.43it/s]\u001b[A\n","Iteration:  18% 207/1173 [01:00<04:41,  3.43it/s]\u001b[A\n","Iteration:  18% 208/1173 [01:01<04:41,  3.42it/s]\u001b[A\n","Iteration:  18% 209/1173 [01:01<04:41,  3.42it/s]\u001b[A\n","Iteration:  18% 210/1173 [01:01<04:41,  3.42it/s]\u001b[A\n","Iteration:  18% 211/1173 [01:01<04:41,  3.42it/s]\u001b[A\n","Iteration:  18% 212/1173 [01:02<04:40,  3.43it/s]\u001b[A\n","Iteration:  18% 213/1173 [01:02<04:39,  3.43it/s]\u001b[A\n","Iteration:  18% 214/1173 [01:02<04:39,  3.43it/s]\u001b[A\n","Iteration:  18% 215/1173 [01:03<04:38,  3.44it/s]\u001b[A\n","Iteration:  18% 216/1173 [01:03<04:37,  3.44it/s]\u001b[A\n","Iteration:  18% 217/1173 [01:03<04:38,  3.43it/s]\u001b[A\n","Iteration:  19% 218/1173 [01:03<04:38,  3.43it/s]\u001b[A\n","Iteration:  19% 219/1173 [01:04<04:38,  3.43it/s]\u001b[A\n","Iteration:  19% 220/1173 [01:04<04:37,  3.43it/s]\u001b[A\n","Iteration:  19% 221/1173 [01:04<04:37,  3.43it/s]\u001b[A\n","Iteration:  19% 222/1173 [01:05<04:36,  3.44it/s]\u001b[A\n","Iteration:  19% 223/1173 [01:05<04:37,  3.43it/s]\u001b[A\n","Iteration:  19% 224/1173 [01:05<04:36,  3.44it/s]\u001b[A\n","Iteration:  19% 225/1173 [01:05<04:36,  3.42it/s]\u001b[A\n","Iteration:  19% 226/1173 [01:06<04:35,  3.43it/s]\u001b[A\n","Iteration:  19% 227/1173 [01:06<04:35,  3.43it/s]\u001b[A\n","Iteration:  19% 228/1173 [01:06<04:35,  3.43it/s]\u001b[A\n","Iteration:  20% 229/1173 [01:07<04:35,  3.42it/s]\u001b[A\n","Iteration:  20% 230/1173 [01:07<04:35,  3.43it/s]\u001b[A\n","Iteration:  20% 231/1173 [01:07<04:34,  3.43it/s]\u001b[A\n","Iteration:  20% 232/1173 [01:08<04:34,  3.42it/s]\u001b[A\n","Iteration:  20% 233/1173 [01:08<04:34,  3.43it/s]\u001b[A\n","Iteration:  20% 234/1173 [01:08<04:33,  3.44it/s]\u001b[A\n","Iteration:  20% 235/1173 [01:08<04:32,  3.44it/s]\u001b[A\n","Iteration:  20% 236/1173 [01:09<04:32,  3.44it/s]\u001b[A\n","Iteration:  20% 237/1173 [01:09<04:32,  3.44it/s]\u001b[A\n","Iteration:  20% 238/1173 [01:09<04:32,  3.43it/s]\u001b[A\n","Iteration:  20% 239/1173 [01:10<04:32,  3.43it/s]\u001b[A\n","Iteration:  20% 240/1173 [01:10<04:32,  3.43it/s]\u001b[A\n","Iteration:  21% 241/1173 [01:10<04:31,  3.43it/s]\u001b[A\n","Iteration:  21% 242/1173 [01:10<04:30,  3.44it/s]\u001b[A\n","Iteration:  21% 243/1173 [01:11<04:30,  3.44it/s]\u001b[A\n","Iteration:  21% 244/1173 [01:11<04:29,  3.44it/s]\u001b[A\n","Iteration:  21% 245/1173 [01:11<04:29,  3.45it/s]\u001b[A\n","Iteration:  21% 246/1173 [01:12<04:29,  3.44it/s]\u001b[A\n","Iteration:  21% 247/1173 [01:12<04:29,  3.43it/s]\u001b[A\n","Iteration:  21% 248/1173 [01:12<04:29,  3.43it/s]\u001b[A\n","Iteration:  21% 249/1173 [01:12<04:29,  3.43it/s]\u001b[A\n","Iteration:  21% 250/1173 [01:13<04:29,  3.43it/s]\u001b[A\n","Iteration:  21% 251/1173 [01:13<04:28,  3.43it/s]\u001b[A\n","Iteration:  21% 252/1173 [01:13<04:28,  3.43it/s]\u001b[A\n","Iteration:  22% 253/1173 [01:14<04:28,  3.43it/s]\u001b[A\n","Iteration:  22% 254/1173 [01:14<04:27,  3.43it/s]\u001b[A\n","Iteration:  22% 255/1173 [01:14<04:26,  3.44it/s]\u001b[A\n","Iteration:  22% 256/1173 [01:14<04:26,  3.43it/s]\u001b[A\n","Iteration:  22% 257/1173 [01:15<04:26,  3.43it/s]\u001b[A\n","Iteration:  22% 258/1173 [01:15<04:26,  3.43it/s]\u001b[A\n","Iteration:  22% 259/1173 [01:15<04:25,  3.44it/s]\u001b[A\n","Iteration:  22% 260/1173 [01:16<04:25,  3.43it/s]\u001b[A\n","Iteration:  22% 261/1173 [01:16<04:25,  3.43it/s]\u001b[A\n","Iteration:  22% 262/1173 [01:16<04:25,  3.44it/s]\u001b[A\n","Iteration:  22% 263/1173 [01:17<04:24,  3.44it/s]\u001b[A\n","Iteration:  23% 264/1173 [01:17<04:24,  3.44it/s]\u001b[A\n","Iteration:  23% 265/1173 [01:17<04:23,  3.44it/s]\u001b[A\n","Iteration:  23% 266/1173 [01:17<04:24,  3.43it/s]\u001b[A\n","Iteration:  23% 267/1173 [01:18<04:24,  3.43it/s]\u001b[A\n","Iteration:  23% 268/1173 [01:18<04:23,  3.44it/s]\u001b[A\n","Iteration:  23% 269/1173 [01:18<04:22,  3.44it/s]\u001b[A\n","Iteration:  23% 270/1173 [01:19<04:22,  3.44it/s]\u001b[A\n","Iteration:  23% 271/1173 [01:19<04:22,  3.44it/s]\u001b[A\n","Iteration:  23% 272/1173 [01:19<04:22,  3.43it/s]\u001b[A\n","Iteration:  23% 273/1173 [01:19<04:22,  3.43it/s]\u001b[A\n","Iteration:  23% 274/1173 [01:20<04:22,  3.43it/s]\u001b[A\n","Iteration:  23% 275/1173 [01:20<04:21,  3.43it/s]\u001b[A\n","Iteration:  24% 276/1173 [01:20<04:21,  3.43it/s]\u001b[A\n","Iteration:  24% 277/1173 [01:21<04:22,  3.41it/s]\u001b[A\n","Iteration:  24% 278/1173 [01:21<04:22,  3.41it/s]\u001b[A\n","Iteration:  24% 279/1173 [01:21<04:21,  3.42it/s]\u001b[A\n","Iteration:  24% 280/1173 [01:21<04:21,  3.42it/s]\u001b[A\n","Iteration:  24% 281/1173 [01:22<04:20,  3.43it/s]\u001b[A\n","Iteration:  24% 282/1173 [01:22<04:19,  3.43it/s]\u001b[A\n","Iteration:  24% 283/1173 [01:22<04:19,  3.43it/s]\u001b[A\n","Iteration:  24% 284/1173 [01:23<04:18,  3.43it/s]\u001b[A\n","Iteration:  24% 285/1173 [01:23<04:18,  3.43it/s]\u001b[A\n","Iteration:  24% 286/1173 [01:23<04:18,  3.43it/s]\u001b[A\n","Iteration:  24% 287/1173 [01:24<04:19,  3.41it/s]\u001b[A\n","Iteration:  25% 288/1173 [01:24<04:19,  3.41it/s]\u001b[A\n","Iteration:  25% 289/1173 [01:24<04:18,  3.42it/s]\u001b[A\n","Iteration:  25% 290/1173 [01:24<04:18,  3.42it/s]\u001b[A\n","Iteration:  25% 291/1173 [01:25<04:17,  3.42it/s]\u001b[A\n","Iteration:  25% 292/1173 [01:25<04:17,  3.43it/s]\u001b[A\n","Iteration:  25% 293/1173 [01:25<04:16,  3.43it/s]\u001b[A\n","Iteration:  25% 294/1173 [01:26<04:15,  3.44it/s]\u001b[A\n","Iteration:  25% 295/1173 [01:26<04:15,  3.44it/s]\u001b[A\n","Iteration:  25% 296/1173 [01:26<04:15,  3.44it/s]\u001b[A\n","Iteration:  25% 297/1173 [01:26<04:15,  3.43it/s]\u001b[A\n","Iteration:  25% 298/1173 [01:27<04:15,  3.42it/s]\u001b[A\n","Iteration:  25% 299/1173 [01:27<04:15,  3.42it/s]\u001b[A\n","Iteration:  26% 300/1173 [01:27<04:15,  3.42it/s]\u001b[A\n","Iteration:  26% 301/1173 [01:28<04:14,  3.43it/s]\u001b[A\n","Iteration:  26% 302/1173 [01:28<04:13,  3.44it/s]\u001b[A\n","Iteration:  26% 303/1173 [01:28<04:12,  3.44it/s]\u001b[A\n","Iteration:  26% 304/1173 [01:28<04:12,  3.44it/s]\u001b[A\n","Iteration:  26% 305/1173 [01:29<04:12,  3.44it/s]\u001b[A\n","Iteration:  26% 306/1173 [01:29<04:12,  3.43it/s]\u001b[A\n","Iteration:  26% 307/1173 [01:29<04:12,  3.42it/s]\u001b[A\n","Iteration:  26% 308/1173 [01:30<04:12,  3.42it/s]\u001b[A\n","Iteration:  26% 309/1173 [01:30<04:13,  3.40it/s]\u001b[A\n","Iteration:  26% 310/1173 [01:30<04:12,  3.41it/s]\u001b[A\n","Iteration:  27% 311/1173 [01:31<04:12,  3.42it/s]\u001b[A\n","Iteration:  27% 312/1173 [01:31<04:11,  3.43it/s]\u001b[A\n","Iteration:  27% 313/1173 [01:31<04:10,  3.43it/s]\u001b[A\n","Iteration:  27% 314/1173 [01:31<04:10,  3.43it/s]\u001b[A\n","Iteration:  27% 315/1173 [01:32<04:09,  3.44it/s]\u001b[A\n","Iteration:  27% 316/1173 [01:32<04:09,  3.44it/s]\u001b[A\n","Iteration:  27% 317/1173 [01:32<04:09,  3.43it/s]\u001b[A\n","Iteration:  27% 318/1173 [01:33<04:09,  3.43it/s]\u001b[A\n","Iteration:  27% 319/1173 [01:33<04:08,  3.44it/s]\u001b[A\n","Iteration:  27% 320/1173 [01:33<04:08,  3.43it/s]\u001b[A\n","Iteration:  27% 321/1173 [01:33<04:07,  3.44it/s]\u001b[A\n","Iteration:  27% 322/1173 [01:34<04:07,  3.44it/s]\u001b[A\n","Iteration:  28% 323/1173 [01:34<04:07,  3.43it/s]\u001b[A\n","Iteration:  28% 324/1173 [01:34<04:07,  3.44it/s]\u001b[A\n","Iteration:  28% 325/1173 [01:35<04:06,  3.44it/s]\u001b[A\n","Iteration:  28% 326/1173 [01:35<04:06,  3.44it/s]\u001b[A\n","Iteration:  28% 327/1173 [01:35<04:06,  3.44it/s]\u001b[A\n","Iteration:  28% 328/1173 [01:35<04:05,  3.44it/s]\u001b[A\n","Iteration:  28% 329/1173 [01:36<04:06,  3.42it/s]\u001b[A\n","Iteration:  28% 330/1173 [01:36<04:05,  3.43it/s]\u001b[A\n","Iteration:  28% 331/1173 [01:36<04:05,  3.43it/s]\u001b[A\n","Iteration:  28% 332/1173 [01:37<04:04,  3.44it/s]\u001b[A\n","Iteration:  28% 333/1173 [01:37<04:04,  3.44it/s]\u001b[A\n","Iteration:  28% 334/1173 [01:37<04:04,  3.43it/s]\u001b[A\n","Iteration:  29% 335/1173 [01:38<04:03,  3.44it/s]\u001b[A\n","Iteration:  29% 336/1173 [01:38<04:03,  3.44it/s]\u001b[A\n","Iteration:  29% 337/1173 [01:38<04:03,  3.43it/s]\u001b[A\n","Iteration:  29% 338/1173 [01:38<04:03,  3.43it/s]\u001b[A\n","Iteration:  29% 339/1173 [01:39<04:02,  3.43it/s]\u001b[A\n","Iteration:  29% 340/1173 [01:39<04:02,  3.43it/s]\u001b[A\n","Iteration:  29% 341/1173 [01:39<04:02,  3.43it/s]\u001b[A\n","Iteration:  29% 342/1173 [01:40<04:01,  3.44it/s]\u001b[A\n","Iteration:  29% 343/1173 [01:40<04:01,  3.44it/s]\u001b[A\n","Iteration:  29% 344/1173 [01:40<04:00,  3.44it/s]\u001b[A\n","Iteration:  29% 345/1173 [01:40<04:00,  3.44it/s]\u001b[A\n","Iteration:  29% 346/1173 [01:41<04:01,  3.43it/s]\u001b[A\n","Iteration:  30% 347/1173 [01:41<04:00,  3.43it/s]\u001b[A\n","Iteration:  30% 348/1173 [01:41<04:00,  3.44it/s]\u001b[A\n","Iteration:  30% 349/1173 [01:42<03:59,  3.44it/s]\u001b[A\n","Iteration:  30% 350/1173 [01:42<03:58,  3.45it/s]\u001b[A\n","Iteration:  30% 351/1173 [01:42<03:58,  3.45it/s]\u001b[A\n","Iteration:  30% 352/1173 [01:42<03:57,  3.45it/s]\u001b[A\n","Iteration:  30% 353/1173 [01:43<03:57,  3.45it/s]\u001b[A\n","Iteration:  30% 354/1173 [01:43<03:57,  3.45it/s]\u001b[A\n","Iteration:  30% 355/1173 [01:43<03:57,  3.44it/s]\u001b[A\n","Iteration:  30% 356/1173 [01:44<03:57,  3.44it/s]\u001b[A\n","Iteration:  30% 357/1173 [01:44<03:56,  3.45it/s]\u001b[A\n","Iteration:  31% 358/1173 [01:44<03:56,  3.44it/s]\u001b[A\n","Iteration:  31% 359/1173 [01:44<03:56,  3.44it/s]\u001b[A\n","Iteration:  31% 360/1173 [01:45<03:56,  3.44it/s]\u001b[A\n","Iteration:  31% 361/1173 [01:45<03:55,  3.44it/s]\u001b[A\n","Iteration:  31% 362/1173 [01:45<03:55,  3.44it/s]\u001b[A\n","Iteration:  31% 363/1173 [01:46<03:55,  3.43it/s]\u001b[A\n","Iteration:  31% 364/1173 [01:46<03:55,  3.44it/s]\u001b[A\n","Iteration:  31% 365/1173 [01:46<03:55,  3.43it/s]\u001b[A\n","Iteration:  31% 366/1173 [01:47<03:55,  3.43it/s]\u001b[A\n","Iteration:  31% 367/1173 [01:47<03:54,  3.43it/s]\u001b[A\n","Iteration:  31% 368/1173 [01:47<03:54,  3.43it/s]\u001b[A\n","Iteration:  31% 369/1173 [01:47<03:54,  3.43it/s]\u001b[A\n","Iteration:  32% 370/1173 [01:48<03:53,  3.43it/s]\u001b[A\n","Iteration:  32% 371/1173 [01:48<03:53,  3.44it/s]\u001b[A\n","Iteration:  32% 372/1173 [01:48<03:52,  3.44it/s]\u001b[A\n","Iteration:  32% 373/1173 [01:49<03:52,  3.43it/s]\u001b[A\n","Iteration:  32% 374/1173 [01:49<03:52,  3.44it/s]\u001b[A\n","Iteration:  32% 375/1173 [01:49<03:52,  3.44it/s]\u001b[A\n","Iteration:  32% 376/1173 [01:49<03:51,  3.44it/s]\u001b[A\n","Iteration:  32% 377/1173 [01:50<03:51,  3.44it/s]\u001b[A\n","Iteration:  32% 378/1173 [01:50<03:50,  3.44it/s]\u001b[A\n","Iteration:  32% 379/1173 [01:50<03:50,  3.45it/s]\u001b[A\n","Iteration:  32% 380/1173 [01:51<03:49,  3.45it/s]\u001b[A\n","Iteration:  32% 381/1173 [01:51<03:49,  3.45it/s]\u001b[A\n","Iteration:  33% 382/1173 [01:51<03:49,  3.44it/s]\u001b[A\n","Iteration:  33% 383/1173 [01:51<03:49,  3.44it/s]\u001b[A\n","Iteration:  33% 384/1173 [01:52<03:49,  3.44it/s]\u001b[A\n","Iteration:  33% 385/1173 [01:52<03:48,  3.44it/s]\u001b[A\n","Iteration:  33% 386/1173 [01:52<03:48,  3.44it/s]\u001b[A\n","Iteration:  33% 387/1173 [01:53<03:48,  3.45it/s]\u001b[A\n","Iteration:  33% 388/1173 [01:53<03:47,  3.45it/s]\u001b[A\n","Iteration:  33% 389/1173 [01:53<03:47,  3.44it/s]\u001b[A\n","Iteration:  33% 390/1173 [01:54<03:47,  3.44it/s]\u001b[A\n","Iteration:  33% 391/1173 [01:54<03:47,  3.44it/s]\u001b[A\n","Iteration:  33% 392/1173 [01:54<03:46,  3.45it/s]\u001b[A\n","Iteration:  34% 393/1173 [01:54<03:46,  3.44it/s]\u001b[A\n","Iteration:  34% 394/1173 [01:55<03:47,  3.43it/s]\u001b[A\n","Iteration:  34% 395/1173 [01:55<03:47,  3.42it/s]\u001b[A\n","Iteration:  34% 396/1173 [01:55<03:46,  3.42it/s]\u001b[A\n","Iteration:  34% 397/1173 [01:56<03:45,  3.43it/s]\u001b[A\n","Iteration:  34% 398/1173 [01:56<03:45,  3.44it/s]\u001b[A\n","Iteration:  34% 399/1173 [01:56<03:44,  3.44it/s]\u001b[A\n","Iteration:  34% 400/1173 [01:56<03:44,  3.45it/s]\u001b[A\n","Iteration:  34% 401/1173 [01:57<03:44,  3.44it/s]\u001b[A\n","Iteration:  34% 402/1173 [01:57<03:45,  3.42it/s]\u001b[A\n","Iteration:  34% 403/1173 [01:57<03:45,  3.42it/s]\u001b[A\n","Iteration:  34% 404/1173 [01:58<03:44,  3.43it/s]\u001b[A\n","Iteration:  35% 405/1173 [01:58<03:43,  3.43it/s]\u001b[A\n","Iteration:  35% 406/1173 [01:58<03:43,  3.43it/s]\u001b[A\n","Iteration:  35% 407/1173 [01:58<03:43,  3.43it/s]\u001b[A\n","Iteration:  35% 408/1173 [01:59<03:42,  3.43it/s]\u001b[A\n","Iteration:  35% 409/1173 [01:59<03:42,  3.44it/s]\u001b[A\n","Iteration:  35% 410/1173 [01:59<03:41,  3.44it/s]\u001b[A\n","Iteration:  35% 411/1173 [02:00<03:41,  3.44it/s]\u001b[A\n","Iteration:  35% 412/1173 [02:00<03:41,  3.44it/s]\u001b[A\n","Iteration:  35% 413/1173 [02:00<03:40,  3.44it/s]\u001b[A\n","Iteration:  35% 414/1173 [02:00<03:40,  3.44it/s]\u001b[A\n","Iteration:  35% 415/1173 [02:01<03:40,  3.44it/s]\u001b[A\n","Iteration:  35% 416/1173 [02:01<03:40,  3.44it/s]\u001b[A\n","Iteration:  36% 417/1173 [02:01<03:39,  3.45it/s]\u001b[A\n","Iteration:  36% 418/1173 [02:02<03:39,  3.44it/s]\u001b[A\n","Iteration:  36% 419/1173 [02:02<03:38,  3.44it/s]\u001b[A\n","Iteration:  36% 420/1173 [02:02<03:39,  3.43it/s]\u001b[A\n","Iteration:  36% 421/1173 [02:03<03:39,  3.43it/s]\u001b[A\n","Iteration:  36% 422/1173 [02:03<03:38,  3.43it/s]\u001b[A\n","Iteration:  36% 423/1173 [02:03<03:38,  3.43it/s]\u001b[A\n","Iteration:  36% 424/1173 [02:03<03:38,  3.43it/s]\u001b[A\n","Iteration:  36% 425/1173 [02:04<03:37,  3.44it/s]\u001b[A\n","Iteration:  36% 426/1173 [02:04<03:37,  3.44it/s]\u001b[A\n","Iteration:  36% 427/1173 [02:04<03:36,  3.44it/s]\u001b[A\n","Iteration:  36% 428/1173 [02:05<03:36,  3.43it/s]\u001b[A\n","Iteration:  37% 429/1173 [02:05<03:36,  3.44it/s]\u001b[A\n","Iteration:  37% 430/1173 [02:05<03:35,  3.44it/s]\u001b[A\n","Iteration:  37% 431/1173 [02:05<03:35,  3.44it/s]\u001b[A\n","Iteration:  37% 432/1173 [02:06<03:35,  3.43it/s]\u001b[A\n","Iteration:  37% 433/1173 [02:06<03:35,  3.44it/s]\u001b[A\n","Iteration:  37% 434/1173 [02:06<03:34,  3.44it/s]\u001b[A\n","Iteration:  37% 435/1173 [02:07<03:34,  3.44it/s]\u001b[A\n","Iteration:  37% 436/1173 [02:07<03:33,  3.45it/s]\u001b[A\n","Iteration:  37% 437/1173 [02:07<03:33,  3.45it/s]\u001b[A\n","Iteration:  37% 438/1173 [02:07<03:33,  3.45it/s]\u001b[A\n","Iteration:  37% 439/1173 [02:08<03:33,  3.44it/s]\u001b[A\n","Iteration:  38% 440/1173 [02:08<03:33,  3.44it/s]\u001b[A\n","Iteration:  38% 441/1173 [02:08<03:32,  3.44it/s]\u001b[A\n","Iteration:  38% 442/1173 [02:09<03:32,  3.44it/s]\u001b[A\n","Iteration:  38% 443/1173 [02:09<03:31,  3.45it/s]\u001b[A\n","Iteration:  38% 444/1173 [02:09<03:32,  3.43it/s]\u001b[A\n","Iteration:  38% 445/1173 [02:10<03:31,  3.44it/s]\u001b[A\n","Iteration:  38% 446/1173 [02:10<03:31,  3.44it/s]\u001b[A\n","Iteration:  38% 447/1173 [02:10<03:31,  3.44it/s]\u001b[A\n","Iteration:  38% 448/1173 [02:10<03:31,  3.43it/s]\u001b[A\n","Iteration:  38% 449/1173 [02:11<03:31,  3.42it/s]\u001b[A\n","Iteration:  38% 450/1173 [02:11<03:31,  3.42it/s]\u001b[A\n","Iteration:  38% 451/1173 [02:11<03:30,  3.43it/s]\u001b[A\n","Iteration:  39% 452/1173 [02:12<03:30,  3.43it/s]\u001b[A\n","Iteration:  39% 453/1173 [02:12<03:29,  3.44it/s]\u001b[A\n","Iteration:  39% 454/1173 [02:12<03:29,  3.44it/s]\u001b[A\n","Iteration:  39% 455/1173 [02:12<03:28,  3.44it/s]\u001b[A\n","Iteration:  39% 456/1173 [02:13<03:28,  3.44it/s]\u001b[A\n","Iteration:  39% 457/1173 [02:13<03:27,  3.45it/s]\u001b[A\n","Iteration:  39% 458/1173 [02:13<03:27,  3.44it/s]\u001b[A\n","Iteration:  39% 459/1173 [02:14<03:27,  3.44it/s]\u001b[A\n","Iteration:  39% 460/1173 [02:14<03:27,  3.44it/s]\u001b[A\n","Iteration:  39% 461/1173 [02:14<03:27,  3.44it/s]\u001b[A\n","Iteration:  39% 462/1173 [02:14<03:26,  3.44it/s]\u001b[A\n","Iteration:  39% 463/1173 [02:15<03:26,  3.44it/s]\u001b[A\n","Iteration:  40% 464/1173 [02:15<03:25,  3.45it/s]\u001b[A\n","Iteration:  40% 465/1173 [02:15<03:25,  3.45it/s]\u001b[A\n","Iteration:  40% 466/1173 [02:16<03:25,  3.44it/s]\u001b[A\n","Iteration:  40% 467/1173 [02:16<03:25,  3.44it/s]\u001b[A\n","Iteration:  40% 468/1173 [02:16<03:25,  3.43it/s]\u001b[A\n","Iteration:  40% 469/1173 [02:16<03:25,  3.43it/s]\u001b[A\n","Iteration:  40% 470/1173 [02:17<03:24,  3.44it/s]\u001b[A\n","Iteration:  40% 471/1173 [02:17<03:24,  3.43it/s]\u001b[A\n","Iteration:  40% 472/1173 [02:17<03:23,  3.44it/s]\u001b[A\n","Iteration:  40% 473/1173 [02:18<03:23,  3.44it/s]\u001b[A\n","Iteration:  40% 474/1173 [02:18<03:23,  3.43it/s]\u001b[A\n","Iteration:  40% 475/1173 [02:18<03:23,  3.43it/s]\u001b[A\n","Iteration:  41% 476/1173 [02:19<03:22,  3.44it/s]\u001b[A\n","Iteration:  41% 477/1173 [02:19<03:22,  3.44it/s]\u001b[A\n","Iteration:  41% 478/1173 [02:19<03:22,  3.44it/s]\u001b[A\n","Iteration:  41% 479/1173 [02:19<03:21,  3.44it/s]\u001b[A\n","Iteration:  41% 480/1173 [02:20<03:20,  3.45it/s]\u001b[A\n","Iteration:  41% 481/1173 [02:20<03:20,  3.44it/s]\u001b[A\n","Iteration:  41% 482/1173 [02:20<03:20,  3.44it/s]\u001b[A\n","Iteration:  41% 483/1173 [02:21<03:20,  3.45it/s]\u001b[A\n","Iteration:  41% 484/1173 [02:21<03:19,  3.45it/s]\u001b[A\n","Iteration:  41% 485/1173 [02:21<03:19,  3.45it/s]\u001b[A\n","Iteration:  41% 486/1173 [02:21<03:19,  3.45it/s]\u001b[A\n","Iteration:  42% 487/1173 [02:22<03:19,  3.45it/s]\u001b[A\n","Iteration:  42% 488/1173 [02:22<03:18,  3.45it/s]\u001b[A\n","Iteration:  42% 489/1173 [02:22<03:18,  3.44it/s]\u001b[A\n","Iteration:  42% 490/1173 [02:23<03:18,  3.44it/s]\u001b[A\n","Iteration:  42% 491/1173 [02:23<03:17,  3.45it/s]\u001b[A\n","Iteration:  42% 492/1173 [02:23<03:17,  3.45it/s]\u001b[A\n","Iteration:  42% 493/1173 [02:23<03:17,  3.45it/s]\u001b[A\n","Iteration:  42% 494/1173 [02:24<03:16,  3.45it/s]\u001b[A\n","Iteration:  42% 495/1173 [02:24<03:16,  3.45it/s]\u001b[A\n","Iteration:  42% 496/1173 [02:24<03:16,  3.45it/s]\u001b[A\n","Iteration:  42% 497/1173 [02:25<03:15,  3.45it/s]\u001b[A\n","Iteration:  42% 498/1173 [02:25<03:15,  3.45it/s]\u001b[A\n","Iteration:  43% 499/1173 [02:25<03:15,  3.45it/s]\u001b[A/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:231: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","05/20/2020 05:25:06 - INFO - transformers.configuration_utils -   Configuration saved in output/checkpoint-500/config.json\n","05/20/2020 05:25:06 - INFO - transformers.modeling_utils -   Model weights saved in output/checkpoint-500/pytorch_model.bin\n","05/20/2020 05:25:06 - INFO - __main__ -   Saving model checkpoint to output/checkpoint-500\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n","  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n","05/20/2020 05:25:10 - INFO - __main__ -   Saving optimizer and scheduler states to output/checkpoint-500\n","\n","Iteration:  43% 500/1173 [02:30<17:15,  1.54s/it]\u001b[A\n","Iteration:  43% 501/1173 [02:30<13:06,  1.17s/it]\u001b[A\n","Iteration:  43% 502/1173 [02:30<10:08,  1.10it/s]\u001b[A\n","Iteration:  43% 503/1173 [02:31<08:04,  1.38it/s]\u001b[A\n","Iteration:  43% 504/1173 [02:31<06:37,  1.68it/s]\u001b[A\n","Iteration:  43% 505/1173 [02:31<05:36,  1.99it/s]\u001b[A\n","Iteration:  43% 506/1173 [02:31<04:53,  2.27it/s]\u001b[A\n","Iteration:  43% 507/1173 [02:32<04:22,  2.53it/s]\u001b[A\n","Iteration:  43% 508/1173 [02:32<04:01,  2.75it/s]\u001b[A\n","Iteration:  43% 509/1173 [02:32<03:46,  2.93it/s]\u001b[A\n","Iteration:  43% 510/1173 [02:33<03:37,  3.05it/s]\u001b[A\n","Iteration:  44% 511/1173 [02:33<03:29,  3.15it/s]\u001b[A\n","Iteration:  44% 512/1173 [02:33<03:24,  3.23it/s]\u001b[A\n","Iteration:  44% 513/1173 [02:33<03:20,  3.30it/s]\u001b[A\n","Iteration:  44% 514/1173 [02:34<03:17,  3.34it/s]\u001b[A\n","Iteration:  44% 515/1173 [02:34<03:15,  3.37it/s]\u001b[A\n","Iteration:  44% 516/1173 [02:34<03:13,  3.39it/s]\u001b[A\n","Iteration:  44% 517/1173 [02:35<03:12,  3.41it/s]\u001b[A\n","Iteration:  44% 518/1173 [02:35<03:11,  3.43it/s]\u001b[A\n","Iteration:  44% 519/1173 [02:35<03:10,  3.43it/s]\u001b[A\n","Iteration:  44% 520/1173 [02:36<03:10,  3.42it/s]\u001b[A\n","Iteration:  44% 521/1173 [02:36<03:10,  3.43it/s]\u001b[A\n","Iteration:  45% 522/1173 [02:36<03:09,  3.43it/s]\u001b[A\n","Iteration:  45% 523/1173 [02:36<03:09,  3.43it/s]\u001b[A\n","Iteration:  45% 524/1173 [02:37<03:08,  3.44it/s]\u001b[A\n","Iteration:  45% 525/1173 [02:37<03:08,  3.44it/s]\u001b[A\n","Iteration:  45% 526/1173 [02:37<03:08,  3.44it/s]\u001b[A\n","Iteration:  45% 527/1173 [02:38<03:08,  3.43it/s]\u001b[A\n","Iteration:  45% 528/1173 [02:38<03:07,  3.44it/s]\u001b[A\n","Iteration:  45% 529/1173 [02:38<03:07,  3.44it/s]\u001b[A\n","Iteration:  45% 530/1173 [02:38<03:08,  3.42it/s]\u001b[A\n","Iteration:  45% 531/1173 [02:39<03:07,  3.42it/s]\u001b[A\n","Iteration:  45% 532/1173 [02:39<03:06,  3.43it/s]\u001b[A\n","Iteration:  45% 533/1173 [02:39<03:06,  3.43it/s]\u001b[A\n","Iteration:  46% 534/1173 [02:40<03:06,  3.43it/s]\u001b[A\n","Iteration:  46% 535/1173 [02:40<03:05,  3.44it/s]\u001b[A\n","Iteration:  46% 536/1173 [02:40<03:05,  3.44it/s]\u001b[A\n","Iteration:  46% 537/1173 [02:40<03:04,  3.44it/s]\u001b[A\n","Iteration:  46% 538/1173 [02:41<03:04,  3.44it/s]\u001b[A\n","Iteration:  46% 539/1173 [02:41<03:05,  3.43it/s]\u001b[A\n","Iteration:  46% 540/1173 [02:41<03:04,  3.42it/s]\u001b[A\n","Iteration:  46% 541/1173 [02:42<03:04,  3.43it/s]\u001b[A\n","Iteration:  46% 542/1173 [02:42<03:03,  3.43it/s]\u001b[A\n","Iteration:  46% 543/1173 [02:42<03:03,  3.43it/s]\u001b[A\n","Iteration:  46% 544/1173 [02:42<03:04,  3.42it/s]\u001b[A\n","Iteration:  46% 545/1173 [02:43<03:03,  3.43it/s]\u001b[A\n","Iteration:  47% 546/1173 [02:43<03:02,  3.44it/s]\u001b[A\n","Iteration:  47% 547/1173 [02:43<03:02,  3.44it/s]\u001b[A\n","Iteration:  47% 548/1173 [02:44<03:02,  3.43it/s]\u001b[A\n","Iteration:  47% 549/1173 [02:44<03:02,  3.43it/s]\u001b[A\n","Iteration:  47% 550/1173 [02:44<03:02,  3.42it/s]\u001b[A\n","Iteration:  47% 551/1173 [02:45<03:01,  3.43it/s]\u001b[A\n","Iteration:  47% 552/1173 [02:45<03:00,  3.43it/s]\u001b[A\n","Iteration:  47% 553/1173 [02:45<03:00,  3.44it/s]\u001b[A\n","Iteration:  47% 554/1173 [02:45<02:59,  3.45it/s]\u001b[A\n","Iteration:  47% 555/1173 [02:46<02:59,  3.45it/s]\u001b[A\n","Iteration:  47% 556/1173 [02:46<02:58,  3.45it/s]\u001b[A\n","Iteration:  47% 557/1173 [02:46<02:58,  3.45it/s]\u001b[A\n","Iteration:  48% 558/1173 [02:47<02:58,  3.44it/s]\u001b[A\n","Iteration:  48% 559/1173 [02:47<02:58,  3.44it/s]\u001b[A\n","Iteration:  48% 560/1173 [02:47<02:58,  3.44it/s]\u001b[A\n","Iteration:  48% 561/1173 [02:47<02:57,  3.44it/s]\u001b[A\n","Iteration:  48% 562/1173 [02:48<02:57,  3.43it/s]\u001b[A\n","Iteration:  48% 563/1173 [02:48<02:57,  3.44it/s]\u001b[A\n","Iteration:  48% 564/1173 [02:48<02:56,  3.44it/s]\u001b[A\n","Iteration:  48% 565/1173 [02:49<02:56,  3.45it/s]\u001b[A\n","Iteration:  48% 566/1173 [02:49<02:55,  3.45it/s]\u001b[A\n","Iteration:  48% 567/1173 [02:49<02:55,  3.45it/s]\u001b[A\n","Iteration:  48% 568/1173 [02:49<02:55,  3.44it/s]\u001b[A\n","Iteration:  49% 569/1173 [02:50<02:55,  3.44it/s]\u001b[A\n","Iteration:  49% 570/1173 [02:50<02:55,  3.44it/s]\u001b[A\n","Iteration:  49% 571/1173 [02:50<02:54,  3.45it/s]\u001b[A\n","Iteration:  49% 572/1173 [02:51<02:54,  3.44it/s]\u001b[A\n","Iteration:  49% 573/1173 [02:51<02:54,  3.45it/s]\u001b[A\n","Iteration:  49% 574/1173 [02:51<02:53,  3.45it/s]\u001b[A\n","Iteration:  49% 575/1173 [02:52<02:53,  3.44it/s]\u001b[A\n","Iteration:  49% 576/1173 [02:52<02:53,  3.45it/s]\u001b[A\n","Iteration:  49% 577/1173 [02:52<02:52,  3.45it/s]\u001b[A\n","Iteration:  49% 578/1173 [02:52<02:52,  3.44it/s]\u001b[A\n","Iteration:  49% 579/1173 [02:53<02:52,  3.44it/s]\u001b[A\n","Iteration:  49% 580/1173 [02:53<02:52,  3.45it/s]\u001b[A\n","Iteration:  50% 581/1173 [02:53<02:51,  3.44it/s]\u001b[A\n","Iteration:  50% 582/1173 [02:54<02:51,  3.45it/s]\u001b[A\n","Iteration:  50% 583/1173 [02:54<02:50,  3.45it/s]\u001b[A\n","Iteration:  50% 584/1173 [02:54<02:50,  3.46it/s]\u001b[A\n","Iteration:  50% 585/1173 [02:54<02:50,  3.45it/s]\u001b[A\n","Iteration:  50% 586/1173 [02:55<02:50,  3.45it/s]\u001b[A\n","Iteration:  50% 587/1173 [02:55<02:49,  3.45it/s]\u001b[A\n","Iteration:  50% 588/1173 [02:55<02:49,  3.45it/s]\u001b[A\n","Iteration:  50% 589/1173 [02:56<02:49,  3.45it/s]\u001b[A\n","Iteration:  50% 590/1173 [02:56<02:48,  3.45it/s]\u001b[A\n","Iteration:  50% 591/1173 [02:56<02:48,  3.45it/s]\u001b[A\n","Iteration:  50% 592/1173 [02:56<02:48,  3.45it/s]\u001b[A\n","Iteration:  51% 593/1173 [02:57<02:48,  3.45it/s]\u001b[A\n","Iteration:  51% 594/1173 [02:57<02:48,  3.44it/s]\u001b[A\n","Iteration:  51% 595/1173 [02:57<02:48,  3.44it/s]\u001b[A\n","Iteration:  51% 596/1173 [02:58<02:47,  3.44it/s]\u001b[A\n","Iteration:  51% 597/1173 [02:58<02:47,  3.44it/s]\u001b[A\n","Iteration:  51% 598/1173 [02:58<02:47,  3.44it/s]\u001b[A\n","Iteration:  51% 599/1173 [02:58<02:46,  3.44it/s]\u001b[A\n","Iteration:  51% 600/1173 [02:59<02:46,  3.45it/s]\u001b[A\n","Iteration:  51% 601/1173 [02:59<02:45,  3.45it/s]\u001b[A\n","Iteration:  51% 602/1173 [02:59<02:45,  3.45it/s]\u001b[A\n","Iteration:  51% 603/1173 [03:00<02:45,  3.45it/s]\u001b[A\n","Iteration:  51% 604/1173 [03:00<02:45,  3.44it/s]\u001b[A\n","Iteration:  52% 605/1173 [03:00<02:44,  3.45it/s]\u001b[A\n","Iteration:  52% 606/1173 [03:00<02:44,  3.45it/s]\u001b[A\n","Iteration:  52% 607/1173 [03:01<02:43,  3.45it/s]\u001b[A\n","Iteration:  52% 608/1173 [03:01<02:43,  3.46it/s]\u001b[A\n","Iteration:  52% 609/1173 [03:01<02:42,  3.46it/s]\u001b[A\n","Iteration:  52% 610/1173 [03:02<02:42,  3.46it/s]\u001b[A\n","Iteration:  52% 611/1173 [03:02<02:43,  3.44it/s]\u001b[A\n","Iteration:  52% 612/1173 [03:02<02:43,  3.43it/s]\u001b[A\n","Iteration:  52% 613/1173 [03:03<02:43,  3.43it/s]\u001b[A\n","Iteration:  52% 614/1173 [03:03<02:42,  3.44it/s]\u001b[A\n","Iteration:  52% 615/1173 [03:03<02:42,  3.44it/s]\u001b[A\n","Iteration:  53% 616/1173 [03:03<02:41,  3.44it/s]\u001b[A\n","Iteration:  53% 617/1173 [03:04<02:41,  3.45it/s]\u001b[A\n","Iteration:  53% 618/1173 [03:04<02:40,  3.45it/s]\u001b[A\n","Iteration:  53% 619/1173 [03:04<02:40,  3.45it/s]\u001b[A\n","Iteration:  53% 620/1173 [03:05<02:40,  3.45it/s]\u001b[A\n","Iteration:  53% 621/1173 [03:05<02:40,  3.45it/s]\u001b[A\n","Iteration:  53% 622/1173 [03:05<02:39,  3.45it/s]\u001b[A\n","Iteration:  53% 623/1173 [03:05<02:39,  3.44it/s]\u001b[A\n","Iteration:  53% 624/1173 [03:06<02:40,  3.43it/s]\u001b[A\n","Iteration:  53% 625/1173 [03:06<02:39,  3.44it/s]\u001b[A\n","Iteration:  53% 626/1173 [03:06<02:38,  3.44it/s]\u001b[A\n","Iteration:  53% 627/1173 [03:07<02:38,  3.45it/s]\u001b[A\n","Iteration:  54% 628/1173 [03:07<02:38,  3.45it/s]\u001b[A\n","Iteration:  54% 629/1173 [03:07<02:37,  3.45it/s]\u001b[A\n","Iteration:  54% 630/1173 [03:07<02:37,  3.45it/s]\u001b[A\n","Iteration:  54% 631/1173 [03:08<02:37,  3.44it/s]\u001b[A\n","Iteration:  54% 632/1173 [03:08<02:37,  3.44it/s]\u001b[A\n","Iteration:  54% 633/1173 [03:08<02:36,  3.44it/s]\u001b[A\n","Iteration:  54% 634/1173 [03:09<02:36,  3.45it/s]\u001b[A\n","Iteration:  54% 635/1173 [03:09<02:35,  3.45it/s]\u001b[A\n","Iteration:  54% 636/1173 [03:09<02:35,  3.45it/s]\u001b[A\n","Iteration:  54% 637/1173 [03:09<02:35,  3.46it/s]\u001b[A\n","Iteration:  54% 638/1173 [03:10<02:35,  3.45it/s]\u001b[A\n","Iteration:  54% 639/1173 [03:10<02:34,  3.45it/s]\u001b[A\n","Iteration:  55% 640/1173 [03:10<02:34,  3.45it/s]\u001b[A\n","Iteration:  55% 641/1173 [03:11<02:34,  3.45it/s]\u001b[A\n","Iteration:  55% 642/1173 [03:11<02:33,  3.45it/s]\u001b[A\n","Iteration:  55% 643/1173 [03:11<02:34,  3.43it/s]\u001b[A\n","Iteration:  55% 644/1173 [03:12<02:34,  3.43it/s]\u001b[A\n","Iteration:  55% 645/1173 [03:12<02:33,  3.43it/s]\u001b[A\n","Iteration:  55% 646/1173 [03:12<02:33,  3.43it/s]\u001b[A\n","Iteration:  55% 647/1173 [03:12<02:33,  3.43it/s]\u001b[A\n","Iteration:  55% 648/1173 [03:13<02:32,  3.43it/s]\u001b[A\n","Iteration:  55% 649/1173 [03:13<02:32,  3.44it/s]\u001b[A\n","Iteration:  55% 650/1173 [03:13<02:31,  3.44it/s]\u001b[A\n","Iteration:  55% 651/1173 [03:14<02:31,  3.45it/s]\u001b[A\n","Iteration:  56% 652/1173 [03:14<02:31,  3.44it/s]\u001b[A\n","Iteration:  56% 653/1173 [03:14<02:31,  3.44it/s]\u001b[A\n","Iteration:  56% 654/1173 [03:14<02:30,  3.44it/s]\u001b[A\n","Iteration:  56% 655/1173 [03:15<02:30,  3.44it/s]\u001b[A\n","Iteration:  56% 656/1173 [03:15<02:30,  3.44it/s]\u001b[A\n","Iteration:  56% 657/1173 [03:15<02:30,  3.44it/s]\u001b[A\n","Iteration:  56% 658/1173 [03:16<02:29,  3.44it/s]\u001b[A\n","Iteration:  56% 659/1173 [03:16<02:29,  3.44it/s]\u001b[A\n","Iteration:  56% 660/1173 [03:16<02:30,  3.42it/s]\u001b[A\n","Iteration:  56% 661/1173 [03:16<02:29,  3.42it/s]\u001b[A\n","Iteration:  56% 662/1173 [03:17<02:28,  3.43it/s]\u001b[A\n","Iteration:  57% 663/1173 [03:17<02:28,  3.44it/s]\u001b[A\n","Iteration:  57% 664/1173 [03:17<02:27,  3.45it/s]\u001b[A\n","Iteration:  57% 665/1173 [03:18<02:27,  3.45it/s]\u001b[A\n","Iteration:  57% 666/1173 [03:18<02:27,  3.45it/s]\u001b[A\n","Iteration:  57% 667/1173 [03:18<02:26,  3.45it/s]\u001b[A\n","Iteration:  57% 668/1173 [03:19<02:26,  3.44it/s]\u001b[A\n","Iteration:  57% 669/1173 [03:19<02:26,  3.44it/s]\u001b[A\n","Iteration:  57% 670/1173 [03:19<02:26,  3.44it/s]\u001b[A\n","Iteration:  57% 671/1173 [03:19<02:25,  3.45it/s]\u001b[A\n","Iteration:  57% 672/1173 [03:20<02:25,  3.45it/s]\u001b[A\n","Iteration:  57% 673/1173 [03:20<02:24,  3.45it/s]\u001b[A\n","Iteration:  57% 674/1173 [03:20<02:24,  3.44it/s]\u001b[A\n","Iteration:  58% 675/1173 [03:21<02:24,  3.44it/s]\u001b[A\n","Iteration:  58% 676/1173 [03:21<02:24,  3.44it/s]\u001b[A\n","Iteration:  58% 677/1173 [03:21<02:24,  3.43it/s]\u001b[A\n","Iteration:  58% 678/1173 [03:21<02:24,  3.44it/s]\u001b[A\n","Iteration:  58% 679/1173 [03:22<02:23,  3.44it/s]\u001b[A\n","Iteration:  58% 680/1173 [03:22<02:22,  3.45it/s]\u001b[A\n","Iteration:  58% 681/1173 [03:22<02:22,  3.45it/s]\u001b[A\n","Iteration:  58% 682/1173 [03:23<02:22,  3.46it/s]\u001b[A\n","Iteration:  58% 683/1173 [03:23<02:21,  3.45it/s]\u001b[A\n","Iteration:  58% 684/1173 [03:23<02:21,  3.45it/s]\u001b[A\n","Iteration:  58% 685/1173 [03:23<02:21,  3.44it/s]\u001b[A\n","Iteration:  58% 686/1173 [03:24<02:21,  3.44it/s]\u001b[A\n","Iteration:  59% 687/1173 [03:24<02:21,  3.44it/s]\u001b[A\n","Iteration:  59% 688/1173 [03:24<02:20,  3.45it/s]\u001b[A\n","Iteration:  59% 689/1173 [03:25<02:20,  3.45it/s]\u001b[A\n","Iteration:  59% 690/1173 [03:25<02:20,  3.45it/s]\u001b[A\n","Iteration:  59% 691/1173 [03:25<02:19,  3.45it/s]\u001b[A\n","Iteration:  59% 692/1173 [03:25<02:19,  3.45it/s]\u001b[A\n","Iteration:  59% 693/1173 [03:26<02:19,  3.45it/s]\u001b[A\n","Iteration:  59% 694/1173 [03:26<02:19,  3.45it/s]\u001b[A\n","Iteration:  59% 695/1173 [03:26<02:18,  3.44it/s]\u001b[A\n","Iteration:  59% 696/1173 [03:27<02:18,  3.45it/s]\u001b[A\n","Iteration:  59% 697/1173 [03:27<02:17,  3.45it/s]\u001b[A\n","Iteration:  60% 698/1173 [03:27<02:17,  3.45it/s]\u001b[A\n","Iteration:  60% 699/1173 [03:27<02:17,  3.45it/s]\u001b[A\n","Iteration:  60% 700/1173 [03:28<02:17,  3.45it/s]\u001b[A\n","Iteration:  60% 701/1173 [03:28<02:16,  3.45it/s]\u001b[A\n","Iteration:  60% 702/1173 [03:28<02:16,  3.44it/s]\u001b[A\n","Iteration:  60% 703/1173 [03:29<02:16,  3.43it/s]\u001b[A\n","Iteration:  60% 704/1173 [03:29<02:16,  3.44it/s]\u001b[A\n","Iteration:  60% 705/1173 [03:29<02:16,  3.43it/s]\u001b[A\n","Iteration:  60% 706/1173 [03:30<02:16,  3.42it/s]\u001b[A\n","Iteration:  60% 707/1173 [03:30<02:16,  3.42it/s]\u001b[A\n","Iteration:  60% 708/1173 [03:30<02:16,  3.41it/s]\u001b[A\n","Iteration:  60% 709/1173 [03:30<02:15,  3.43it/s]\u001b[A\n","Iteration:  61% 710/1173 [03:31<02:15,  3.43it/s]\u001b[A\n","Iteration:  61% 711/1173 [03:31<02:15,  3.42it/s]\u001b[A\n","Iteration:  61% 712/1173 [03:31<02:14,  3.43it/s]\u001b[A\n","Iteration:  61% 713/1173 [03:32<02:14,  3.42it/s]\u001b[A\n","Iteration:  61% 714/1173 [03:32<02:14,  3.43it/s]\u001b[A\n","Iteration:  61% 715/1173 [03:32<02:13,  3.43it/s]\u001b[A\n","Iteration:  61% 716/1173 [03:32<02:12,  3.44it/s]\u001b[A\n","Iteration:  61% 717/1173 [03:33<02:12,  3.44it/s]\u001b[A\n","Iteration:  61% 718/1173 [03:33<02:12,  3.43it/s]\u001b[A\n","Iteration:  61% 719/1173 [03:33<02:12,  3.43it/s]\u001b[A\n","Iteration:  61% 720/1173 [03:34<02:11,  3.43it/s]\u001b[A\n","Iteration:  61% 721/1173 [03:34<02:11,  3.44it/s]\u001b[A\n","Iteration:  62% 722/1173 [03:34<02:11,  3.43it/s]\u001b[A\n","Iteration:  62% 723/1173 [03:34<02:11,  3.43it/s]\u001b[A\n","Iteration:  62% 724/1173 [03:35<02:10,  3.44it/s]\u001b[A\n","Iteration:  62% 725/1173 [03:35<02:10,  3.44it/s]\u001b[A\n","Iteration:  62% 726/1173 [03:35<02:09,  3.44it/s]\u001b[A\n","Iteration:  62% 727/1173 [03:36<02:09,  3.44it/s]\u001b[A\n","Iteration:  62% 728/1173 [03:36<02:09,  3.44it/s]\u001b[A\n","Iteration:  62% 729/1173 [03:36<02:09,  3.44it/s]\u001b[A\n","Iteration:  62% 730/1173 [03:37<02:08,  3.44it/s]\u001b[A\n","Iteration:  62% 731/1173 [03:37<02:08,  3.43it/s]\u001b[A\n","Iteration:  62% 732/1173 [03:37<02:08,  3.43it/s]\u001b[A\n","Iteration:  62% 733/1173 [03:37<02:08,  3.43it/s]\u001b[A\n","Iteration:  63% 734/1173 [03:38<02:07,  3.44it/s]\u001b[A\n","Iteration:  63% 735/1173 [03:38<02:07,  3.44it/s]\u001b[A\n","Iteration:  63% 736/1173 [03:38<02:06,  3.44it/s]\u001b[A\n","Iteration:  63% 737/1173 [03:39<02:06,  3.44it/s]\u001b[A\n","Iteration:  63% 738/1173 [03:39<02:06,  3.45it/s]\u001b[A\n","Iteration:  63% 739/1173 [03:39<02:06,  3.44it/s]\u001b[A\n","Iteration:  63% 740/1173 [03:39<02:06,  3.44it/s]\u001b[A\n","Iteration:  63% 741/1173 [03:40<02:05,  3.43it/s]\u001b[A\n","Iteration:  63% 742/1173 [03:40<02:05,  3.43it/s]\u001b[A\n","Iteration:  63% 743/1173 [03:40<02:05,  3.44it/s]\u001b[A\n","Iteration:  63% 744/1173 [03:41<02:04,  3.44it/s]\u001b[A\n","Iteration:  64% 745/1173 [03:41<02:04,  3.44it/s]\u001b[A\n","Iteration:  64% 746/1173 [03:41<02:03,  3.44it/s]\u001b[A\n","Iteration:  64% 747/1173 [03:41<02:03,  3.45it/s]\u001b[A\n","Iteration:  64% 748/1173 [03:42<02:03,  3.45it/s]\u001b[A\n","Iteration:  64% 749/1173 [03:42<02:03,  3.45it/s]\u001b[A\n","Iteration:  64% 750/1173 [03:42<02:02,  3.44it/s]\u001b[A\n","Iteration:  64% 751/1173 [03:43<02:02,  3.44it/s]\u001b[A\n","Iteration:  64% 752/1173 [03:43<02:02,  3.43it/s]\u001b[A\n","Iteration:  64% 753/1173 [03:43<02:02,  3.43it/s]\u001b[A\n","Iteration:  64% 754/1173 [03:44<02:02,  3.43it/s]\u001b[A\n","Iteration:  64% 755/1173 [03:44<02:01,  3.44it/s]\u001b[A\n","Iteration:  64% 756/1173 [03:44<02:00,  3.45it/s]\u001b[A\n","Iteration:  65% 757/1173 [03:44<02:00,  3.45it/s]\u001b[A\n","Iteration:  65% 758/1173 [03:45<02:00,  3.45it/s]\u001b[A\n","Iteration:  65% 759/1173 [03:45<02:00,  3.45it/s]\u001b[A\n","Iteration:  65% 760/1173 [03:45<02:00,  3.44it/s]\u001b[A\n","Iteration:  65% 761/1173 [03:46<01:59,  3.44it/s]\u001b[A\n","Iteration:  65% 762/1173 [03:46<01:59,  3.44it/s]\u001b[A\n","Iteration:  65% 763/1173 [03:46<01:59,  3.44it/s]\u001b[A\n","Iteration:  65% 764/1173 [03:46<01:58,  3.45it/s]\u001b[A\n","Iteration:  65% 765/1173 [03:47<01:58,  3.45it/s]\u001b[A\n","Iteration:  65% 766/1173 [03:47<01:57,  3.45it/s]\u001b[A\n","Iteration:  65% 767/1173 [03:47<01:57,  3.44it/s]\u001b[A\n","Iteration:  65% 768/1173 [03:48<01:57,  3.45it/s]\u001b[A\n","Iteration:  66% 769/1173 [03:48<01:57,  3.45it/s]\u001b[A\n","Iteration:  66% 770/1173 [03:48<01:56,  3.45it/s]\u001b[A\n","Iteration:  66% 771/1173 [03:48<01:56,  3.45it/s]\u001b[A\n","Iteration:  66% 772/1173 [03:49<01:55,  3.46it/s]\u001b[A\n","Iteration:  66% 773/1173 [03:49<01:55,  3.46it/s]\u001b[A\n","Iteration:  66% 774/1173 [03:49<01:55,  3.46it/s]\u001b[A\n","Iteration:  66% 775/1173 [03:50<01:55,  3.45it/s]\u001b[A\n","Iteration:  66% 776/1173 [03:50<01:55,  3.45it/s]\u001b[A\n","Iteration:  66% 777/1173 [03:50<01:54,  3.45it/s]\u001b[A\n","Iteration:  66% 778/1173 [03:50<01:54,  3.45it/s]\u001b[A\n","Iteration:  66% 779/1173 [03:51<01:54,  3.44it/s]\u001b[A\n","Iteration:  66% 780/1173 [03:51<01:53,  3.45it/s]\u001b[A\n","Iteration:  67% 781/1173 [03:51<01:53,  3.45it/s]\u001b[A\n","Iteration:  67% 782/1173 [03:52<01:53,  3.45it/s]\u001b[A\n","Iteration:  67% 783/1173 [03:52<01:52,  3.45it/s]\u001b[A\n","Iteration:  67% 784/1173 [03:52<01:52,  3.45it/s]\u001b[A\n","Iteration:  67% 785/1173 [03:52<01:52,  3.44it/s]\u001b[A\n","Iteration:  67% 786/1173 [03:53<01:52,  3.44it/s]\u001b[A\n","Iteration:  67% 787/1173 [03:53<01:52,  3.44it/s]\u001b[A\n","Iteration:  67% 788/1173 [03:53<01:52,  3.44it/s]\u001b[A\n","Iteration:  67% 789/1173 [03:54<01:51,  3.44it/s]\u001b[A\n","Iteration:  67% 790/1173 [03:54<01:51,  3.45it/s]\u001b[A\n","Iteration:  67% 791/1173 [03:54<01:51,  3.43it/s]\u001b[A\n","Iteration:  68% 792/1173 [03:55<01:50,  3.44it/s]\u001b[A\n","Iteration:  68% 793/1173 [03:55<01:50,  3.44it/s]\u001b[A\n","Iteration:  68% 794/1173 [03:55<01:50,  3.43it/s]\u001b[A\n","Iteration:  68% 795/1173 [03:55<01:50,  3.42it/s]\u001b[A\n","Iteration:  68% 796/1173 [03:56<01:49,  3.43it/s]\u001b[A\n","Iteration:  68% 797/1173 [03:56<01:49,  3.44it/s]\u001b[A\n","Iteration:  68% 798/1173 [03:56<01:49,  3.44it/s]\u001b[A\n","Iteration:  68% 799/1173 [03:57<01:48,  3.44it/s]\u001b[A\n","Iteration:  68% 800/1173 [03:57<01:48,  3.45it/s]\u001b[A\n","Iteration:  68% 801/1173 [03:57<01:47,  3.45it/s]\u001b[A\n","Iteration:  68% 802/1173 [03:57<01:47,  3.45it/s]\u001b[A\n","Iteration:  68% 803/1173 [03:58<01:47,  3.44it/s]\u001b[A\n","Iteration:  69% 804/1173 [03:58<01:47,  3.44it/s]\u001b[A\n","Iteration:  69% 805/1173 [03:58<01:46,  3.45it/s]\u001b[A\n","Iteration:  69% 806/1173 [03:59<01:46,  3.44it/s]\u001b[A\n","Iteration:  69% 807/1173 [03:59<01:46,  3.45it/s]\u001b[A\n","Iteration:  69% 808/1173 [03:59<01:45,  3.46it/s]\u001b[A\n","Iteration:  69% 809/1173 [03:59<01:45,  3.45it/s]\u001b[A\n","Iteration:  69% 810/1173 [04:00<01:44,  3.46it/s]\u001b[A\n","Iteration:  69% 811/1173 [04:00<01:44,  3.46it/s]\u001b[A\n","Iteration:  69% 812/1173 [04:00<01:44,  3.44it/s]\u001b[A\n","Iteration:  69% 813/1173 [04:01<01:44,  3.44it/s]\u001b[A\n","Iteration:  69% 814/1173 [04:01<01:44,  3.44it/s]\u001b[A\n","Iteration:  69% 815/1173 [04:01<01:43,  3.44it/s]\u001b[A\n","Iteration:  70% 816/1173 [04:02<01:43,  3.44it/s]\u001b[A\n","Iteration:  70% 817/1173 [04:02<01:43,  3.44it/s]\u001b[A\n","Iteration:  70% 818/1173 [04:02<01:43,  3.44it/s]\u001b[A\n","Iteration:  70% 819/1173 [04:02<01:42,  3.45it/s]\u001b[A\n","Iteration:  70% 820/1173 [04:03<01:42,  3.45it/s]\u001b[A\n","Iteration:  70% 821/1173 [04:03<01:42,  3.45it/s]\u001b[A\n","Iteration:  70% 822/1173 [04:03<01:41,  3.44it/s]\u001b[A\n","Iteration:  70% 823/1173 [04:04<01:41,  3.44it/s]\u001b[A\n","Iteration:  70% 824/1173 [04:04<01:41,  3.44it/s]\u001b[A\n","Iteration:  70% 825/1173 [04:04<01:40,  3.45it/s]\u001b[A\n","Iteration:  70% 826/1173 [04:04<01:40,  3.45it/s]\u001b[A\n","Iteration:  71% 827/1173 [04:05<01:39,  3.46it/s]\u001b[A\n","Iteration:  71% 828/1173 [04:05<01:39,  3.46it/s]\u001b[A\n","Iteration:  71% 829/1173 [04:05<01:39,  3.45it/s]\u001b[A\n","Iteration:  71% 830/1173 [04:06<01:39,  3.45it/s]\u001b[A\n","Iteration:  71% 831/1173 [04:06<01:39,  3.45it/s]\u001b[A\n","Iteration:  71% 832/1173 [04:06<01:38,  3.45it/s]\u001b[A\n","Iteration:  71% 833/1173 [04:06<01:38,  3.45it/s]\u001b[A\n","Iteration:  71% 834/1173 [04:07<01:38,  3.45it/s]\u001b[A\n","Iteration:  71% 835/1173 [04:07<01:37,  3.45it/s]\u001b[A\n","Iteration:  71% 836/1173 [04:07<01:37,  3.45it/s]\u001b[A\n","Iteration:  71% 837/1173 [04:08<01:37,  3.43it/s]\u001b[A\n","Iteration:  71% 838/1173 [04:08<01:37,  3.44it/s]\u001b[A\n","Iteration:  72% 839/1173 [04:08<01:37,  3.43it/s]\u001b[A\n","Iteration:  72% 840/1173 [04:08<01:36,  3.44it/s]\u001b[A\n","Iteration:  72% 841/1173 [04:09<01:36,  3.44it/s]\u001b[A\n","Iteration:  72% 842/1173 [04:09<01:36,  3.44it/s]\u001b[A\n","Iteration:  72% 843/1173 [04:09<01:36,  3.43it/s]\u001b[A\n","Iteration:  72% 844/1173 [04:10<01:35,  3.44it/s]\u001b[A\n","Iteration:  72% 845/1173 [04:10<01:35,  3.44it/s]\u001b[A\n","Iteration:  72% 846/1173 [04:10<01:34,  3.45it/s]\u001b[A\n","Iteration:  72% 847/1173 [04:11<01:34,  3.44it/s]\u001b[A\n","Iteration:  72% 848/1173 [04:11<01:34,  3.43it/s]\u001b[A\n","Iteration:  72% 849/1173 [04:11<01:34,  3.43it/s]\u001b[A\n","Iteration:  72% 850/1173 [04:11<01:33,  3.44it/s]\u001b[A\n","Iteration:  73% 851/1173 [04:12<01:33,  3.44it/s]\u001b[A\n","Iteration:  73% 852/1173 [04:12<01:33,  3.44it/s]\u001b[A\n","Iteration:  73% 853/1173 [04:12<01:33,  3.44it/s]\u001b[A\n","Iteration:  73% 854/1173 [04:13<01:32,  3.44it/s]\u001b[A\n","Iteration:  73% 855/1173 [04:13<01:32,  3.45it/s]\u001b[A\n","Iteration:  73% 856/1173 [04:13<01:31,  3.45it/s]\u001b[A\n","Iteration:  73% 857/1173 [04:13<01:31,  3.45it/s]\u001b[A\n","Iteration:  73% 858/1173 [04:14<01:31,  3.45it/s]\u001b[A\n","Iteration:  73% 859/1173 [04:14<01:31,  3.45it/s]\u001b[A\n","Iteration:  73% 860/1173 [04:14<01:30,  3.45it/s]\u001b[A\n","Iteration:  73% 861/1173 [04:15<01:30,  3.45it/s]\u001b[A\n","Iteration:  73% 862/1173 [04:15<01:30,  3.45it/s]\u001b[A\n","Iteration:  74% 863/1173 [04:15<01:29,  3.45it/s]\u001b[A\n","Iteration:  74% 864/1173 [04:15<01:29,  3.45it/s]\u001b[A\n","Iteration:  74% 865/1173 [04:16<01:29,  3.44it/s]\u001b[A\n","Iteration:  74% 866/1173 [04:16<01:29,  3.45it/s]\u001b[A\n","Iteration:  74% 867/1173 [04:16<01:28,  3.45it/s]\u001b[A\n","Iteration:  74% 868/1173 [04:17<01:28,  3.45it/s]\u001b[A\n","Iteration:  74% 869/1173 [04:17<01:28,  3.45it/s]\u001b[A\n","Iteration:  74% 870/1173 [04:17<01:27,  3.45it/s]\u001b[A\n","Iteration:  74% 871/1173 [04:17<01:27,  3.45it/s]\u001b[A\n","Iteration:  74% 872/1173 [04:18<01:27,  3.42it/s]\u001b[A\n","Iteration:  74% 873/1173 [04:18<01:27,  3.44it/s]\u001b[A\n","Iteration:  75% 874/1173 [04:18<01:26,  3.44it/s]\u001b[A\n","Iteration:  75% 875/1173 [04:19<01:26,  3.45it/s]\u001b[A\n","Iteration:  75% 876/1173 [04:19<01:26,  3.45it/s]\u001b[A\n","Iteration:  75% 877/1173 [04:19<01:25,  3.45it/s]\u001b[A\n","Iteration:  75% 878/1173 [04:19<01:25,  3.45it/s]\u001b[A\n","Iteration:  75% 879/1173 [04:20<01:25,  3.45it/s]\u001b[A\n","Iteration:  75% 880/1173 [04:20<01:24,  3.45it/s]\u001b[A\n","Iteration:  75% 881/1173 [04:20<01:24,  3.45it/s]\u001b[A\n","Iteration:  75% 882/1173 [04:21<01:24,  3.45it/s]\u001b[A\n","Iteration:  75% 883/1173 [04:21<01:24,  3.45it/s]\u001b[A\n","Iteration:  75% 884/1173 [04:21<01:24,  3.43it/s]\u001b[A\n","Iteration:  75% 885/1173 [04:22<01:24,  3.42it/s]\u001b[A\n","Iteration:  76% 886/1173 [04:22<01:23,  3.43it/s]\u001b[A\n","Iteration:  76% 887/1173 [04:22<01:23,  3.44it/s]\u001b[A\n","Iteration:  76% 888/1173 [04:22<01:22,  3.45it/s]\u001b[A\n","Iteration:  76% 889/1173 [04:23<01:22,  3.45it/s]\u001b[A\n","Iteration:  76% 890/1173 [04:23<01:21,  3.45it/s]\u001b[A\n","Iteration:  76% 891/1173 [04:23<01:21,  3.45it/s]\u001b[A\n","Iteration:  76% 892/1173 [04:24<01:21,  3.44it/s]\u001b[A\n","Iteration:  76% 893/1173 [04:24<01:21,  3.44it/s]\u001b[A\n","Iteration:  76% 894/1173 [04:24<01:21,  3.44it/s]\u001b[A\n","Iteration:  76% 895/1173 [04:24<01:20,  3.44it/s]\u001b[A\n","Iteration:  76% 896/1173 [04:25<01:20,  3.45it/s]\u001b[A\n","Iteration:  76% 897/1173 [04:25<01:20,  3.45it/s]\u001b[A\n","Iteration:  77% 898/1173 [04:25<01:19,  3.45it/s]\u001b[A\n","Iteration:  77% 899/1173 [04:26<01:19,  3.45it/s]\u001b[A\n","Iteration:  77% 900/1173 [04:26<01:19,  3.45it/s]\u001b[A\n","Iteration:  77% 901/1173 [04:26<01:18,  3.45it/s]\u001b[A\n","Iteration:  77% 902/1173 [04:26<01:18,  3.45it/s]\u001b[A\n","Iteration:  77% 903/1173 [04:27<01:18,  3.45it/s]\u001b[A\n","Iteration:  77% 904/1173 [04:27<01:17,  3.45it/s]\u001b[A\n","Iteration:  77% 905/1173 [04:27<01:17,  3.45it/s]\u001b[A\n","Iteration:  77% 906/1173 [04:28<01:17,  3.44it/s]\u001b[A\n","Iteration:  77% 907/1173 [04:28<01:17,  3.45it/s]\u001b[A\n","Iteration:  77% 908/1173 [04:28<01:16,  3.45it/s]\u001b[A\n","Iteration:  77% 909/1173 [04:28<01:16,  3.45it/s]\u001b[A\n","Iteration:  78% 910/1173 [04:29<01:16,  3.45it/s]\u001b[A\n","Iteration:  78% 911/1173 [04:29<01:15,  3.46it/s]\u001b[A\n","Iteration:  78% 912/1173 [04:29<01:15,  3.46it/s]\u001b[A\n","Iteration:  78% 913/1173 [04:30<01:15,  3.45it/s]\u001b[A\n","Iteration:  78% 914/1173 [04:30<01:15,  3.45it/s]\u001b[A\n","Iteration:  78% 915/1173 [04:30<01:15,  3.43it/s]\u001b[A\n","Iteration:  78% 916/1173 [04:31<01:14,  3.44it/s]\u001b[A\n","Iteration:  78% 917/1173 [04:31<01:14,  3.45it/s]\u001b[A\n","Iteration:  78% 918/1173 [04:31<01:13,  3.45it/s]\u001b[A\n","Iteration:  78% 919/1173 [04:31<01:13,  3.44it/s]\u001b[A\n","Iteration:  78% 920/1173 [04:32<01:13,  3.44it/s]\u001b[A\n","Iteration:  79% 921/1173 [04:32<01:13,  3.44it/s]\u001b[A\n","Iteration:  79% 922/1173 [04:32<01:12,  3.45it/s]\u001b[A\n","Iteration:  79% 923/1173 [04:33<01:12,  3.45it/s]\u001b[A\n","Iteration:  79% 924/1173 [04:33<01:12,  3.46it/s]\u001b[A\n","Iteration:  79% 925/1173 [04:33<01:11,  3.45it/s]\u001b[A\n","Iteration:  79% 926/1173 [04:33<01:11,  3.44it/s]\u001b[A\n","Iteration:  79% 927/1173 [04:34<01:11,  3.43it/s]\u001b[A\n","Iteration:  79% 928/1173 [04:34<01:11,  3.44it/s]\u001b[A\n","Iteration:  79% 929/1173 [04:34<01:10,  3.44it/s]\u001b[A\n","Iteration:  79% 930/1173 [04:35<01:10,  3.44it/s]\u001b[A\n","Iteration:  79% 931/1173 [04:35<01:10,  3.44it/s]\u001b[A\n","Iteration:  79% 932/1173 [04:35<01:09,  3.45it/s]\u001b[A\n","Iteration:  80% 933/1173 [04:35<01:09,  3.45it/s]\u001b[A\n","Iteration:  80% 934/1173 [04:36<01:09,  3.45it/s]\u001b[A\n","Iteration:  80% 935/1173 [04:36<01:09,  3.45it/s]\u001b[A\n","Iteration:  80% 936/1173 [04:36<01:08,  3.44it/s]\u001b[A\n","Iteration:  80% 937/1173 [04:37<01:08,  3.44it/s]\u001b[A\n","Iteration:  80% 938/1173 [04:37<01:08,  3.45it/s]\u001b[A\n","Iteration:  80% 939/1173 [04:37<01:08,  3.44it/s]\u001b[A\n","Iteration:  80% 940/1173 [04:37<01:07,  3.44it/s]\u001b[A\n","Iteration:  80% 941/1173 [04:38<01:07,  3.43it/s]\u001b[A\n","Iteration:  80% 942/1173 [04:38<01:07,  3.44it/s]\u001b[A\n","Iteration:  80% 943/1173 [04:38<01:06,  3.44it/s]\u001b[A\n","Iteration:  80% 944/1173 [04:39<01:06,  3.45it/s]\u001b[A\n","Iteration:  81% 945/1173 [04:39<01:06,  3.44it/s]\u001b[A\n","Iteration:  81% 946/1173 [04:39<01:06,  3.43it/s]\u001b[A\n","Iteration:  81% 947/1173 [04:40<01:06,  3.42it/s]\u001b[A\n","Iteration:  81% 948/1173 [04:40<01:06,  3.41it/s]\u001b[A\n","Iteration:  81% 949/1173 [04:40<01:05,  3.42it/s]\u001b[A\n","Iteration:  81% 950/1173 [04:40<01:04,  3.43it/s]\u001b[A\n","Iteration:  81% 951/1173 [04:41<01:04,  3.44it/s]\u001b[A\n","Iteration:  81% 952/1173 [04:41<01:04,  3.45it/s]\u001b[A\n","Iteration:  81% 953/1173 [04:41<01:03,  3.45it/s]\u001b[A\n","Iteration:  81% 954/1173 [04:42<01:03,  3.45it/s]\u001b[A\n","Iteration:  81% 955/1173 [04:42<01:03,  3.44it/s]\u001b[A\n","Iteration:  82% 956/1173 [04:42<01:02,  3.44it/s]\u001b[A\n","Iteration:  82% 957/1173 [04:42<01:02,  3.44it/s]\u001b[A\n","Iteration:  82% 958/1173 [04:43<01:02,  3.44it/s]\u001b[A\n","Iteration:  82% 959/1173 [04:43<01:02,  3.45it/s]\u001b[A\n","Iteration:  82% 960/1173 [04:43<01:01,  3.45it/s]\u001b[A\n","Iteration:  82% 961/1173 [04:44<01:01,  3.45it/s]\u001b[A\n","Iteration:  82% 962/1173 [04:44<01:01,  3.44it/s]\u001b[A\n","Iteration:  82% 963/1173 [04:44<01:00,  3.45it/s]\u001b[A\n","Iteration:  82% 964/1173 [04:44<01:00,  3.45it/s]\u001b[A\n","Iteration:  82% 965/1173 [04:45<01:00,  3.45it/s]\u001b[A\n","Iteration:  82% 966/1173 [04:45<01:00,  3.44it/s]\u001b[A\n","Iteration:  82% 967/1173 [04:45<00:59,  3.44it/s]\u001b[A\n","Iteration:  83% 968/1173 [04:46<00:59,  3.45it/s]\u001b[A\n","Iteration:  83% 969/1173 [04:46<00:59,  3.44it/s]\u001b[A\n","Iteration:  83% 970/1173 [04:46<00:58,  3.45it/s]\u001b[A\n","Iteration:  83% 971/1173 [04:47<00:58,  3.45it/s]\u001b[A\n","Iteration:  83% 972/1173 [04:47<00:58,  3.43it/s]\u001b[A\n","Iteration:  83% 973/1173 [04:47<00:58,  3.44it/s]\u001b[A\n","Iteration:  83% 974/1173 [04:47<00:57,  3.44it/s]\u001b[A\n","Iteration:  83% 975/1173 [04:48<00:57,  3.44it/s]\u001b[A\n","Iteration:  83% 976/1173 [04:48<00:57,  3.41it/s]\u001b[A\n","Iteration:  83% 977/1173 [04:48<00:57,  3.42it/s]\u001b[A\n","Iteration:  83% 978/1173 [04:49<00:56,  3.43it/s]\u001b[A\n","Iteration:  83% 979/1173 [04:49<00:56,  3.44it/s]\u001b[A\n","Iteration:  84% 980/1173 [04:49<00:56,  3.44it/s]\u001b[A\n","Iteration:  84% 981/1173 [04:49<00:55,  3.45it/s]\u001b[A\n","Iteration:  84% 982/1173 [04:50<00:55,  3.45it/s]\u001b[A\n","Iteration:  84% 983/1173 [04:50<00:55,  3.43it/s]\u001b[A\n","Iteration:  84% 984/1173 [04:50<00:55,  3.43it/s]\u001b[A\n","Iteration:  84% 985/1173 [04:51<00:54,  3.44it/s]\u001b[A\n","Iteration:  84% 986/1173 [04:51<00:54,  3.45it/s]\u001b[A\n","Iteration:  84% 987/1173 [04:51<00:53,  3.45it/s]\u001b[A\n","Iteration:  84% 988/1173 [04:51<00:53,  3.45it/s]\u001b[A\n","Iteration:  84% 989/1173 [04:52<00:53,  3.44it/s]\u001b[A\n","Iteration:  84% 990/1173 [04:52<00:53,  3.42it/s]\u001b[A\n","Iteration:  84% 991/1173 [04:52<00:53,  3.43it/s]\u001b[A\n","Iteration:  85% 992/1173 [04:53<00:52,  3.43it/s]\u001b[A\n","Iteration:  85% 993/1173 [04:53<00:52,  3.43it/s]\u001b[A\n","Iteration:  85% 994/1173 [04:53<00:52,  3.43it/s]\u001b[A\n","Iteration:  85% 995/1173 [04:53<00:51,  3.44it/s]\u001b[A\n","Iteration:  85% 996/1173 [04:54<00:51,  3.45it/s]\u001b[A\n","Iteration:  85% 997/1173 [04:54<00:51,  3.43it/s]\u001b[A\n","Iteration:  85% 998/1173 [04:54<00:50,  3.44it/s]\u001b[A\n","Iteration:  85% 999/1173 [04:55<00:50,  3.45it/s]\u001b[A05/20/2020 05:27:35 - INFO - transformers.configuration_utils -   Configuration saved in output/checkpoint-1000/config.json\n","05/20/2020 05:27:36 - INFO - transformers.modeling_utils -   Model weights saved in output/checkpoint-1000/pytorch_model.bin\n","05/20/2020 05:27:36 - INFO - __main__ -   Saving model checkpoint to output/checkpoint-1000\n","05/20/2020 05:27:39 - INFO - __main__ -   Saving optimizer and scheduler states to output/checkpoint-1000\n","\n","Iteration:  85% 1000/1173 [04:59<04:27,  1.55s/it]\u001b[A\n","Iteration:  85% 1001/1173 [04:59<03:22,  1.18s/it]\u001b[A\n","Iteration:  85% 1002/1173 [05:00<02:35,  1.10it/s]\u001b[A\n","Iteration:  86% 1003/1173 [05:00<02:03,  1.38it/s]\u001b[A\n","Iteration:  86% 1004/1173 [05:00<01:40,  1.68it/s]\u001b[A\n","Iteration:  86% 1005/1173 [05:01<01:24,  1.99it/s]\u001b[A\n","Iteration:  86% 1006/1173 [05:01<01:13,  2.28it/s]\u001b[A\n","Iteration:  86% 1007/1173 [05:01<01:05,  2.54it/s]\u001b[A\n","Iteration:  86% 1008/1173 [05:01<00:59,  2.76it/s]\u001b[A\n","Iteration:  86% 1009/1173 [05:02<00:55,  2.93it/s]\u001b[A\n","Iteration:  86% 1010/1173 [05:02<00:53,  3.07it/s]\u001b[A\n","Iteration:  86% 1011/1173 [05:02<00:51,  3.17it/s]\u001b[A\n","Iteration:  86% 1012/1173 [05:03<00:49,  3.25it/s]\u001b[A\n","Iteration:  86% 1013/1173 [05:03<00:48,  3.31it/s]\u001b[A\n","Iteration:  86% 1014/1173 [05:03<00:47,  3.35it/s]\u001b[A\n","Iteration:  87% 1015/1173 [05:04<00:47,  3.36it/s]\u001b[A\n","Iteration:  87% 1016/1173 [05:04<00:46,  3.39it/s]\u001b[A\n","Iteration:  87% 1017/1173 [05:04<00:45,  3.41it/s]\u001b[A\n","Iteration:  87% 1018/1173 [05:04<00:45,  3.42it/s]\u001b[A\n","Iteration:  87% 1019/1173 [05:05<00:44,  3.42it/s]\u001b[A\n","Iteration:  87% 1020/1173 [05:05<00:44,  3.43it/s]\u001b[A\n","Iteration:  87% 1021/1173 [05:05<00:44,  3.43it/s]\u001b[A\n","Iteration:  87% 1022/1173 [05:06<00:44,  3.41it/s]\u001b[A\n","Iteration:  87% 1023/1173 [05:06<00:43,  3.43it/s]\u001b[A\n","Iteration:  87% 1024/1173 [05:06<00:43,  3.44it/s]\u001b[A\n","Iteration:  87% 1025/1173 [05:06<00:42,  3.45it/s]\u001b[A\n","Iteration:  87% 1026/1173 [05:07<00:42,  3.45it/s]\u001b[A\n","Iteration:  88% 1027/1173 [05:07<00:42,  3.45it/s]\u001b[A\n","Iteration:  88% 1028/1173 [05:07<00:42,  3.45it/s]\u001b[A\n","Iteration:  88% 1029/1173 [05:08<00:41,  3.44it/s]\u001b[A\n","Iteration:  88% 1030/1173 [05:08<00:41,  3.45it/s]\u001b[A\n","Iteration:  88% 1031/1173 [05:08<00:41,  3.44it/s]\u001b[A\n","Iteration:  88% 1032/1173 [05:08<00:40,  3.45it/s]\u001b[A\n","Iteration:  88% 1033/1173 [05:09<00:40,  3.44it/s]\u001b[A\n","Iteration:  88% 1034/1173 [05:09<00:40,  3.43it/s]\u001b[A\n","Iteration:  88% 1035/1173 [05:09<00:40,  3.44it/s]\u001b[A\n","Iteration:  88% 1036/1173 [05:10<00:39,  3.44it/s]\u001b[A\n","Iteration:  88% 1037/1173 [05:10<00:39,  3.43it/s]\u001b[A\n","Iteration:  88% 1038/1173 [05:10<00:39,  3.43it/s]\u001b[A\n","Iteration:  89% 1039/1173 [05:10<00:39,  3.44it/s]\u001b[A\n","Iteration:  89% 1040/1173 [05:11<00:38,  3.44it/s]\u001b[A\n","Iteration:  89% 1041/1173 [05:11<00:38,  3.43it/s]\u001b[A\n","Iteration:  89% 1042/1173 [05:11<00:38,  3.44it/s]\u001b[A\n","Iteration:  89% 1043/1173 [05:12<00:37,  3.44it/s]\u001b[A\n","Iteration:  89% 1044/1173 [05:12<00:37,  3.45it/s]\u001b[A\n","Iteration:  89% 1045/1173 [05:12<00:37,  3.45it/s]\u001b[A\n","Iteration:  89% 1046/1173 [05:13<00:36,  3.45it/s]\u001b[A\n","Iteration:  89% 1047/1173 [05:13<00:36,  3.44it/s]\u001b[A\n","Iteration:  89% 1048/1173 [05:13<00:36,  3.44it/s]\u001b[A\n","Iteration:  89% 1049/1173 [05:13<00:35,  3.45it/s]\u001b[A\n","Iteration:  90% 1050/1173 [05:14<00:35,  3.45it/s]\u001b[A\n","Iteration:  90% 1051/1173 [05:14<00:35,  3.45it/s]\u001b[A\n","Iteration:  90% 1052/1173 [05:14<00:35,  3.45it/s]\u001b[A\n","Iteration:  90% 1053/1173 [05:15<00:34,  3.45it/s]\u001b[A\n","Iteration:  90% 1054/1173 [05:15<00:34,  3.45it/s]\u001b[A\n","Iteration:  90% 1055/1173 [05:15<00:34,  3.44it/s]\u001b[A\n","Iteration:  90% 1056/1173 [05:15<00:33,  3.44it/s]\u001b[A\n","Iteration:  90% 1057/1173 [05:16<00:33,  3.45it/s]\u001b[A\n","Iteration:  90% 1058/1173 [05:16<00:33,  3.45it/s]\u001b[A\n","Iteration:  90% 1059/1173 [05:16<00:33,  3.45it/s]\u001b[A\n","Iteration:  90% 1060/1173 [05:17<00:32,  3.45it/s]\u001b[A\n","Iteration:  90% 1061/1173 [05:17<00:32,  3.46it/s]\u001b[A\n","Iteration:  91% 1062/1173 [05:17<00:32,  3.46it/s]\u001b[A\n","Iteration:  91% 1063/1173 [05:17<00:31,  3.46it/s]\u001b[A\n","Iteration:  91% 1064/1173 [05:18<00:31,  3.46it/s]\u001b[A\n","Iteration:  91% 1065/1173 [05:18<00:31,  3.46it/s]\u001b[A\n","Iteration:  91% 1066/1173 [05:18<00:31,  3.45it/s]\u001b[A\n","Iteration:  91% 1067/1173 [05:19<00:30,  3.45it/s]\u001b[A\n","Iteration:  91% 1068/1173 [05:19<00:30,  3.46it/s]\u001b[A\n","Iteration:  91% 1069/1173 [05:19<00:30,  3.46it/s]\u001b[A\n","Iteration:  91% 1070/1173 [05:19<00:29,  3.46it/s]\u001b[A\n","Iteration:  91% 1071/1173 [05:20<00:29,  3.45it/s]\u001b[A\n","Iteration:  91% 1072/1173 [05:20<00:29,  3.45it/s]\u001b[A\n","Iteration:  91% 1073/1173 [05:20<00:29,  3.45it/s]\u001b[A\n","Iteration:  92% 1074/1173 [05:21<00:28,  3.44it/s]\u001b[A\n","Iteration:  92% 1075/1173 [05:21<00:28,  3.45it/s]\u001b[A\n","Iteration:  92% 1076/1173 [05:21<00:28,  3.45it/s]\u001b[A\n","Iteration:  92% 1077/1173 [05:21<00:27,  3.45it/s]\u001b[A\n","Iteration:  92% 1078/1173 [05:22<00:27,  3.45it/s]\u001b[A\n","Iteration:  92% 1079/1173 [05:22<00:27,  3.46it/s]\u001b[A\n","Iteration:  92% 1080/1173 [05:22<00:26,  3.45it/s]\u001b[A\n","Iteration:  92% 1081/1173 [05:23<00:26,  3.45it/s]\u001b[A\n","Iteration:  92% 1082/1173 [05:23<00:26,  3.45it/s]\u001b[A\n","Iteration:  92% 1083/1173 [05:23<00:26,  3.44it/s]\u001b[A\n","Iteration:  92% 1084/1173 [05:24<00:25,  3.45it/s]\u001b[A\n","Iteration:  92% 1085/1173 [05:24<00:25,  3.45it/s]\u001b[A\n","Iteration:  93% 1086/1173 [05:24<00:25,  3.45it/s]\u001b[A\n","Iteration:  93% 1087/1173 [05:24<00:24,  3.46it/s]\u001b[A\n","Iteration:  93% 1088/1173 [05:25<00:24,  3.45it/s]\u001b[A\n","Iteration:  93% 1089/1173 [05:25<00:24,  3.45it/s]\u001b[A\n","Iteration:  93% 1090/1173 [05:25<00:24,  3.45it/s]\u001b[A\n","Iteration:  93% 1091/1173 [05:26<00:23,  3.45it/s]\u001b[A\n","Iteration:  93% 1092/1173 [05:26<00:23,  3.46it/s]\u001b[A\n","Iteration:  93% 1093/1173 [05:26<00:23,  3.46it/s]\u001b[A\n","Iteration:  93% 1094/1173 [05:26<00:22,  3.46it/s]\u001b[A\n","Iteration:  93% 1095/1173 [05:27<00:22,  3.46it/s]\u001b[A\n","Iteration:  93% 1096/1173 [05:27<00:22,  3.46it/s]\u001b[A\n","Iteration:  94% 1097/1173 [05:27<00:21,  3.46it/s]\u001b[A\n","Iteration:  94% 1098/1173 [05:28<00:21,  3.46it/s]\u001b[A\n","Iteration:  94% 1099/1173 [05:28<00:21,  3.45it/s]\u001b[A\n","Iteration:  94% 1100/1173 [05:28<00:21,  3.45it/s]\u001b[A\n","Iteration:  94% 1101/1173 [05:28<00:20,  3.46it/s]\u001b[A\n","Iteration:  94% 1102/1173 [05:29<00:20,  3.46it/s]\u001b[A\n","Iteration:  94% 1103/1173 [05:29<00:20,  3.45it/s]\u001b[A\n","Iteration:  94% 1104/1173 [05:29<00:19,  3.46it/s]\u001b[A\n","Iteration:  94% 1105/1173 [05:30<00:19,  3.46it/s]\u001b[A\n","Iteration:  94% 1106/1173 [05:30<00:19,  3.45it/s]\u001b[A\n","Iteration:  94% 1107/1173 [05:30<00:19,  3.46it/s]\u001b[A\n","Iteration:  94% 1108/1173 [05:30<00:18,  3.46it/s]\u001b[A\n","Iteration:  95% 1109/1173 [05:31<00:18,  3.46it/s]\u001b[A\n","Iteration:  95% 1110/1173 [05:31<00:18,  3.46it/s]\u001b[A\n","Iteration:  95% 1111/1173 [05:31<00:17,  3.46it/s]\u001b[A\n","Iteration:  95% 1112/1173 [05:32<00:17,  3.44it/s]\u001b[A\n","Iteration:  95% 1113/1173 [05:32<00:17,  3.44it/s]\u001b[A\n","Iteration:  95% 1114/1173 [05:32<00:17,  3.45it/s]\u001b[A\n","Iteration:  95% 1115/1173 [05:33<00:16,  3.45it/s]\u001b[A\n","Iteration:  95% 1116/1173 [05:33<00:16,  3.45it/s]\u001b[A\n","Iteration:  95% 1117/1173 [05:33<00:16,  3.46it/s]\u001b[A\n","Iteration:  95% 1118/1173 [05:33<00:15,  3.46it/s]\u001b[A\n","Iteration:  95% 1119/1173 [05:34<00:15,  3.46it/s]\u001b[A\n","Iteration:  95% 1120/1173 [05:34<00:15,  3.45it/s]\u001b[A\n","Iteration:  96% 1121/1173 [05:34<00:15,  3.45it/s]\u001b[A\n","Iteration:  96% 1122/1173 [05:35<00:14,  3.44it/s]\u001b[A\n","Iteration:  96% 1123/1173 [05:35<00:14,  3.44it/s]\u001b[A\n","Iteration:  96% 1124/1173 [05:35<00:14,  3.44it/s]\u001b[A\n","Iteration:  96% 1125/1173 [05:35<00:13,  3.45it/s]\u001b[A\n","Iteration:  96% 1126/1173 [05:36<00:13,  3.45it/s]\u001b[A\n","Iteration:  96% 1127/1173 [05:36<00:13,  3.45it/s]\u001b[A\n","Iteration:  96% 1128/1173 [05:36<00:13,  3.46it/s]\u001b[A\n","Iteration:  96% 1129/1173 [05:37<00:12,  3.46it/s]\u001b[A\n","Iteration:  96% 1130/1173 [05:37<00:12,  3.45it/s]\u001b[A\n","Iteration:  96% 1131/1173 [05:37<00:12,  3.45it/s]\u001b[A\n","Iteration:  97% 1132/1173 [05:37<00:11,  3.45it/s]\u001b[A\n","Iteration:  97% 1133/1173 [05:38<00:11,  3.45it/s]\u001b[A\n","Iteration:  97% 1134/1173 [05:38<00:11,  3.45it/s]\u001b[A\n","Iteration:  97% 1135/1173 [05:38<00:11,  3.45it/s]\u001b[A\n","Iteration:  97% 1136/1173 [05:39<00:10,  3.46it/s]\u001b[A\n","Iteration:  97% 1137/1173 [05:39<00:10,  3.46it/s]\u001b[A\n","Iteration:  97% 1138/1173 [05:39<00:10,  3.46it/s]\u001b[A\n","Iteration:  97% 1139/1173 [05:39<00:09,  3.45it/s]\u001b[A\n","Iteration:  97% 1140/1173 [05:40<00:09,  3.45it/s]\u001b[A\n","Iteration:  97% 1141/1173 [05:40<00:09,  3.45it/s]\u001b[A\n","Iteration:  97% 1142/1173 [05:40<00:08,  3.45it/s]\u001b[A\n","Iteration:  97% 1143/1173 [05:41<00:08,  3.45it/s]\u001b[A\n","Iteration:  98% 1144/1173 [05:41<00:08,  3.46it/s]\u001b[A\n","Iteration:  98% 1145/1173 [05:41<00:08,  3.45it/s]\u001b[A\n","Iteration:  98% 1146/1173 [05:41<00:07,  3.46it/s]\u001b[A\n","Iteration:  98% 1147/1173 [05:42<00:07,  3.46it/s]\u001b[A\n","Iteration:  98% 1148/1173 [05:42<00:07,  3.45it/s]\u001b[A\n","Iteration:  98% 1149/1173 [05:42<00:06,  3.45it/s]\u001b[A\n","Iteration:  98% 1150/1173 [05:43<00:06,  3.46it/s]\u001b[A\n","Iteration:  98% 1151/1173 [05:43<00:06,  3.46it/s]\u001b[A\n","Iteration:  98% 1152/1173 [05:43<00:06,  3.46it/s]\u001b[A\n","Iteration:  98% 1153/1173 [05:44<00:05,  3.45it/s]\u001b[A\n","Iteration:  98% 1154/1173 [05:44<00:05,  3.46it/s]\u001b[A\n","Iteration:  98% 1155/1173 [05:44<00:05,  3.46it/s]\u001b[A\n","Iteration:  99% 1156/1173 [05:44<00:04,  3.46it/s]\u001b[A\n","Iteration:  99% 1157/1173 [05:45<00:04,  3.45it/s]\u001b[A\n","Iteration:  99% 1158/1173 [05:45<00:04,  3.45it/s]\u001b[A\n","Iteration:  99% 1159/1173 [05:45<00:04,  3.44it/s]\u001b[A\n","Iteration:  99% 1160/1173 [05:46<00:03,  3.44it/s]\u001b[A\n","Iteration:  99% 1161/1173 [05:46<00:03,  3.45it/s]\u001b[A\n","Iteration:  99% 1162/1173 [05:46<00:03,  3.45it/s]\u001b[A\n","Iteration:  99% 1163/1173 [05:46<00:02,  3.46it/s]\u001b[A\n","Iteration:  99% 1164/1173 [05:47<00:02,  3.46it/s]\u001b[A\n","Iteration:  99% 1165/1173 [05:47<00:02,  3.46it/s]\u001b[A\n","Iteration:  99% 1166/1173 [05:47<00:02,  3.46it/s]\u001b[A\n","Iteration:  99% 1167/1173 [05:48<00:01,  3.46it/s]\u001b[A\n","Iteration: 100% 1168/1173 [05:48<00:01,  3.46it/s]\u001b[A\n","Iteration: 100% 1169/1173 [05:48<00:01,  3.46it/s]\u001b[A\n","Iteration: 100% 1170/1173 [05:48<00:00,  3.46it/s]\u001b[A\n","Iteration: 100% 1171/1173 [05:49<00:00,  3.46it/s]\u001b[A\n","Iteration: 100% 1172/1173 [05:49<00:00,  3.46it/s]\u001b[A\n","Iteration: 100% 1173/1173 [05:49<00:00,  3.35it/s]\n","Epoch: 100% 1/1 [05:49<00:00, 349.74s/it]\n","05/20/2020 05:28:29 - INFO - __main__ -    global_step = 1173, average loss = 1.6659822640821451\n","05/20/2020 05:28:29 - INFO - __main__ -   Saving model checkpoint to output\n","05/20/2020 05:28:29 - INFO - transformers.configuration_utils -   Configuration saved in output/config.json\n","05/20/2020 05:28:30 - INFO - transformers.modeling_utils -   Model weights saved in output/pytorch_model.bin\n","05/20/2020 05:28:30 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","05/20/2020 05:28:30 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","05/20/2020 05:28:30 - INFO - transformers.modeling_utils -   loading weights file output/pytorch_model.bin\n","05/20/2020 05:28:34 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","05/20/2020 05:28:34 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","05/20/2020 05:28:34 - INFO - transformers.tokenization_utils -   Model name 'output' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'output' is a path, a model identifier, or url to a directory containing tokenizer files.\n","05/20/2020 05:28:34 - INFO - transformers.tokenization_utils -   Didn't find file output/added_tokens.json. We won't load it.\n","05/20/2020 05:28:34 - INFO - transformers.tokenization_utils -   loading file output/vocab.txt\n","05/20/2020 05:28:34 - INFO - transformers.tokenization_utils -   loading file None\n","05/20/2020 05:28:34 - INFO - transformers.tokenization_utils -   loading file output/special_tokens_map.json\n","05/20/2020 05:28:34 - INFO - transformers.tokenization_utils -   loading file output/tokenizer_config.json\n","05/20/2020 05:28:34 - INFO - __main__ -   Evaluate the following checkpoints: ['output']\n","05/20/2020 05:28:34 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","05/20/2020 05:28:34 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","05/20/2020 05:28:34 - INFO - transformers.modeling_utils -   loading weights file output/pytorch_model.bin\n","05/20/2020 05:28:37 - INFO - __main__ -   Creating features from dataset file at /content/wikitext-2\n","05/20/2020 05:28:41 - INFO - __main__ -   Saving features into cached file /content/wikitext-2/bert_cached_lm_510_wiki.test.tokens\n","05/20/2020 05:28:41 - INFO - __main__ -   ***** Running evaluation  *****\n","05/20/2020 05:28:41 - INFO - __main__ -     Num examples = 586\n","05/20/2020 05:28:41 - INFO - __main__ -     Batch size = 4\n","Evaluating: 100% 147/147 [00:13<00:00, 11.03it/s]\n","05/20/2020 05:28:54 - INFO - __main__ -   ***** Eval results  *****\n","05/20/2020 05:28:54 - INFO - __main__ -     perplexity = tensor(3.7466)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"c8yN_i71s-YN","colab_type":"text"},"source":["# DensRay"]},{"cell_type":"code","metadata":{"id":"cf_OLbsfzLdd","colab_type":"code","colab":{}},"source":["nlayer=12\n","nsamples = 5000\n","\n","def get_eigvecs_dict(layer=-1):\n","    eigvecs_dict = {}\n","    #-1:apply to all layers\n","    if layer==-1:\n","        for l in range(nlayer):\n","            eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_base_noavg_'+str(nsamples)+'_'+str(l)+'.pt', True)\n","    elif layer ==-2:\n","        for l in range(nlayer):\n","            eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_base_noavg_'+str(nsamples)+'_'+str(l)+'.pt', False)\n","    else:\n","        for l in range(nlayer):\n","            if l==layer:\n","                eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_base_noavg_'+str(nsamples)+'_'+str(l)+'.pt', True)\n","            else:\n","                eigvecs_dict[str(l)] = ('/content/drive/My Drive/eigvecs_base_noavg_'+str(nsamples)+'_'+str(l)+'.pt', False)\n","    return eigvecs_dict\n","\n","import pickle\n","for l in range(-2,nlayer):\n","    d = get_eigvecs_dict(l)\n","    df2=open('/content/eigvecs_dict_'+str(l)+'.txt','wb')\n","    pickle.dump(d,df2)\n","    df2.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pTvKqwhis5Zr","colab_type":"code","outputId":"88d26861-e27d-44c0-a8be-3bcb8ebabe91","executionInfo":{"status":"ok","timestamp":1589952967808,"user_tz":-120,"elapsed":34477,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python run_language_modeling_densray.py \\\n","    --output_dir=output \\\n","    --model_type=bert \\\n","    --model_name_or_path=bert-base-uncased \\\n","    --eigvecs_dict=/content/eigvecs_dict_-2.txt \\\n","    --train_data_file=/content/wikitext-2/wiki.train.tokens \\\n","    --do_eval \\\n","    --eval_data_file=/content/wikitext-2/wiki.test.tokens \\\n","    --mlm "],"execution_count":7,"outputs":[{"output_type":"stream","text":["2020-05-20 05:35:34.698948: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","05/20/2020 05:35:36 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","05/20/2020 05:35:37 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","05/20/2020 05:35:37 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","05/20/2020 05:35:38 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","05/20/2020 05:35:38 - INFO - densray_bert -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","05/20/2020 05:35:43 - INFO - densray_bert -   Weights of BertForMaskedLM_1 not initialized from pretrained model: ['cls.predictions.decoder.bias']\n","05/20/2020 05:35:43 - INFO - densray_bert -   Weights from pretrained model not used in BertForMaskedLM_1: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","05/20/2020 05:35:47 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=False, eigvecs_dict={'0': ('/content/drive/My Drive/eigvecs_base_noavg_5000_0.pt', False), '1': ('/content/drive/My Drive/eigvecs_base_noavg_5000_1.pt', False), '2': ('/content/drive/My Drive/eigvecs_base_noavg_5000_2.pt', False), '3': ('/content/drive/My Drive/eigvecs_base_noavg_5000_3.pt', False), '4': ('/content/drive/My Drive/eigvecs_base_noavg_5000_4.pt', False), '5': ('/content/drive/My Drive/eigvecs_base_noavg_5000_5.pt', False), '6': ('/content/drive/My Drive/eigvecs_base_noavg_5000_6.pt', False), '7': ('/content/drive/My Drive/eigvecs_base_noavg_5000_7.pt', False), '8': ('/content/drive/My Drive/eigvecs_base_noavg_5000_8.pt', False), '9': ('/content/drive/My Drive/eigvecs_base_noavg_5000_9.pt', False), '10': ('/content/drive/My Drive/eigvecs_base_noavg_5000_10.pt', False), '11': ('/content/drive/My Drive/eigvecs_base_noavg_5000_11.pt', False)}, eval_all_checkpoints=False, eval_data_file='/content/wikitext-2/wiki.test.tokens', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='/content/wikitext-2/wiki.train.tokens', warmup_steps=0, weight_decay=0.0)\n","05/20/2020 05:35:47 - INFO - __main__ -   Evaluate the following checkpoints: ['output']\n","05/20/2020 05:35:47 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","05/20/2020 05:35:47 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","05/20/2020 05:35:47 - INFO - densray_bert -   loading weights file output/pytorch_model.bin\n","05/20/2020 05:35:51 - INFO - __main__ -   ***** Running evaluation  *****\n","05/20/2020 05:35:51 - INFO - __main__ -     Num examples = 586\n","05/20/2020 05:35:51 - INFO - __main__ -     Batch size = 4\n","Evaluating: 100% 147/147 [00:13<00:00, 11.02it/s]\n","05/20/2020 05:36:05 - INFO - __main__ -   ***** Eval results  *****\n","05/20/2020 05:36:05 - INFO - __main__ -     perplexity = tensor(3.7714)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oAMHVlc6s5gm","colab_type":"code","outputId":"c8db343b-1a21-4238-e6e3-20969a098054","executionInfo":{"status":"ok","timestamp":1589953017870,"user_tz":-120,"elapsed":50056,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python run_language_modeling_densray.py \\\n","    --output_dir=output \\\n","    --model_type=bert \\\n","    --model_name_or_path=bert-base-uncased \\\n","    --eigvecs_dict=/content/eigvecs_dict_-1.txt \\\n","    --train_data_file=/content/wikitext-2/wiki.train.tokens \\\n","    --do_eval \\\n","    --eval_data_file=/content/wikitext-2/wiki.test.tokens \\\n","    --mlm "],"execution_count":8,"outputs":[{"output_type":"stream","text":["2020-05-20 05:36:09.594664: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","05/20/2020 05:36:11 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","05/20/2020 05:36:11 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","05/20/2020 05:36:11 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","05/20/2020 05:36:12 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","05/20/2020 05:36:13 - INFO - densray_bert -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","05/20/2020 05:36:35 - INFO - densray_bert -   Weights of BertForMaskedLM_1 not initialized from pretrained model: ['cls.predictions.decoder.bias']\n","05/20/2020 05:36:35 - INFO - densray_bert -   Weights from pretrained model not used in BertForMaskedLM_1: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","05/20/2020 05:36:35 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=False, eigvecs_dict={'0': ('/content/drive/My Drive/eigvecs_base_noavg_5000_0.pt', True), '1': ('/content/drive/My Drive/eigvecs_base_noavg_5000_1.pt', True), '2': ('/content/drive/My Drive/eigvecs_base_noavg_5000_2.pt', True), '3': ('/content/drive/My Drive/eigvecs_base_noavg_5000_3.pt', True), '4': ('/content/drive/My Drive/eigvecs_base_noavg_5000_4.pt', True), '5': ('/content/drive/My Drive/eigvecs_base_noavg_5000_5.pt', True), '6': ('/content/drive/My Drive/eigvecs_base_noavg_5000_6.pt', True), '7': ('/content/drive/My Drive/eigvecs_base_noavg_5000_7.pt', True), '8': ('/content/drive/My Drive/eigvecs_base_noavg_5000_8.pt', True), '9': ('/content/drive/My Drive/eigvecs_base_noavg_5000_9.pt', True), '10': ('/content/drive/My Drive/eigvecs_base_noavg_5000_10.pt', True), '11': ('/content/drive/My Drive/eigvecs_base_noavg_5000_11.pt', True)}, eval_all_checkpoints=False, eval_data_file='/content/wikitext-2/wiki.test.tokens', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='/content/wikitext-2/wiki.train.tokens', warmup_steps=0, weight_decay=0.0)\n","05/20/2020 05:36:35 - INFO - __main__ -   Evaluate the following checkpoints: ['output']\n","05/20/2020 05:36:35 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","05/20/2020 05:36:35 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","05/20/2020 05:36:35 - INFO - densray_bert -   loading weights file output/pytorch_model.bin\n","05/20/2020 05:36:40 - INFO - __main__ -   ***** Running evaluation  *****\n","05/20/2020 05:36:40 - INFO - __main__ -     Num examples = 586\n","05/20/2020 05:36:40 - INFO - __main__ -     Batch size = 4\n","Evaluating: 100% 147/147 [00:14<00:00,  9.95it/s]\n","05/20/2020 05:36:54 - INFO - __main__ -   ***** Eval results  *****\n","05/20/2020 05:36:54 - INFO - __main__ -     perplexity = tensor(3.8058)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Pq201K72R4OG","colab_type":"code","outputId":"4d02afd4-2620-4328-afe1-20e61969232d","executionInfo":{"status":"ok","timestamp":1588243620553,"user_tz":-120,"elapsed":33896,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python run_language_modeling_densray.py \\\n","    --output_dir=output \\\n","    --model_type=bert \\\n","    --model_name_or_path=bert-base-uncased \\\n","    --eigvecs_dict=/content/eigvecs_dict_0.txt \\\n","    --train_data_file=/content/wikitext-2/wiki.train.tokens \\\n","    --do_eval \\\n","    --eval_data_file=/content/wikitext-2/wiki.test.tokens \\\n","    --mlm "],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-04-30 10:46:29.197270: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","04/30/2020 10:46:30 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","04/30/2020 10:46:31 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","04/30/2020 10:46:31 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:46:32 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","04/30/2020 10:46:33 - INFO - densray_bert -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","04/30/2020 10:46:40 - INFO - densray_bert -   Weights of BertForMaskedLM_1 not initialized from pretrained model: ['cls.predictions.decoder.bias']\n","04/30/2020 10:46:40 - INFO - densray_bert -   Weights from pretrained model not used in BertForMaskedLM_1: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","04/30/2020 10:46:41 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=False, eigvecs_dict={'0': ('/content/drive/My Drive/eigvecs_base_noavg_2000_0.pt', True), '1': ('/content/drive/My Drive/eigvecs_base_noavg_2000_1.pt', False), '2': ('/content/drive/My Drive/eigvecs_base_noavg_2000_2.pt', False), '3': ('/content/drive/My Drive/eigvecs_base_noavg_2000_3.pt', False), '4': ('/content/drive/My Drive/eigvecs_base_noavg_2000_4.pt', False), '5': ('/content/drive/My Drive/eigvecs_base_noavg_2000_5.pt', False), '6': ('/content/drive/My Drive/eigvecs_base_noavg_2000_6.pt', False), '7': ('/content/drive/My Drive/eigvecs_base_noavg_2000_7.pt', False), '8': ('/content/drive/My Drive/eigvecs_base_noavg_2000_8.pt', False), '9': ('/content/drive/My Drive/eigvecs_base_noavg_2000_9.pt', False), '10': ('/content/drive/My Drive/eigvecs_base_noavg_2000_10.pt', False), '11': ('/content/drive/My Drive/eigvecs_base_noavg_2000_11.pt', False)}, eval_all_checkpoints=False, eval_data_file='/content/wikitext-2/wiki.test.tokens', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='/content/wikitext-2/wiki.train.tokens', warmup_steps=0, weight_decay=0.0)\n","04/30/2020 10:46:41 - INFO - __main__ -   Evaluate the following checkpoints: ['output']\n","04/30/2020 10:46:41 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","04/30/2020 10:46:41 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:46:41 - INFO - densray_bert -   loading weights file output/pytorch_model.bin\n","04/30/2020 10:46:45 - INFO - __main__ -   ***** Running evaluation  *****\n","04/30/2020 10:46:45 - INFO - __main__ -     Num examples = 586\n","04/30/2020 10:46:45 - INFO - __main__ -     Batch size = 4\n","Evaluating: 100% 147/147 [00:13<00:00, 10.94it/s]\n","04/30/2020 10:46:58 - INFO - __main__ -   ***** Eval results  *****\n","04/30/2020 10:46:58 - INFO - __main__ -     perplexity = tensor(3.7866)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KcMSyQxBmHhP","colab_type":"code","outputId":"e2ed4ddd-22da-4736-8644-b56de698ad2a","executionInfo":{"status":"ok","timestamp":1588243655075,"user_tz":-120,"elapsed":34519,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python run_language_modeling_densray.py \\\n","    --output_dir=output \\\n","    --model_type=bert \\\n","    --model_name_or_path=bert-base-uncased \\\n","    --eigvecs_dict=/content/eigvecs_dict_1.txt \\\n","    --train_data_file=/content/wikitext-2/wiki.train.tokens \\\n","    --do_eval \\\n","    --eval_data_file=/content/wikitext-2/wiki.test.tokens \\\n","    --mlm \\\n","    --overwrite_output_dir"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-04-30 10:47:03.403224: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","04/30/2020 10:47:04 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","04/30/2020 10:47:05 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","04/30/2020 10:47:05 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:47:06 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","04/30/2020 10:47:07 - INFO - densray_bert -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","04/30/2020 10:47:15 - INFO - densray_bert -   Weights of BertForMaskedLM_1 not initialized from pretrained model: ['cls.predictions.decoder.bias']\n","04/30/2020 10:47:15 - INFO - densray_bert -   Weights from pretrained model not used in BertForMaskedLM_1: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","04/30/2020 10:47:15 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=False, eigvecs_dict={'0': ('/content/drive/My Drive/eigvecs_base_noavg_2000_0.pt', False), '1': ('/content/drive/My Drive/eigvecs_base_noavg_2000_1.pt', True), '2': ('/content/drive/My Drive/eigvecs_base_noavg_2000_2.pt', False), '3': ('/content/drive/My Drive/eigvecs_base_noavg_2000_3.pt', False), '4': ('/content/drive/My Drive/eigvecs_base_noavg_2000_4.pt', False), '5': ('/content/drive/My Drive/eigvecs_base_noavg_2000_5.pt', False), '6': ('/content/drive/My Drive/eigvecs_base_noavg_2000_6.pt', False), '7': ('/content/drive/My Drive/eigvecs_base_noavg_2000_7.pt', False), '8': ('/content/drive/My Drive/eigvecs_base_noavg_2000_8.pt', False), '9': ('/content/drive/My Drive/eigvecs_base_noavg_2000_9.pt', False), '10': ('/content/drive/My Drive/eigvecs_base_noavg_2000_10.pt', False), '11': ('/content/drive/My Drive/eigvecs_base_noavg_2000_11.pt', False)}, eval_all_checkpoints=False, eval_data_file='/content/wikitext-2/wiki.test.tokens', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='/content/wikitext-2/wiki.train.tokens', warmup_steps=0, weight_decay=0.0)\n","04/30/2020 10:47:15 - INFO - __main__ -   Evaluate the following checkpoints: ['output']\n","04/30/2020 10:47:15 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","04/30/2020 10:47:15 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:47:15 - INFO - densray_bert -   loading weights file output/pytorch_model.bin\n","04/30/2020 10:47:19 - INFO - __main__ -   ***** Running evaluation  *****\n","04/30/2020 10:47:19 - INFO - __main__ -     Num examples = 586\n","04/30/2020 10:47:19 - INFO - __main__ -     Batch size = 4\n","Evaluating: 100% 147/147 [00:13<00:00, 10.92it/s]\n","04/30/2020 10:47:33 - INFO - __main__ -   ***** Eval results  *****\n","04/30/2020 10:47:33 - INFO - __main__ -     perplexity = tensor(3.7913)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_CVwEoQPsl0H","colab_type":"code","outputId":"362043bf-ea60-41ac-d7ef-cd1267ca536c","executionInfo":{"status":"ok","timestamp":1588243690726,"user_tz":-120,"elapsed":35649,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python run_language_modeling_densray.py \\\n","    --output_dir=output \\\n","    --model_type=bert \\\n","    --model_name_or_path=bert-base-uncased \\\n","    --eigvecs_dict=/content/eigvecs_dict_2.txt \\\n","    --train_data_file=/content/wikitext-2/wiki.train.tokens \\\n","    --do_eval \\\n","    --eval_data_file=/content/wikitext-2/wiki.test.tokens \\\n","    --mlm \\\n","    --overwrite_output_dir"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-04-30 10:47:37.855878: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","04/30/2020 10:47:39 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","04/30/2020 10:47:40 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","04/30/2020 10:47:40 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:47:40 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","04/30/2020 10:47:41 - INFO - densray_bert -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","04/30/2020 10:47:49 - INFO - densray_bert -   Weights of BertForMaskedLM_1 not initialized from pretrained model: ['cls.predictions.decoder.bias']\n","04/30/2020 10:47:49 - INFO - densray_bert -   Weights from pretrained model not used in BertForMaskedLM_1: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","04/30/2020 10:47:49 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=False, eigvecs_dict={'0': ('/content/drive/My Drive/eigvecs_base_noavg_2000_0.pt', False), '1': ('/content/drive/My Drive/eigvecs_base_noavg_2000_1.pt', False), '2': ('/content/drive/My Drive/eigvecs_base_noavg_2000_2.pt', True), '3': ('/content/drive/My Drive/eigvecs_base_noavg_2000_3.pt', False), '4': ('/content/drive/My Drive/eigvecs_base_noavg_2000_4.pt', False), '5': ('/content/drive/My Drive/eigvecs_base_noavg_2000_5.pt', False), '6': ('/content/drive/My Drive/eigvecs_base_noavg_2000_6.pt', False), '7': ('/content/drive/My Drive/eigvecs_base_noavg_2000_7.pt', False), '8': ('/content/drive/My Drive/eigvecs_base_noavg_2000_8.pt', False), '9': ('/content/drive/My Drive/eigvecs_base_noavg_2000_9.pt', False), '10': ('/content/drive/My Drive/eigvecs_base_noavg_2000_10.pt', False), '11': ('/content/drive/My Drive/eigvecs_base_noavg_2000_11.pt', False)}, eval_all_checkpoints=False, eval_data_file='/content/wikitext-2/wiki.test.tokens', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='/content/wikitext-2/wiki.train.tokens', warmup_steps=0, weight_decay=0.0)\n","04/30/2020 10:47:49 - INFO - __main__ -   Evaluate the following checkpoints: ['output']\n","04/30/2020 10:47:49 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","04/30/2020 10:47:49 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:47:49 - INFO - densray_bert -   loading weights file output/pytorch_model.bin\n","04/30/2020 10:47:54 - INFO - __main__ -   ***** Running evaluation  *****\n","04/30/2020 10:47:54 - INFO - __main__ -     Num examples = 586\n","04/30/2020 10:47:54 - INFO - __main__ -     Batch size = 4\n","Evaluating: 100% 147/147 [00:13<00:00, 10.94it/s]\n","04/30/2020 10:48:07 - INFO - __main__ -   ***** Eval results  *****\n","04/30/2020 10:48:07 - INFO - __main__ -     perplexity = tensor(3.7849)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9E9szgF8snIS","colab_type":"code","outputId":"028a6256-1f90-4fbc-eec1-957c4d8923df","executionInfo":{"status":"ok","timestamp":1588243726467,"user_tz":-120,"elapsed":34845,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python run_language_modeling_densray.py \\\n","    --output_dir=output \\\n","    --model_type=bert \\\n","    --model_name_or_path=bert-base-uncased \\\n","    --eigvecs_dict=/content/eigvecs_dict_3.txt \\\n","    --train_data_file=/content/wikitext-2/wiki.train.tokens \\\n","    --do_eval \\\n","    --eval_data_file=/content/wikitext-2/wiki.test.tokens \\\n","    --mlm \\\n","    --overwrite_output_dir"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-04-30 10:48:14.590278: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","04/30/2020 10:48:16 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","04/30/2020 10:48:16 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","04/30/2020 10:48:16 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:48:17 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","04/30/2020 10:48:18 - INFO - densray_bert -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","04/30/2020 10:48:26 - INFO - densray_bert -   Weights of BertForMaskedLM_1 not initialized from pretrained model: ['cls.predictions.decoder.bias']\n","04/30/2020 10:48:26 - INFO - densray_bert -   Weights from pretrained model not used in BertForMaskedLM_1: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","04/30/2020 10:48:26 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=False, eigvecs_dict={'0': ('/content/drive/My Drive/eigvecs_base_noavg_2000_0.pt', False), '1': ('/content/drive/My Drive/eigvecs_base_noavg_2000_1.pt', False), '2': ('/content/drive/My Drive/eigvecs_base_noavg_2000_2.pt', False), '3': ('/content/drive/My Drive/eigvecs_base_noavg_2000_3.pt', True), '4': ('/content/drive/My Drive/eigvecs_base_noavg_2000_4.pt', False), '5': ('/content/drive/My Drive/eigvecs_base_noavg_2000_5.pt', False), '6': ('/content/drive/My Drive/eigvecs_base_noavg_2000_6.pt', False), '7': ('/content/drive/My Drive/eigvecs_base_noavg_2000_7.pt', False), '8': ('/content/drive/My Drive/eigvecs_base_noavg_2000_8.pt', False), '9': ('/content/drive/My Drive/eigvecs_base_noavg_2000_9.pt', False), '10': ('/content/drive/My Drive/eigvecs_base_noavg_2000_10.pt', False), '11': ('/content/drive/My Drive/eigvecs_base_noavg_2000_11.pt', False)}, eval_all_checkpoints=False, eval_data_file='/content/wikitext-2/wiki.test.tokens', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='/content/wikitext-2/wiki.train.tokens', warmup_steps=0, weight_decay=0.0)\n","04/30/2020 10:48:26 - INFO - __main__ -   Evaluate the following checkpoints: ['output']\n","04/30/2020 10:48:26 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","04/30/2020 10:48:26 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:48:26 - INFO - densray_bert -   loading weights file output/pytorch_model.bin\n","04/30/2020 10:48:30 - INFO - __main__ -   ***** Running evaluation  *****\n","04/30/2020 10:48:30 - INFO - __main__ -     Num examples = 586\n","04/30/2020 10:48:30 - INFO - __main__ -     Batch size = 4\n","Evaluating: 100% 147/147 [00:13<00:00, 10.96it/s]\n","04/30/2020 10:48:44 - INFO - __main__ -   ***** Eval results  *****\n","04/30/2020 10:48:44 - INFO - __main__ -     perplexity = tensor(3.8068)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Uu-OI30tsoPe","colab_type":"code","outputId":"a2b84301-c8ee-41b2-b412-628a460ded85","executionInfo":{"status":"ok","timestamp":1588243759251,"user_tz":-120,"elapsed":67624,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python run_language_modeling_densray.py \\\n","    --output_dir=output \\\n","    --model_type=bert \\\n","    --model_name_or_path=bert-base-uncased \\\n","    --eigvecs_dict=/content/eigvecs_dict_4.txt \\\n","    --train_data_file=/content/wikitext-2/wiki.train.tokens \\\n","    --do_eval \\\n","    --eval_data_file=/content/wikitext-2/wiki.test.tokens \\\n","    --mlm \\\n","    --overwrite_output_dir"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-04-30 10:48:47.537841: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","04/30/2020 10:48:49 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","04/30/2020 10:48:49 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","04/30/2020 10:48:49 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:48:50 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","04/30/2020 10:48:51 - INFO - densray_bert -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","04/30/2020 10:48:59 - INFO - densray_bert -   Weights of BertForMaskedLM_1 not initialized from pretrained model: ['cls.predictions.decoder.bias']\n","04/30/2020 10:48:59 - INFO - densray_bert -   Weights from pretrained model not used in BertForMaskedLM_1: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","04/30/2020 10:48:59 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=False, eigvecs_dict={'0': ('/content/drive/My Drive/eigvecs_base_noavg_2000_0.pt', False), '1': ('/content/drive/My Drive/eigvecs_base_noavg_2000_1.pt', False), '2': ('/content/drive/My Drive/eigvecs_base_noavg_2000_2.pt', False), '3': ('/content/drive/My Drive/eigvecs_base_noavg_2000_3.pt', False), '4': ('/content/drive/My Drive/eigvecs_base_noavg_2000_4.pt', True), '5': ('/content/drive/My Drive/eigvecs_base_noavg_2000_5.pt', False), '6': ('/content/drive/My Drive/eigvecs_base_noavg_2000_6.pt', False), '7': ('/content/drive/My Drive/eigvecs_base_noavg_2000_7.pt', False), '8': ('/content/drive/My Drive/eigvecs_base_noavg_2000_8.pt', False), '9': ('/content/drive/My Drive/eigvecs_base_noavg_2000_9.pt', False), '10': ('/content/drive/My Drive/eigvecs_base_noavg_2000_10.pt', False), '11': ('/content/drive/My Drive/eigvecs_base_noavg_2000_11.pt', False)}, eval_all_checkpoints=False, eval_data_file='/content/wikitext-2/wiki.test.tokens', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='/content/wikitext-2/wiki.train.tokens', warmup_steps=0, weight_decay=0.0)\n","04/30/2020 10:48:59 - INFO - __main__ -   Evaluate the following checkpoints: ['output']\n","04/30/2020 10:48:59 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","04/30/2020 10:48:59 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:48:59 - INFO - densray_bert -   loading weights file output/pytorch_model.bin\n","04/30/2020 10:49:03 - INFO - __main__ -   ***** Running evaluation  *****\n","04/30/2020 10:49:03 - INFO - __main__ -     Num examples = 586\n","04/30/2020 10:49:03 - INFO - __main__ -     Batch size = 4\n","Evaluating: 100% 147/147 [00:13<00:00, 10.94it/s]\n","04/30/2020 10:49:17 - INFO - __main__ -   ***** Eval results  *****\n","04/30/2020 10:49:17 - INFO - __main__ -     perplexity = tensor(3.8226)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jkD4ZHnqsp4c","colab_type":"code","outputId":"9e44a51a-ab23-4cd5-c466-070c538e3cf4","executionInfo":{"status":"ok","timestamp":1588243791984,"user_tz":-120,"elapsed":100353,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python run_language_modeling_densray.py \\\n","    --output_dir=output \\\n","    --model_type=bert \\\n","    --model_name_or_path=bert-base-uncased \\\n","    --eigvecs_dict=/content/eigvecs_dict_5.txt \\\n","    --train_data_file=/content/wikitext-2/wiki.train.tokens \\\n","    --do_eval \\\n","    --eval_data_file=/content/wikitext-2/wiki.test.tokens \\\n","    --mlm \\\n","    --overwrite_output_dir"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-04-30 10:49:20.750483: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","04/30/2020 10:49:22 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","04/30/2020 10:49:22 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","04/30/2020 10:49:22 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:49:23 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","04/30/2020 10:49:24 - INFO - densray_bert -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","04/30/2020 10:49:32 - INFO - densray_bert -   Weights of BertForMaskedLM_1 not initialized from pretrained model: ['cls.predictions.decoder.bias']\n","04/30/2020 10:49:32 - INFO - densray_bert -   Weights from pretrained model not used in BertForMaskedLM_1: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","04/30/2020 10:49:32 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=False, eigvecs_dict={'0': ('/content/drive/My Drive/eigvecs_base_noavg_2000_0.pt', False), '1': ('/content/drive/My Drive/eigvecs_base_noavg_2000_1.pt', False), '2': ('/content/drive/My Drive/eigvecs_base_noavg_2000_2.pt', False), '3': ('/content/drive/My Drive/eigvecs_base_noavg_2000_3.pt', False), '4': ('/content/drive/My Drive/eigvecs_base_noavg_2000_4.pt', False), '5': ('/content/drive/My Drive/eigvecs_base_noavg_2000_5.pt', True), '6': ('/content/drive/My Drive/eigvecs_base_noavg_2000_6.pt', False), '7': ('/content/drive/My Drive/eigvecs_base_noavg_2000_7.pt', False), '8': ('/content/drive/My Drive/eigvecs_base_noavg_2000_8.pt', False), '9': ('/content/drive/My Drive/eigvecs_base_noavg_2000_9.pt', False), '10': ('/content/drive/My Drive/eigvecs_base_noavg_2000_10.pt', False), '11': ('/content/drive/My Drive/eigvecs_base_noavg_2000_11.pt', False)}, eval_all_checkpoints=False, eval_data_file='/content/wikitext-2/wiki.test.tokens', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='/content/wikitext-2/wiki.train.tokens', warmup_steps=0, weight_decay=0.0)\n","04/30/2020 10:49:32 - INFO - __main__ -   Evaluate the following checkpoints: ['output']\n","04/30/2020 10:49:32 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","04/30/2020 10:49:32 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:49:32 - INFO - densray_bert -   loading weights file output/pytorch_model.bin\n","04/30/2020 10:49:36 - INFO - __main__ -   ***** Running evaluation  *****\n","04/30/2020 10:49:36 - INFO - __main__ -     Num examples = 586\n","04/30/2020 10:49:36 - INFO - __main__ -     Batch size = 4\n","Evaluating: 100% 147/147 [00:13<00:00, 10.94it/s]\n","04/30/2020 10:49:50 - INFO - __main__ -   ***** Eval results  *****\n","04/30/2020 10:49:50 - INFO - __main__ -     perplexity = tensor(3.8504)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IUx5lU-ksrWy","colab_type":"code","outputId":"de3c7e32-dedc-4797-9f37-d93d7b71507a","executionInfo":{"status":"ok","timestamp":1588243826355,"user_tz":-120,"elapsed":34356,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python run_language_modeling_densray.py \\\n","    --output_dir=output \\\n","    --model_type=bert \\\n","    --model_name_or_path=bert-base-uncased \\\n","    --eigvecs_dict=/content/eigvecs_dict_6.txt \\\n","    --train_data_file=/content/wikitext-2/wiki.train.tokens \\\n","    --do_eval \\\n","    --eval_data_file=/content/wikitext-2/wiki.test.tokens \\\n","    --mlm \\\n","    --overwrite_output_dir"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-04-30 10:49:54.689178: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","04/30/2020 10:49:56 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","04/30/2020 10:49:56 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","04/30/2020 10:49:56 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:49:57 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","04/30/2020 10:49:58 - INFO - densray_bert -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","04/30/2020 10:50:06 - INFO - densray_bert -   Weights of BertForMaskedLM_1 not initialized from pretrained model: ['cls.predictions.decoder.bias']\n","04/30/2020 10:50:06 - INFO - densray_bert -   Weights from pretrained model not used in BertForMaskedLM_1: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","04/30/2020 10:50:06 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=False, eigvecs_dict={'0': ('/content/drive/My Drive/eigvecs_base_noavg_2000_0.pt', False), '1': ('/content/drive/My Drive/eigvecs_base_noavg_2000_1.pt', False), '2': ('/content/drive/My Drive/eigvecs_base_noavg_2000_2.pt', False), '3': ('/content/drive/My Drive/eigvecs_base_noavg_2000_3.pt', False), '4': ('/content/drive/My Drive/eigvecs_base_noavg_2000_4.pt', False), '5': ('/content/drive/My Drive/eigvecs_base_noavg_2000_5.pt', False), '6': ('/content/drive/My Drive/eigvecs_base_noavg_2000_6.pt', True), '7': ('/content/drive/My Drive/eigvecs_base_noavg_2000_7.pt', False), '8': ('/content/drive/My Drive/eigvecs_base_noavg_2000_8.pt', False), '9': ('/content/drive/My Drive/eigvecs_base_noavg_2000_9.pt', False), '10': ('/content/drive/My Drive/eigvecs_base_noavg_2000_10.pt', False), '11': ('/content/drive/My Drive/eigvecs_base_noavg_2000_11.pt', False)}, eval_all_checkpoints=False, eval_data_file='/content/wikitext-2/wiki.test.tokens', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='/content/wikitext-2/wiki.train.tokens', warmup_steps=0, weight_decay=0.0)\n","04/30/2020 10:50:06 - INFO - __main__ -   Evaluate the following checkpoints: ['output']\n","04/30/2020 10:50:06 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","04/30/2020 10:50:06 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:50:06 - INFO - densray_bert -   loading weights file output/pytorch_model.bin\n","04/30/2020 10:50:10 - INFO - __main__ -   ***** Running evaluation  *****\n","04/30/2020 10:50:10 - INFO - __main__ -     Num examples = 586\n","04/30/2020 10:50:10 - INFO - __main__ -     Batch size = 4\n","Evaluating: 100% 147/147 [00:13<00:00, 10.94it/s]\n","04/30/2020 10:50:24 - INFO - __main__ -   ***** Eval results  *****\n","04/30/2020 10:50:24 - INFO - __main__ -     perplexity = tensor(3.8655)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DOZLvBW1ssW8","colab_type":"code","outputId":"f9d6a2a6-4914-49fb-f4d9-957bf0ff16f7","executionInfo":{"status":"ok","timestamp":1588243858695,"user_tz":-120,"elapsed":66689,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python run_language_modeling_densray.py \\\n","    --output_dir=output \\\n","    --model_type=bert \\\n","    --model_name_or_path=bert-base-uncased \\\n","    --eigvecs_dict=/content/eigvecs_dict_7.txt \\\n","    --train_data_file=/content/wikitext-2/wiki.train.tokens \\\n","    --do_eval \\\n","    --eval_data_file=/content/wikitext-2/wiki.test.tokens \\\n","    --mlm \\\n","    --overwrite_output_dir"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-04-30 10:50:27.675082: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","04/30/2020 10:50:29 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","04/30/2020 10:50:29 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","04/30/2020 10:50:29 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:50:30 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","04/30/2020 10:50:31 - INFO - densray_bert -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","04/30/2020 10:50:39 - INFO - densray_bert -   Weights of BertForMaskedLM_1 not initialized from pretrained model: ['cls.predictions.decoder.bias']\n","04/30/2020 10:50:39 - INFO - densray_bert -   Weights from pretrained model not used in BertForMaskedLM_1: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","04/30/2020 10:50:39 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=False, eigvecs_dict={'0': ('/content/drive/My Drive/eigvecs_base_noavg_2000_0.pt', False), '1': ('/content/drive/My Drive/eigvecs_base_noavg_2000_1.pt', False), '2': ('/content/drive/My Drive/eigvecs_base_noavg_2000_2.pt', False), '3': ('/content/drive/My Drive/eigvecs_base_noavg_2000_3.pt', False), '4': ('/content/drive/My Drive/eigvecs_base_noavg_2000_4.pt', False), '5': ('/content/drive/My Drive/eigvecs_base_noavg_2000_5.pt', False), '6': ('/content/drive/My Drive/eigvecs_base_noavg_2000_6.pt', False), '7': ('/content/drive/My Drive/eigvecs_base_noavg_2000_7.pt', True), '8': ('/content/drive/My Drive/eigvecs_base_noavg_2000_8.pt', False), '9': ('/content/drive/My Drive/eigvecs_base_noavg_2000_9.pt', False), '10': ('/content/drive/My Drive/eigvecs_base_noavg_2000_10.pt', False), '11': ('/content/drive/My Drive/eigvecs_base_noavg_2000_11.pt', False)}, eval_all_checkpoints=False, eval_data_file='/content/wikitext-2/wiki.test.tokens', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='/content/wikitext-2/wiki.train.tokens', warmup_steps=0, weight_decay=0.0)\n","04/30/2020 10:50:39 - INFO - __main__ -   Evaluate the following checkpoints: ['output']\n","04/30/2020 10:50:39 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","04/30/2020 10:50:39 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:50:39 - INFO - densray_bert -   loading weights file output/pytorch_model.bin\n","04/30/2020 10:50:43 - INFO - __main__ -   ***** Running evaluation  *****\n","04/30/2020 10:50:43 - INFO - __main__ -     Num examples = 586\n","04/30/2020 10:50:43 - INFO - __main__ -     Batch size = 4\n","Evaluating: 100% 147/147 [00:13<00:00, 10.93it/s]\n","04/30/2020 10:50:57 - INFO - __main__ -   ***** Eval results  *****\n","04/30/2020 10:50:57 - INFO - __main__ -     perplexity = tensor(3.8361)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4cEFjnRostPv","colab_type":"code","outputId":"e67252b1-3053-4794-c746-422fff325749","executionInfo":{"status":"ok","timestamp":1588243891961,"user_tz":-120,"elapsed":99952,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python run_language_modeling_densray.py \\\n","    --output_dir=output \\\n","    --model_type=bert \\\n","    --model_name_or_path=bert-base-uncased \\\n","    --eigvecs_dict=/content/eigvecs_dict_8.txt \\\n","    --train_data_file=/content/wikitext-2/wiki.train.tokens \\\n","    --do_eval \\\n","    --eval_data_file=/content/wikitext-2/wiki.test.tokens \\\n","    --mlm \\\n","    --overwrite_output_dir"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-04-30 10:51:00.118073: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","04/30/2020 10:51:01 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","04/30/2020 10:51:02 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","04/30/2020 10:51:02 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:51:03 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","04/30/2020 10:51:03 - INFO - densray_bert -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","04/30/2020 10:51:11 - INFO - densray_bert -   Weights of BertForMaskedLM_1 not initialized from pretrained model: ['cls.predictions.decoder.bias']\n","04/30/2020 10:51:11 - INFO - densray_bert -   Weights from pretrained model not used in BertForMaskedLM_1: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","04/30/2020 10:51:11 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=False, eigvecs_dict={'0': ('/content/drive/My Drive/eigvecs_base_noavg_2000_0.pt', False), '1': ('/content/drive/My Drive/eigvecs_base_noavg_2000_1.pt', False), '2': ('/content/drive/My Drive/eigvecs_base_noavg_2000_2.pt', False), '3': ('/content/drive/My Drive/eigvecs_base_noavg_2000_3.pt', False), '4': ('/content/drive/My Drive/eigvecs_base_noavg_2000_4.pt', False), '5': ('/content/drive/My Drive/eigvecs_base_noavg_2000_5.pt', False), '6': ('/content/drive/My Drive/eigvecs_base_noavg_2000_6.pt', False), '7': ('/content/drive/My Drive/eigvecs_base_noavg_2000_7.pt', False), '8': ('/content/drive/My Drive/eigvecs_base_noavg_2000_8.pt', True), '9': ('/content/drive/My Drive/eigvecs_base_noavg_2000_9.pt', False), '10': ('/content/drive/My Drive/eigvecs_base_noavg_2000_10.pt', False), '11': ('/content/drive/My Drive/eigvecs_base_noavg_2000_11.pt', False)}, eval_all_checkpoints=False, eval_data_file='/content/wikitext-2/wiki.test.tokens', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='/content/wikitext-2/wiki.train.tokens', warmup_steps=0, weight_decay=0.0)\n","04/30/2020 10:51:11 - INFO - __main__ -   Evaluate the following checkpoints: ['output']\n","04/30/2020 10:51:11 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","04/30/2020 10:51:11 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:51:11 - INFO - densray_bert -   loading weights file output/pytorch_model.bin\n","04/30/2020 10:51:16 - INFO - __main__ -   ***** Running evaluation  *****\n","04/30/2020 10:51:16 - INFO - __main__ -     Num examples = 586\n","04/30/2020 10:51:16 - INFO - __main__ -     Batch size = 4\n","Evaluating: 100% 147/147 [00:13<00:00, 10.95it/s]\n","04/30/2020 10:51:29 - INFO - __main__ -   ***** Eval results  *****\n","04/30/2020 10:51:29 - INFO - __main__ -     perplexity = tensor(3.7869)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"B3O3QSuUsuGa","colab_type":"code","outputId":"dfcda4d5-0c40-4591-ce9e-18c585e1630e","executionInfo":{"status":"ok","timestamp":1588243924546,"user_tz":-120,"elapsed":132534,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python run_language_modeling_densray.py \\\n","    --output_dir=output \\\n","    --model_type=bert \\\n","    --model_name_or_path=bert-base-uncased \\\n","    --eigvecs_dict=/content/eigvecs_dict_9.txt \\\n","    --train_data_file=/content/wikitext-2/wiki.train.tokens \\\n","    --do_eval \\\n","    --eval_data_file=/content/wikitext-2/wiki.test.tokens \\\n","    --mlm \\\n","    --overwrite_output_dir"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-04-30 10:51:33.097771: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","04/30/2020 10:51:34 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","04/30/2020 10:51:35 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","04/30/2020 10:51:35 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:51:36 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","04/30/2020 10:51:36 - INFO - densray_bert -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","04/30/2020 10:51:44 - INFO - densray_bert -   Weights of BertForMaskedLM_1 not initialized from pretrained model: ['cls.predictions.decoder.bias']\n","04/30/2020 10:51:44 - INFO - densray_bert -   Weights from pretrained model not used in BertForMaskedLM_1: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","04/30/2020 10:51:44 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=False, eigvecs_dict={'0': ('/content/drive/My Drive/eigvecs_base_noavg_2000_0.pt', False), '1': ('/content/drive/My Drive/eigvecs_base_noavg_2000_1.pt', False), '2': ('/content/drive/My Drive/eigvecs_base_noavg_2000_2.pt', False), '3': ('/content/drive/My Drive/eigvecs_base_noavg_2000_3.pt', False), '4': ('/content/drive/My Drive/eigvecs_base_noavg_2000_4.pt', False), '5': ('/content/drive/My Drive/eigvecs_base_noavg_2000_5.pt', False), '6': ('/content/drive/My Drive/eigvecs_base_noavg_2000_6.pt', False), '7': ('/content/drive/My Drive/eigvecs_base_noavg_2000_7.pt', False), '8': ('/content/drive/My Drive/eigvecs_base_noavg_2000_8.pt', False), '9': ('/content/drive/My Drive/eigvecs_base_noavg_2000_9.pt', True), '10': ('/content/drive/My Drive/eigvecs_base_noavg_2000_10.pt', False), '11': ('/content/drive/My Drive/eigvecs_base_noavg_2000_11.pt', False)}, eval_all_checkpoints=False, eval_data_file='/content/wikitext-2/wiki.test.tokens', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='/content/wikitext-2/wiki.train.tokens', warmup_steps=0, weight_decay=0.0)\n","04/30/2020 10:51:44 - INFO - __main__ -   Evaluate the following checkpoints: ['output']\n","04/30/2020 10:51:44 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","04/30/2020 10:51:44 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:51:44 - INFO - densray_bert -   loading weights file output/pytorch_model.bin\n","04/30/2020 10:51:49 - INFO - __main__ -   ***** Running evaluation  *****\n","04/30/2020 10:51:49 - INFO - __main__ -     Num examples = 586\n","04/30/2020 10:51:49 - INFO - __main__ -     Batch size = 4\n","Evaluating: 100% 147/147 [00:13<00:00, 10.91it/s]\n","04/30/2020 10:52:02 - INFO - __main__ -   ***** Eval results  *****\n","04/30/2020 10:52:02 - INFO - __main__ -     perplexity = tensor(3.7765)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4zad5YoQsvA5","colab_type":"code","outputId":"5d995216-29d5-40ba-936c-999c0a2f0fa0","executionInfo":{"status":"ok","timestamp":1588243957205,"user_tz":-120,"elapsed":165188,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python run_language_modeling_densray.py \\\n","    --output_dir=output \\\n","    --model_type=bert \\\n","    --model_name_or_path=bert-base-uncased \\\n","    --eigvecs_dict=/content/eigvecs_dict_10.txt \\\n","    --train_data_file=/content/wikitext-2/wiki.train.tokens \\\n","    --do_eval \\\n","    --eval_data_file=/content/wikitext-2/wiki.test.tokens \\\n","    --mlm \\\n","    --overwrite_output_dir"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-04-30 10:52:06.149103: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","04/30/2020 10:52:07 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","04/30/2020 10:52:08 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","04/30/2020 10:52:08 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:52:09 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","04/30/2020 10:52:09 - INFO - densray_bert -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","04/30/2020 10:52:17 - INFO - densray_bert -   Weights of BertForMaskedLM_1 not initialized from pretrained model: ['cls.predictions.decoder.bias']\n","04/30/2020 10:52:17 - INFO - densray_bert -   Weights from pretrained model not used in BertForMaskedLM_1: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","04/30/2020 10:52:17 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=False, eigvecs_dict={'0': ('/content/drive/My Drive/eigvecs_base_noavg_2000_0.pt', False), '1': ('/content/drive/My Drive/eigvecs_base_noavg_2000_1.pt', False), '2': ('/content/drive/My Drive/eigvecs_base_noavg_2000_2.pt', False), '3': ('/content/drive/My Drive/eigvecs_base_noavg_2000_3.pt', False), '4': ('/content/drive/My Drive/eigvecs_base_noavg_2000_4.pt', False), '5': ('/content/drive/My Drive/eigvecs_base_noavg_2000_5.pt', False), '6': ('/content/drive/My Drive/eigvecs_base_noavg_2000_6.pt', False), '7': ('/content/drive/My Drive/eigvecs_base_noavg_2000_7.pt', False), '8': ('/content/drive/My Drive/eigvecs_base_noavg_2000_8.pt', False), '9': ('/content/drive/My Drive/eigvecs_base_noavg_2000_9.pt', False), '10': ('/content/drive/My Drive/eigvecs_base_noavg_2000_10.pt', True), '11': ('/content/drive/My Drive/eigvecs_base_noavg_2000_11.pt', False)}, eval_all_checkpoints=False, eval_data_file='/content/wikitext-2/wiki.test.tokens', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='/content/wikitext-2/wiki.train.tokens', warmup_steps=0, weight_decay=0.0)\n","04/30/2020 10:52:17 - INFO - __main__ -   Evaluate the following checkpoints: ['output']\n","04/30/2020 10:52:17 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","04/30/2020 10:52:17 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:52:17 - INFO - densray_bert -   loading weights file output/pytorch_model.bin\n","04/30/2020 10:52:22 - INFO - __main__ -   ***** Running evaluation  *****\n","04/30/2020 10:52:22 - INFO - __main__ -     Num examples = 586\n","04/30/2020 10:52:22 - INFO - __main__ -     Batch size = 4\n","Evaluating: 100% 147/147 [00:13<00:00, 10.89it/s]\n","04/30/2020 10:52:35 - INFO - __main__ -   ***** Eval results  *****\n","04/30/2020 10:52:35 - INFO - __main__ -     perplexity = tensor(3.7754)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ah3zIePisv7C","colab_type":"code","outputId":"977e4235-c324-4571-86e8-ea7964b77de3","executionInfo":{"status":"ok","timestamp":1588243990170,"user_tz":-120,"elapsed":198149,"user":{"displayName":"Liang Sheng","photoUrl":"","userId":"09714697225400851958"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python run_language_modeling_densray.py \\\n","    --output_dir=output \\\n","    --model_type=bert \\\n","    --model_name_or_path=bert-base-uncased \\\n","    --eigvecs_dict=/content/eigvecs_dict_11.txt \\\n","    --train_data_file=/content/wikitext-2/wiki.train.tokens \\\n","    --do_eval \\\n","    --eval_data_file=/content/wikitext-2/wiki.test.tokens \\\n","    --mlm \\\n","    --overwrite_output_dir"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-04-30 10:52:38.728511: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","04/30/2020 10:52:40 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","04/30/2020 10:52:40 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n","04/30/2020 10:52:40 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:52:41 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","04/30/2020 10:52:42 - INFO - densray_bert -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n","04/30/2020 10:52:50 - INFO - densray_bert -   Weights of BertForMaskedLM_1 not initialized from pretrained model: ['cls.predictions.decoder.bias']\n","04/30/2020 10:52:50 - INFO - densray_bert -   Weights from pretrained model not used in BertForMaskedLM_1: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","04/30/2020 10:52:50 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=False, eigvecs_dict={'0': ('/content/drive/My Drive/eigvecs_base_noavg_2000_0.pt', False), '1': ('/content/drive/My Drive/eigvecs_base_noavg_2000_1.pt', False), '2': ('/content/drive/My Drive/eigvecs_base_noavg_2000_2.pt', False), '3': ('/content/drive/My Drive/eigvecs_base_noavg_2000_3.pt', False), '4': ('/content/drive/My Drive/eigvecs_base_noavg_2000_4.pt', False), '5': ('/content/drive/My Drive/eigvecs_base_noavg_2000_5.pt', False), '6': ('/content/drive/My Drive/eigvecs_base_noavg_2000_6.pt', False), '7': ('/content/drive/My Drive/eigvecs_base_noavg_2000_7.pt', False), '8': ('/content/drive/My Drive/eigvecs_base_noavg_2000_8.pt', False), '9': ('/content/drive/My Drive/eigvecs_base_noavg_2000_9.pt', False), '10': ('/content/drive/My Drive/eigvecs_base_noavg_2000_10.pt', False), '11': ('/content/drive/My Drive/eigvecs_base_noavg_2000_11.pt', True)}, eval_all_checkpoints=False, eval_data_file='/content/wikitext-2/wiki.test.tokens', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='/content/wikitext-2/wiki.train.tokens', warmup_steps=0, weight_decay=0.0)\n","04/30/2020 10:52:50 - INFO - __main__ -   Evaluate the following checkpoints: ['output']\n","04/30/2020 10:52:50 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","04/30/2020 10:52:50 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"_num_labels\": 2,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","04/30/2020 10:52:50 - INFO - densray_bert -   loading weights file output/pytorch_model.bin\n","04/30/2020 10:52:54 - INFO - __main__ -   ***** Running evaluation  *****\n","04/30/2020 10:52:54 - INFO - __main__ -     Num examples = 586\n","04/30/2020 10:52:54 - INFO - __main__ -     Batch size = 4\n","Evaluating: 100% 147/147 [00:13<00:00, 10.92it/s]\n","04/30/2020 10:53:08 - INFO - __main__ -   ***** Eval results  *****\n","04/30/2020 10:53:08 - INFO - __main__ -     perplexity = tensor(3.7796)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-VRdYR3RsxSS","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}