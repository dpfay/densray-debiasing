In our opinion, debiasing involves two distinct
problems. First, how can bias be removed from the underlying
model? Second, how does bias manifest in a particular
language? The removal of bias from the underlying model can
be argued to be largely independent of the language whereas
the way bias manifests is highly language-dependent. For
example, Chinese does not mark gender and most French nouns
describing people are gender-specific. So on the surface,
Chinese sentences are gender-neutral and French sentences
cannot be gender-neutral (at least if wordy phrases like
... and
newer constructions like ... are to be avoided). However,
these particularities of surface form of individual
languages do not change the underlying problem of biased
language models: Chinese and French language models are
still biased and should be debiased to avoid unfair and
biased impact caused by deployed NLP systems.
